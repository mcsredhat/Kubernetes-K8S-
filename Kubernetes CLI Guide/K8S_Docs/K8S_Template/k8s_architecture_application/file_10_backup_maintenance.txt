# ============================================================================
# 10-backup-maintenance-enhanced.yaml - INTEGRATED Backup & Rollback
# ============================================================================
# Purpose: Automated backup with comprehensive rollback - FULLY INTEGRATED
# Dependencies: Uses {{APP_NAME}}-sa with enhanced RBAC from 04-rbac-enhanced.yaml
# ============================================================================

# Volume Snapshot Class
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: {{APP_NAME}}-snapshot-class
  labels:
    app: {{APP_NAME}}
    app.kubernetes.io/component: backup
driver: ebs.csi.aws.com  # Change to your CSI driver
deletionPolicy: Retain
parameters:
  encrypted: "true"

---
# ConfigMap for Backup Registry
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{APP_NAME}}-backup-registry
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    app.kubernetes.io/component: backup
data:
  last-successful-backup: ""
  backup-count: "0"
  last-restore: ""
  backup-schedule: "0 2 * * *"  # Daily at 2 AM

---
# Backup Storage PVC (integrates with 02-storage.yaml)
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: {{APP_NAME}}-backup-pvc
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    app.kubernetes.io/component: backup-storage
    app.kubernetes.io/part-of: {{APP_NAME}}
  annotations:
    description: "Persistent storage for {{APP_NAME}} backups"
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: {{STORAGE_CLASS}}-aws
  resources:
    requests:
      storage: {{BACKUP_STORAGE_SIZE:=100Gi}}

---
# Enhanced Backup CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: {{APP_NAME}}-backup
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    app.kubernetes.io/component: backup
  annotations:
    description: "Automated daily backup with integrity verification"
spec:
  schedule: "{{BACKUP_SCHEDULE:=0 2 * * *}}"
  timeZone: "UTC"
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  concurrencyPolicy: Forbid
  startingDeadlineSeconds: 3600
  jobTemplate:
    spec:
      activeDeadlineSeconds: 3600
      backoffLimit: 2
      template:
        metadata:
          labels:
            app: {{APP_NAME}}-backup
            app.kubernetes.io/component: backup
        spec:
          restartPolicy: OnFailure
          serviceAccountName: {{APP_NAME}}-sa
          securityContext:
            runAsNonRoot: true
            runAsUser: 65534
            fsGroup: 65534
          containers:
          - name: backup
            image: bitnami/kubectl:latest
            command:
            - /bin/bash
            - -c
            - |
              set -e
              
              BACKUP_DATE=$(date +%Y%m%d_%H%M%S)
              BACKUP_DIR="/backup/${BACKUP_DATE}"
              
              echo "=== {{APP_NAME}} Backup Started at $(date -Iseconds) ==="
              mkdir -p "${BACKUP_DIR}"
              
              # Backup application data
              if [ -d "/data" ] && [ "$(ls -A /data)" ]; then
                tar -czf "${BACKUP_DIR}/app-data.tar.gz" -C /data .
                echo "‚úì Data backup: $(ls -lh ${BACKUP_DIR}/app-data.tar.gz | awk '{print $5}')"
              else
                echo "‚ö† No data to backup"
                touch "${BACKUP_DIR}/no-data-found"
              fi
              
              # Get deployment info for restore
              REPLICAS=$(kubectl get deployment {{APP_NAME}}-deployment -n {{NAMESPACE}} -o jsonpath='{.spec.replicas}' 2>/dev/null || echo '3')
              
              # Create metadata
              cat > "${BACKUP_DIR}/backup-info.json" << EOF
              {
                "app": "{{APP_NAME}}",
                "environment": "{{ENVIRONMENT}}",
                "namespace": "{{NAMESPACE}}", 
                "backup_date": "${BACKUP_DATE}",
                "backup_timestamp": "$(date -Iseconds)",
                "backup_type": "automated",
                "deployment_replicas": "${REPLICAS}",
                "storage_size": "{{STORAGE_SIZE}}",
                "files": ["app-data.tar.gz"],
                "status": "completed"
              }
              EOF
              
              # Checksums
              cd "${BACKUP_DIR}"
              if [ -f "app-data.tar.gz" ]; then
                sha256sum app-data.tar.gz > checksums.sha256
                echo "‚úì Integrity checksums created"
              fi
              
              # Update registry
              kubectl patch configmap {{APP_NAME}}-backup-registry -n {{NAMESPACE}} \
                --type merge -p "{\"data\":{\"last-successful-backup\":\"${BACKUP_DATE}\"}}" || true
              
              # Cleanup old backups (keep {{BACKUP_RETENTION_DAYS:=7}} days)
              find /backup -name "20*" -type d -mtime +{{BACKUP_RETENTION_DAYS:=7}} -exec rm -rf {} + 2>/dev/null || true
              
              echo "=== Backup Summary ==="
              echo "Size: $(du -sh ${BACKUP_DIR} | cut -f1)"
              echo "Location: ${BACKUP_DIR}"
              echo "‚úì Backup completed at $(date -Iseconds)"
            
            volumeMounts:
            - name: app-data
              mountPath: /data
              readOnly: true
            - name: backup-storage
              mountPath: /backup
            
            resources:
              requests:
                memory: "128Mi"
                cpu: "100m"
              limits:
                memory: "512Mi"
                cpu: "500m"
          
          volumes:
          - name: app-data
            persistentVolumeClaim:
              claimName: {{APP_NAME}}-data-pvc
          - name: backup-storage
            persistentVolumeClaim:
              claimName: {{APP_NAME}}-backup-pvc

---
# AUTOMATED ROLLBACK JOB - One-Click Restoration
apiVersion: batch/v1
kind: Job
metadata:
  name: {{APP_NAME}}-rollback
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    app.kubernetes.io/component: rollback
  annotations:
    description: "One-click rollback to last known good backup"
    usage: "kubectl create -f this-section.yaml"
spec:
  activeDeadlineSeconds: 3600
  backoffLimit: 1
  template:
    metadata:
      labels:
        app: {{APP_NAME}}-rollback
    spec:
      restartPolicy: Never
      serviceAccountName: {{APP_NAME}}-sa
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        fsGroup: 65534
      initContainers:
      - name: pre-rollback-check
        image: busybox:1.36
        command:
        - /bin/sh
        - -c
        - |
          echo "=== Pre-Rollback Validation ==="
          
          LATEST_BACKUP=$(ls -t /backup | grep "^20" | head -n 1)
          
          if [ -z "$LATEST_BACKUP" ]; then
            echo "‚ùå ERROR: No backup found!"
            exit 1
          fi
          
          echo "‚úì Latest backup: $LATEST_BACKUP"
          
          # Verify integrity
          if [ -f "/backup/$LATEST_BACKUP/checksums.sha256" ]; then
            cd /backup/$LATEST_BACKUP
            if sha256sum -c checksums.sha256; then
              echo "‚úì Backup integrity verified"
            else
              echo "‚ùå Checksum verification failed!"
              exit 1
            fi
          fi
          
          echo "$LATEST_BACKUP" > /shared/backup-to-restore
          echo "‚úì Pre-rollback checks passed"
        volumeMounts:
        - name: backup-storage
          mountPath: /backup
          readOnly: true
        - name: shared
          mountPath: /shared
      
      containers:
      - name: rollback
        image: bitnami/kubectl:latest
        command:
        - /bin/bash
        - -c
        - |
          set -e
          
          echo "=========================================="
          echo "  AUTOMATED ROLLBACK PROCEDURE"
          echo "=========================================="
          echo "Application: {{APP_NAME}}"
          echo "Namespace: {{NAMESPACE}}"
          echo "Timestamp: $(date -Iseconds)"
          echo ""
          
          BACKUP_TO_RESTORE=$(cat /shared/backup-to-restore)
          echo "üì¶ Using backup: $BACKUP_TO_RESTORE"
          echo ""
          
          # Step 1: Scale down
          echo "Step 1: Scaling down application..."
          ORIGINAL_REPLICAS=$(kubectl get deployment {{APP_NAME}}-deployment -n {{NAMESPACE}} -o jsonpath='{.spec.replicas}')
          echo "  Current replicas: $ORIGINAL_REPLICAS"
          
          kubectl scale deployment {{APP_NAME}}-deployment --replicas=0 -n {{NAMESPACE}}
          kubectl wait --for=delete pod -l app={{APP_NAME}} -n {{NAMESPACE}} --timeout=300s || true
          sleep 10
          echo "  ‚úì Application stopped"
          echo ""
          
          # Step 2: Safety backup
          echo "Step 2: Creating safety backup..."
          SAFETY_BACKUP="/backup/pre-rollback-$(date +%Y%m%d_%H%M%S)"
          mkdir -p "$SAFETY_BACKUP"
          
          if [ -d "/data" ] && [ "$(ls -A /data 2>/dev/null)" ]; then
            tar -czf "$SAFETY_BACKUP/current-state.tar.gz" -C /data . 2>/dev/null || true
            echo "  ‚úì Safety backup: $SAFETY_BACKUP"
          fi
          echo ""
          
          # Step 3: Clear data
          echo "Step 3: Clearing current data..."
          rm -rf /data/* /data/.* 2>/dev/null || true
          echo "  ‚úì Data cleared"
          echo ""
          
          # Step 4: Restore
          echo "Step 4: Restoring from backup..."
          cd /data
          
          if [ -f "/backup/$BACKUP_TO_RESTORE/app-data.tar.gz" ]; then
            tar -xzf "/backup/$BACKUP_TO_RESTORE/app-data.tar.gz"
            echo "  ‚úì Data restored"
            echo "  Restored size: $(du -sh /data | cut -f1)"
          else
            echo "  ‚ùå Backup file not found!"
            exit 1
          fi
          echo ""
          
          # Step 5: Scale up
          echo "Step 5: Scaling up application..."
          kubectl scale deployment {{APP_NAME}}-deployment --replicas=$ORIGINAL_REPLICAS -n {{NAMESPACE}}
          
          echo "  Waiting for deployment..."
          kubectl wait --for=condition=available --timeout=300s \
            deployment/{{APP_NAME}}-deployment -n {{NAMESPACE}} || true
          echo ""
          
          # Step 6: Health check
          echo "Step 6: Health check..."
          sleep 10
          
          READY_PODS=$(kubectl get pods -n {{NAMESPACE}} -l app={{APP_NAME}} \
            -o jsonpath='{.items[?(@.status.phase=="Running")].metadata.name}' | wc -w)
          
          echo "  Ready pods: $READY_PODS / $ORIGINAL_REPLICAS"
          echo ""
          
          # Update registry
          kubectl patch configmap {{APP_NAME}}-backup-registry -n {{NAMESPACE}} \
            --type merge -p "{\"data\":{\"last-restore\":\"$(date -Iseconds)\",\"restored-from\":\"$BACKUP_TO_RESTORE\"}}" || true
          
          echo "=========================================="
          echo "  ‚úì ROLLBACK COMPLETED"
          echo "=========================================="
          echo "Restored from: $BACKUP_TO_RESTORE"
          echo "Application: Running ($READY_PODS pods)"
          echo "Safety backup: $SAFETY_BACKUP"
          echo "=========================================="
        
        volumeMounts:
        - name: app-data
          mountPath: /data
        - name: backup-storage
          mountPath: /backup
          readOnly: true
        - name: shared
          mountPath: /shared
          readOnly: true
        
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "500m"
      
      volumes:
      - name: app-data
        persistentVolumeClaim:
          claimName: {{APP_NAME}}-data-pvc
      - name: backup-storage
        persistentVolumeClaim:
          claimName: {{APP_NAME}}-backup-pvc
      - name: shared
        emptyDir: {}

---
# POINT-IN-TIME RESTORE Job
apiVersion: batch/v1
kind: Job
metadata:
  name: {{APP_NAME}}-restore-specific
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    app.kubernetes.io/component: restore
  annotations:
    description: "Restore from specific backup date"
    usage: "Set BACKUP_DATE env var: kubectl set env job/{{APP_NAME}}-restore-specific BACKUP_DATE=20250102_020000"
spec:
  activeDeadlineSeconds: 3600
  backoffLimit: 1
  template:
    spec:
      restartPolicy: Never
      serviceAccountName: {{APP_NAME}}-sa
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        fsGroup: 65534
      containers:
      - name: restore-specific
        image: bitnami/kubectl:latest
        env:
        - name: BACKUP_DATE
          value: "SPECIFY_BACKUP_DATE"  # Format: 20250102_020000
        command:
        - /bin/bash
        - -c
        - |
          set -e
          
          if [ "$BACKUP_DATE" = "SPECIFY_BACKUP_DATE" ]; then
            echo "‚ùå ERROR: BACKUP_DATE not set!"
            echo "Available backups:"
            ls -lt /backup | grep "^d" | head -n 10
            exit 1
          fi
          
          echo "=== Point-in-Time Restore: $BACKUP_DATE ==="
          
          if [ ! -d "/backup/$BACKUP_DATE" ]; then
            echo "‚ùå Backup not found!"
            ls -lt /backup | grep "^d" | head -n 10
            exit 1
          fi
          
          # Verify integrity
          cd /backup/$BACKUP_DATE
          sha256sum -c checksums.sha256 || exit 1
          echo "‚úì Integrity verified"
          
          # Scale down
          REPLICAS=$(kubectl get deployment {{APP_NAME}}-deployment -n {{NAMESPACE}} -o jsonpath='{.spec.replicas}')
          kubectl scale deployment {{APP_NAME}}-deployment --replicas=0 -n {{NAMESPACE}}
          kubectl wait --for=delete pod -l app={{APP_NAME}} -n {{NAMESPACE}} --timeout=300s || true
          
          # Restore
          rm -rf /data/* /data/.* 2>/dev/null || true
          cd /data
          tar -xzf /backup/$BACKUP_DATE/app-data.tar.gz
          echo "‚úì Data restored"
          
          # Scale up
          kubectl scale deployment {{APP_NAME}}-deployment --replicas=$REPLICAS -n {{NAMESPACE}}
          
          echo "‚úì Restore from $BACKUP_DATE completed!"
        
        volumeMounts:
        - name: app-data
          mountPath: /data
        - name: backup-storage
          mountPath: /backup
          readOnly: true
        
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "500m"

      volumes:
      - name: app-data
        persistentVolumeClaim:
          claimName: {{APP_NAME}}-data-pvc
      - name: backup-storage
        persistentVolumeClaim:
          claimName: {{APP_NAME}}-backup-pvc

---
# Volume Snapshot CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: {{APP_NAME}}-snapshot
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    app.kubernetes.io/component: backup
spec:
  schedule: "{{SNAPSHOT_SCHEDULE:=0 1 * * 0}}"  # Weekly Sunday 1 AM
  timeZone: "UTC"
  successfulJobsHistoryLimit: 2
  failedJobsHistoryLimit: 1
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      activeDeadlineSeconds: 1800
      template:
        spec:
          restartPolicy: OnFailure
          serviceAccountName: {{APP_NAME}}-sa
          containers:
          - name: snapshot-creator
            image: bitnami/kubectl:latest
            command:
            - /bin/bash
            - -c
            - |
              SNAPSHOT_NAME="{{APP_NAME}}-auto-$(date +%Y%m%d-%H%M%S)"
              
              cat <<EOF | kubectl apply -f -
              apiVersion: snapshot.storage.k8s.io/v1
              kind: VolumeSnapshot
              metadata:
                name: ${SNAPSHOT_NAME}
                namespace: {{NAMESPACE}}
                labels:
                  app: {{APP_NAME}}
                  backup-type: automated
                annotations:
                  created-by: "snapshot-cronjob"
                  backup-date: "$(date -Iseconds)"
              spec:
                volumeSnapshotClassName: {{APP_NAME}}-snapshot-class
                source:
                  persistentVolumeClaimName: {{APP_NAME}}-data-pvc
              EOF
              
              echo "‚úì Created snapshot: ${SNAPSHOT_NAME}"
              
              # Cleanup old snapshots (keep {{SNAPSHOT_RETENTION:=4}})
              kubectl get volumesnapshots -n {{NAMESPACE}} \
                -l backup-type=automated \
                --sort-by=.metadata.creationTimestamp \
                -o name | head -n -{{SNAPSHOT_RETENTION:=4}} | xargs -r kubectl delete -n {{NAMESPACE}} || true
            resources:
              requests:
                memory: "64Mi"
                cpu: "50m"
              limits:
                memory: "128Mi"
                cpu: "100m"