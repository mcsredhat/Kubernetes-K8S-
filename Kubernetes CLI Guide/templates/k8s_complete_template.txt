# ============================================================================
# KUBERNETES COMPLETE APPLICATION TEMPLATE
# ============================================================================
# This template provides a production-ready Kubernetes application deployment
# with comprehensive monitoring, security, and operational features.
#
# TEMPLATE VARIABLES - Replace these throughout the file:
# {{APP_NAME}} - Name of your application (e.g., "web-server", "api-service")
# {{NAMESPACE}} - Kubernetes namespace (e.g., "production", "staging", "web-app")
# {{DOMAIN}} - Your domain name (e.g., "myapp.example.com")
# {{ENVIRONMENT}} - Environment type (e.g., "production", "staging", "development")
# {{STORAGE_SIZE}} - Storage size for PVC (e.g., "10Gi", "50Gi")
# {{REPLICAS}} - Number of replicas (e.g., 3, 5)
# {{IMAGE}} - Container image (e.g., "nginx:1.25-alpine", "myapp:v1.0.0")
# {{TEAM}} - Team responsible (e.g., "frontend", "backend", "platform")
# {{STORAGE_CLASS}} - StorageClass name (e.g., "fast-ssd", "gp3-encrypted")
# ============================================================================

# ============================================================================
# 01-namespace.yaml
# ============================================================================
apiVersion: v1
kind: Namespace
metadata:
  name: {{NAMESPACE}}
  labels:
    name: {{NAMESPACE}}
    environment: {{ENVIRONMENT}}
    team: {{TEAM}}
    # Pod Security Standards - Enforces security policies at namespace level
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted  
    pod-security.kubernetes.io/warn: restricted
  annotations:
    description: "Namespace for {{APP_NAME}} application"
    contact: "{{TEAM}}@company.com"
spec:
  finalizers: ["kubernetes"]

---
# ============================================================================
# 02-resource-quota.yaml
# ============================================================================
# ResourceQuota prevents any single namespace from consuming too many cluster resources
# Think of it as setting spending limits on a credit card
apiVersion: v1
kind: ResourceQuota
metadata:
  name: {{NAMESPACE}}-quota
  namespace: {{NAMESPACE}}
  labels:
    component: resource-management
spec:
  hard:
    # Compute resources
    requests.cpu: "4000m"      # Total CPU requests cannot exceed 4 cores
    requests.memory: "8Gi"     # Total memory requests cannot exceed 8GB
    limits.cpu: "8000m"        # Total CPU limits cannot exceed 8 cores  
    limits.memory: "16Gi"      # Total memory limits cannot exceed 16GB
    
    # Storage resources
    requests.storage: "100Gi"  # Total storage requests cannot exceed 100GB
    persistentvolumeclaims: "10"  # Maximum 10 PVCs in this namespace
    
    # Object count limits
    pods: "20"                 # Maximum 20 pods
    services: "10"             # Maximum 10 services
    secrets: "20"              # Maximum 20 secrets
    configmaps: "20"           # Maximum 20 configmaps
    
---
# ============================================================================
# 03-storage-class.yaml - Choose ONE based on your environment
# ============================================================================
# DEVELOPMENT ENVIRONMENT - Local storage (fast but not persistent across nodes)
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: {{STORAGE_CLASS}}-local
  annotations:
    storageclass.kubernetes.io/is-default-class: "false"
provisioner: kubernetes.io/no-provisioner  # Manual provisioning required
parameters:
  type: local
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
allowVolumeExpansion: false

---
# AWS PRODUCTION ENVIRONMENT - EBS volumes with encryption
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: {{STORAGE_CLASS}}-aws
  annotations:
    storageclass.kubernetes.io/is-default-class: "false"
provisioner: ebs.csi.aws.com  # Modern CSI driver (not legacy kubernetes.io/aws-ebs)
parameters:
  type: gp3                    # Latest generation general purpose SSD
  iops: "3000"                # Provisioned IOPS for consistent performance
  throughput: "125"           # MB/s throughput
  fsType: ext4                # Filesystem type
  encrypted: "true"           # Encryption at rest
  kmsKeyId: alias/ebs-encryption-key  # Your KMS key for encryption
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
allowVolumeExpansion: true
mountOptions:
  - noatime                   # Don't update access times - improves performance

---
# GCP PRODUCTION ENVIRONMENT - Persistent Disk with encryption
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: {{STORAGE_CLASS}}-gcp
  annotations:
    storageclass.kubernetes.io/is-default-class: "false"
provisioner: pd.csi.storage.gke.io  # GCP CSI driver
parameters:
  type: pd-ssd                # SSD persistent disk
  replication-type: regional-pd  # Regional replication for high availability
  disk-encryption-kms-key: projects/{{PROJECT_ID}}/locations/{{REGION}}/keyRings/{{KEYRING}}/cryptoKeys/{{KEY}}
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
allowVolumeExpansion: true

---
# ============================================================================
# 04-persistent-volume-claim.yaml
# ============================================================================
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: {{APP_NAME}}-data-pvc
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: storage
    environment: {{ENVIRONMENT}}
  annotations:
    # Volume snapshot class for backup
    snapshot.storage.kubernetes.io/snapshot-class: "{{APP_NAME}}-snapshot-class"
spec:
  accessModes:
    - ReadWriteOnce           # Single pod read-write access
  storageClassName: {{STORAGE_CLASS}}-aws  # Choose the appropriate StorageClass
  resources:
    requests:
      storage: {{STORAGE_SIZE}}
  # Optional: Snapshot as data source for restoring from backup
  dataSource:
    name: {{APP_NAME}}-snapshot
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io

---
# ============================================================================
# 05-configmap.yaml - Application Configuration
# ============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{APP_NAME}}-config
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: configuration
    environment: {{ENVIRONMENT}}
data:
  # Environment-specific variables
  environment: {{ENVIRONMENT}}
  app_name: {{APP_NAME}}
  domain: {{DOMAIN}}
  
  # Application configuration
  server_port: "8080"
  log_level: "info"
  max_connections: "1000"
  worker_processes: "auto"
  
  # Nginx configuration with production-ready settings
  nginx.conf: |
    upstream backend {
        # Backend service endpoint - replace with your actual backend
        server {{APP_NAME}}-backend:8080 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }
    
    # Rate limiting zones
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=1r/s;
    
    server {
        listen 8080;
        server_name {{DOMAIN}};
        root /usr/share/nginx/html;
        index index.html index.htm;
        
        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;
        add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'; img-src 'self' data:;" always;
        
        # Compression
        gzip on;
        gzip_vary on;
        gzip_min_length 1024;
        gzip_types
            text/plain
            text/css
            text/xml
            text/javascript
            application/javascript
            application/xml+rss
            application/json
            application/xml
            image/svg+xml;
        
        # Logging with structured format
        log_format json_combined escape=json
            '{'
                '"time":"$time_iso8601",'
                '"remote_addr":"$remote_addr",'
                '"request":"$request",'
                '"status":"$status",'
                '"body_bytes_sent":"$body_bytes_sent",'
                '"request_time":"$request_time",'
                '"http_user_agent":"$http_user_agent",'
                '"http_referer":"$http_referer"'
            '}';
        
        access_log /var/log/nginx/access.log json_combined;
        error_log /var/log/nginx/error.log warn;
        
        # Health checks
        location /health {
            access_log off;
            return 200 '{"status":"healthy","timestamp":"$time_iso8601"}';
            add_header Content-Type application/json;
        }
        
        location /ready {
            access_log off;
            return 200 '{"status":"ready","timestamp":"$time_iso8601"}';
            add_header Content-Type application/json;
        }
        
        # Metrics for monitoring
        location /metrics {
            access_log off;
            stub_status on;
            allow 10.0.0.0/8;
            allow 172.16.0.0/12;
            allow 192.168.0.0/16;
            deny all;
        }
        
        # API routes with rate limiting
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            
            proxy_pass http://backend/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Timeout settings
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
            
            # Buffer settings for better performance
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
        }
        
        # Static files with aggressive caching
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            add_header Vary "Accept-Encoding";
            try_files $uri =404;
        }
        
        # Default location
        location / {
            try_files $uri $uri/ /index.html;
            expires 1h;
            add_header Cache-Control "public, no-cache";
        }
    }

  # Default application page with monitoring info
  index.html: |
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{{APP_NAME}} - {{ENVIRONMENT}}</title>
        <style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
                margin: 0;
                padding: 0;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                min-height: 100vh;
                display: flex;
                align-items: center;
                justify-content: center;
            }
            .container {
                max-width: 1000px;
                width: 90%;
                background: rgba(255, 255, 255, 0.1);
                padding: 40px;
                border-radius: 20px;
                backdrop-filter: blur(20px);
                box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
                border: 1px solid rgba(255, 255, 255, 0.2);
            }
            h1 {
                text-align: center;
                margin-bottom: 40px;
                font-size: 3rem;
                text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
                font-weight: 300;
            }
            .grid {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
                gap: 30px;
                margin: 40px 0;
            }
            .card {
                background: rgba(255, 255, 255, 0.1);
                padding: 25px;
                border-radius: 15px;
                border: 1px solid rgba(255, 255, 255, 0.2);
                transition: transform 0.3s ease;
            }
            .card:hover {
                transform: translateY(-5px);
            }
            .card h3 {
                margin-top: 0;
                color: #ffd700;
                font-size: 1.4rem;
            }
            .status-badge {
                display: inline-block;
                padding: 8px 16px;
                border-radius: 25px;
                background: #28a745;
                color: white;
                font-weight: 600;
                font-size: 0.9rem;
            }
            .info-list {
                list-style: none;
                padding: 0;
            }
            .info-list li {
                margin: 12px 0;
                padding: 12px;
                background: rgba(255, 255, 255, 0.1);
                border-radius: 8px;
                border-left: 4px solid #ffd700;
            }
            .links {
                text-align: center;
                margin-top: 40px;
            }
            .btn {
                display: inline-block;
                margin: 10px;
                padding: 12px 24px;
                background: rgba(255, 255, 255, 0.2);
                color: white;
                text-decoration: none;
                border-radius: 30px;
                border: 2px solid rgba(255, 255, 255, 0.3);
                transition: all 0.3s ease;
                font-weight: 500;
            }
            .btn:hover {
                background: rgba(255, 255, 255, 0.3);
                transform: translateY(-2px);
                box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
            }
            .metrics {
                font-family: monospace;
                font-size: 0.9rem;
            }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>{{APP_NAME}}</h1>
            
            <div class="grid">
                <div class="card">
                    <h3>System Status</h3>
                    <p><span class="status-badge">RUNNING</span></p>
                    <ul class="info-list">
                        <li><strong>Environment:</strong> {{ENVIRONMENT}}</li>
                        <li><strong>Namespace:</strong> {{NAMESPACE}}</li>
                        <li><strong>Domain:</strong> {{DOMAIN}}</li>
                        <li><strong>Started:</strong> <span id="timestamp"></span></li>
                    </ul>
                </div>
                
                <div class="card">
                    <h3>Storage & Volumes</h3>
                    <ul class="info-list">
                        <li><strong>ConfigMap:</strong> /etc/nginx/conf.d</li>
                        <li><strong>PVC:</strong> /usr/share/nginx/html ({{STORAGE_SIZE}})</li>
                        <li><strong>EmptyDir:</strong> /tmp (Memory)</li>
                        <li><strong>Logs:</strong> /var/log/nginx</li>
                    </ul>
                </div>
                
                <div class="card">
                    <h3>Monitoring & Health</h3>
                    <ul class="info-list">
                        <li><strong>Prometheus:</strong> Enabled</li>
                        <li><strong>Grafana:</strong> Dashboard Available</li>
                        <li><strong>Alerting:</strong> Configured</li>
                        <li><strong>Tracing:</strong> Jaeger Integration</li>
                    </ul>
                </div>
            </div>
            
            <div class="links">
                <a href="/health" class="btn">Health Check</a>
                <a href="/ready" class="btn">Readiness</a>
                <a href="/metrics" class="btn">Metrics</a>
                <a href="http://grafana.{{DOMAIN}}" class="btn" target="_blank">Grafana Dashboard</a>
            </div>
        </div>
        
        <script>
            document.getElementById('timestamp').textContent = new Date().toLocaleString();
            
            // Simple health monitoring
            setInterval(() => {
                fetch('/health')
                    .then(response => response.json())
                    .then(data => console.log('Health check:', data))
                    .catch(error => console.error('Health check failed:', error));
            }, 30000);
        </script>
    </body>
    </html>

---
# ============================================================================
# 06-secret.yaml - Sensitive Configuration
# ============================================================================
apiVersion: v1
kind: Secret
metadata:
  name: {{APP_NAME}}-secret
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: credentials
    environment: {{ENVIRONMENT}}
  annotations:
    # External secret management - uncomment if using external secrets
    # external-secrets.io/backend: vault
    # external-secrets.io/key: {{APP_NAME}}/credentials
type: Opaque
data:
  # Replace these with your actual base64-encoded values
  # Use: echo -n "your-value" | base64
  database-username: YWRtaW4=  # admin
  database-password: cGFzc3dvcmQxMjM=  # password123
  api-key: YWJjZGVmZ2hpams=  # abcdefghijk
  jwt-secret: c3VwZXItc2VjcmV0LWp3dC1rZXk=  # super-secret-jwt-key
stringData:
  # Plain text values (automatically base64 encoded)
  database-url: "postgresql://{{APP_NAME}}:password@postgres:5432/{{APP_NAME}}"
  redis-url: "redis://redis:6379/0"
  encryption-key: "change-this-32-character-key-in-production"

---
# ============================================================================
# 07-service-account.yaml - RBAC Configuration  
# ============================================================================
apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{APP_NAME}}-sa
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: rbac
    environment: {{ENVIRONMENT}}
  annotations:
    description: "Service account for {{APP_NAME}} with minimal required permissions"
automountServiceAccountToken: true

---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: {{NAMESPACE}}
  name: {{APP_NAME}}-role
  labels:
    app: {{APP_NAME}}
    component: rbac
rules:
# Configuration access
- apiGroups: [""]
  resources: ["configmaps", "secrets"]
  verbs: ["get", "list", "watch"]
# Event logging
- apiGroups: [""]
  resources: ["events"]
  verbs: ["create"]
# Pod information access
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]
# Service discovery
- apiGroups: [""]
  resources: ["services", "endpoints"]
  verbs: ["get", "list"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: {{APP_NAME}}-binding
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: rbac
subjects:
- kind: ServiceAccount
  name: {{APP_NAME}}-sa
  namespace: {{NAMESPACE}}
roleRef:
  kind: Role
  name: {{APP_NAME}}-role
  apiGroup: rbac.authorization.k8s.io

---
# ============================================================================
# 08-deployment.yaml - Main Application
# ============================================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{APP_NAME}}-deployment
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    version: v1.0
    environment: {{ENVIRONMENT}}
    component: application
  annotations:
    description: "Main {{APP_NAME}} deployment"
    deployment.kubernetes.io/revision: "1"
spec:
  replicas: {{REPLICAS}}
  revisionHistoryLimit: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 25%
      maxSurge: 25%
  selector:
    matchLabels:
      app: {{APP_NAME}}
      version: v1.0
  template:
    metadata:
      labels:
        app: {{APP_NAME}}
        version: v1.0
        environment: {{ENVIRONMENT}}
      annotations:
        # Prometheus monitoring
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
        # Restart policy
        kubectl.kubernetes.io/restartedAt: ""
    spec:
      serviceAccountName: {{APP_NAME}}-sa
      
      # Security context
      securityContext:
        runAsUser: 101
        runAsGroup: 101
        runAsNonRoot: true
        fsGroup: 101
        seccompProfile:
          type: RuntimeDefault
      
      # Init container for setup
      initContainers:
      - name: setup
        image: busybox:1.36
        command: ['sh', '-c']
        args:
        - |
          echo "Initializing {{APP_NAME}}..."
          echo "Environment: {{ENVIRONMENT}}"
          echo "Namespace: {{NAMESPACE}}"
          
          # Create necessary directories
          mkdir -p /app-data/logs /app-data/cache /app-data/uploads
          
          # Copy configuration files
          if [ -f /config/index.html ]; then
            cp /config/index.html /app-data/
          fi
          
          # Set permissions
          chown -R 101:101 /app-data
          chmod -R 755 /app-data
          
          echo "Setup completed successfully"
        volumeMounts:
        - name: app-data
          mountPath: /app-data
        - name: app-config
          mountPath: /config
        securityContext:
          runAsUser: 101
          runAsGroup: 101
          runAsNonRoot: true
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop: ["ALL"]
      
      containers:
      - name: {{APP_NAME}}
        image: {{IMAGE}}
        imagePullPolicy: IfNotPresent
        
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        
        # Environment variables
        env:
        - name: APP_NAME
          value: "{{APP_NAME}}"
        - name: ENVIRONMENT
          value: "{{ENVIRONMENT}}"
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        
        # Load configuration from ConfigMap and Secret
        envFrom:
        - configMapRef:
            name: {{APP_NAME}}-config
        - secretRef:
            name: {{APP_NAME}}-secret
        
        # Volume mounts
        volumeMounts:
        - name: app-config
          mountPath: /etc/nginx/conf.d
          readOnly: true
        - name: app-data
          mountPath: /usr/share/nginx/html
        - name: tmp-storage
          mountPath: /tmp
        - name: nginx-cache
          mountPath: /var/cache/nginx
        - name: nginx-run
          mountPath: /var/run
        - name: logs
          mountPath: /var/log/nginx
        
        # Resource limits
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
            ephemeral-storage: "1Gi"
          limits:
            memory: "1Gi"
            cpu: "1000m"
            ephemeral-storage: "5Gi"
        
        # Security context
        securityContext:
          runAsUser: 101
          runAsGroup: 101
          runAsNonRoot: true
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: false
          capabilities:
            drop: ["ALL"]
            add: ["NET_BIND_SERVICE"]
        
        # Health probes
        startupProbe:
          httpGet:
            path: /health
            port: http
            httpHeaders:
            - name: User-Agent
              value: "kubernetes/startup-probe"
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 12
          successThreshold: 1
        
        livenessProbe:
          httpGet:
            path: /health
            port: http
            httpHeaders:
            - name: User-Agent
              value: "kubernetes/liveness-probe"
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
        
        readinessProbe:
          httpGet:
            path: /ready
            port: http
            httpHeaders:
            - name: User-Agent
              value: "kubernetes/readiness-probe"
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
          successThreshold: 1
        
        # Lifecycle hooks
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 15"]
      
      # Volume definitions
      volumes:
      - name: app-config
        configMap:
          name: {{APP_NAME}}-config
          items:
          - key: nginx.conf
            path: default.conf
          - key: index.html
            path: index.html
          defaultMode: 0644
      
      - name: app-data
        persistentVolumeClaim:
          claimName: {{APP_NAME}}-data-pvc
      
      - name: tmp-storage
        emptyDir:
          medium: Memory
          sizeLimit: 256Mi
      
      - name: logs
        emptyDir:
          sizeLimit: 1Gi
      
      - name: nginx-cache
        emptyDir:
          sizeLimit: 100Mi
      
      - name: nginx-run
        emptyDir:
          sizeLimit: 50Mi
      
      # DNS and scheduling
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      
      # Optional: Node affinity for better placement
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - {{APP_NAME}}
              topologyKey: kubernetes.io/hostname

---
# ============================================================================
# 09-service.yaml - Service Discovery
# ============================================================================
apiVersion: v1
kind: Service
metadata:
  name: {{APP_NAME}}-service
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: service
    environment: {{ENVIRONMENT}}
  annotations:
    # Prometheus monitoring
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
    prometheus.io/path: "/metrics"
    # Service mesh annotations (if using Istio)
    # sidecar.istio.io/inject: "true"
spec:
  type: ClusterIP
  selector:
    app: {{APP_NAME}}
    version: v1.0
  ports:
  - name: http
    port: 80
    targetPort: http
    protocol: TCP
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800

---
# ============================================================================
# 10-ingress.yaml - External Access
# ============================================================================
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: {{APP_NAME}}-ingress
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: ingress
    environment: {{ENVIRONMENT}}
  annotations:
    # Ingress class
    kubernetes.io/ingress.class: "nginx"
    
    # SSL/TLS
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    
    # Security headers
    nginx.ingress.kubernetes.io/configuration-snippet: |
      more_set_headers "X-Frame-Options: DENY";
      more_set_headers "X-Content-Type-Options: nosniff";
      more_set_headers "X-XSS-Protection: 1; mode=block";
      more_set_headers "Strict-Transport-Security: max-age=31536000; includeSubDomains; preload";
      more_set_headers "Referrer-Policy: strict-origin-when-cross-origin";
    
    # Rate limiting
    nginx.ingress.kubernetes.io/rate-limit-connections: "50"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
    nginx.ingress.kubernetes.io/rate-limit-rpm: "300"
    
    # Performance
    nginx.ingress.kubernetes.io/proxy-body-size: "10m"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "60"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "60"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "60"

spec:
  ingressClassName: nginx
  rules:
  - host: {{DOMAIN}}
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: {{APP_NAME}}-service
            port:
              number: 80
  tls:
  - hosts:
    - {{DOMAIN}}
    secretName: {{APP_NAME}}-tls

---
# ============================================================================
# 11-backend-service.yaml - Backend API Service (Referenced in nginx config)
# ============================================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{APP_NAME}}-backend
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}-backend
    component: api
    environment: {{ENVIRONMENT}}
spec:
  replicas: 2
  selector:
    matchLabels:
      app: {{APP_NAME}}-backend
  template:
    metadata:
      labels:
        app: {{APP_NAME}}-backend
        environment: {{ENVIRONMENT}}
    spec:
      containers:
      - name: backend
        image: nginx:1.25-alpine  # Replace with your backend image
        ports:
        - containerPort: 8080
        env:
        - name: APP_NAME
          value: "{{APP_NAME}}-backend"
        - name: ENVIRONMENT
          value: "{{ENVIRONMENT}}"
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: {{APP_NAME}}-backend
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}-backend
    component: api
spec:
  selector:
    app: {{APP_NAME}}-backend
  ports:
  - port: 8080
    targetPort: 8080
    name: http

---
# ============================================================================
# 12-hpa.yaml - Horizontal Pod Autoscaler
# ============================================================================
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: {{APP_NAME}}-hpa
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: autoscaling
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: {{APP_NAME}}-deployment
  minReplicas: {{REPLICAS}}
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60

---
# ============================================================================
# 13-pdb.yaml - Pod Disruption Budget
# ============================================================================
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: {{APP_NAME}}-pdb
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: availability
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app: {{APP_NAME}}

---
# ============================================================================
# 14-network-policy.yaml - Network Security
# ============================================================================
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: {{APP_NAME}}-network-policy
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: security
spec:
  podSelector:
    matchLabels:
      app: {{APP_NAME}}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Allow from ingress controller
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080
  # Allow from monitoring namespace
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 8080
  # Allow from same namespace
  - from:
    - podSelector: {}
    ports:
    - protocol: TCP
      port: 8080
  egress:
  # DNS resolution
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: kube-system
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 53
  # Backend services
  - to:
    - podSelector:
        matchLabels:
          app: {{APP_NAME}}-backend
    ports:
    - protocol: TCP
      port: 8080
  # External HTTPS (for APIs, etc.)
  - ports:
    - protocol: TCP
      port: 443

---
# ============================================================================
# 15-monitoring-stack.yaml - Complete Prometheus & Grafana Setup
# ============================================================================

# Prometheus Namespace
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    name: monitoring
    
---
# Prometheus ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 15s
      external_labels:
        cluster: '{{APP_NAME}}-cluster'
        environment: '{{ENVIRONMENT}}'
    
    rule_files:
      - "/etc/prometheus/rules/*.yml"
    
    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093
    
    scrape_configs:
      # Prometheus itself
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']
      
      # Kubernetes API server
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
          - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: default;kubernetes;https
      
      # Kubernetes nodes
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics
      
      # Kubernetes pods
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name

  # Alert rules
  alert_rules.yml: |
    groups:
    - name: {{APP_NAME}}.rules
      rules:
      - alert: HighCPUUsage
        expr: (cpu_usage_active / cpu_usage_total) * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: {{APP_NAME}}
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is above 80% for more than 5 minutes"
      
      - alert: HighMemoryUsage
        expr: (memory_usage_bytes / memory_limit_bytes) * 100 > 90
        for: 5m
        labels:
          severity: critical
          service: {{APP_NAME}}
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is above 90% for more than 5 minutes"
      
      - alert: PodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
        for: 5m
        labels:
          severity: critical
          service: {{APP_NAME}}
        annotations:
          summary: "Pod is crash looping"
          description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is restarting frequently"

---
# Prometheus Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:v2.45.0
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus/'
          - '--web.console.libraries=/etc/prometheus/console_libraries'
          - '--web.console.templates=/etc/prometheus/consoles'
          - '--storage.tsdb.retention.time=30d'
          - '--web.enable-lifecycle'
          - '--web.enable-admin-api'
        ports:
        - containerPort: 9090
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus/
        - name: prometheus-storage
          mountPath: /prometheus/
        resources:
          requests:
            memory: "512Mi"
            cpu: "200m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
      - name: prometheus-storage
        emptyDir: {}

---
# Prometheus Service
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  ports:
  - port: 9090
    targetPort: 9090
    name: web
  selector:
    app: prometheus

---
# Prometheus ServiceAccount and RBAC
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["get"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring

---
# Grafana ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-config
  namespace: monitoring
data:
  grafana.ini: |
    [server]
    http_port = 3000
    root_url = http://grafana.{{DOMAIN}}
    
    [security]
    admin_user = admin
    admin_password = admin123  # Change this in production!
    
    [database]
    type = sqlite3
    path = grafana.db
    
    [session]
    provider = memory
    
    [analytics]
    reporting_enabled = false
    check_for_updates = false
    
    [log]
    mode = console
    level = info

  datasources.yaml: |
    apiVersion: 1
    datasources:
      - name: Prometheus
        type: prometheus
        access: proxy
        url: http://prometheus:9090
        isDefault: true
        editable: true

  dashboards.yaml: |
    apiVersion: 1
    providers:
      - name: 'default'
        orgId: 1
        folder: ''
        folderUid: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards

  # Basic dashboard for your application
  app-dashboard.json: |
    {
      "dashboard": {
        "id": null,
        "title": "{{APP_NAME}} Dashboard",
        "tags": ["{{APP_NAME}}", "{{ENVIRONMENT}}"],
        "timezone": "browser",
        "panels": [
          {
            "id": 1,
            "title": "CPU Usage",
            "type": "stat",
            "targets": [
              {
                "expr": "rate(container_cpu_usage_seconds_total{pod=~\"{{APP_NAME}}-.*\"}[5m]) * 100",
                "legendFormat": "CPU %"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Memory Usage",
            "type": "stat",
            "targets": [
              {
                "expr": "container_memory_usage_bytes{pod=~\"{{APP_NAME}}-.*\"} / container_spec_memory_limit_bytes * 100",
                "legendFormat": "Memory %"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "unit": "percent"
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
          }
        ],
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "refresh": "5s"
      }
    }

---
# Grafana Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
  labels:
    app: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:10.1.0
        ports:
        - containerPort: 3000
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          value: "admin123"  # Change this!
        volumeMounts:
        - name: grafana-config
          mountPath: /etc/grafana/
        - name: grafana-dashboards
          mountPath: /var/lib/grafana/dashboards/
        - name: grafana-storage
          mountPath: /var/lib/grafana/
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "200m"
      volumes:
      - name: grafana-config
        configMap:
          name: grafana-config
      - name: grafana-dashboards
        configMap:
          name: grafana-config
      - name: grafana-storage
        emptyDir: {}

---
# Grafana Service
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
  labels:
    app: grafana
spec:
  ports:
  - port: 3000
    targetPort: 3000
    name: web
  selector:
    app: grafana

---
# Grafana Ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: grafana-ingress
  namespace: monitoring
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  tls:
  - hosts:
    - grafana.{{DOMAIN}}
    secretName: grafana-tls
  rules:
  - host: grafana.{{DOMAIN}}
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: grafana
            port:
              number: 3000

---
# ============================================================================
# 16-servicemonitor.yaml - Prometheus ServiceMonitor for your app
# ============================================================================
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: {{APP_NAME}}-metrics
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: monitoring
spec:
  selector:
    matchLabels:
      app: {{APP_NAME}}
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
  namespaceSelector:
    matchNames:
    - {{NAMESPACE}}

---
# ============================================================================
# 17-volume-snapshot.yaml - Backup Configuration
# ============================================================================
# VolumeSnapshotClass defines how to create snapshots
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: {{APP_NAME}}-snapshot-class
  labels:
    app: {{APP_NAME}}
    component: backup
driver: ebs.csi.aws.com  # Use appropriate CSI driver
deletionPolicy: Delete
parameters:
  # Add driver-specific parameters here

---
# VolumeSnapshot for backup
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: {{APP_NAME}}-snapshot
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: backup
spec:
  volumeSnapshotClassName: {{APP_NAME}}-snapshot-class
  source:
    persistentVolumeClaimName: {{APP_NAME}}-data-pvc

---
# ============================================================================
# 18-cronjob-backup.yaml - Automated Backup Job
# ============================================================================
apiVersion: batch/v1
kind: CronJob
metadata:
  name: {{APP_NAME}}-backup
  namespace: {{NAMESPACE}}
  labels:
    app: {{APP_NAME}}
    component: backup
spec:
  schedule: "0 2 * * *"  # Daily at 2 AM
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: busybox:1.36
            command:
            - /bin/sh
            - -c
            - |
              echo "Starting backup for {{APP_NAME}} at $(date)"
              # Add your backup logic here
              # This could include:
              # - Database dumps
              # - File compression
              # - Upload to cloud storage
              echo "Backup completed at $(date)"
            volumeMounts:
            - name: app-data
              mountPath: /data
              readOnly: true
          volumes:
          - name: app-data
            persistentVolumeClaim:
              claimName: {{APP_NAME}}-data-pvc
          restartPolicy: OnFailure
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1

---
# ============================================================================
# TEMPLATE USAGE INSTRUCTIONS
# ============================================================================
# 
# To use this template:
# 
# 1. Replace all template variables with your actual values:
#    - {{APP_NAME}} -> your-app-name
#    - {{NAMESPACE}} -> your-namespace
#    - {{DOMAIN}} -> your-domain.com
#    - {{ENVIRONMENT}} -> production/staging/development
#    - {{STORAGE_SIZE}} -> 10Gi
#    - {{REPLICAS}} -> 3
#    - {{IMAGE}} -> your-app:v1.0.0
#    - {{TEAM}} -> your-team-name
#    - {{STORAGE_CLASS}} -> fast-ssd
# 
# 2. Choose the appropriate StorageClass section for your environment:
#    - Keep only the local, AWS, or GCP section based on your infrastructure
# 
# 3. Update sensitive values in secrets:
#    - Generate new passwords and API keys
#    - Use proper base64 encoding for data section
# 
# 4. Customize resource limits based on your application needs
# 
# 5. Update the nginx.conf in ConfigMap with your actual backend services
# 
# 6. Deploy in order:
#    kubectl apply -f namespace.yaml
#    kubectl apply -f storage-class.yaml
#    kubectl apply -f pvc.yaml
#    kubectl apply -f configmap.yaml
#    kubectl apply -f secret.yaml
#    kubectl apply -f rbac.yaml
#    kubectl apply -f deployment.yaml
#    kubectl apply -f service.yaml
#    kubectl apply -f ingress.yaml
#    kubectl apply -f hpa.yaml
#    kubectl apply -f pdb.yaml
#    kubectl apply -f network-policy.yaml
#    kubectl apply -f monitoring-stack.yaml
#    kubectl apply -f servicemonitor.yaml
#    kubectl apply -f backup.yaml
# 
# 7. Verify deployment:
#    kubectl get all -n {{NAMESPACE}}
#    kubectl get pv,pvc -n {{NAMESPACE}}
#    kubectl get ingress -n {{NAMESPACE}}
#    kubectl get servicemonitor -n {{NAMESPACE}}
# 
# 8. Access your application:
#    - Main app: https://{{DOMAIN}}
#    - Grafana dashboard: https://grafana.{{DOMAIN}}
#    - Health check: https://{{DOMAIN}}/health
#    - Metrics: https://{{DOMAIN}}/metrics
# 
# ============================================================================