The journey from basic pod creation to expert-level pod management represents a significant milestone in your Kubernetes mastery. These enhanced examples, demos, and mini-projects provide the practical foundation you need to confidently manage pods in any environment‚Äîfrom development experiments to mission-critical production workloads.

Remember that every Kubernetes resource ultimately depends on pods, so the time you invest in truly understanding pod management will pay dividends throughout your entire Kubernetes journey. Whether you're debugging a complex multi-container application, optimizing resource usage, or designing resilient architectures, the skills you've developed here will guide your decisions and help you create better solutions.

---

## üìö Additional Resources and Extended Learning

### üîß Advanced Tooling Scripts

Here are some additional utility scripts to enhance your pod management workflow:

```bash
#!/bin/bash
# pod-management-suite.sh - Complete pod management toolkit

# Quick pod creation with best practices
quick_pod() {
    local name=$1
    local image=$2
    local namespace=${3:-default}
    
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: $name
  namespace: $namespace
  labels:
    created-by: pod-management-suite
    created-at: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
spec:
  securityContext:
    runAsUser: 1000
    runAsNonRoot: true
  containers:
  - name: main
    image: $image
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      capabilities:
        drop: ["ALL"]
    volumeMounts:
    - name: tmp
      mountPath: /tmp
  volumes:
  - name: tmp
    emptyDir: {}
  restartPolicy: Always
EOF
}

# Bulk pod operations
bulk_pod_operation() {
    local operation=$1
    local label_selector=$2
    local namespace=${3:-default}
    
    case $operation in
        "delete")
            kubectl delete pods -l "$label_selector" -n "$namespace"
            ;;
        "describe")
            kubectl get pods -l "$label_selector" -n "$namespace" -o name | \
            xargs -I {} kubectl describe {} -n "$namespace"
            ;;
        "logs")
            kubectl get pods -l "$label_selector" -n "$namespace" -o name | \
            xargs -I {} kubectl logs {} -n "$namespace" --tail=10
            ;;
        *)
            echo "Supported operations: delete, describe, logs"
            ;;
    esac
}

# Pod resource optimization analyzer
analyze_pod_resources() {
    local pod_name=$1
    local namespace=${2:-default}
    
    echo "=== Resource Analysis for $pod_name ==="
    
    # Current resource configuration
    echo "Current Configuration:"
    kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources}' | jq '.'
    
    # Actual usage if metrics available
    if kubectl top pod "$pod_name" -n "$namespace" >/dev/null 2>&1; then
        echo ""
        echo "Current Usage:"
        kubectl top pod "$pod_name" -n "$namespace"
        
        # Calculate efficiency
        local cpu_request=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.cpu}' | sed 's/m$//')
        local cpu_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $2}' | sed 's/m$//')
        
        if [[ -n "$cpu_request" && -n "$cpu_usage" ]]; then
            local cpu_efficiency=$((cpu_usage * 100 / cpu_request))
            echo ""
            echo "Resource Efficiency:"
            echo "CPU Efficiency: ${cpu_efficiency}% (${cpu_usage}m used / ${cpu_request}m requested)"
            
            if [[ $cpu_efficiency -lt 25 ]]; then
                echo "üí° Consider reducing CPU request"
            elif [[ $cpu_efficiency -gt 80 ]]; then
                echo "‚ö†Ô∏è  Consider increasing CPU request/limit"
            fi
        fi
    fi
}

# Export functions for use
export -f quick_pod bulk_pod_operation analyze_pod_resources
```

### üéØ Real-World Scenarios and Solutions

#### Scenario 1: High-Traffic Web Application

```yaml
# high-traffic-web-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: high-traffic-web
  labels:
    app: web
    tier: frontend
    traffic: high
spec:
  # Optimized for high performance
  priorityClassName: high-priority
  nodeSelector:
    node-type: "high-memory"
  
  containers:
  - name: nginx
    image: nginx:1.21-alpine
    ports:
    - containerPort: 80
    
    # Aggressive resource allocation for high traffic
    resources:
      requests:
        memory: "512Mi"
        cpu: "500m"
      limits:
        memory: "1Gi"
        cpu: "1000m"
    
    # Tuned environment for performance
    env:
    - name: NGINX_WORKER_PROCESSES
      value: "auto"
    - name: NGINX_WORKER_CONNECTIONS
      value: "2048"
    
    # Aggressive health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 2
    
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 3
      timeoutSeconds: 1
      failureThreshold: 1
    
    # Performance-optimized volumes
    volumeMounts:
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: tmp-fast
      mountPath: /tmp
  
  volumes:
  - name: nginx-cache
    emptyDir:
      medium: Memory  # Use RAM for cache
      sizeLimit: 256Mi
  - name: tmp-fast
    emptyDir:
      medium: Memory
      sizeLimit: 128Mi
```

#### Scenario 2: Database Pod with Persistence

```yaml
# database-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: postgres-db
  labels:
    app: postgres
    tier: database
    persistence: enabled
spec:
  # Database-specific optimizations
  securityContext:
    fsGroup: 999  # postgres group
  
  containers:
  - name: postgres
    image: postgres:13-alpine
    
    # Database-appropriate resources
    resources:
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
    
    env:
    - name: POSTGRES_DB
      value: "appdb"
    - name: POSTGRES_USER
      value: "dbuser"
    - name: POSTGRES_PASSWORD
      valueFrom:
        secretKeyRef:
          name: postgres-secret
          key: password
    - name: PGDATA
      value: "/var/lib/postgresql/data/pgdata"
    
    ports:
    - containerPort: 5432
    
    # Database health checks
    livenessProbe:
      exec:
        command:
        - pg_isready
        - -U
        - dbuser
        - -d
        - appdb
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
    
    readinessProbe:
      exec:
        command:
        - pg_isready
        - -U
        - dbuser
        - -d
        - appdb
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 3
    
    # Data persistence
    volumeMounts:
    - name: postgres-data
      mountPath: /var/lib/postgresql/data
    - name: postgres-config
      mountPath: /etc/postgresql
      readOnly: true
  
  volumes:
  - name: postgres-data
    persistentVolumeClaim:
      claimName: postgres-pvc
  - name: postgres-config
    configMap:
      name: postgres-config
```

#### Scenario 3: Microservice with Service Mesh

```yaml
# microservice-with-istio.yaml
apiVersion: v1
kind: Pod
metadata:
  name: user-service
  labels:
    app: user-service
    version: v1
  annotations:
    sidecar.istio.io/inject: "true"
    sidecar.istio.io/proxyCPU: "100m"
    sidecar.istio.io/proxyMemory: "128Mi"
spec:
  containers:
  - name: user-service
    image: myregistry/user-service:1.2.0
    
    ports:
    - name: http
      containerPort: 8080
    - name: grpc
      containerPort: 9090
    
    # Microservice resources
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
      limits:
        memory: "512Mi"
        cpu: "500m"
    
    # Service mesh compatible health checks
    livenessProbe:
      httpGet:
        path: /health/live
        port: 8080
        scheme: HTTP
      initialDelaySeconds: 15
      periodSeconds: 20
    
    readinessProbe:
      httpGet:
        path: /health/ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 10
    
    # Environment for service discovery
    env:
    - name: SERVICE_NAME
      value: "user-service"
    - name: SERVICE_VERSION
      value: "v1"
    - name: NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    
    # Security for zero-trust environment
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
    
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: app-cache
      mountPath: /app/cache
  
  volumes:
  - name: tmp
    emptyDir: {}
  - name: app-cache
    emptyDir:
      sizeLimit: 100Mi
```

### üõ†Ô∏è Troubleshooting Scenarios and Solutions

#### Common Issue 1: Pod Stuck in Pending State

```bash
# diagnose-pending-pod.sh
diagnose_pending_pod() {
    local pod_name=$1
    local namespace=${2:-default}
    
    echo "=== Diagnosing Pending Pod: $pod_name ==="
    
    # Check basic status
    kubectl get pod "$pod_name" -n "$namespace" -o wide
    
    # Look for scheduling issues
    echo ""
    echo "=== Events ==="
    kubectl describe pod "$pod_name" -n "$namespace" | grep -A 20 "Events:"
    
    # Check resource requests vs available
    echo ""
    echo "=== Resource Analysis ==="
    local cpu_request=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.cpu}')
    local memory_request=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.memory}')
    
    echo "Pod requests: CPU=$cpu_request, Memory=$memory_request"
    
    # Check node capacity
    echo ""
    echo "=== Node Capacity ==="
    kubectl describe nodes | grep -A 5 "Allocatable\|Allocated resources"
    
    # Check for node selectors and taints
    echo ""
    echo "=== Scheduling Constraints ==="
    kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.nodeSelector}'
    kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.tolerations}'
}
```

#### Common Issue 2: Container Restart Loop

```bash
# diagnose-restart-loop.sh
diagnose_restart_loop() {
    local pod_name=$1
    local namespace=${2:-default}
    
    echo "=== Diagnosing Restart Loop: $pod_name ==="
    
    # Get restart count
    local restarts=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[0].restartCount}')
    echo "Current restart count: $restarts"
    
    # Check current and previous logs
    echo ""
    echo "=== Current Logs ==="
    kubectl logs "$pod_name" -n "$namespace" --tail=20
    
    echo ""
    echo "=== Previous Logs ==="
    kubectl logs "$pod_name" -n "$namespace" --previous --tail=20
    
    # Check liveness probe configuration
    echo ""
    echo "=== Liveness Probe ==="
    kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].livenessProbe}' | jq '.'
    
    # Check for OOM kills
    echo ""
    echo "=== Resource Limits ==="
    kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources}' | jq '.'
    
    # Recent events
    echo ""
    echo "=== Recent Events ==="
    kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" --sort-by='.lastTimestamp' | tail -10
}
```

### üìä Performance Monitoring and Alerting

```bash
#!/bin/bash
# pod-performance-monitor.sh

monitor_pod_performance() {
    local pod_name=$1
    local namespace=${2:-default}
    local duration=${3:-300}  # 5 minutes
    local alert_cpu_threshold=${4:-80}      # 80% of limit
    local alert_memory_threshold=${5:-80}   # 80% of limit
    
    echo "=== Starting Performance Monitor ==="
    echo "Pod: $pod_name"
    echo "Duration: ${duration}s"
    echo "CPU Alert Threshold: ${alert_cpu_threshold}%"
    echo "Memory Alert Threshold: ${alert_memory_threshold}%"
    echo ""
    
    local start_time=$(date +%s)
    local end_time=$((start_time + duration))
    local sample_count=0
    local cpu_alerts=0
    local memory_alerts=0
    
    # Get resource limits for percentage calculation
    local cpu_limit=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.cpu}' | sed 's/m$//')
    local memory_limit=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.memory}' | sed 's/Mi$//')
    
    while [ $(date +%s) -lt $end_time ]; do
        if kubectl top pod "$pod_name" -n "$namespace" &>/dev/null; then
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            local metrics=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers)
            local cpu_usage=$(echo $metrics | awk '{print $2}' | sed 's/m$//')
            local memory_usage=$(echo $metrics | awk '{print $3}' | sed 's/Mi$//')
            
            # Calculate percentages
            local cpu_percent=$((cpu_usage * 100 / cpu_limit))
            local memory_percent=$((memory_usage * 100 / memory_limit))
            
            printf "[$timestamp] CPU: %3d%% (%4dm/%4dm) | Memory: %3d%% (%4dMi/%4dMi)" \
                   $cpu_percent $cpu_usage $cpu_limit $memory_percent $memory_usage $memory_limit
            
            # Check for alerts
            if [[ $cpu_percent -gt $alert_cpu_threshold ]]; then
                printf " | üö® CPU ALERT"
                ((cpu_alerts++))
            fi
            
            if [[ $memory_percent -gt $alert_memory_threshold ]]; then
                printf " | üö® MEMORY ALERT"
                ((memory_alerts++))
            fi
            
            printf "\n"
            ((sample_count++))
        fi
        
        sleep 10
    done
    
    echo ""
    echo "=== Monitoring Summary ==="
    echo "Total samples: $sample_count"
    echo "CPU alerts: $cpu_alerts"
    echo "Memory alerts: $memory_alerts"
    
    if [[ $cpu_alerts -gt 0 || $memory_alerts -gt 0 ]]; then
        echo ""
        echo "‚ö†Ô∏è  RECOMMENDATIONS:"
        if [[ $cpu_alerts -gt 0 ]]; then
            echo "- Consider increasing CPU limits or optimizing application"
        fi
        if [[ $memory_alerts -gt 0 ]]; then
            echo "- Consider increasing memory limits or investigating memory leaks"
        fi
    fi
}

# Export function
export -f monitor_pod_performance
```

### üèÜ Production Readiness Checklist

Use this comprehensive checklist to ensure your pods are production-ready:

```bash
#!/bin/bash
# production-readiness-checker.sh

check_production_readiness() {
    local pod_name=$1
    local namespace=${2:-default}
    
    echo "üîç Production Readiness Assessment for $pod_name"
    echo "================================================"
    
    local score=0
    local max_score=0
    
    # Helper function to check and score
    check_item() {
        local description="$1"
        local command="$2"
        local points="$3"
        
        ((max_score += points))
        
        if eval "$command" &>/dev/null; then
            echo "‚úÖ $description ($points pts)"
            ((score += points))
        else
            echo "‚ùå $description (0/$points pts)"
        fi
    }
    
    echo ""
    echo "üîê Security Checks"
    echo "-----------------"
    
    check_item "Running as non-root user" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.spec.securityContext.runAsNonRoot}' | grep -q true" \
        10
    
    check_item "Security context configured" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.spec.containers[0].securityContext}' | grep -q allowPrivilegeEscalation" \
        10
    
    check_item "Capabilities dropped" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.spec.containers[0].securityContext.capabilities.drop}' | grep -q ALL" \
        15
    
    check_item "Read-only root filesystem" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.spec.containers[0].securityContext.readOnlyRootFilesystem}' | grep -q true" \
        15
    
    echo ""
    echo "üíæ Resource Management"
    echo "--------------------"
    
    check_item "CPU requests defined" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.spec.containers[0].resources.requests.cpu}' | grep -v '^
                kubectl describe pod "$pod_name" -n "$namespace" | grep -A 10 "Status\|Conditions"
                ;;
            2)
                echo "=== Recent Events ==="
                kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
                    --sort-by='.lastTimestamp' | tail -10
                ;;
            3)
                echo "=== Container Selection ==="
                local containers=($(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}'))
                if [[ ${#containers[@]} -eq 1 ]]; then
                    echo "Showing logs for container: ${containers[0]}"
                    kubectl logs "$pod_name" -n "$namespace" --tail=50
                else
                    echo "Available containers:"
                    for i in "${!containers[@]}"; do
                        echo "$((i+1))) ${containers[i]}"
                    done
                    read -p "Select container [1-${#containers[@]}]: " container_choice
                    if [[ $container_choice -ge 1 && $container_choice -le ${#containers[@]} ]]; then
                        local selected_container=${containers[$((container_choice-1))]}
                        echo "Showing logs for container: $selected_container"
                        kubectl logs "$pod_name" -n "$namespace" -c "$selected_container" --tail=50
                    fi
                fi
                ;;
            4)
                read -p "Enter command to execute: " exec_command
                kubectl exec -it "$pod_name" -n "$namespace" -- $exec_command
                ;;
            5)
                read -p "Enter local port: " local_port
                read -p "Enter pod port: " pod_port
                echo "Port forwarding $local_port:$pod_port - Press Ctrl+C to stop"
                kubectl port-forward "$pod_name" -n "$namespace" "$local_port:$pod_port"
                ;;
            6)
                echo "=== Resource Usage ==="
                kubectl top pod "$pod_name" -n "$namespace" 2>/dev/null || echo "Metrics not available"
                ;;
            7)
                gather_pod_info "$pod_name" "$namespace"
                detect_common_issues "$pod_name" "$namespace"
                generate_recommendations "$pod_name" "$namespace"
                echo "Full diagnostic completed. Check $OUTPUT_DIR/pods/$pod_name/"
                ;;
            8)
                generate_recommendations "$pod_name" "$namespace"
                echo "Recommendations generated. Check $OUTPUT_DIR/pods/$pod_name/recommendations.md"
                ;;
            q|Q)
                log_info "Exiting interactive diagnostics"
                break
                ;;
            *)
                echo "Invalid choice. Please try again."
                ;;
        esac
        
        echo ""
        read -p "Press Enter to continue..."
        echo ""
    done
}

# Cluster-wide pod health assessment
cluster_health_assessment() {
    log_info "Running cluster-wide pod health assessment..."
    
    local health_report="$OUTPUT_DIR/cluster_health_report.md"
    
    cat > "$health_report" <<EOF
# Cluster Pod Health Assessment

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)

---

EOF
    
    # Get all namespaces
    local namespaces=($(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'))
    
    local total_pods=0
    local healthy_pods=0
    local unhealthy_pods=0
    
    for ns in "${namespaces[@]}"; do
        log_info "Assessing namespace: $ns"
        
        local pods=($(kubectl get pods -n "$ns" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null))
        
        if [[ ${#pods[@]} -eq 0 ]]; then
            continue
        fi
        
        echo "## Namespace: $ns" >> "$health_report"
        echo "" >> "$health_report"
        
        local ns_healthy=0
        local ns_unhealthy=0
        
        for pod in "${pods[@]}"; do
            ((total_pods++))
            
            local phase=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.phase}')
            local ready_condition=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
            local restarts=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
            
            if [[ "$phase" == "Running" && "$ready_condition" == "True" && $restarts -lt 5 ]]; then
                ((healthy_pods++))
                ((ns_healthy++))
                echo "‚úÖ **$pod** - Healthy" >> "$health_report"
            else
                ((unhealthy_pods++))
                ((ns_unhealthy++))
                echo "‚ùå **$pod** - Issues detected (Phase: $phase, Ready: $ready_condition, Restarts: $restarts)" >> "$health_report"
                
                # Run quick diagnostics for unhealthy pods
                gather_pod_info "$pod" "$ns"
                detect_common_issues "$pod" "$ns"
            fi
        done
        
        echo "" >> "$health_report"
        echo "**Namespace Summary:** $ns_healthy healthy, $ns_unhealthy unhealthy" >> "$health_report"
        echo "" >> "$health_report"
    done
    
    # Overall summary
    local health_percentage=$((healthy_pods * 100 / total_pods))
    
    cat >> "$health_report" <<EOF

---

## Overall Cluster Health

- **Total Pods:** $total_pods
- **Healthy Pods:** $healthy_pods
- **Unhealthy Pods:** $unhealthy_pods
- **Health Percentage:** $health_percentage%

### Health Status
EOF
    
    if [[ $health_percentage -ge 90 ]]; then
        echo "üü¢ **EXCELLENT** - Cluster is in excellent health" >> "$health_report"
    elif [[ $health_percentage -ge 75 ]]; then
        echo "üü° **GOOD** - Cluster is in good health with minor issues" >> "$health_report"
    elif [[ $health_percentage -ge 50 ]]; then
        echo "üü† **WARNING** - Cluster has significant health issues" >> "$health_report"
    else
        echo "üî¥ **CRITICAL** - Cluster is in critical condition" >> "$health_report"
    fi
    
    log_success "Cluster health assessment completed. Report: $health_report"
}

# Generate comprehensive diagnostic report
generate_final_report() {
    log_info "Generating comprehensive diagnostic report..."
    
    local final_report="$OUTPUT_DIR/comprehensive_report.html"
    
    cat > "$final_report" <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Pod Diagnostics Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
        .header { background-color: #f4f4f4; padding: 20px; border-radius: 5px; margin-bottom: 30px; }
        .section { margin: 30px 0; }
        .pod-card { border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin: 10px 0; }
        .healthy { border-left: 5px solid #28a745; }
        .unhealthy { border-left: 5px solid #dc3545; }
        .warning { border-left: 5px solid #ffc107; }
        .metric { display: inline-block; margin: 10px 15px 10px 0; padding: 8px 12px; background-color: #e9ecef; border-radius: 3px; }
        .issue { background-color: #fff3cd; padding: 10px; border-radius: 3px; margin: 10px 0; }
        pre { background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }
        .tabs { border-bottom: 1px solid #ddd; margin-bottom: 20px; }
        .tab { display: inline-block; padding: 10px 20px; cursor: pointer; border-bottom: 2px solid transparent; }
        .tab.active { border-bottom-color: #007bff; color: #007bff; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }
    </style>
    <script>
        function showTab(tabName) {
            // Hide all tab contents
            var contents = document.getElementsByClassName('tab-content');
            for (var i = 0; i < contents.length; i++) {
                contents[i].classList.remove('active');
            }
            
            // Remove active class from all tabs
            var tabs = document.getElementsByClassName('tab');
            for (var i = 0; i < tabs.length; i++) {
                tabs[i].classList.remove('active');
            }
            
            // Show selected tab content and mark tab as active
            document.getElementById(tabName).classList.add('active');
            event.target.classList.add('active');
        }
    </script>
</head>
<body>
    <div class="header">
        <h1>üîç Pod Diagnostics Report</h1>
        <div class="metric">
            <strong>Generated:</strong> $(date)
        </div>
        <div class="metric">
            <strong>Cluster:</strong> $(kubectl config current-context)
        </div>
        <div class="metric">
            <strong>Diagnostics Version:</strong> 2.0
        </div>
    </div>
    
    <div class="tabs">
        <div class="tab active" onclick="showTab('overview')">Overview</div>
        <div class="tab" onclick="showTab('pods')">Pod Analysis</div>
        <div class="tab" onclick="showTab('issues')">Detected Issues</div>
        <div class="tab" onclick="showTab('recommendations')">Recommendations</div>
    </div>
    
    <div id="overview" class="tab-content active">
        <h2>üìä Cluster Overview</h2>
        <div class="section">
EOF
    
    # Add cluster metrics
    local total_nodes=$(kubectl get nodes --no-headers | wc -l)
    local ready_nodes=$(kubectl get nodes --no-headers | grep " Ready " | wc -l)
    local total_namespaces=$(kubectl get namespaces --no-headers | wc -l)
    
    cat >> "$final_report" <<EOF
            <div class="pod-card healthy">
                <h3>Cluster Metrics</h3>
                <div class="metric"><strong>Nodes:</strong> $ready_nodes/$total_nodes Ready</div>
                <div class="metric"><strong>Namespaces:</strong> $total_namespaces</div>
                <div class="metric"><strong>Kubernetes Version:</strong> $(kubectl version --short --client | cut -d' ' -f3)</div>
            </div>
        </div>
    </div>
    
    <div id="pods" class="tab-content">
        <h2>üöÄ Pod Analysis</h2>
EOF
    
    # Add pod analysis for each analyzed pod
    for pod_dir in "$OUTPUT_DIR"/pods/*/; do
        if [[ -d "$pod_dir" ]]; then
            local pod_name=$(basename "$pod_dir")
            local issues_count=0
            
            if [[ -f "$pod_dir/detected_issues.md" ]]; then
                issues_count=$(grep -c "## Issue" "$pod_dir/detected_issues.md" 2>/dev/null || echo "0")
            fi
            
            local card_class="healthy"
            if [[ $issues_count -gt 0 ]]; then
                card_class="unhealthy"
            fi
            
            cat >> "$final_report" <<EOF
        <div class="pod-card $card_class">
            <h3>üì¶ $pod_name</h3>
            <div class="metric"><strong>Issues Detected:</strong> $issues_count</div>
            <div class="metric"><strong>Analysis Files:</strong> $(ls "$pod_dir" | wc -l)</div>
            <div class="metric"><strong>Report Location:</strong> pods/$pod_name/</div>
        </div>
EOF
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="issues" class="tab-content">
        <h2>‚ö†Ô∏è Detected Issues</h2>
EOF
    
    # Aggregate all issues
    local total_issues=0
    for issues_file in "$OUTPUT_DIR"/pods/*/detected_issues.md; do
        if [[ -f "$issues_file" ]]; then
            local pod_issues=$(grep -c "## Issue" "$issues_file" 2>/dev/null || echo "0")
            ((total_issues += pod_issues))
            
            if [[ $pod_issues -gt 0 ]]; then
                local pod_name=$(basename "$(dirname "$issues_file")")
                echo "<h3>Issues for $pod_name</h3>" >> "$final_report"
                
                # Convert markdown issues to HTML
                grep "## Issue" "$issues_file" | while read -r line; do
                    echo "<div class=\"issue\">$line</div>" >> "$final_report"
                done
            fi
        fi
    done
    
    if [[ $total_issues -eq 0 ]]; then
        echo "<div class=\"pod-card healthy\"><h3>‚úÖ No Issues Detected</h3><p>All analyzed pods appear to be healthy!</p></div>" >> "$final_report"
    fi
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="recommendations" class="tab-content">
        <h2>üí° Recommendations</h2>
        <div class="section">
            <div class="pod-card warning">
                <h3>General Recommendations</h3>
                <ul>
                    <li>‚úÖ Implement comprehensive health checks for all pods</li>
                    <li>‚úÖ Set appropriate resource requests and limits</li>
                    <li>‚úÖ Use security contexts to harden pod security</li>
                    <li>‚úÖ Monitor resource usage and optimize accordingly</li>
                    <li>‚úÖ Implement graceful shutdown handling</li>
                    <li>‚úÖ Use multi-stage Docker builds for smaller images</li>
                    <li>‚úÖ Implement proper logging and observability</li>
                </ul>
            </div>
        </div>
EOF
    
    # Add pod-specific recommendations
    for rec_file in "$OUTPUT_DIR"/pods/*/recommendations.md; do
        if [[ -f "$rec_file" ]]; then
            local pod_name=$(basename "$(dirname "$rec_file")")
            echo "<div class=\"pod-card\"><h3>Recommendations for $pod_name</h3>" >> "$final_report"
            echo "<p>See detailed recommendations in: pods/$pod_name/recommendations.md</p></div>" >> "$final_report"
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div class="section">
        <hr>
        <p><em>Report generated by Pod Diagnostics Toolkit v2.0</em></p>
        <p><em>For detailed analysis, check individual files in the diagnostics output directory.</em></p>
    </div>
    
</body>
</html>
EOF
    
    log_success "Comprehensive report generated: $final_report"
    echo ""
    echo -e "${BOLD}üìã Diagnostic Summary:${NC}"
    echo "- Output Directory: $OUTPUT_DIR"
    echo "- HTML Report: $final_report"
    echo "- Total Issues Found: $total_issues"
    echo ""
    echo -e "${CYAN}üí° Next Steps:${NC}"
    echo "1. Open $final_report in your browser"
    echo "2. Review individual pod analysis in $OUTPUT_DIR/pods/"
    echo "3. Implement recommended fixes"
    echo "4. Re-run diagnostics to verify improvements"
}

# Main execution function
main() {
    local command=${1:-help}
    local pod_name=${2:-}
    local namespace=${3:-$NAMESPACE}
    
    case "$command" in
        "analyze")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for analysis"
                echo "Usage: $0 analyze <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            gather_pod_info "$pod_name" "$namespace"
            detect_common_issues "$pod_name" "$namespace"
            generate_recommendations "$pod_name" "$namespace"
            generate_final_report
            ;;
            
        "interactive")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for interactive mode"
                echo "Usage: $0 interactive <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            interactive_diagnostics "$pod_name" "$namespace"
            ;;
            
        "cluster-health")
            init_diagnostics
            cluster_health_assessment
            generate_final_report
            ;;
            
        "help"|*)
            cat <<EOF
üîç Advanced Pod Diagnostics Toolkit

Usage: $0 <command> [options]

Commands:
  analyze <pod-name> [namespace]     - Run comprehensive pod analysis
  interactive <pod-name> [namespace] - Start interactive diagnostic session
  cluster-health                     - Assess health of all pods in cluster
  help                              - Show this help message

Environment Variables:
  NAMESPACE - Default namespace (default: default)
  VERBOSE   - Enable verbose output (default: false)

Examples:
  $0 analyze nginx-pod production
  $0 interactive web-app-123
  $0 cluster-health
  VERBOSE=true $0 analyze problematic-pod

Output:
  All diagnostic data is saved to ./diagnostics-TIMESTAMP/
  HTML report provides comprehensive overview
  Individual pod analysis available in pods/ subdirectory

EOF
            ;;
    esac
}

# Execute main function
main "$@"
```

---

## Summary and Production-Ready Examples

### üèÜ Complete Production Workflow

Let's create a final comprehensive example that brings everything together:

```yaml
# complete-production-workflow.yaml
# This represents a complete production-ready pod deployment workflow

apiVersion: v1
kind: Namespace
metadata:
  name: production-workload
  labels:
    environment: production
    team: platform
---
# ConfigMap for application configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production-workload
data:
  app.properties: |
    server.port=8080
    management.port=8081
    logging.level=INFO
    metrics.enabled=true
  nginx.conf: |
    server {
        listen 80;
        location /health { return 200 'healthy\n'; }
        location /ready { return 200 'ready\n'; }
        location / {
            proxy_pass http://127.0.0.1:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
---
# Secret for sensitive configuration
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: production-workload
type: Opaque
data:
  database-password: c3VwZXJzZWNyZXQ=  # supersecret (base64)
  api-key: YWJjZGVmZ2hpams=  # abcdefghijk (base64)
---
# Production-ready pod with all best practices
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production-workload
  labels:
    app: production-app
    version: "2.1.0"
    environment: production
    team: platform
    component: backend
  annotations:
    description: "Production application with full observability"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/production-app"
    prometheus.io/scrape: "true"
    prometheus.io/port: "8081"
    prometheus.io/path: "/metrics"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Resource constraints and node placement
  nodeSelector:
    node-type: "application"
    performance-tier: "high"
    
  tolerations:
  - key: "dedicated-app"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
    
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: production-app
        topologyKey: kubernetes.io/hostname
        
  # DNS and network configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  # Init container for setup tasks
  initContainers:
  - name: setup
    image: busybox:1.35
    command:
    - /bin/sh
    - -c
    - |
      echo "Initializing application..."
      
      # Database migration simulation
      echo "Running database migrations..."
      sleep 5
      
      # Cache warming
      echo "Warming up caches..."
      sleep 3
      
      # Configuration validation
      echo "Validating configuration..."
      if [ -f /config/app.properties ]; then
        echo "‚úÖ Configuration file found"
      else
        echo "‚ùå Configuration file missing"
        exit 1
      fi
      
      echo "Initialization completed successfully"
      
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-init
      mountPath: /tmp
      
  # Main application containers
  containers:
  # Application container
  - name: app
    image: openjdk:11-jre-slim
    command:
    - /bin/bash
    - -c
    - |
      echo "Starting application..."
      
      # Simulated application startup
      java -Xmx200m -Xms100m -jar /app/application.jar \
        --spring.config.location=file:/config/app.properties \
        --server.port=8080 \
        --management.server.port=8081
        
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP
    - name: management
      containerPort: 8081
      protocol: TCP
      
    # Environment configuration
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # Sensitive configuration from secrets
    - name: DATABASE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: database-password
    - name: API_KEY
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: api-key
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security hardening
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    # Comprehensive health checks
    livenessProbe:
      httpGet:
        path: /actuator/health/liveness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /actuator/health/readiness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /actuator/health
        port: 8081
      initialDelaySeconds: 20
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle management
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Application started at $(date)" >> /tmp/startup.log
            # Custom post-start logic here
            
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Graceful shutdown initiated at $(date)" >> /tmp/shutdown.log
            # Send SIGTERM to application
            kill -TERM 1
            # Wait for graceful shutdown
            sleep 30
            
    # Volume mounts
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-volume
      mountPath: /tmp
    - name: app-logs
      mountPath: /app/logs
    - name: app-data
      mountPath: /app/data
      
  # Nginx reverse proxy sidecar
  - name: nginx-proxy
    image: nginx:1.21-alpine
    ports:
    - name: http-proxy
      containerPort: 80
      protocol: TCP
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        add: ["NET_BIND_SERVICE"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: nginx-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
      
  # Logging and monitoring sidecar
  - name: log-shipper
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: fluent-tmp
      mountPath: /tmp
      
  # Volumes
  volumes:
  - name: config-volume
    configMap:
      name: app-config
      items:
      - key: app.properties
        path: app.properties
  - name: nginx-config
    configMap:
      name: app-config
      items:
      - key: nginx.conf
        path: default.conf
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config  # Would be created separately
  # Temporary and cache volumes
  - name: tmp-volume
    emptyDir:
      sizeLimit: 256Mi
  - name: tmp-init
    emptyDir:
      sizeLimit: 64Mi
  - name: nginx-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: fluent-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: nginx-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: nginx-run
    emptyDir:
      sizeLimit: 32Mi
  # Application data volumes
  - name: app-logs
    emptyDir:
      sizeLimit: 1Gi
  - name: app-data
    emptyDir:
      sizeLimit: 2Gi
```

This comprehensive example demonstrates:

- **Complete security hardening** with proper contexts and capabilities
- **Multi-container architecture** with main app, proxy, and logging sidecars
- **Comprehensive health checks** for all containers
- **Resource optimization** with appropriate requests and limits
- **Configuration management** using ConfigMaps and Secrets
- **Observability** with structured logging and metrics endpoints
- **Production-ready networking** with reverse proxy
- **Graceful lifecycle management** with init containers and shutdown hooks

## üéì Key Learning Outcomes

By working through these enhanced examples, demos, and mini-projects, you've gained:

1. **Foundation Skills**: Basic pod creation, inspection, and management
2. **Intermediate Capabilities**: Multi-container patterns, health monitoring, and debugging
3. **Advanced Techniques**: Performance optimization, security hardening, and automation
4. **Expert-Level Mastery**: Custom controllers, comprehensive diagnostics, and production workflows

### üöÄ Next Steps for Continued Learning

1. **Practice the Examples**: Work through each example in your own cluster
2. **Customize for Your Use Cases**: Adapt the patterns to your specific applications
3. **Build Your Toolkit**: Create your own diagnostic and management scripts
4. **Share and Learn**: Contribute back to the community with your own improvements
5. **Scale Up**: Apply these pod management skills to higher-level controllers

The journey from basic pod creation to# 5. Working with Pods - From Fundamentals to Mastery (Enhanced Edition)

Understanding how to work with pods effectively forms the foundation of all Kubernetes operations. While you'll typically use higher-level controllers like Deployments in production environments, direct pod management skills are essential for debugging, troubleshooting, and truly understanding how Kubernetes applications function at their core. Think of this knowledge as learning to drive a manual transmission car‚Äîeven if you usually drive automatic, understanding the underlying mechanics makes you a better driver overall.

This enhanced guide provides progressive examples, hands-on demos, and real-world mini-projects to solidify your understanding through practical application.

## üéØ Learning Path Overview

- **Foundation Level**: Basic pod creation and inspection
- **Intermediate Level**: Multi-container patterns and health checks
- **Advanced Level**: Complex debugging and optimization
- **Expert Level**: Custom tooling and automation

---

## Understanding Pod Creation Strategies

Creating pods effectively requires understanding when to use imperative commands versus declarative configurations, and how different creation approaches serve different purposes.

### üìö Foundation Examples

Let's start with the absolute basics and progressively build complexity.

#### Example 1: Your First Pod
```bash
# Create the simplest possible pod
kubectl run hello-world --image=nginx --restart=Never

# Verify it's running
kubectl get pods

# Expected output:
# NAME          READY   STATUS    RESTARTS   AGE
# hello-world   1/1     Running   0          30s
```

#### Example 2: Pod with Custom Commands
```bash
# Create a pod that runs a custom command
kubectl run date-pod --image=busybox --restart=Never -- date

# This pod will run the date command and then exit
# Check the output
kubectl logs date-pod

# Clean up
kubectl delete pod date-pod
```

#### Example 3: Interactive Pod Session
```bash
# Create an interactive debugging pod
kubectl run -it debug-pod --image=busybox --restart=Never -- sh

# Inside the pod, try these commands:
# ls -la
# ps aux
# ping google.com
# nslookup kubernetes.default.svc.cluster.local

# Exit and clean up
# exit
kubectl delete pod debug-pod
```

### üõ†Ô∏è Demo: Pod Lifecycle Observation

Let's create a demo that shows the complete pod lifecycle in action:

```bash
#!/bin/bash
# pod-lifecycle-demo.sh

echo "=== Pod Lifecycle Demonstration ==="

# Terminal 1: Start watching pods
echo "In a separate terminal, run: kubectl get pods -w"
echo "Press Enter when ready..."
read

# Create a pod with a slow-starting application
echo "Creating pod with slow startup..."
kubectl run lifecycle-demo --image=nginx --restart=Never \
  --dry-run=client -o yaml > lifecycle-pod.yaml

# Add some customizations to make it more interesting
cat <<EOF >> lifecycle-pod.yaml
  containers:
  - name: nginx
    image: nginx:1.21
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod starting up...' && sleep 10"
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod shutting down...' && sleep 5"
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 5
EOF

echo "Applying pod configuration..."
kubectl apply -f lifecycle-pod.yaml

echo "Watch the pod states change from Pending -> ContainerCreating -> Running"
echo "Press Enter to continue when pod is Running..."
read

# Show detailed pod information
echo "=== Pod Details ==="
kubectl describe pod lifecycle-demo

echo "Press Enter to delete the pod and observe termination..."
read

# Delete and watch termination
kubectl delete pod lifecycle-demo

echo "Demo complete! Clean up the YAML file:"
echo "rm lifecycle-pod.yaml"
```

### üéØ Mini-Project 1: Pod Resource Monitor

Create a simple monitoring system using pods:

```yaml
# resource-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-monitor
  labels:
    app: monitor
    type: demo
spec:
  containers:
  - name: monitor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Starting Resource Monitor..."
      while true; do
        echo "=== $(date) ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "Load average:"
        uptime
        echo "Sleeping for 30 seconds..."
        sleep 30
      done
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
  restartPolicy: Always
```

```bash
# Deploy and monitor
kubectl apply -f resource-monitor-pod.yaml

# Watch the logs
kubectl logs -f resource-monitor

# In another terminal, check resource usage
kubectl top pod resource-monitor

# Clean up
kubectl delete -f resource-monitor-pod.yaml
```

---

## Deep Pod Inspection and Monitoring

### üîç Intermediate Examples

#### Example 4: Multi-Container Pod Investigation

```yaml
# multi-container-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-demo
  labels:
    demo: multi-container
spec:
  containers:
  - name: web-server
    image: nginx:1.21
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
    
  - name: log-processor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Log processor starting..."
      while true; do
        if [ -f /var/log/nginx/access.log ]; then
          echo "=== Access Log Summary $(date) ==="
          tail -10 /var/log/nginx/access.log | wc -l
          echo "Recent requests:"
          tail -5 /var/log/nginx/access.log
        else
          echo "Waiting for access.log..."
        fi
        sleep 30
      done
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
      
  - name: metrics-collector
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Metrics collector starting..."
      while true; do
        echo "=== Metrics $(date) ==="
        echo "Container count: 3"
        echo "Uptime: $(uptime)"
        echo "Memory: $(free -h | grep Mem)"
        sleep 60
      done
      
  volumes:
  - name: shared-logs
    emptyDir: {}
```

**Inspection Commands:**
```bash
# Apply the multi-container pod
kubectl apply -f multi-container-demo.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/multi-container-demo

# Inspect different aspects
echo "=== Basic Information ==="
kubectl get pod multi-container-demo -o wide

echo "=== Container Status ==="
kubectl get pod multi-container-demo -o jsonpath='{.status.containerStatuses[*].name}' | tr ' ' '\n'

echo "=== Logs from each container ==="
kubectl logs multi-container-demo -c web-server --tail=5
kubectl logs multi-container-demo -c log-processor --tail=5
kubectl logs multi-container-demo -c metrics-collector --tail=5

# Generate some traffic to see shared volume in action
kubectl port-forward multi-container-demo 8080:80 &
PF_PID=$!

# Generate requests
for i in {1..10}; do
  curl -s http://localhost:8080 > /dev/null
  echo "Request $i sent"
  sleep 1
done

kill $PF_PID

# Check log processor output
kubectl logs multi-container-demo -c log-processor --tail=10

# Clean up
kubectl delete -f multi-container-demo.yaml
```

### üõ†Ô∏è Demo: Advanced Pod Debugging Techniques

```bash
#!/bin/bash
# advanced-debugging-demo.sh

echo "=== Advanced Pod Debugging Demo ==="

# Create a problematic pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: problematic-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "2000m"  # This might cause scheduling issues
      limits:
        memory: "512Mi"  # Less than request - invalid!
        cpu: "500m"
    livenessProbe:
      httpGet:
        path: /nonexistent
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
EOF

echo "Created a pod with multiple issues. Let's debug it..."

# Wait a moment for issues to manifest
sleep 10

echo "=== Debugging Steps ==="

echo "1. Check pod status:"
kubectl get pod problematic-pod -o wide

echo "2. Look at events:"
kubectl describe pod problematic-pod | grep -A 10 Events:

echo "3. Check for resource issues:"
kubectl describe pod problematic-pod | grep -A 5 -B 5 "resource"

echo "4. Examine container status:"
kubectl get pod problematic-pod -o jsonpath='{.status.containerStatuses[0]}' | jq '.'

# Fix the pod
echo "5. Let's fix the issues..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: fixed-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
EOF

echo "6. Compare the fixed pod:"
kubectl wait --for=condition=Ready pod/fixed-pod --timeout=60s
kubectl get pods -l debug=demo

# Clean up
echo "Cleaning up..."
kubectl delete pod problematic-pod fixed-pod
```

### üéØ Mini-Project 2: Pod Health Monitoring Dashboard

Create a comprehensive health monitoring system:

```yaml
# health-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: health-dashboard
  labels:
    app: health-monitor
spec:
  containers:
  - name: health-checker
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Health Dashboard Starting..."
      
      # Create a simple HTML dashboard
      mkdir -p /tmp/dashboard
      
      while true; do
        cat > /tmp/dashboard/health.html <<EOF
      <!DOCTYPE html>
      <html>
      <head>
          <title>Pod Health Dashboard</title>
          <meta http-equiv="refresh" content="30">
          <style>
              body { font-family: Arial, sans-serif; margin: 40px; }
              .healthy { color: green; }
              .warning { color: orange; }
              .critical { color: red; }
              .metric { margin: 10px 0; padding: 10px; border: 1px solid #ccc; }
          </style>
      </head>
      <body>
          <h1>Pod Health Dashboard</h1>
          <p>Last Update: $(date)</p>
          
          <div class="metric">
              <h3>System Load</h3>
              <p>$(uptime)</p>
          </div>
          
          <div class="metric">
              <h3>Memory Usage</h3>
              <pre>$(free -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Disk Usage</h3>
              <pre>$(df -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Process Count</h3>
              <p>Running processes: $(ps aux | wc -l)</p>
          </div>
          
      </body>
      </html>
      EOF
        
        echo "Dashboard updated at $(date)"
        sleep 30
      done
    volumeMounts:
    - name: dashboard-storage
      mountPath: /tmp/dashboard
      
  - name: web-server
    image: nginx:alpine
    ports:
    - containerPort: 80
    command:
    - /bin/sh
    - -c
    - |
      # Configure nginx to serve our dashboard
      cat > /etc/nginx/conf.d/default.conf <<EOF
      server {
          listen 80;
          location / {
              root /usr/share/nginx/html;
              index health.html;
          }
      }
      EOF
      
      # Start nginx
      nginx -g "daemon off;"
    volumeMounts:
    - name: dashboard-storage
      mountPath: /usr/share/nginx/html
      
  volumes:
  - name: dashboard-storage
    emptyDir: {}
    
  restartPolicy: Always
```

**Usage:**
```bash
# Deploy the health dashboard
kubectl apply -f health-monitor-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/health-dashboard

# Access the dashboard
kubectl port-forward health-dashboard 8080:80

# Open browser to http://localhost:8080
echo "Open http://localhost:8080 in your browser"

# Monitor the pod's own health
kubectl top pod health-dashboard

# Check logs from both containers
kubectl logs health-dashboard -c health-checker --tail=10
kubectl logs health-dashboard -c web-server --tail=10

# Clean up
kubectl delete -f health-monitor-pod.yaml
```

---

## Interactive Pod Management and Debugging

### üîß Advanced Examples

#### Example 5: Network Debugging Pod

```yaml
# network-debug-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: network-debugger
  labels:
    purpose: network-debug
spec:
  containers:
  - name: nettools
    image: nicolaka/netshoot
    command: ["/bin/bash"]
    args:
    - -c
    - |
      echo "Network debugging tools ready!"
      echo "Available tools: dig, nslookup, ping, curl, wget, tcpdump, netstat"
      echo "Example commands:"
      echo "  dig kubernetes.default.svc.cluster.local"
      echo "  ping 8.8.8.8"
      echo "  curl -I http://httpbin.org/headers"
      echo "  netstat -tulpn"
      
      # Keep container running
      sleep 3600
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
  restartPolicy: Never
```

**Debugging Session:**
```bash
# Deploy the network debugger
kubectl apply -f network-debug-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/network-debugger

# Start interactive session
kubectl exec -it network-debugger -- bash

# Inside the pod, run network diagnostics:
# Test DNS resolution
# dig kubernetes.default.svc.cluster.local

# Test external connectivity
# ping -c 3 8.8.8.8

# Test HTTP services
# curl -I https://httpbin.org/headers

# Check network interfaces
# ip addr show

# Check routing table
# ip route show

# Test service discovery
# nslookup kubernetes.default

# Exit and clean up
# exit
kubectl delete -f network-debug-pod.yaml
```

### üõ†Ô∏è Demo: File Transfer and Volume Management

```bash
#!/bin/bash
# file-transfer-demo.sh

echo "=== File Transfer and Volume Demo ==="

# Create a pod with persistent data
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: file-demo
spec:
  containers:
  - name: app
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Creating sample files..."
      mkdir -p /data/logs /data/config
      
      # Generate some sample data
      for i in {1..5}; do
        echo "Log entry \$i at \$(date)" >> /data/logs/app.log
        sleep 1
      done
      
      echo "app_name=demo-app" > /data/config/settings.conf
      echo "version=1.0.0" >> /data/config/settings.conf
      echo "debug=true" >> /data/config/settings.conf
      
      echo "Files created. Keeping container running..."
      sleep 3600
    volumeMounts:
    - name: data-storage
      mountPath: /data
  volumes:
  - name: data-storage
    emptyDir: {}
EOF

echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/file-demo

# Demonstrate file operations
echo "=== File Operations Demo ==="

echo "1. List files in the pod:"
kubectl exec file-demo -- find /data -type f

echo "2. Copy file from pod to local:"
kubectl cp file-demo:/data/logs/app.log ./app.log.backup
echo "File copied to: app.log.backup"
cat app.log.backup

echo "3. Create local config file:"
cat > new-config.conf <<EOF
app_name=updated-demo-app
version=2.0.0
debug=false
environment=production
EOF

echo "4. Copy local file to pod:"
kubectl cp new-config.conf file-demo:/data/config/

echo "5. Verify file in pod:"
kubectl exec file-demo -- cat /data/config/new-config.conf

echo "6. Create a backup of all data:"
kubectl exec file-demo -- tar -czf /tmp/backup.tar.gz -C /data .
kubectl cp file-demo:/tmp/backup.tar.gz ./pod-data-backup.tar.gz
echo "Backup created: pod-data-backup.tar.gz"

# Clean up
echo "Cleaning up..."
kubectl delete pod file-demo
rm -f app.log.backup new-config.conf pod-data-backup.tar.gz

echo "Demo complete!"
```

### üéØ Mini-Project 3: Pod Security Scanner

Create a security scanning tool using pods:

```yaml
# security-scanner-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-scanner
  labels:
    app: security
    type: scanner
spec:
  serviceAccountName: default
  containers:
  - name: scanner
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "=== Pod Security Scanner Starting ==="
      
      # Function to check security configurations
      check_security() {
        echo "Checking security configurations..."
        
        # Check if running as root
        if [ "$(id -u)" -eq 0 ]; then
          echo "‚ö†Ô∏è  WARNING: Running as root user"
        else
          echo "‚úÖ GOOD: Running as non-root user ($(id -u))"
        fi
        
        # Check filesystem permissions
        if [ -w "/" ]; then
          echo "‚ö†Ô∏è  WARNING: Root filesystem is writable"
        else
          echo "‚úÖ GOOD: Root filesystem is read-only"
        fi
        
        # Check for sensitive mounts
        if mount | grep -q "/var/run/secrets"; then
          echo "‚ÑπÔ∏è  INFO: Service account token mounted"
        fi
        
        # Check available capabilities
        echo "Current capabilities:"
        if [ -f "/proc/self/status" ]; then
          grep Cap /proc/self/status
        fi
        
        # Check network access
        echo "Testing network access..."
        if ping -c 1 8.8.8.8 >/dev/null 2>&1; then
          echo "‚ÑπÔ∏è  INFO: External network access available"
        else
          echo "‚ÑπÔ∏è  INFO: No external network access"
        fi
        
        # Generate security report
        cat > /tmp/security-report.txt <<EOF
      === Security Scan Report ===
      Timestamp: $(date)
      User ID: $(id -u)
      Group ID: $(id -g)
      Working Directory: $(pwd)
      
      Filesystem Check:
      - Root writable: $([ -w "/" ] && echo "YES" || echo "NO")
      - /tmp writable: $([ -w "/tmp" ] && echo "YES" || echo "NO")
      
      Network Check:
      - External access: $(ping -c 1 8.8.8.8 >/dev/null 2>&1 && echo "YES" || echo "NO")
      
      Process Information:
      $(ps aux)
      EOF
        
        echo "Report generated at /tmp/security-report.txt"
      }
      
      # Run security check
      check_security
      
      # Keep running for inspection
      echo "Scanner complete. Container will stay running for inspection."
      sleep 3600
      
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 1000
      runAsGroup: 3000
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir: {}
    
  restartPolicy: Never
```

**Usage:**
```bash
# Deploy the security scanner
kubectl apply -f security-scanner-pod.yaml

# Monitor the scan
kubectl logs -f security-scanner

# Get the security report
kubectl cp security-scanner:/tmp/security-report.txt ./security-report.txt
cat security-report.txt

# Create a comparison with an insecure pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: insecure-pod
spec:
  containers:
  - name: insecure
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      runAsUser: 0  # Running as root
      privileged: true
EOF

# Compare security postures
echo "=== Security Comparison ==="
echo "Secure pod user:"
kubectl exec security-scanner -- id

echo "Insecure pod user:"
kubectl exec insecure-pod -- id

echo "Secure pod capabilities:"
kubectl exec security-scanner -- grep Cap /proc/self/status

echo "Insecure pod capabilities:"
kubectl exec insecure-pod -- grep Cap /proc/self/status

# Clean up
kubectl delete pod security-scanner insecure-pod
rm -f security-report.txt
```

---

## Declarative Pod Configuration and Management

### üèóÔ∏è Expert Examples

#### Example 6: Production-Ready Pod Template

```yaml
# production-pod-template.yaml
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production
  labels:
    app: web-server
    version: "2.1.0"
    environment: production
    team: platform
  annotations:
    description: "Production web server with full monitoring and security"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/web-server"
    version: "2.1.0"
    build-date: "2024-01-15T10:30:00Z"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Node selection
  nodeSelector:
    node-type: "application"
    zone: "us-west-2a"
    
  # Tolerations for dedicated nodes
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "application"
    effect: "NoSchedule"
    
  # Pod placement preferences
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: "node-type"
            operator: In
            values: ["application"]
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: web-server
          topologyKey: kubernetes.io/hostname
          
  # DNS configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  containers:
  - name: web-server
    image: nginx:1.21-alpine
    imagePullPolicy: IfNotPresent
    
    ports:
    - name: http
      containerPort: 80
      protocol: TCP
    - name: metrics
      containerPort: 9113
      protocol: TCP
      
    # Environment variables
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "info"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security context
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE
        
    # Health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 80
        scheme: HTTP
        httpHeaders:
        - name: Custom-Header
          value: liveness-check
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
        scheme: HTTP
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle hooks
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container started at $(date)" >> /tmp/startup.log
            # Custom initialization logic here
            
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container stopping at $(date)" >> /tmp/shutdown.log
            # Graceful shutdown logic here
            nginx -s quit
            sleep 15
            
    # Volume mounts
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  # Sidecar container for log processing
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  # Monitoring sidecar
  - name: nginx-exporter
    image: nginx/nginx-prometheus-exporter:0.10.0
    args:
    - -nginx.scrape-uri=http://localhost:80/nginx_status
    ports:
    - name: metrics
      containerPort: 9113
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
  # Shared volumes
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
      defaultMode: 0644
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
      defaultMode: 0644
  - name: html-content
    configMap:
      name: html-content
      defaultMode: 0644
  - name: tmp-dir
    emptyDir:
      sizeLimit: 256Mi
  - name: var-cache-nginx
    emptyDir:
      sizeLimit: 512Mi
  - name: var-run
    emptyDir:
      sizeLimit: 64Mi
  - name: logs
    emptyDir:
      sizeLimit: 1Gi
```

### üõ†Ô∏è Demo: Complex Pod Deployment Pipeline

```bash
#!/bin/bash
# production-pod-deployment.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

# Configuration
NAMESPACE="production-demo"
APP_NAME="web-server"
CONFIG_DIR="./config"

# Create namespace if it doesn't exist
create_namespace() {
    log "Creating namespace: $NAMESPACE"
    kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    success "Namespace $NAMESPACE ready"
}

# Create ConfigMaps for the application
create_configmaps() {
    log "Creating ConfigMaps..."
    
    mkdir -p $CONFIG_DIR
    
    # Nginx configuration
    cat > $CONFIG_DIR/nginx.conf <<EOF
server {
    listen 80;
    server_name localhost;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
    
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    location /ready {
        access_log off;
        return 200 "ready\n";
        add_header Content-Type text/plain;
    }
    
    location /nginx_status {
        stub_status on;
        access_log off;
        allow all;
    }
}
EOF

    # HTML content
    cat > $CONFIG_DIR/index.html <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Production Pod Demo</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .container { max-width: 800px; margin: 0 auto; }
        .status { padding: 20px; margin: 20px 0; border-radius: 5px; }
        .healthy { background-color: #d4edda; color: #155724; }
        .info { background-color: #d1ecf1; color: #0c5460; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Production Pod Demo</h1>
        <div class="status healthy">
            <h3>‚úÖ Application Status: Healthy</h3>
            <p>Pod is running successfully with full production configuration</p>
        </div>
        
        <div class="status info">
            <h3>üìä Features Enabled:</h3>
            <ul>
                <li>Multi-container architecture</li>
                <li>Comprehensive health checks</li>
                <li>Security hardening</li>
                <li>Log processing sidecar</li>
                <li>Prometheus metrics export</li>
                <li>Resource management</li>
            </ul>
        </div>
        
        <div class="status info">
            <h3>üîó Endpoints:</h3>
            <ul>
                <li><a href="/health">Health Check</a></li>
                <li><a href="/ready">Readiness Check</a></li>
                <li><a href="/nginx_status">Nginx Status</a></li>
            </ul>
        </div>
    </div>
</body>
</html>
EOF

    # Fluent Bit configuration
    cat > $CONFIG_DIR/fluent-bit.conf <<EOF
[SERVICE]
    Flush         1
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf

[INPUT]
    Name              tail
    Path              /var/log/nginx/access.log
    Parser            nginx
    Tag               nginx.access
    Refresh_Interval  5

[INPUT]
    Name              tail
    Path              /var/log/nginx/error.log
    Tag               nginx.error
    Refresh_Interval  5

[OUTPUT]
    Name  stdout
    Match nginx.*
EOF

    cat > $CONFIG_DIR/parsers.conf <<EOF
[PARSER]
    Name   nginx
    Format regex
    Regex  ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
    Time_Key time
    Time_Format %d/%b/%Y:%H:%M:%S %z
EOF

    # Create ConfigMaps
    kubectl create configmap nginx-config --from-file=$CONFIG_DIR/nginx.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap html-content --from-file=$CONFIG_DIR/index.html -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap fluent-bit-config --from-file=$CONFIG_DIR/fluent-bit.conf --from-file=$CONFIG_DIR/parsers.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    
    success "ConfigMaps created successfully"
}

# Deploy the production pod
deploy_pod() {
    log "Deploying production pod..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: $APP_NAME
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
    version: "1.0.0"
    environment: production
  annotations:
    deployment.kubernetes.io/revision: "1"
    deployed-by: "production-deployment-script"
    deployment-time: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    
  containers:
  - name: nginx
    image: nginx:1.21-alpine
    ports:
    - name: http
      containerPort: 80
    - name: metrics
      containerPort: 9113
      
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
  - name: html-content
    configMap:
      name: html-content
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
  - name: tmp-dir
    emptyDir: {}
  - name: var-cache-nginx
    emptyDir: {}
  - name: var-run
    emptyDir: {}
  - name: logs
    emptyDir: {}
EOF

    success "Pod deployed successfully"
}

# Wait for pod to be ready and perform health checks
verify_deployment() {
    log "Waiting for pod to be ready..."
    
    if kubectl wait --for=condition=Ready pod/$APP_NAME -n $NAMESPACE --timeout=120s; then
        success "Pod is ready!"
    else
        error "Pod failed to become ready within timeout"
    fi
    
    # Perform comprehensive health checks
    log "Performing health checks..."
    
    # Check pod status
    kubectl get pod $APP_NAME -n $NAMESPACE -o wide
    
    # Test health endpoints
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    if curl -s http://localhost:8080/health | grep -q "healthy"; then
        success "Health check passed"
    else
        warning "Health check failed"
    fi
    
    if curl -s http://localhost:8080/ready | grep -q "ready"; then
        success "Readiness check passed"
    else
        warning "Readiness check failed"
    fi
    
    # Test the main application
    if curl -s http://localhost:8080 | grep -q "Production Pod Demo"; then
        success "Application is serving content correctly"
    else
        warning "Application content check failed"
    fi
    
    kill $PF_PID 2>/dev/null
    
    # Check resource usage
    log "Checking resource usage..."
    if kubectl top pod $APP_NAME -n $NAMESPACE &>/dev/null; then
        kubectl top pod $APP_NAME -n $NAMESPACE
    else
        warning "Resource metrics not available"
    fi
    
    # Check logs from all containers
    log "Checking container logs..."
    echo "=== Nginx logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c nginx --tail=5
    echo "=== Log processor logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=5
}

# Generate load and monitor performance
performance_test() {
    log "Running performance test..."
    
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    # Generate some load
    for i in {1..50}; do
        curl -s http://localhost:8080 > /dev/null &
    done
    
    wait
    kill $PF_PID 2>/dev/null
    
    # Check logs after load test
    log "Logs after load test:"
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=10
    
    success "Performance test completed"
}

# Cleanup function
cleanup() {
    log "Cleaning up resources..."
    kubectl delete pod $APP_NAME -n $NAMESPACE --ignore-not-found
    kubectl delete configmap nginx-config html-content fluent-bit-config -n $NAMESPACE --ignore-not-found
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -rf $CONFIG_DIR
    success "Cleanup completed"
}

# Main execution
main() {
    echo "=== Production Pod Deployment Demo ==="
    
    case "${1:-deploy}" in
        "deploy")
            create_namespace
            create_configmaps
            deploy_pod
            verify_deployment
            performance_test
            
            echo ""
            success "Deployment completed successfully!"
            echo "Access the application:"
            echo "  kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80"
            echo "  Then open: http://localhost:8080"
            echo ""
            echo "Monitor the pod:"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c nginx"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c log-processor"
            echo ""
            echo "Run 'bash $0 cleanup' to remove all resources"
            ;;
        "cleanup")
            cleanup
            ;;
        "test")
            verify_deployment
            performance_test
            ;;
        *)
            echo "Usage: $0 [deploy|cleanup|test]"
            echo "  deploy  - Deploy the production pod (default)"
            echo "  cleanup - Remove all created resources"
            echo "  test    - Run verification and performance tests"
            ;;
    esac
}

main "$@"
```

### üéØ Mini-Project 4: Pod Chaos Engineering

Test pod resilience with chaos engineering principles:

```yaml
# chaos-test-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: chaos-resilient-app
  labels:
    app: chaos-test
    resilience: enabled
spec:
  containers:
  - name: main-app
    image: nginx:1.21-alpine
    ports:
    - containerPort: 80
    
    # Aggressive resource limits to test resilience
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    # Tight health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 2
      
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
      timeoutSeconds: 1
      failureThreshold: 2
      
    # Graceful shutdown
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 10"]
          
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  # Chaos monkey sidecar
  - name: chaos-monkey
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Chaos monkey starting..."
      
      # Function to create CPU load
      cpu_chaos() {
        echo "Creating CPU chaos..."
        for i in {1..4}; do
          yes > /dev/null &
        done
        sleep 30
        killall yes
      }
      
      # Function to create memory pressure
      memory_chaos() {
        echo "Creating memory chaos..."
        cat <(yes | tr \\n x | head -c 50000000) <(yes | tr \\n x | head -c 50000000) > /tmp/memory_eater &
        sleep 20
        rm -f /tmp/memory_eater
        killall cat
      }
      
      # Function to simulate network issues
      network_chaos() {
        echo "Creating network chaos..."
        # Simulate slow responses
        sleep $((RANDOM % 10 + 5))
      }
      
      # Function to create disk I/O pressure
      disk_chaos() {
        echo "Creating disk I/O chaos..."
        dd if=/dev/zero of=/tmp/disk_eater bs=1M count=10 2>/dev/null
        rm -f /tmp/disk_eater
      }
      
      # Main chaos loop
      while true; do
        chaos_type=$((RANDOM % 4))
        case $chaos_type in
          0) cpu_chaos ;;
          1) memory_chaos ;;
          2) network_chaos ;;
          3) disk_chaos ;;
        esac
        
        # Wait between chaos events
        sleep $((RANDOM % 60 + 30))
      done
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir:
      sizeLimit: 100Mi
      
  restartPolicy: Always
```

**Chaos Testing Script:**
```bash
#!/bin/bash
# chaos-engineering-test.sh

echo "=== Chaos Engineering Test ==="

# Deploy the chaos test pod
kubectl apply -f chaos-test-pod.yaml

# Wait for it to be ready
echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/chaos-resilient-app --timeout=60s

# Monitor pod resilience
echo "Starting resilience monitoring (Ctrl+C to stop)..."

monitor_resilience() {
    while true; do
        timestamp=$(date '+%H:%M:%S')
        
        # Check pod status
        status=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.phase}')
        ready=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
        restarts=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.containerStatuses[0].restartCount}')
        
        # Test application responsiveness
        kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
        PF_PID=$!
        sleep 2
        
        response_time=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8080 2>/dev/null || echo "FAIL")
        kill $PF_PID 2>/dev/null
        
        # Get resource usage if available
        resources=""
        if kubectl top pod chaos-resilient-app &>/dev/null; then
            resources=$(kubectl top pod chaos-resilient-app --no-headers 2>/dev/null | awk '{print $2" "$3}')
        fi
        
        printf "[$timestamp] Status: $status | Ready: $ready | Restarts: $restarts | Response: ${response_time}s | Resources: $resources\n"
        
        sleep 5
    done
}

# Start monitoring in background
monitor_resilience &
MONITOR_PID=$!

# Generate additional load to test resilience
echo "Generating load to test resilience..."
for i in {1..100}; do
    kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
    PF_PID=$!
    sleep 1
    
    curl -s http://localhost:8080 > /dev/null &
    
    kill $PF_PID 2>/dev/null
    sleep 2
done

# Stop monitoring
kill $MONITOR_PID 2>/dev/null

echo "Chaos test completed. Check pod logs:"
echo "kubectl logs chaos-resilient-app -c main-app --tail=20"
echo "kubectl logs chaos-resilient-app -c chaos-monkey --tail=20"

# Cleanup
read -p "Delete the chaos test pod? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    kubectl delete -f chaos-test-pod.yaml
fi
```

---

## Advanced Pod Management Techniques

### üî¨ Expert-Level Examples

#### Example 7: Custom Pod Controller

Create a custom controller for specialized pod management:

```python
#!/usr/bin/env python3
# custom-pod-controller.py

import time
import yaml
import subprocess
import json
from datetime import datetime, timedelta

class PodController:
    def __init__(self):
        self.managed_pods = {}
        self.check_interval = 30  # seconds
        
    def log(self, message):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"[{timestamp}] {message}")
        
    def run_kubectl(self, command):
        """Execute kubectl command and return JSON output"""
        try:
            result = subprocess.run(
                f"kubectl {command} -o json",
                shell=True,
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                self.log(f"kubectl error: {result.stderr}")
                return None
        except Exception as e:
            self.log(f"Command execution error: {e}")
            return None
            
    def get_pods_by_label(self, label_selector):
        """Get pods matching label selector"""
        command = f"get pods -l {label_selector}"
        result = self.run_kubectl(command)
        return result.get('items', []) if result else []
        
    def create_pod(self, name, spec):
        """Create a pod with given specification"""
        pod_manifest = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'name': name,
                'labels': {
                    'managed-by': 'custom-controller',
                    'created': datetime.now().strftime('%Y%m%d-%H%M%S')
                }
            },
            'spec': spec
        }
        
        # Write manifest to temporary file
        with open(f'/tmp/{name}.yaml', 'w') as f:
            yaml.dump(pod_manifest, f)
            
        # Apply the manifest
        result = subprocess.run(
            f"kubectl apply -f /tmp/{name}.yaml",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Created pod: {name}")
            return True
        else:
            self.log(f"Failed to create pod {name}: {result.stderr}")
            return False
            
    def delete_pod(self, name):
        """Delete a pod"""
        result = subprocess.run(
            f"kubectl delete pod {name} --grace-period=30",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Deleted pod: {name}")
            return True
        else:
            self.log(f"Failed to delete pod {name}: {result.stderr}")
            return False
            
    def check_pod_health(self, pod):
        """Check if a pod is healthy based on custom criteria"""
        name = pod['metadata']['name']
        status = pod['status']
        
        # Check if pod is running
        if status.get('phase') != 'Running':
            return False, f"Pod {name} is not running (phase: {status.get('phase')})"
            
        # Check container statuses
        container_statuses = status.get('containerStatuses', [])
        for container in container_statuses:
            if not container.get('ready'):
                return False, f"Container {container['name']} not ready in pod {name}"
                
            # Check restart count
            restart_count = container.get('restartCount', 0)
            if restart_count > 5:
                return False, f"Container {container['name']} restarted {restart_count} times"
                
        # Check resource usage (if metrics available)
        metrics = self.get_pod_metrics(name)
        if metrics:
            cpu_usage = self.parse_cpu_usage(metrics.get('cpu', '0m'))
            memory_usage = self.parse_memory_usage(metrics.get('memory', '0Mi'))
            
            if cpu_usage > 800:  # 800 millicores
                return False, f"Pod {name} CPU usage too high: {cpu_usage}m"
                
            if memory_usage > 512:  # 512 Mi
                return False, f"Pod {name} memory usage too high: {memory_usage}Mi"
                
        return True, f"Pod {name} is healthy"
        
    def get_pod_metrics(self, pod_name):
        """Get pod resource metrics if available"""
        result = subprocess.run(
            f"kubectl top pod {pod_name} --no-headers",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            parts = result.stdout.strip().split()
            if len(parts) >= 3:
                return {
                    'cpu': parts[1],
                    'memory': parts[2]
                }
        return None
        
    def parse_cpu_usage(self, cpu_str):
        """Parse CPU usage from string like '100m' to millicores"""
        if cpu_str.endswith('m'):
            return int(cpu_str[:-1])
        return int(cpu_str) * 1000
        
    def parse_memory_usage(self, memory_str):
        """Parse memory usage from string like '128Mi' to Mi"""
        if memory_str.endswith('Mi'):
            return int(memory_str[:-2])
        elif memory_str.endswith('Gi'):
            return int(memory_str[:-2]) * 1024
        return int(memory_str) // (1024 * 1024)
        
    def auto_heal_pod(self, pod_name, reason):
        """Attempt to heal an unhealthy pod"""
        self.log(f"Attempting to heal pod {pod_name}: {reason}")
        
        # Strategy 1: Restart the pod
        if "restart" in reason.lower():
            return self.delete_pod(pod_name)  # Pod will be recreated if managed by controller
            
        # Strategy 2: Scale resources if high usage
        if "usage too high" in reason.lower():
            self.log(f"High resource usage detected for {pod_name}, marking for recreation")
            return self.delete_pod(pod_name)
            
        # Strategy 3: Generic restart
        return self.delete_pod(pod_name)
        
    def manage_workload(self, workload_config):
        """Manage a workload with desired replica count"""
        app_name = workload_config['name']
        desired_replicas = workload_config['replicas']
        pod_spec = workload_config['pod_spec']
        
        # Get current pods for this workload
        current_pods = self.get_pods_by_label(f"app={app_name},managed-by=custom-controller")
        current_count = len(current_pods)
        
        self.log(f"Managing workload {app_name}: current={current_count}, desired={desired_replicas}")
        
        # Scale up if needed
        if current_count < desired_replicas:
            for i in range(current_count, desired_replicas):
                pod_name = f"{app_name}-{i}"
                pod_spec_copy = pod_spec.copy()
                pod_spec_copy.setdefault('containers', [{}])[0]['env'] = [
                    {'name': 'REPLICA_ID', 'value': str(i)},
                    {'name': 'APP_NAME', 'value': app_name}
                ]
                self.create_pod(pod_name, pod_spec_copy)
                
        # Scale down if needed
        elif current_count > desired_replicas:
            pods_to_delete = current_pods[desired_replicas:]
            for pod in pods_to_delete:
                self.delete_pod(pod['metadata']['name'])
                
        # Health check existing pods
        for pod in current_pods[:desired_replicas]:
            healthy, reason = self.check_pod_health(pod)
            if not healthy:
                self.log(f"Pod unhealthy: {reason}")
                self.auto_heal_pod(pod['metadata']['name'], reason)
                
    def run_control_loop(self):
        """Main control loop"""
        self.log("Starting custom pod controller...")
        
        # Sample workload configuration
        workloads = [
            {
                'name': 'web-app',
                'replicas': 2,
                'pod_spec': {
                    'containers': [{
                        'name': 'nginx',
                        'image': 'nginx:1.21-alpine',
                        'ports': [{'containerPort': 80}],
                        'resources': {
                            'requests': {'memory': '64Mi', 'cpu': '50m'},
                            'limits': {'memory': '128Mi', 'cpu': '100m'}
                        },
                        'livenessProbe': {
                            'httpGet': {'path': '/', 'port': 80},
                            'initialDelaySeconds': 10,
                            'periodSeconds': 30
                        }
                    }],
                    'restartPolicy': 'Always'
                }
            }
        ]
        
        try:
            while True:
                self.log("Running control loop...")
                
                for workload in workloads:
                    try:
                        self.manage_workload(workload)
                    except Exception as e:
                        self.log(f"Error managing workload {workload['name']}: {e}")
                        
                self.log(f"Sleeping for {self.check_interval} seconds...")
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            self.log("Shutting down controller...")
            
        except Exception as e:
            self.log(f"Controller error: {e}")
            
    def cleanup(self):
        """Clean up managed resources"""
        self.log("Cleaning up managed pods...")
        pods = self.get_pods_by_label("managed-by=custom-controller")
        for pod in pods:
            self.delete_pod(pod['metadata']['name'])

if __name__ == "__main__":
    import sys
    
    controller = PodController()
    
    if len(sys.argv) > 1 and sys.argv[1] == "cleanup":
        controller.cleanup()
    else:
        controller.run_control_loop()
```

**Usage:**
```bash
# Make the script executable
chmod +x custom-pod-controller.py

# Install dependencies
pip3 install pyyaml

# Run the controller
python3 custom-pod-controller.py

# In another terminal, watch the managed pods
watch kubectl get pods -l managed-by=custom-controller

# Simulate pod failures
kubectl delete pod web-app-0  # Controller will recreate it

# Clean up when done
python3 custom-pod-controller.py cleanup
```

### üéØ Mini-Project 5: Pod Performance Optimization Lab

Create a comprehensive performance optimization laboratory:

```yaml
# performance-lab-setup.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: performance-lab
---
# Baseline pod - unoptimized
apiVersion: v1
kind: Pod
metadata:
  name: baseline-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: baseline
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "1000m"
      limits:
        memory: "2Gi"
        cpu: "2000m"
---
# Optimized pod - resource-efficient
apiVersion: v1
kind: Pod
metadata:
  name: optimized-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: optimized
spec:
  containers:
  - name: app
    image: nginx:1.21-alpine  # Smaller image
    resources:
      requests:
        memory: "64Mi"        # Right-sized requests
        cpu: "100m"
      limits:
        memory: "128Mi"       # Conservative limits
        cpu: "200m"
    # Optimized health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5   # Faster startup
      periodSeconds: 30        # Less frequent checks
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
    # Security optimizations
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
    # Volume optimizations
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp-dir
    emptyDir:
      medium: Memory  # Use memory for temp files
      sizeLimit: 64Mi
  - name: var-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: var-run
    emptyDir:
      sizeLimit: 32Mi
---
# High-performance pod with advanced optimizations
apiVersion: v1
kind: Pod
metadata:
  name: high-performance-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: high-performance
spec:
  # Pod-level optimizations
  priorityClassName: high-priority
  nodeSelector:
    node-type: performance
  tolerations:
  - key: performance-node
    operator: Equal
    value: "true"
    effect: NoSchedule
  # Network optimizations
  dnsPolicy: ClusterFirstWithHostNet
  dnsConfig:
    options:
    - name: ndots
      value: "1"
    - name: edns0
  containers:
  - name: app
    image: nginx:1.21-alpine
    # Optimized resource allocation
    resources:
      requests:
        memory: "128Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "256Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
    # Performance-tuned environment
    env:
    - name: NGINX_WORKER_PROCESSES
      value: "auto"
    - name: NGINX_WORKER_CONNECTIONS
      value: "1024"
    # Aggressive health checks for faster recovery
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 15
      timeoutSeconds: 2
      failureThreshold: 2
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 3
      timeoutSeconds: 1
      failureThreshold: 1
    # Startup optimization
    startupProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 1
      timeoutSeconds: 1
      failureThreshold: 10
    # Performance-optimized volumes
    volumeMounts:
    - name: high-speed-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
  volumes:
  - name: high-speed-tmp
    emptyDir:
      medium: Memory
      sizeLimit: 128Mi
  - name: nginx-cache
    emptyDir:
      medium: Memory
      sizeLimit: 256Mi
  - name: nginx-run
    emptyDir:
      medium: Memory
      sizeLimit: 64Mi
```

**Performance Benchmarking Script:**
```bash
#!/bin/bash
# performance-benchmark.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

NAMESPACE="performance-lab"

# Deploy the performance lab
setup_lab() {
    log "Setting up performance lab..."
    kubectl apply -f performance-lab-setup.yaml
    
    log "Waiting for pods to be ready..."
    kubectl wait --for=condition=Ready pod/baseline-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/optimized-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/high-performance-app -n $NAMESPACE --timeout=120s
    
    success "Performance lab setup complete"
}

# Measure startup time
measure_startup_time() {
    local pod_name=$1
    log "Measuring startup time for $pod_name..."
    
    # Delete and recreate pod to measure startup
    kubectl delete pod $pod_name -n $NAMESPACE
    local start_time=$(date +%s.%N)
    
    # Recreate the pod (extract from original manifest)
    kubectl get pod $pod_name -n $NAMESPACE -o yaml --export 2>/dev/null | kubectl apply -f - 2>/dev/null || {
        warning "Couldn't recreate pod automatically, recreating from manifest"
        kubectl apply -f performance-lab-setup.yaml
    }
    
    # Wait for ready and measure time
    kubectl wait --for=condition=Ready pod/$pod_name -n $NAMESPACE --timeout=120s
    local end_time=$(date +%s.%N)
    
    local startup_time=$(echo "$end_time - $start_time" | bc -l)
    echo "$startup_time"
}

# Run load test on a pod
load_test_pod() {
    local pod_name=$1
    local duration=${2:-30}
    local concurrency=${3:-10}
    
    log "Running load test on $pod_name (${duration}s, ${concurrency} concurrent)"
    
    # Start port forwarding
    kubectl port-forward pod/$pod_name -n $NAMESPACE 8080:80 >/dev/null 2>&1 &
    local pf_pid=$!
    sleep 3
    
    # Use Apache Bench for load testing
    local results_file="/tmp/ab_results_${pod_name}.txt"
    
    if command -v ab >/dev/null; then
        ab -n $((duration * concurrency)) -c $concurrency -g /tmp/gnuplot_${pod_name}.dat \
           http://localhost:8080/ > $results_file 2>&1
        
        # Extract key metrics
        local rps=$(grep "Requests per second" $results_file | awk '{print $4}')
        local response_time=$(grep "Time per request.*mean" $results_file | head -1 | awk '{print $4}')
        local failed_requests=$(grep "Failed requests" $results_file | awk '{print $3}')
        
        echo "RPS:$rps,ResponseTime:$response_time,Failed:$failed_requests"
    else
        # Fallback to curl-based test
        local start_time=$(date +%s)
        local requests=0
        local total_time=0
        
        for i in $(seq 1 $((duration * concurrency))); do
            local req_start=$(date +%s.%N)
            if curl -s http://localhost:8080 >/dev/null 2>&1; then
                ((requests++))
            fi
            local req_end=$(date +%s.%N)
            local req_time=$(echo "$req_end - $req_start" | bc -l)
            total_time=$(echo "$total_time + $req_time" | bc -l)
            
            # Basic rate limiting
            sleep 0.1
        done
        
        local avg_response_time=$(echo "scale=3; $total_time / $requests" | bc -l)
        local rps=$(echo "scale=2; $requests / $duration" | bc -l)
        
        echo "RPS:$rps,ResponseTime:$avg_response_time,Failed:0"
    fi
    
    kill $pf_pid 2>/dev/null
}

# Get resource usage metrics
get_resource_usage() {
    local pod_name=$1
    log "Getting resource usage for $pod_name..."
    
    if kubectl top pod $pod_name -n $NAMESPACE >/dev/null 2>&1; then
        kubectl top pod $pod_name -n $NAMESPACE --no-headers | awk '{print "CPU:"$2",Memory:"$3}'
    else
        echo "CPU:N/A,Memory:N/A"
    fi
}

# Comprehensive benchmark
run_comprehensive_benchmark() {
    log "Running comprehensive performance benchmark..."
    
    declare -A results
    local pods=("baseline-app" "optimized-app" "high-performance-app")
    
    echo "=== Performance Benchmark Results ===" > benchmark_results.txt
    echo "Timestamp: $(date)" >> benchmark_results.txt
    echo "" >> benchmark_results.txt
    
    for pod in "${pods[@]}"; do
        log "Benchmarking $pod..."
        
        # Startup time measurement
        log "Measuring startup time for $pod..."
        # Skip startup measurement in this demo to avoid pod recreation issues
        startup_time="N/A"
        
        # Resource usage
        resource_usage=$(get_resource_usage $pod)
        
        # Load test
        load_results=$(load_test_pod $pod 30 10)
        
        # Pod status information
        pod_info=$(kubectl get pod $pod -n $NAMESPACE -o custom-columns=STATUS:.status.phase,READY:.status.conditions[?\(@.type==\"Ready\"\)].status,RESTARTS:.status.containerStatuses[0].restartCount --no-headers)
        
        # Store results
        results[$pod]="Startup:$startup_time,Resources:$resource_usage,Load:$load_results,Status:$pod_info"
        
        # Write to file
        cat >> benchmark_results.txt <<EOF

=== $pod ===
Startup Time: $startup_time seconds
Resource Usage: $resource_usage
Load Test Results: $load_results
Pod Status: $pod_info

EOF
    done
    
    # Generate comparison summary
    cat >> benchmark_results.txt <<EOF

=== Performance Summary ===
This benchmark compares three pod configurations:

1. Baseline App: Standard configuration with generous resource allocation
2. Optimized App: Resource-efficient with security hardening
3. High-Performance App: Maximum performance optimizations

Key Findings:
- Resource efficiency varies significantly between configurations
- Startup time impacts overall application availability
- Load handling capacity differs based on resource allocation
- Security optimizations may have performance trade-offs

Recommendations:
- Use optimized configuration for production workloads
- Consider high-performance setup for critical applications
- Monitor resource usage to fine-tune allocations
- Balance security and performance based on requirements

EOF
    
    success "Benchmark completed. Results saved to benchmark_results.txt"
    cat benchmark_results.txt
}

# Resource monitoring script
monitor_resources() {
    local duration=${1:-300}  # 5 minutes default
    log "Starting resource monitoring for ${duration} seconds..."
    
    local monitor_file="resource_monitor_$(date +%Y%m%d_%H%M%S).log"
    
    {
        echo "Timestamp,Pod,CPU,Memory,Status"
        local end_time=$(($(date +%s) + duration))
        
        while [ $(date +%s) -lt $end_time ]; do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            
            for pod in baseline-app optimized-app high-performance-app; do
                if kubectl get pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                    local status=$(kubectl get pod $pod -n $NAMESPACE -o jsonpath='{.status.phase}')
                    local usage="N/A,N/A"
                    
                    if kubectl top pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                        usage=$(kubectl top pod $pod -n $NAMESPACE --no-headers | awk '{print $2","$3}')
                    fi
                    
                    echo "$timestamp,$pod,$usage,$status"
                fi
            done
            
            sleep 10
        done
    } > $monitor_file
    
    success "Resource monitoring completed. Data saved to $monitor_file"
    
    # Generate simple analysis
    log "Generating resource usage analysis..."
    
    {
        echo "=== Resource Usage Analysis ==="
        echo ""
        
        for pod in baseline-app optimized-app high-performance-app; do
            echo "=== $pod ==="
            grep "$pod" $monitor_file | tail -10 | while IFS=',' read timestamp pod_name cpu memory status; do
                echo "[$timestamp] CPU: $cpu, Memory: $memory, Status: $status"
            done
            echo ""
        done
    } > resource_analysis.txt
    
    success "Analysis saved to resource_analysis.txt"
}

# Cleanup function
cleanup_lab() {
    log "Cleaning up performance lab..."
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -f benchmark_results.txt resource_*.log resource_analysis.txt
    rm -f /tmp/ab_results_*.txt /tmp/gnuplot_*.dat
    success "Cleanup completed"
}

# Main execution
main() {
    case "${1:-benchmark}" in
        "setup")
            setup_lab
            ;;
        "benchmark")
            setup_lab
            run_comprehensive_benchmark
            ;;
        "monitor")
            monitor_resources "${2:-300}"
            ;;
        "cleanup")
            cleanup_lab
            ;;
        "all")
            setup_lab
            run_comprehensive_benchmark
            monitor_resources 300
            echo ""
            success "Complete performance analysis finished!"
            echo "Files created:"
            echo "  - benchmark_results.txt"
            echo "  - resource_monitor_*.log"
            echo "  - resource_analysis.txt"
            ;;
        *)
            echo "Performance Lab - Pod Optimization Benchmark"
            echo ""
            echo "Usage: $0 <command> [options]"
            echo ""
            echo "Commands:"
            echo "  setup      - Set up the performance lab environment"
            echo "  benchmark  - Run comprehensive performance benchmark"
            echo "  monitor    - Monitor resource usage for specified duration"
            echo "  cleanup    - Remove all lab resources"
            echo "  all        - Run complete analysis (setup + benchmark + monitor)"
            echo ""
            echo "Examples:"
            echo "  $0 setup"
            echo "  $0 benchmark"
            echo "  $0 monitor 600  # Monitor for 10 minutes"
            echo "  $0 all          # Complete analysis"
            ;;
    esac
}

main "$@"
```

---

## Pod Troubleshooting Methodologies

### üîß Advanced Troubleshooting Toolkit

#### Example 8: Automated Diagnostic System

```bash
#!/bin/bash
# advanced-pod-diagnostics.sh

set -euo pipefail

# Enhanced diagnostic toolkit with automated problem detection
class PodDiagnostics {
    
# Configuration
NAMESPACE=${NAMESPACE:-default}
OUTPUT_DIR="./diagnostics-$(date +%Y%m%d-%H%M%S)"
VERBOSE=${VERBOSE:-false}

# Colors and formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'
BOLD='\033[1m'

# Logging functions with levels
log_debug() { [[ $VERBOSE == "true" ]] && echo -e "${CYAN}[DEBUG]${NC} $1"; }
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }

# Initialize diagnostics
init_diagnostics() {
    log_info "Initializing pod diagnostics system..."
    mkdir -p "$OUTPUT_DIR"/{logs,reports,metrics,manifests}
    
    # Create diagnostic report header
    cat > "$OUTPUT_DIR/diagnostic_report.md" <<EOF
# Pod Diagnostics Report

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)  
**Namespace:** $NAMESPACE  
**Output Directory:** $OUTPUT_DIR

---

EOF
    
    log_success "Diagnostics initialized in $OUTPUT_DIR"
}

# Comprehensive pod information gathering
gather_pod_info() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Gathering comprehensive information for pod: $pod_name"
    
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    mkdir -p "$pod_dir"
    
    # Basic pod information
    kubectl get pod "$pod_name" -n "$namespace" -o wide > "$pod_dir/basic_info.txt" 2>&1
    kubectl get pod "$pod_name" -n "$namespace" -o yaml > "$pod_dir/manifest.yaml" 2>&1
    
    # Detailed description
    kubectl describe pod "$pod_name" -n "$namespace" > "$pod_dir/description.txt" 2>&1
    
    # Events related to the pod
    kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
        --sort-by='.lastTimestamp' > "$pod_dir/events.txt" 2>&1
    
    # Container logs
    local containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}' 2>/dev/null)
    for container in $containers; do
        log_debug "Collecting logs for container: $container"
        kubectl logs "$pod_name" -n "$namespace" -c "$container" > "$pod_dir/logs_${container}.txt" 2>&1
        
        # Previous logs if container restarted
        kubectl logs "$pod_name" -n "$namespace" -c "$container" --previous > "$pod_dir/logs_${container}_previous.txt" 2>&1 || true
    done
    
    # Resource usage
    kubectl top pod "$pod_name" -n "$namespace" > "$pod_dir/resource_usage.txt" 2>&1 || echo "Metrics not available" > "$pod_dir/resource_usage.txt"
    
    log_success "Pod information gathered for $pod_name"
}

# Automated problem detection
detect_common_issues() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Running automated issue detection for $pod_name..."
    
    local issues_file="$pod_dir/detected_issues.md"
    echo "# Automated Issue Detection Report" > "$issues_file"
    echo "**Pod:** $pod_name" >> "$issues_file"
    echo "**Analysis Time:** $(date)" >> "$issues_file"
    echo "" >> "$issues_file"
    
    local issue_count=0
    
    # Check 1: Pod phase issues
    local phase=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.phase}' 2>/dev/null)
    if [[ "$phase" != "Running" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Pod Not Running
- **Severity:** High
- **Status:** Pod is in '$phase' phase instead of 'Running'
- **Impact:** Application unavailable
- **Investigation:** Check pod events and container status

EOF
    fi
    
    # Check 2: Container readiness issues
    local ready_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[?(@.ready==true)]}' | jq '. | length' 2>/dev/null || echo "0")
    local total_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers}' | jq '. | length' 2>/dev/null || echo "1")
    
    if [[ "$ready_containers" -lt "$total_containers" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Container Readiness Problems
- **Severity:** High
- **Status:** Only $ready_containers of $total_containers containers are ready
- **Impact:** Traffic routing may be affected
- **Investigation:** Check readiness probes and container logs

EOF
    fi
    
    # Check 3: Excessive restarts
    local restarts=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
    if [[ "$restarts" -gt 5 ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Excessive Container Restarts
- **Severity:** Medium
- **Status:** Container has restarted $restarts times
- **Impact:** Service instability and potential data loss
- **Investigation:** Check liveness probes, resource limits, and application logs

EOF
    fi
    
    # Check 4: Resource usage issues
    if kubectl top pod "$pod_name" -n "$namespace" >/dev/null 2>&1; then
        local cpu_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $2}' | sed 's/m$//')
        local memory_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $3}' | sed 's/Mi$//')
        
        if [[ "$cpu_usage" -gt 800 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High CPU Usage
- **Severity:** Medium
- **Status:** CPU usage is ${cpu_usage}m (> 800m threshold)
- **Impact:** Performance degradation and potential throttling
- **Investigation:** Check for CPU-intensive processes and consider scaling

EOF
        fi
        
        if [[ "$memory_usage" -gt 512 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High Memory Usage
- **Severity:** Medium  
- **Status:** Memory usage is ${memory_usage}Mi (> 512Mi threshold)
- **Impact:** Risk of OOM kills and service disruption
- **Investigation:** Check for memory leaks and optimize memory usage

EOF
        fi
    fi
    
    # Check 5: Image pull issues
    if grep -q "ImagePullBackOff\|ErrImagePull" "$pod_dir/description.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Image Pull Problems
- **Severity:** High
- **Status:** Unable to pull container image
- **Impact:** Pod cannot start
- **Investigation:** Check image name, registry access, and credentials

EOF
    fi
    
    # Check 6: Resource constraints
    if grep -q "Insufficient.*resources" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Resource Constraints
- **Severity:** High
- **Status:** Insufficient cluster resources for pod scheduling
- **Impact:** Pod cannot be scheduled
- **Investigation:** Check cluster capacity and node resources

EOF
    fi
    
    # Check 7: Network issues
    if grep -q "NetworkNotReady\|CNI.*error" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Network Configuration Problems
- **Severity:** High
- **Status:** Network setup issues detected
- **Impact:** Pod networking may not function correctly
- **Investigation:** Check CNI configuration and network policies

EOF
    fi
    
    # Summary
    if [[ $issue_count -eq 0 ]]; then
        echo "## Summary: No Critical Issues Detected ‚úÖ" >> "$issues_file"
        echo "The automated analysis found no obvious problems with this pod." >> "$issues_file"
        log_success "No critical issues detected for $pod_name"
    else
        echo "## Summary: $issue_count Issue(s) Detected ‚ö†Ô∏è" >> "$issues_file"
        echo "Review the issues above and follow the investigation recommendations." >> "$issues_file"
        log_warn "$issue_count issue(s) detected for $pod_name"
    fi
    
    return $issue_count
}

# Generate recommendations
generate_recommendations() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Generating recommendations for $pod_name..."
    
    local rec_file="$pod_dir/recommendations.md"
    echo "# Optimization Recommendations" > "$rec_file"
    echo "**Pod:** $pod_name" >> "$rec_file"
    echo "" >> "$rec_file"
    
    # Resource optimization recommendations
    echo "## Resource Optimization" >> "$rec_file"
    
    # Check current resource configuration
    local requests_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.memory}' 2>/dev/null || echo "not set")
    local requests_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.cpu}' 2>/dev/null || echo "not set")
    local limits_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.memory}' 2>/dev/null || echo "not set")
    local limits_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.cpu}' 2>/dev/null || echo "not set")
    
    cat >> "$rec_file" <<EOF
### Current Resource Configuration
- **Memory Request:** $requests_mem
- **CPU Request:** $requests_cpu  
- **Memory Limit:** $limits_mem
- **CPU Limit:** $limits_cpu

EOF
    
    # Security recommendations
    echo "## Security Hardening" >> "$rec_file"
    
    local security_context=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.securityContext}' 2>/dev/null)
    if [[ -z "$security_context" || "$security_context" == "null" ]]; then
        cat >> "$rec_file" <<EOF
### Security Context Improvements
- ‚úÖ **Add security context:** Configure runAsNonRoot, runAsUser, and fsGroup
- ‚úÖ **Drop capabilities:** Remove unnecessary Linux capabilities  
- ‚úÖ **Read-only root filesystem:** Set readOnlyRootFilesystem: true
- ‚úÖ **Prevent privilege escalation:** Set allowPrivilegeEscalation: false

EOF
    fi
    
    # Health check recommendations
    echo "## Health Check Optimization" >> "$rec_file"
    
    local has_liveness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].livenessProbe}' 2>/dev/null)
    local has_readiness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].readinessProbe}' 2>/dev/null)
    
    if [[ -z "$has_liveness" || "$has_liveness" == "null" ]]; then
        echo "- ‚úÖ **Add liveness probe:** Implement health checking for automatic restart" >> "$rec_file"
    fi
    
    if [[ -z "$has_readiness" || "$has_readiness" == "null" ]]; then
        echo "- ‚úÖ **Add readiness probe:** Control traffic routing based on application readiness" >> "$rec_file"
    fi
    
    # Performance recommendations
    echo "" >> "$rec_file"
    echo "## Performance Optimization" >> "$rec_file"
    cat >> "$rec_file" <<EOF
- ‚úÖ **Use Alpine images:** Reduce image size and startup time
- ‚úÖ **Implement resource requests:** Help scheduler make better placement decisions
- ‚úÖ **Optimize health check frequency:** Balance responsiveness with overhead
- ‚úÖ **Use memory-backed volumes:** For temporary files and caches
- ‚úÖ **Configure DNS caching:** Reduce DNS lookup overhead

EOF
    
    log_success "Recommendations generated for $pod_name"
}

# Interactive diagnostic session
interactive_diagnostics() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Starting interactive diagnostics for $pod_name..."
    
    echo -e "${BOLD}Interactive Pod Diagnostics${NC}"
    echo "Pod: $pod_name"
    echo "Namespace: $namespace"
    echo ""
    
    while true; do
        echo -e "${CYAN}Available actions:${NC}"
        echo "1) Show pod status"
        echo "2) View recent events"
        echo "3) Check container logs"
        echo "4) Execute command in pod"
        echo "5) Port forward to pod"
        echo "6) Resource usage"
        echo "7) Run full diagnostic"
        echo "8) Generate recommendations"
        echo "q) Quit"
        echo ""
        
        read -p "Select action [1-8,q]: " choice
        
        case $choice in
            1)
                echo "=== Pod Status ==="
                kubectl get pod "$pod_name" -n "$namespace" -o wide
```" \
        10
    
    check_item "Memory requests defined" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.spec.containers[0].resources.requests.memory}' | grep -v '^
                kubectl describe pod "$pod_name" -n "$namespace" | grep -A 10 "Status\|Conditions"
                ;;
            2)
                echo "=== Recent Events ==="
                kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
                    --sort-by='.lastTimestamp' | tail -10
                ;;
            3)
                echo "=== Container Selection ==="
                local containers=($(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}'))
                if [[ ${#containers[@]} -eq 1 ]]; then
                    echo "Showing logs for container: ${containers[0]}"
                    kubectl logs "$pod_name" -n "$namespace" --tail=50
                else
                    echo "Available containers:"
                    for i in "${!containers[@]}"; do
                        echo "$((i+1))) ${containers[i]}"
                    done
                    read -p "Select container [1-${#containers[@]}]: " container_choice
                    if [[ $container_choice -ge 1 && $container_choice -le ${#containers[@]} ]]; then
                        local selected_container=${containers[$((container_choice-1))]}
                        echo "Showing logs for container: $selected_container"
                        kubectl logs "$pod_name" -n "$namespace" -c "$selected_container" --tail=50
                    fi
                fi
                ;;
            4)
                read -p "Enter command to execute: " exec_command
                kubectl exec -it "$pod_name" -n "$namespace" -- $exec_command
                ;;
            5)
                read -p "Enter local port: " local_port
                read -p "Enter pod port: " pod_port
                echo "Port forwarding $local_port:$pod_port - Press Ctrl+C to stop"
                kubectl port-forward "$pod_name" -n "$namespace" "$local_port:$pod_port"
                ;;
            6)
                echo "=== Resource Usage ==="
                kubectl top pod "$pod_name" -n "$namespace" 2>/dev/null || echo "Metrics not available"
                ;;
            7)
                gather_pod_info "$pod_name" "$namespace"
                detect_common_issues "$pod_name" "$namespace"
                generate_recommendations "$pod_name" "$namespace"
                echo "Full diagnostic completed. Check $OUTPUT_DIR/pods/$pod_name/"
                ;;
            8)
                generate_recommendations "$pod_name" "$namespace"
                echo "Recommendations generated. Check $OUTPUT_DIR/pods/$pod_name/recommendations.md"
                ;;
            q|Q)
                log_info "Exiting interactive diagnostics"
                break
                ;;
            *)
                echo "Invalid choice. Please try again."
                ;;
        esac
        
        echo ""
        read -p "Press Enter to continue..."
        echo ""
    done
}

# Cluster-wide pod health assessment
cluster_health_assessment() {
    log_info "Running cluster-wide pod health assessment..."
    
    local health_report="$OUTPUT_DIR/cluster_health_report.md"
    
    cat > "$health_report" <<EOF
# Cluster Pod Health Assessment

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)

---

EOF
    
    # Get all namespaces
    local namespaces=($(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'))
    
    local total_pods=0
    local healthy_pods=0
    local unhealthy_pods=0
    
    for ns in "${namespaces[@]}"; do
        log_info "Assessing namespace: $ns"
        
        local pods=($(kubectl get pods -n "$ns" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null))
        
        if [[ ${#pods[@]} -eq 0 ]]; then
            continue
        fi
        
        echo "## Namespace: $ns" >> "$health_report"
        echo "" >> "$health_report"
        
        local ns_healthy=0
        local ns_unhealthy=0
        
        for pod in "${pods[@]}"; do
            ((total_pods++))
            
            local phase=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.phase}')
            local ready_condition=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
            local restarts=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
            
            if [[ "$phase" == "Running" && "$ready_condition" == "True" && $restarts -lt 5 ]]; then
                ((healthy_pods++))
                ((ns_healthy++))
                echo "‚úÖ **$pod** - Healthy" >> "$health_report"
            else
                ((unhealthy_pods++))
                ((ns_unhealthy++))
                echo "‚ùå **$pod** - Issues detected (Phase: $phase, Ready: $ready_condition, Restarts: $restarts)" >> "$health_report"
                
                # Run quick diagnostics for unhealthy pods
                gather_pod_info "$pod" "$ns"
                detect_common_issues "$pod" "$ns"
            fi
        done
        
        echo "" >> "$health_report"
        echo "**Namespace Summary:** $ns_healthy healthy, $ns_unhealthy unhealthy" >> "$health_report"
        echo "" >> "$health_report"
    done
    
    # Overall summary
    local health_percentage=$((healthy_pods * 100 / total_pods))
    
    cat >> "$health_report" <<EOF

---

## Overall Cluster Health

- **Total Pods:** $total_pods
- **Healthy Pods:** $healthy_pods
- **Unhealthy Pods:** $unhealthy_pods
- **Health Percentage:** $health_percentage%

### Health Status
EOF
    
    if [[ $health_percentage -ge 90 ]]; then
        echo "üü¢ **EXCELLENT** - Cluster is in excellent health" >> "$health_report"
    elif [[ $health_percentage -ge 75 ]]; then
        echo "üü° **GOOD** - Cluster is in good health with minor issues" >> "$health_report"
    elif [[ $health_percentage -ge 50 ]]; then
        echo "üü† **WARNING** - Cluster has significant health issues" >> "$health_report"
    else
        echo "üî¥ **CRITICAL** - Cluster is in critical condition" >> "$health_report"
    fi
    
    log_success "Cluster health assessment completed. Report: $health_report"
}

# Generate comprehensive diagnostic report
generate_final_report() {
    log_info "Generating comprehensive diagnostic report..."
    
    local final_report="$OUTPUT_DIR/comprehensive_report.html"
    
    cat > "$final_report" <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Pod Diagnostics Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
        .header { background-color: #f4f4f4; padding: 20px; border-radius: 5px; margin-bottom: 30px; }
        .section { margin: 30px 0; }
        .pod-card { border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin: 10px 0; }
        .healthy { border-left: 5px solid #28a745; }
        .unhealthy { border-left: 5px solid #dc3545; }
        .warning { border-left: 5px solid #ffc107; }
        .metric { display: inline-block; margin: 10px 15px 10px 0; padding: 8px 12px; background-color: #e9ecef; border-radius: 3px; }
        .issue { background-color: #fff3cd; padding: 10px; border-radius: 3px; margin: 10px 0; }
        pre { background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }
        .tabs { border-bottom: 1px solid #ddd; margin-bottom: 20px; }
        .tab { display: inline-block; padding: 10px 20px; cursor: pointer; border-bottom: 2px solid transparent; }
        .tab.active { border-bottom-color: #007bff; color: #007bff; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }
    </style>
    <script>
        function showTab(tabName) {
            // Hide all tab contents
            var contents = document.getElementsByClassName('tab-content');
            for (var i = 0; i < contents.length; i++) {
                contents[i].classList.remove('active');
            }
            
            // Remove active class from all tabs
            var tabs = document.getElementsByClassName('tab');
            for (var i = 0; i < tabs.length; i++) {
                tabs[i].classList.remove('active');
            }
            
            // Show selected tab content and mark tab as active
            document.getElementById(tabName).classList.add('active');
            event.target.classList.add('active');
        }
    </script>
</head>
<body>
    <div class="header">
        <h1>üîç Pod Diagnostics Report</h1>
        <div class="metric">
            <strong>Generated:</strong> $(date)
        </div>
        <div class="metric">
            <strong>Cluster:</strong> $(kubectl config current-context)
        </div>
        <div class="metric">
            <strong>Diagnostics Version:</strong> 2.0
        </div>
    </div>
    
    <div class="tabs">
        <div class="tab active" onclick="showTab('overview')">Overview</div>
        <div class="tab" onclick="showTab('pods')">Pod Analysis</div>
        <div class="tab" onclick="showTab('issues')">Detected Issues</div>
        <div class="tab" onclick="showTab('recommendations')">Recommendations</div>
    </div>
    
    <div id="overview" class="tab-content active">
        <h2>üìä Cluster Overview</h2>
        <div class="section">
EOF
    
    # Add cluster metrics
    local total_nodes=$(kubectl get nodes --no-headers | wc -l)
    local ready_nodes=$(kubectl get nodes --no-headers | grep " Ready " | wc -l)
    local total_namespaces=$(kubectl get namespaces --no-headers | wc -l)
    
    cat >> "$final_report" <<EOF
            <div class="pod-card healthy">
                <h3>Cluster Metrics</h3>
                <div class="metric"><strong>Nodes:</strong> $ready_nodes/$total_nodes Ready</div>
                <div class="metric"><strong>Namespaces:</strong> $total_namespaces</div>
                <div class="metric"><strong>Kubernetes Version:</strong> $(kubectl version --short --client | cut -d' ' -f3)</div>
            </div>
        </div>
    </div>
    
    <div id="pods" class="tab-content">
        <h2>üöÄ Pod Analysis</h2>
EOF
    
    # Add pod analysis for each analyzed pod
    for pod_dir in "$OUTPUT_DIR"/pods/*/; do
        if [[ -d "$pod_dir" ]]; then
            local pod_name=$(basename "$pod_dir")
            local issues_count=0
            
            if [[ -f "$pod_dir/detected_issues.md" ]]; then
                issues_count=$(grep -c "## Issue" "$pod_dir/detected_issues.md" 2>/dev/null || echo "0")
            fi
            
            local card_class="healthy"
            if [[ $issues_count -gt 0 ]]; then
                card_class="unhealthy"
            fi
            
            cat >> "$final_report" <<EOF
        <div class="pod-card $card_class">
            <h3>üì¶ $pod_name</h3>
            <div class="metric"><strong>Issues Detected:</strong> $issues_count</div>
            <div class="metric"><strong>Analysis Files:</strong> $(ls "$pod_dir" | wc -l)</div>
            <div class="metric"><strong>Report Location:</strong> pods/$pod_name/</div>
        </div>
EOF
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="issues" class="tab-content">
        <h2>‚ö†Ô∏è Detected Issues</h2>
EOF
    
    # Aggregate all issues
    local total_issues=0
    for issues_file in "$OUTPUT_DIR"/pods/*/detected_issues.md; do
        if [[ -f "$issues_file" ]]; then
            local pod_issues=$(grep -c "## Issue" "$issues_file" 2>/dev/null || echo "0")
            ((total_issues += pod_issues))
            
            if [[ $pod_issues -gt 0 ]]; then
                local pod_name=$(basename "$(dirname "$issues_file")")
                echo "<h3>Issues for $pod_name</h3>" >> "$final_report"
                
                # Convert markdown issues to HTML
                grep "## Issue" "$issues_file" | while read -r line; do
                    echo "<div class=\"issue\">$line</div>" >> "$final_report"
                done
            fi
        fi
    done
    
    if [[ $total_issues -eq 0 ]]; then
        echo "<div class=\"pod-card healthy\"><h3>‚úÖ No Issues Detected</h3><p>All analyzed pods appear to be healthy!</p></div>" >> "$final_report"
    fi
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="recommendations" class="tab-content">
        <h2>üí° Recommendations</h2>
        <div class="section">
            <div class="pod-card warning">
                <h3>General Recommendations</h3>
                <ul>
                    <li>‚úÖ Implement comprehensive health checks for all pods</li>
                    <li>‚úÖ Set appropriate resource requests and limits</li>
                    <li>‚úÖ Use security contexts to harden pod security</li>
                    <li>‚úÖ Monitor resource usage and optimize accordingly</li>
                    <li>‚úÖ Implement graceful shutdown handling</li>
                    <li>‚úÖ Use multi-stage Docker builds for smaller images</li>
                    <li>‚úÖ Implement proper logging and observability</li>
                </ul>
            </div>
        </div>
EOF
    
    # Add pod-specific recommendations
    for rec_file in "$OUTPUT_DIR"/pods/*/recommendations.md; do
        if [[ -f "$rec_file" ]]; then
            local pod_name=$(basename "$(dirname "$rec_file")")
            echo "<div class=\"pod-card\"><h3>Recommendations for $pod_name</h3>" >> "$final_report"
            echo "<p>See detailed recommendations in: pods/$pod_name/recommendations.md</p></div>" >> "$final_report"
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div class="section">
        <hr>
        <p><em>Report generated by Pod Diagnostics Toolkit v2.0</em></p>
        <p><em>For detailed analysis, check individual files in the diagnostics output directory.</em></p>
    </div>
    
</body>
</html>
EOF
    
    log_success "Comprehensive report generated: $final_report"
    echo ""
    echo -e "${BOLD}üìã Diagnostic Summary:${NC}"
    echo "- Output Directory: $OUTPUT_DIR"
    echo "- HTML Report: $final_report"
    echo "- Total Issues Found: $total_issues"
    echo ""
    echo -e "${CYAN}üí° Next Steps:${NC}"
    echo "1. Open $final_report in your browser"
    echo "2. Review individual pod analysis in $OUTPUT_DIR/pods/"
    echo "3. Implement recommended fixes"
    echo "4. Re-run diagnostics to verify improvements"
}

# Main execution function
main() {
    local command=${1:-help}
    local pod_name=${2:-}
    local namespace=${3:-$NAMESPACE}
    
    case "$command" in
        "analyze")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for analysis"
                echo "Usage: $0 analyze <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            gather_pod_info "$pod_name" "$namespace"
            detect_common_issues "$pod_name" "$namespace"
            generate_recommendations "$pod_name" "$namespace"
            generate_final_report
            ;;
            
        "interactive")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for interactive mode"
                echo "Usage: $0 interactive <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            interactive_diagnostics "$pod_name" "$namespace"
            ;;
            
        "cluster-health")
            init_diagnostics
            cluster_health_assessment
            generate_final_report
            ;;
            
        "help"|*)
            cat <<EOF
üîç Advanced Pod Diagnostics Toolkit

Usage: $0 <command> [options]

Commands:
  analyze <pod-name> [namespace]     - Run comprehensive pod analysis
  interactive <pod-name> [namespace] - Start interactive diagnostic session
  cluster-health                     - Assess health of all pods in cluster
  help                              - Show this help message

Environment Variables:
  NAMESPACE - Default namespace (default: default)
  VERBOSE   - Enable verbose output (default: false)

Examples:
  $0 analyze nginx-pod production
  $0 interactive web-app-123
  $0 cluster-health
  VERBOSE=true $0 analyze problematic-pod

Output:
  All diagnostic data is saved to ./diagnostics-TIMESTAMP/
  HTML report provides comprehensive overview
  Individual pod analysis available in pods/ subdirectory

EOF
            ;;
    esac
}

# Execute main function
main "$@"
```

---

## Summary and Production-Ready Examples

### üèÜ Complete Production Workflow

Let's create a final comprehensive example that brings everything together:

```yaml
# complete-production-workflow.yaml
# This represents a complete production-ready pod deployment workflow

apiVersion: v1
kind: Namespace
metadata:
  name: production-workload
  labels:
    environment: production
    team: platform
---
# ConfigMap for application configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production-workload
data:
  app.properties: |
    server.port=8080
    management.port=8081
    logging.level=INFO
    metrics.enabled=true
  nginx.conf: |
    server {
        listen 80;
        location /health { return 200 'healthy\n'; }
        location /ready { return 200 'ready\n'; }
        location / {
            proxy_pass http://127.0.0.1:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
---
# Secret for sensitive configuration
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: production-workload
type: Opaque
data:
  database-password: c3VwZXJzZWNyZXQ=  # supersecret (base64)
  api-key: YWJjZGVmZ2hpams=  # abcdefghijk (base64)
---
# Production-ready pod with all best practices
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production-workload
  labels:
    app: production-app
    version: "2.1.0"
    environment: production
    team: platform
    component: backend
  annotations:
    description: "Production application with full observability"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/production-app"
    prometheus.io/scrape: "true"
    prometheus.io/port: "8081"
    prometheus.io/path: "/metrics"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Resource constraints and node placement
  nodeSelector:
    node-type: "application"
    performance-tier: "high"
    
  tolerations:
  - key: "dedicated-app"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
    
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: production-app
        topologyKey: kubernetes.io/hostname
        
  # DNS and network configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  # Init container for setup tasks
  initContainers:
  - name: setup
    image: busybox:1.35
    command:
    - /bin/sh
    - -c
    - |
      echo "Initializing application..."
      
      # Database migration simulation
      echo "Running database migrations..."
      sleep 5
      
      # Cache warming
      echo "Warming up caches..."
      sleep 3
      
      # Configuration validation
      echo "Validating configuration..."
      if [ -f /config/app.properties ]; then
        echo "‚úÖ Configuration file found"
      else
        echo "‚ùå Configuration file missing"
        exit 1
      fi
      
      echo "Initialization completed successfully"
      
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-init
      mountPath: /tmp
      
  # Main application containers
  containers:
  # Application container
  - name: app
    image: openjdk:11-jre-slim
    command:
    - /bin/bash
    - -c
    - |
      echo "Starting application..."
      
      # Simulated application startup
      java -Xmx200m -Xms100m -jar /app/application.jar \
        --spring.config.location=file:/config/app.properties \
        --server.port=8080 \
        --management.server.port=8081
        
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP
    - name: management
      containerPort: 8081
      protocol: TCP
      
    # Environment configuration
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # Sensitive configuration from secrets
    - name: DATABASE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: database-password
    - name: API_KEY
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: api-key
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security hardening
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    # Comprehensive health checks
    livenessProbe:
      httpGet:
        path: /actuator/health/liveness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /actuator/health/readiness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /actuator/health
        port: 8081
      initialDelaySeconds: 20
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle management
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Application started at $(date)" >> /tmp/startup.log
            # Custom post-start logic here
            
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Graceful shutdown initiated at $(date)" >> /tmp/shutdown.log
            # Send SIGTERM to application
            kill -TERM 1
            # Wait for graceful shutdown
            sleep 30
            
    # Volume mounts
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-volume
      mountPath: /tmp
    - name: app-logs
      mountPath: /app/logs
    - name: app-data
      mountPath: /app/data
      
  # Nginx reverse proxy sidecar
  - name: nginx-proxy
    image: nginx:1.21-alpine
    ports:
    - name: http-proxy
      containerPort: 80
      protocol: TCP
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        add: ["NET_BIND_SERVICE"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: nginx-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
      
  # Logging and monitoring sidecar
  - name: log-shipper
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: fluent-tmp
      mountPath: /tmp
      
  # Volumes
  volumes:
  - name: config-volume
    configMap:
      name: app-config
      items:
      - key: app.properties
        path: app.properties
  - name: nginx-config
    configMap:
      name: app-config
      items:
      - key: nginx.conf
        path: default.conf
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config  # Would be created separately
  # Temporary and cache volumes
  - name: tmp-volume
    emptyDir:
      sizeLimit: 256Mi
  - name: tmp-init
    emptyDir:
      sizeLimit: 64Mi
  - name: nginx-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: fluent-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: nginx-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: nginx-run
    emptyDir:
      sizeLimit: 32Mi
  # Application data volumes
  - name: app-logs
    emptyDir:
      sizeLimit: 1Gi
  - name: app-data
    emptyDir:
      sizeLimit: 2Gi
```

This comprehensive example demonstrates:

- **Complete security hardening** with proper contexts and capabilities
- **Multi-container architecture** with main app, proxy, and logging sidecars
- **Comprehensive health checks** for all containers
- **Resource optimization** with appropriate requests and limits
- **Configuration management** using ConfigMaps and Secrets
- **Observability** with structured logging and metrics endpoints
- **Production-ready networking** with reverse proxy
- **Graceful lifecycle management** with init containers and shutdown hooks

## üéì Key Learning Outcomes

By working through these enhanced examples, demos, and mini-projects, you've gained:

1. **Foundation Skills**: Basic pod creation, inspection, and management
2. **Intermediate Capabilities**: Multi-container patterns, health monitoring, and debugging
3. **Advanced Techniques**: Performance optimization, security hardening, and automation
4. **Expert-Level Mastery**: Custom controllers, comprehensive diagnostics, and production workflows

### üöÄ Next Steps for Continued Learning

1. **Practice the Examples**: Work through each example in your own cluster
2. **Customize for Your Use Cases**: Adapt the patterns to your specific applications
3. **Build Your Toolkit**: Create your own diagnostic and management scripts
4. **Share and Learn**: Contribute back to the community with your own improvements
5. **Scale Up**: Apply these pod management skills to higher-level controllers

The journey from basic pod creation to# 5. Working with Pods - From Fundamentals to Mastery (Enhanced Edition)

Understanding how to work with pods effectively forms the foundation of all Kubernetes operations. While you'll typically use higher-level controllers like Deployments in production environments, direct pod management skills are essential for debugging, troubleshooting, and truly understanding how Kubernetes applications function at their core. Think of this knowledge as learning to drive a manual transmission car‚Äîeven if you usually drive automatic, understanding the underlying mechanics makes you a better driver overall.

This enhanced guide provides progressive examples, hands-on demos, and real-world mini-projects to solidify your understanding through practical application.

## üéØ Learning Path Overview

- **Foundation Level**: Basic pod creation and inspection
- **Intermediate Level**: Multi-container patterns and health checks
- **Advanced Level**: Complex debugging and optimization
- **Expert Level**: Custom tooling and automation

---

## Understanding Pod Creation Strategies

Creating pods effectively requires understanding when to use imperative commands versus declarative configurations, and how different creation approaches serve different purposes.

### üìö Foundation Examples

Let's start with the absolute basics and progressively build complexity.

#### Example 1: Your First Pod
```bash
# Create the simplest possible pod
kubectl run hello-world --image=nginx --restart=Never

# Verify it's running
kubectl get pods

# Expected output:
# NAME          READY   STATUS    RESTARTS   AGE
# hello-world   1/1     Running   0          30s
```

#### Example 2: Pod with Custom Commands
```bash
# Create a pod that runs a custom command
kubectl run date-pod --image=busybox --restart=Never -- date

# This pod will run the date command and then exit
# Check the output
kubectl logs date-pod

# Clean up
kubectl delete pod date-pod
```

#### Example 3: Interactive Pod Session
```bash
# Create an interactive debugging pod
kubectl run -it debug-pod --image=busybox --restart=Never -- sh

# Inside the pod, try these commands:
# ls -la
# ps aux
# ping google.com
# nslookup kubernetes.default.svc.cluster.local

# Exit and clean up
# exit
kubectl delete pod debug-pod
```

### üõ†Ô∏è Demo: Pod Lifecycle Observation

Let's create a demo that shows the complete pod lifecycle in action:

```bash
#!/bin/bash
# pod-lifecycle-demo.sh

echo "=== Pod Lifecycle Demonstration ==="

# Terminal 1: Start watching pods
echo "In a separate terminal, run: kubectl get pods -w"
echo "Press Enter when ready..."
read

# Create a pod with a slow-starting application
echo "Creating pod with slow startup..."
kubectl run lifecycle-demo --image=nginx --restart=Never \
  --dry-run=client -o yaml > lifecycle-pod.yaml

# Add some customizations to make it more interesting
cat <<EOF >> lifecycle-pod.yaml
  containers:
  - name: nginx
    image: nginx:1.21
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod starting up...' && sleep 10"
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod shutting down...' && sleep 5"
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 5
EOF

echo "Applying pod configuration..."
kubectl apply -f lifecycle-pod.yaml

echo "Watch the pod states change from Pending -> ContainerCreating -> Running"
echo "Press Enter to continue when pod is Running..."
read

# Show detailed pod information
echo "=== Pod Details ==="
kubectl describe pod lifecycle-demo

echo "Press Enter to delete the pod and observe termination..."
read

# Delete and watch termination
kubectl delete pod lifecycle-demo

echo "Demo complete! Clean up the YAML file:"
echo "rm lifecycle-pod.yaml"
```

### üéØ Mini-Project 1: Pod Resource Monitor

Create a simple monitoring system using pods:

```yaml
# resource-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-monitor
  labels:
    app: monitor
    type: demo
spec:
  containers:
  - name: monitor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Starting Resource Monitor..."
      while true; do
        echo "=== $(date) ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "Load average:"
        uptime
        echo "Sleeping for 30 seconds..."
        sleep 30
      done
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
  restartPolicy: Always
```

```bash
# Deploy and monitor
kubectl apply -f resource-monitor-pod.yaml

# Watch the logs
kubectl logs -f resource-monitor

# In another terminal, check resource usage
kubectl top pod resource-monitor

# Clean up
kubectl delete -f resource-monitor-pod.yaml
```

---

## Deep Pod Inspection and Monitoring

### üîç Intermediate Examples

#### Example 4: Multi-Container Pod Investigation

```yaml
# multi-container-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-demo
  labels:
    demo: multi-container
spec:
  containers:
  - name: web-server
    image: nginx:1.21
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
    
  - name: log-processor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Log processor starting..."
      while true; do
        if [ -f /var/log/nginx/access.log ]; then
          echo "=== Access Log Summary $(date) ==="
          tail -10 /var/log/nginx/access.log | wc -l
          echo "Recent requests:"
          tail -5 /var/log/nginx/access.log
        else
          echo "Waiting for access.log..."
        fi
        sleep 30
      done
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
      
  - name: metrics-collector
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Metrics collector starting..."
      while true; do
        echo "=== Metrics $(date) ==="
        echo "Container count: 3"
        echo "Uptime: $(uptime)"
        echo "Memory: $(free -h | grep Mem)"
        sleep 60
      done
      
  volumes:
  - name: shared-logs
    emptyDir: {}
```

**Inspection Commands:**
```bash
# Apply the multi-container pod
kubectl apply -f multi-container-demo.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/multi-container-demo

# Inspect different aspects
echo "=== Basic Information ==="
kubectl get pod multi-container-demo -o wide

echo "=== Container Status ==="
kubectl get pod multi-container-demo -o jsonpath='{.status.containerStatuses[*].name}' | tr ' ' '\n'

echo "=== Logs from each container ==="
kubectl logs multi-container-demo -c web-server --tail=5
kubectl logs multi-container-demo -c log-processor --tail=5
kubectl logs multi-container-demo -c metrics-collector --tail=5

# Generate some traffic to see shared volume in action
kubectl port-forward multi-container-demo 8080:80 &
PF_PID=$!

# Generate requests
for i in {1..10}; do
  curl -s http://localhost:8080 > /dev/null
  echo "Request $i sent"
  sleep 1
done

kill $PF_PID

# Check log processor output
kubectl logs multi-container-demo -c log-processor --tail=10

# Clean up
kubectl delete -f multi-container-demo.yaml
```

### üõ†Ô∏è Demo: Advanced Pod Debugging Techniques

```bash
#!/bin/bash
# advanced-debugging-demo.sh

echo "=== Advanced Pod Debugging Demo ==="

# Create a problematic pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: problematic-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "2000m"  # This might cause scheduling issues
      limits:
        memory: "512Mi"  # Less than request - invalid!
        cpu: "500m"
    livenessProbe:
      httpGet:
        path: /nonexistent
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
EOF

echo "Created a pod with multiple issues. Let's debug it..."

# Wait a moment for issues to manifest
sleep 10

echo "=== Debugging Steps ==="

echo "1. Check pod status:"
kubectl get pod problematic-pod -o wide

echo "2. Look at events:"
kubectl describe pod problematic-pod | grep -A 10 Events:

echo "3. Check for resource issues:"
kubectl describe pod problematic-pod | grep -A 5 -B 5 "resource"

echo "4. Examine container status:"
kubectl get pod problematic-pod -o jsonpath='{.status.containerStatuses[0]}' | jq '.'

# Fix the pod
echo "5. Let's fix the issues..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: fixed-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
EOF

echo "6. Compare the fixed pod:"
kubectl wait --for=condition=Ready pod/fixed-pod --timeout=60s
kubectl get pods -l debug=demo

# Clean up
echo "Cleaning up..."
kubectl delete pod problematic-pod fixed-pod
```

### üéØ Mini-Project 2: Pod Health Monitoring Dashboard

Create a comprehensive health monitoring system:

```yaml
# health-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: health-dashboard
  labels:
    app: health-monitor
spec:
  containers:
  - name: health-checker
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Health Dashboard Starting..."
      
      # Create a simple HTML dashboard
      mkdir -p /tmp/dashboard
      
      while true; do
        cat > /tmp/dashboard/health.html <<EOF
      <!DOCTYPE html>
      <html>
      <head>
          <title>Pod Health Dashboard</title>
          <meta http-equiv="refresh" content="30">
          <style>
              body { font-family: Arial, sans-serif; margin: 40px; }
              .healthy { color: green; }
              .warning { color: orange; }
              .critical { color: red; }
              .metric { margin: 10px 0; padding: 10px; border: 1px solid #ccc; }
          </style>
      </head>
      <body>
          <h1>Pod Health Dashboard</h1>
          <p>Last Update: $(date)</p>
          
          <div class="metric">
              <h3>System Load</h3>
              <p>$(uptime)</p>
          </div>
          
          <div class="metric">
              <h3>Memory Usage</h3>
              <pre>$(free -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Disk Usage</h3>
              <pre>$(df -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Process Count</h3>
              <p>Running processes: $(ps aux | wc -l)</p>
          </div>
          
      </body>
      </html>
      EOF
        
        echo "Dashboard updated at $(date)"
        sleep 30
      done
    volumeMounts:
    - name: dashboard-storage
      mountPath: /tmp/dashboard
      
  - name: web-server
    image: nginx:alpine
    ports:
    - containerPort: 80
    command:
    - /bin/sh
    - -c
    - |
      # Configure nginx to serve our dashboard
      cat > /etc/nginx/conf.d/default.conf <<EOF
      server {
          listen 80;
          location / {
              root /usr/share/nginx/html;
              index health.html;
          }
      }
      EOF
      
      # Start nginx
      nginx -g "daemon off;"
    volumeMounts:
    - name: dashboard-storage
      mountPath: /usr/share/nginx/html
      
  volumes:
  - name: dashboard-storage
    emptyDir: {}
    
  restartPolicy: Always
```

**Usage:**
```bash
# Deploy the health dashboard
kubectl apply -f health-monitor-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/health-dashboard

# Access the dashboard
kubectl port-forward health-dashboard 8080:80

# Open browser to http://localhost:8080
echo "Open http://localhost:8080 in your browser"

# Monitor the pod's own health
kubectl top pod health-dashboard

# Check logs from both containers
kubectl logs health-dashboard -c health-checker --tail=10
kubectl logs health-dashboard -c web-server --tail=10

# Clean up
kubectl delete -f health-monitor-pod.yaml
```

---

## Interactive Pod Management and Debugging

### üîß Advanced Examples

#### Example 5: Network Debugging Pod

```yaml
# network-debug-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: network-debugger
  labels:
    purpose: network-debug
spec:
  containers:
  - name: nettools
    image: nicolaka/netshoot
    command: ["/bin/bash"]
    args:
    - -c
    - |
      echo "Network debugging tools ready!"
      echo "Available tools: dig, nslookup, ping, curl, wget, tcpdump, netstat"
      echo "Example commands:"
      echo "  dig kubernetes.default.svc.cluster.local"
      echo "  ping 8.8.8.8"
      echo "  curl -I http://httpbin.org/headers"
      echo "  netstat -tulpn"
      
      # Keep container running
      sleep 3600
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
  restartPolicy: Never
```

**Debugging Session:**
```bash
# Deploy the network debugger
kubectl apply -f network-debug-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/network-debugger

# Start interactive session
kubectl exec -it network-debugger -- bash

# Inside the pod, run network diagnostics:
# Test DNS resolution
# dig kubernetes.default.svc.cluster.local

# Test external connectivity
# ping -c 3 8.8.8.8

# Test HTTP services
# curl -I https://httpbin.org/headers

# Check network interfaces
# ip addr show

# Check routing table
# ip route show

# Test service discovery
# nslookup kubernetes.default

# Exit and clean up
# exit
kubectl delete -f network-debug-pod.yaml
```

### üõ†Ô∏è Demo: File Transfer and Volume Management

```bash
#!/bin/bash
# file-transfer-demo.sh

echo "=== File Transfer and Volume Demo ==="

# Create a pod with persistent data
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: file-demo
spec:
  containers:
  - name: app
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Creating sample files..."
      mkdir -p /data/logs /data/config
      
      # Generate some sample data
      for i in {1..5}; do
        echo "Log entry \$i at \$(date)" >> /data/logs/app.log
        sleep 1
      done
      
      echo "app_name=demo-app" > /data/config/settings.conf
      echo "version=1.0.0" >> /data/config/settings.conf
      echo "debug=true" >> /data/config/settings.conf
      
      echo "Files created. Keeping container running..."
      sleep 3600
    volumeMounts:
    - name: data-storage
      mountPath: /data
  volumes:
  - name: data-storage
    emptyDir: {}
EOF

echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/file-demo

# Demonstrate file operations
echo "=== File Operations Demo ==="

echo "1. List files in the pod:"
kubectl exec file-demo -- find /data -type f

echo "2. Copy file from pod to local:"
kubectl cp file-demo:/data/logs/app.log ./app.log.backup
echo "File copied to: app.log.backup"
cat app.log.backup

echo "3. Create local config file:"
cat > new-config.conf <<EOF
app_name=updated-demo-app
version=2.0.0
debug=false
environment=production
EOF

echo "4. Copy local file to pod:"
kubectl cp new-config.conf file-demo:/data/config/

echo "5. Verify file in pod:"
kubectl exec file-demo -- cat /data/config/new-config.conf

echo "6. Create a backup of all data:"
kubectl exec file-demo -- tar -czf /tmp/backup.tar.gz -C /data .
kubectl cp file-demo:/tmp/backup.tar.gz ./pod-data-backup.tar.gz
echo "Backup created: pod-data-backup.tar.gz"

# Clean up
echo "Cleaning up..."
kubectl delete pod file-demo
rm -f app.log.backup new-config.conf pod-data-backup.tar.gz

echo "Demo complete!"
```

### üéØ Mini-Project 3: Pod Security Scanner

Create a security scanning tool using pods:

```yaml
# security-scanner-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-scanner
  labels:
    app: security
    type: scanner
spec:
  serviceAccountName: default
  containers:
  - name: scanner
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "=== Pod Security Scanner Starting ==="
      
      # Function to check security configurations
      check_security() {
        echo "Checking security configurations..."
        
        # Check if running as root
        if [ "$(id -u)" -eq 0 ]; then
          echo "‚ö†Ô∏è  WARNING: Running as root user"
        else
          echo "‚úÖ GOOD: Running as non-root user ($(id -u))"
        fi
        
        # Check filesystem permissions
        if [ -w "/" ]; then
          echo "‚ö†Ô∏è  WARNING: Root filesystem is writable"
        else
          echo "‚úÖ GOOD: Root filesystem is read-only"
        fi
        
        # Check for sensitive mounts
        if mount | grep -q "/var/run/secrets"; then
          echo "‚ÑπÔ∏è  INFO: Service account token mounted"
        fi
        
        # Check available capabilities
        echo "Current capabilities:"
        if [ -f "/proc/self/status" ]; then
          grep Cap /proc/self/status
        fi
        
        # Check network access
        echo "Testing network access..."
        if ping -c 1 8.8.8.8 >/dev/null 2>&1; then
          echo "‚ÑπÔ∏è  INFO: External network access available"
        else
          echo "‚ÑπÔ∏è  INFO: No external network access"
        fi
        
        # Generate security report
        cat > /tmp/security-report.txt <<EOF
      === Security Scan Report ===
      Timestamp: $(date)
      User ID: $(id -u)
      Group ID: $(id -g)
      Working Directory: $(pwd)
      
      Filesystem Check:
      - Root writable: $([ -w "/" ] && echo "YES" || echo "NO")
      - /tmp writable: $([ -w "/tmp" ] && echo "YES" || echo "NO")
      
      Network Check:
      - External access: $(ping -c 1 8.8.8.8 >/dev/null 2>&1 && echo "YES" || echo "NO")
      
      Process Information:
      $(ps aux)
      EOF
        
        echo "Report generated at /tmp/security-report.txt"
      }
      
      # Run security check
      check_security
      
      # Keep running for inspection
      echo "Scanner complete. Container will stay running for inspection."
      sleep 3600
      
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 1000
      runAsGroup: 3000
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir: {}
    
  restartPolicy: Never
```

**Usage:**
```bash
# Deploy the security scanner
kubectl apply -f security-scanner-pod.yaml

# Monitor the scan
kubectl logs -f security-scanner

# Get the security report
kubectl cp security-scanner:/tmp/security-report.txt ./security-report.txt
cat security-report.txt

# Create a comparison with an insecure pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: insecure-pod
spec:
  containers:
  - name: insecure
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      runAsUser: 0  # Running as root
      privileged: true
EOF

# Compare security postures
echo "=== Security Comparison ==="
echo "Secure pod user:"
kubectl exec security-scanner -- id

echo "Insecure pod user:"
kubectl exec insecure-pod -- id

echo "Secure pod capabilities:"
kubectl exec security-scanner -- grep Cap /proc/self/status

echo "Insecure pod capabilities:"
kubectl exec insecure-pod -- grep Cap /proc/self/status

# Clean up
kubectl delete pod security-scanner insecure-pod
rm -f security-report.txt
```

---

## Declarative Pod Configuration and Management

### üèóÔ∏è Expert Examples

#### Example 6: Production-Ready Pod Template

```yaml
# production-pod-template.yaml
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production
  labels:
    app: web-server
    version: "2.1.0"
    environment: production
    team: platform
  annotations:
    description: "Production web server with full monitoring and security"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/web-server"
    version: "2.1.0"
    build-date: "2024-01-15T10:30:00Z"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Node selection
  nodeSelector:
    node-type: "application"
    zone: "us-west-2a"
    
  # Tolerations for dedicated nodes
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "application"
    effect: "NoSchedule"
    
  # Pod placement preferences
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: "node-type"
            operator: In
            values: ["application"]
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: web-server
          topologyKey: kubernetes.io/hostname
          
  # DNS configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  containers:
  - name: web-server
    image: nginx:1.21-alpine
    imagePullPolicy: IfNotPresent
    
    ports:
    - name: http
      containerPort: 80
      protocol: TCP
    - name: metrics
      containerPort: 9113
      protocol: TCP
      
    # Environment variables
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "info"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security context
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE
        
    # Health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 80
        scheme: HTTP
        httpHeaders:
        - name: Custom-Header
          value: liveness-check
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
        scheme: HTTP
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle hooks
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container started at $(date)" >> /tmp/startup.log
            # Custom initialization logic here
            
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container stopping at $(date)" >> /tmp/shutdown.log
            # Graceful shutdown logic here
            nginx -s quit
            sleep 15
            
    # Volume mounts
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  # Sidecar container for log processing
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  # Monitoring sidecar
  - name: nginx-exporter
    image: nginx/nginx-prometheus-exporter:0.10.0
    args:
    - -nginx.scrape-uri=http://localhost:80/nginx_status
    ports:
    - name: metrics
      containerPort: 9113
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
  # Shared volumes
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
      defaultMode: 0644
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
      defaultMode: 0644
  - name: html-content
    configMap:
      name: html-content
      defaultMode: 0644
  - name: tmp-dir
    emptyDir:
      sizeLimit: 256Mi
  - name: var-cache-nginx
    emptyDir:
      sizeLimit: 512Mi
  - name: var-run
    emptyDir:
      sizeLimit: 64Mi
  - name: logs
    emptyDir:
      sizeLimit: 1Gi
```

### üõ†Ô∏è Demo: Complex Pod Deployment Pipeline

```bash
#!/bin/bash
# production-pod-deployment.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

# Configuration
NAMESPACE="production-demo"
APP_NAME="web-server"
CONFIG_DIR="./config"

# Create namespace if it doesn't exist
create_namespace() {
    log "Creating namespace: $NAMESPACE"
    kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    success "Namespace $NAMESPACE ready"
}

# Create ConfigMaps for the application
create_configmaps() {
    log "Creating ConfigMaps..."
    
    mkdir -p $CONFIG_DIR
    
    # Nginx configuration
    cat > $CONFIG_DIR/nginx.conf <<EOF
server {
    listen 80;
    server_name localhost;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
    
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    location /ready {
        access_log off;
        return 200 "ready\n";
        add_header Content-Type text/plain;
    }
    
    location /nginx_status {
        stub_status on;
        access_log off;
        allow all;
    }
}
EOF

    # HTML content
    cat > $CONFIG_DIR/index.html <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Production Pod Demo</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .container { max-width: 800px; margin: 0 auto; }
        .status { padding: 20px; margin: 20px 0; border-radius: 5px; }
        .healthy { background-color: #d4edda; color: #155724; }
        .info { background-color: #d1ecf1; color: #0c5460; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Production Pod Demo</h1>
        <div class="status healthy">
            <h3>‚úÖ Application Status: Healthy</h3>
            <p>Pod is running successfully with full production configuration</p>
        </div>
        
        <div class="status info">
            <h3>üìä Features Enabled:</h3>
            <ul>
                <li>Multi-container architecture</li>
                <li>Comprehensive health checks</li>
                <li>Security hardening</li>
                <li>Log processing sidecar</li>
                <li>Prometheus metrics export</li>
                <li>Resource management</li>
            </ul>
        </div>
        
        <div class="status info">
            <h3>üîó Endpoints:</h3>
            <ul>
                <li><a href="/health">Health Check</a></li>
                <li><a href="/ready">Readiness Check</a></li>
                <li><a href="/nginx_status">Nginx Status</a></li>
            </ul>
        </div>
    </div>
</body>
</html>
EOF

    # Fluent Bit configuration
    cat > $CONFIG_DIR/fluent-bit.conf <<EOF
[SERVICE]
    Flush         1
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf

[INPUT]
    Name              tail
    Path              /var/log/nginx/access.log
    Parser            nginx
    Tag               nginx.access
    Refresh_Interval  5

[INPUT]
    Name              tail
    Path              /var/log/nginx/error.log
    Tag               nginx.error
    Refresh_Interval  5

[OUTPUT]
    Name  stdout
    Match nginx.*
EOF

    cat > $CONFIG_DIR/parsers.conf <<EOF
[PARSER]
    Name   nginx
    Format regex
    Regex  ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
    Time_Key time
    Time_Format %d/%b/%Y:%H:%M:%S %z
EOF

    # Create ConfigMaps
    kubectl create configmap nginx-config --from-file=$CONFIG_DIR/nginx.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap html-content --from-file=$CONFIG_DIR/index.html -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap fluent-bit-config --from-file=$CONFIG_DIR/fluent-bit.conf --from-file=$CONFIG_DIR/parsers.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    
    success "ConfigMaps created successfully"
}

# Deploy the production pod
deploy_pod() {
    log "Deploying production pod..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: $APP_NAME
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
    version: "1.0.0"
    environment: production
  annotations:
    deployment.kubernetes.io/revision: "1"
    deployed-by: "production-deployment-script"
    deployment-time: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    
  containers:
  - name: nginx
    image: nginx:1.21-alpine
    ports:
    - name: http
      containerPort: 80
    - name: metrics
      containerPort: 9113
      
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
  - name: html-content
    configMap:
      name: html-content
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
  - name: tmp-dir
    emptyDir: {}
  - name: var-cache-nginx
    emptyDir: {}
  - name: var-run
    emptyDir: {}
  - name: logs
    emptyDir: {}
EOF

    success "Pod deployed successfully"
}

# Wait for pod to be ready and perform health checks
verify_deployment() {
    log "Waiting for pod to be ready..."
    
    if kubectl wait --for=condition=Ready pod/$APP_NAME -n $NAMESPACE --timeout=120s; then
        success "Pod is ready!"
    else
        error "Pod failed to become ready within timeout"
    fi
    
    # Perform comprehensive health checks
    log "Performing health checks..."
    
    # Check pod status
    kubectl get pod $APP_NAME -n $NAMESPACE -o wide
    
    # Test health endpoints
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    if curl -s http://localhost:8080/health | grep -q "healthy"; then
        success "Health check passed"
    else
        warning "Health check failed"
    fi
    
    if curl -s http://localhost:8080/ready | grep -q "ready"; then
        success "Readiness check passed"
    else
        warning "Readiness check failed"
    fi
    
    # Test the main application
    if curl -s http://localhost:8080 | grep -q "Production Pod Demo"; then
        success "Application is serving content correctly"
    else
        warning "Application content check failed"
    fi
    
    kill $PF_PID 2>/dev/null
    
    # Check resource usage
    log "Checking resource usage..."
    if kubectl top pod $APP_NAME -n $NAMESPACE &>/dev/null; then
        kubectl top pod $APP_NAME -n $NAMESPACE
    else
        warning "Resource metrics not available"
    fi
    
    # Check logs from all containers
    log "Checking container logs..."
    echo "=== Nginx logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c nginx --tail=5
    echo "=== Log processor logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=5
}

# Generate load and monitor performance
performance_test() {
    log "Running performance test..."
    
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    # Generate some load
    for i in {1..50}; do
        curl -s http://localhost:8080 > /dev/null &
    done
    
    wait
    kill $PF_PID 2>/dev/null
    
    # Check logs after load test
    log "Logs after load test:"
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=10
    
    success "Performance test completed"
}

# Cleanup function
cleanup() {
    log "Cleaning up resources..."
    kubectl delete pod $APP_NAME -n $NAMESPACE --ignore-not-found
    kubectl delete configmap nginx-config html-content fluent-bit-config -n $NAMESPACE --ignore-not-found
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -rf $CONFIG_DIR
    success "Cleanup completed"
}

# Main execution
main() {
    echo "=== Production Pod Deployment Demo ==="
    
    case "${1:-deploy}" in
        "deploy")
            create_namespace
            create_configmaps
            deploy_pod
            verify_deployment
            performance_test
            
            echo ""
            success "Deployment completed successfully!"
            echo "Access the application:"
            echo "  kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80"
            echo "  Then open: http://localhost:8080"
            echo ""
            echo "Monitor the pod:"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c nginx"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c log-processor"
            echo ""
            echo "Run 'bash $0 cleanup' to remove all resources"
            ;;
        "cleanup")
            cleanup
            ;;
        "test")
            verify_deployment
            performance_test
            ;;
        *)
            echo "Usage: $0 [deploy|cleanup|test]"
            echo "  deploy  - Deploy the production pod (default)"
            echo "  cleanup - Remove all created resources"
            echo "  test    - Run verification and performance tests"
            ;;
    esac
}

main "$@"
```

### üéØ Mini-Project 4: Pod Chaos Engineering

Test pod resilience with chaos engineering principles:

```yaml
# chaos-test-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: chaos-resilient-app
  labels:
    app: chaos-test
    resilience: enabled
spec:
  containers:
  - name: main-app
    image: nginx:1.21-alpine
    ports:
    - containerPort: 80
    
    # Aggressive resource limits to test resilience
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    # Tight health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 2
      
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
      timeoutSeconds: 1
      failureThreshold: 2
      
    # Graceful shutdown
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 10"]
          
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  # Chaos monkey sidecar
  - name: chaos-monkey
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Chaos monkey starting..."
      
      # Function to create CPU load
      cpu_chaos() {
        echo "Creating CPU chaos..."
        for i in {1..4}; do
          yes > /dev/null &
        done
        sleep 30
        killall yes
      }
      
      # Function to create memory pressure
      memory_chaos() {
        echo "Creating memory chaos..."
        cat <(yes | tr \\n x | head -c 50000000) <(yes | tr \\n x | head -c 50000000) > /tmp/memory_eater &
        sleep 20
        rm -f /tmp/memory_eater
        killall cat
      }
      
      # Function to simulate network issues
      network_chaos() {
        echo "Creating network chaos..."
        # Simulate slow responses
        sleep $((RANDOM % 10 + 5))
      }
      
      # Function to create disk I/O pressure
      disk_chaos() {
        echo "Creating disk I/O chaos..."
        dd if=/dev/zero of=/tmp/disk_eater bs=1M count=10 2>/dev/null
        rm -f /tmp/disk_eater
      }
      
      # Main chaos loop
      while true; do
        chaos_type=$((RANDOM % 4))
        case $chaos_type in
          0) cpu_chaos ;;
          1) memory_chaos ;;
          2) network_chaos ;;
          3) disk_chaos ;;
        esac
        
        # Wait between chaos events
        sleep $((RANDOM % 60 + 30))
      done
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir:
      sizeLimit: 100Mi
      
  restartPolicy: Always
```

**Chaos Testing Script:**
```bash
#!/bin/bash
# chaos-engineering-test.sh

echo "=== Chaos Engineering Test ==="

# Deploy the chaos test pod
kubectl apply -f chaos-test-pod.yaml

# Wait for it to be ready
echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/chaos-resilient-app --timeout=60s

# Monitor pod resilience
echo "Starting resilience monitoring (Ctrl+C to stop)..."

monitor_resilience() {
    while true; do
        timestamp=$(date '+%H:%M:%S')
        
        # Check pod status
        status=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.phase}')
        ready=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
        restarts=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.containerStatuses[0].restartCount}')
        
        # Test application responsiveness
        kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
        PF_PID=$!
        sleep 2
        
        response_time=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8080 2>/dev/null || echo "FAIL")
        kill $PF_PID 2>/dev/null
        
        # Get resource usage if available
        resources=""
        if kubectl top pod chaos-resilient-app &>/dev/null; then
            resources=$(kubectl top pod chaos-resilient-app --no-headers 2>/dev/null | awk '{print $2" "$3}')
        fi
        
        printf "[$timestamp] Status: $status | Ready: $ready | Restarts: $restarts | Response: ${response_time}s | Resources: $resources\n"
        
        sleep 5
    done
}

# Start monitoring in background
monitor_resilience &
MONITOR_PID=$!

# Generate additional load to test resilience
echo "Generating load to test resilience..."
for i in {1..100}; do
    kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
    PF_PID=$!
    sleep 1
    
    curl -s http://localhost:8080 > /dev/null &
    
    kill $PF_PID 2>/dev/null
    sleep 2
done

# Stop monitoring
kill $MONITOR_PID 2>/dev/null

echo "Chaos test completed. Check pod logs:"
echo "kubectl logs chaos-resilient-app -c main-app --tail=20"
echo "kubectl logs chaos-resilient-app -c chaos-monkey --tail=20"

# Cleanup
read -p "Delete the chaos test pod? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    kubectl delete -f chaos-test-pod.yaml
fi
```

---

## Advanced Pod Management Techniques

### üî¨ Expert-Level Examples

#### Example 7: Custom Pod Controller

Create a custom controller for specialized pod management:

```python
#!/usr/bin/env python3
# custom-pod-controller.py

import time
import yaml
import subprocess
import json
from datetime import datetime, timedelta

class PodController:
    def __init__(self):
        self.managed_pods = {}
        self.check_interval = 30  # seconds
        
    def log(self, message):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"[{timestamp}] {message}")
        
    def run_kubectl(self, command):
        """Execute kubectl command and return JSON output"""
        try:
            result = subprocess.run(
                f"kubectl {command} -o json",
                shell=True,
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                self.log(f"kubectl error: {result.stderr}")
                return None
        except Exception as e:
            self.log(f"Command execution error: {e}")
            return None
            
    def get_pods_by_label(self, label_selector):
        """Get pods matching label selector"""
        command = f"get pods -l {label_selector}"
        result = self.run_kubectl(command)
        return result.get('items', []) if result else []
        
    def create_pod(self, name, spec):
        """Create a pod with given specification"""
        pod_manifest = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'name': name,
                'labels': {
                    'managed-by': 'custom-controller',
                    'created': datetime.now().strftime('%Y%m%d-%H%M%S')
                }
            },
            'spec': spec
        }
        
        # Write manifest to temporary file
        with open(f'/tmp/{name}.yaml', 'w') as f:
            yaml.dump(pod_manifest, f)
            
        # Apply the manifest
        result = subprocess.run(
            f"kubectl apply -f /tmp/{name}.yaml",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Created pod: {name}")
            return True
        else:
            self.log(f"Failed to create pod {name}: {result.stderr}")
            return False
            
    def delete_pod(self, name):
        """Delete a pod"""
        result = subprocess.run(
            f"kubectl delete pod {name} --grace-period=30",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Deleted pod: {name}")
            return True
        else:
            self.log(f"Failed to delete pod {name}: {result.stderr}")
            return False
            
    def check_pod_health(self, pod):
        """Check if a pod is healthy based on custom criteria"""
        name = pod['metadata']['name']
        status = pod['status']
        
        # Check if pod is running
        if status.get('phase') != 'Running':
            return False, f"Pod {name} is not running (phase: {status.get('phase')})"
            
        # Check container statuses
        container_statuses = status.get('containerStatuses', [])
        for container in container_statuses:
            if not container.get('ready'):
                return False, f"Container {container['name']} not ready in pod {name}"
                
            # Check restart count
            restart_count = container.get('restartCount', 0)
            if restart_count > 5:
                return False, f"Container {container['name']} restarted {restart_count} times"
                
        # Check resource usage (if metrics available)
        metrics = self.get_pod_metrics(name)
        if metrics:
            cpu_usage = self.parse_cpu_usage(metrics.get('cpu', '0m'))
            memory_usage = self.parse_memory_usage(metrics.get('memory', '0Mi'))
            
            if cpu_usage > 800:  # 800 millicores
                return False, f"Pod {name} CPU usage too high: {cpu_usage}m"
                
            if memory_usage > 512:  # 512 Mi
                return False, f"Pod {name} memory usage too high: {memory_usage}Mi"
                
        return True, f"Pod {name} is healthy"
        
    def get_pod_metrics(self, pod_name):
        """Get pod resource metrics if available"""
        result = subprocess.run(
            f"kubectl top pod {pod_name} --no-headers",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            parts = result.stdout.strip().split()
            if len(parts) >= 3:
                return {
                    'cpu': parts[1],
                    'memory': parts[2]
                }
        return None
        
    def parse_cpu_usage(self, cpu_str):
        """Parse CPU usage from string like '100m' to millicores"""
        if cpu_str.endswith('m'):
            return int(cpu_str[:-1])
        return int(cpu_str) * 1000
        
    def parse_memory_usage(self, memory_str):
        """Parse memory usage from string like '128Mi' to Mi"""
        if memory_str.endswith('Mi'):
            return int(memory_str[:-2])
        elif memory_str.endswith('Gi'):
            return int(memory_str[:-2]) * 1024
        return int(memory_str) // (1024 * 1024)
        
    def auto_heal_pod(self, pod_name, reason):
        """Attempt to heal an unhealthy pod"""
        self.log(f"Attempting to heal pod {pod_name}: {reason}")
        
        # Strategy 1: Restart the pod
        if "restart" in reason.lower():
            return self.delete_pod(pod_name)  # Pod will be recreated if managed by controller
            
        # Strategy 2: Scale resources if high usage
        if "usage too high" in reason.lower():
            self.log(f"High resource usage detected for {pod_name}, marking for recreation")
            return self.delete_pod(pod_name)
            
        # Strategy 3: Generic restart
        return self.delete_pod(pod_name)
        
    def manage_workload(self, workload_config):
        """Manage a workload with desired replica count"""
        app_name = workload_config['name']
        desired_replicas = workload_config['replicas']
        pod_spec = workload_config['pod_spec']
        
        # Get current pods for this workload
        current_pods = self.get_pods_by_label(f"app={app_name},managed-by=custom-controller")
        current_count = len(current_pods)
        
        self.log(f"Managing workload {app_name}: current={current_count}, desired={desired_replicas}")
        
        # Scale up if needed
        if current_count < desired_replicas:
            for i in range(current_count, desired_replicas):
                pod_name = f"{app_name}-{i}"
                pod_spec_copy = pod_spec.copy()
                pod_spec_copy.setdefault('containers', [{}])[0]['env'] = [
                    {'name': 'REPLICA_ID', 'value': str(i)},
                    {'name': 'APP_NAME', 'value': app_name}
                ]
                self.create_pod(pod_name, pod_spec_copy)
                
        # Scale down if needed
        elif current_count > desired_replicas:
            pods_to_delete = current_pods[desired_replicas:]
            for pod in pods_to_delete:
                self.delete_pod(pod['metadata']['name'])
                
        # Health check existing pods
        for pod in current_pods[:desired_replicas]:
            healthy, reason = self.check_pod_health(pod)
            if not healthy:
                self.log(f"Pod unhealthy: {reason}")
                self.auto_heal_pod(pod['metadata']['name'], reason)
                
    def run_control_loop(self):
        """Main control loop"""
        self.log("Starting custom pod controller...")
        
        # Sample workload configuration
        workloads = [
            {
                'name': 'web-app',
                'replicas': 2,
                'pod_spec': {
                    'containers': [{
                        'name': 'nginx',
                        'image': 'nginx:1.21-alpine',
                        'ports': [{'containerPort': 80}],
                        'resources': {
                            'requests': {'memory': '64Mi', 'cpu': '50m'},
                            'limits': {'memory': '128Mi', 'cpu': '100m'}
                        },
                        'livenessProbe': {
                            'httpGet': {'path': '/', 'port': 80},
                            'initialDelaySeconds': 10,
                            'periodSeconds': 30
                        }
                    }],
                    'restartPolicy': 'Always'
                }
            }
        ]
        
        try:
            while True:
                self.log("Running control loop...")
                
                for workload in workloads:
                    try:
                        self.manage_workload(workload)
                    except Exception as e:
                        self.log(f"Error managing workload {workload['name']}: {e}")
                        
                self.log(f"Sleeping for {self.check_interval} seconds...")
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            self.log("Shutting down controller...")
            
        except Exception as e:
            self.log(f"Controller error: {e}")
            
    def cleanup(self):
        """Clean up managed resources"""
        self.log("Cleaning up managed pods...")
        pods = self.get_pods_by_label("managed-by=custom-controller")
        for pod in pods:
            self.delete_pod(pod['metadata']['name'])

if __name__ == "__main__":
    import sys
    
    controller = PodController()
    
    if len(sys.argv) > 1 and sys.argv[1] == "cleanup":
        controller.cleanup()
    else:
        controller.run_control_loop()
```

**Usage:**
```bash
# Make the script executable
chmod +x custom-pod-controller.py

# Install dependencies
pip3 install pyyaml

# Run the controller
python3 custom-pod-controller.py

# In another terminal, watch the managed pods
watch kubectl get pods -l managed-by=custom-controller

# Simulate pod failures
kubectl delete pod web-app-0  # Controller will recreate it

# Clean up when done
python3 custom-pod-controller.py cleanup
```

### üéØ Mini-Project 5: Pod Performance Optimization Lab

Create a comprehensive performance optimization laboratory:

```yaml
# performance-lab-setup.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: performance-lab
---
# Baseline pod - unoptimized
apiVersion: v1
kind: Pod
metadata:
  name: baseline-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: baseline
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "1000m"
      limits:
        memory: "2Gi"
        cpu: "2000m"
---
# Optimized pod - resource-efficient
apiVersion: v1
kind: Pod
metadata:
  name: optimized-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: optimized
spec:
  containers:
  - name: app
    image: nginx:1.21-alpine  # Smaller image
    resources:
      requests:
        memory: "64Mi"        # Right-sized requests
        cpu: "100m"
      limits:
        memory: "128Mi"       # Conservative limits
        cpu: "200m"
    # Optimized health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5   # Faster startup
      periodSeconds: 30        # Less frequent checks
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
    # Security optimizations
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
    # Volume optimizations
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp-dir
    emptyDir:
      medium: Memory  # Use memory for temp files
      sizeLimit: 64Mi
  - name: var-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: var-run
    emptyDir:
      sizeLimit: 32Mi
---
# High-performance pod with advanced optimizations
apiVersion: v1
kind: Pod
metadata:
  name: high-performance-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: high-performance
spec:
  # Pod-level optimizations
  priorityClassName: high-priority
  nodeSelector:
    node-type: performance
  tolerations:
  - key: performance-node
    operator: Equal
    value: "true"
    effect: NoSchedule
  # Network optimizations
  dnsPolicy: ClusterFirstWithHostNet
  dnsConfig:
    options:
    - name: ndots
      value: "1"
    - name: edns0
  containers:
  - name: app
    image: nginx:1.21-alpine
    # Optimized resource allocation
    resources:
      requests:
        memory: "128Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "256Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
    # Performance-tuned environment
    env:
    - name: NGINX_WORKER_PROCESSES
      value: "auto"
    - name: NGINX_WORKER_CONNECTIONS
      value: "1024"
    # Aggressive health checks for faster recovery
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 15
      timeoutSeconds: 2
      failureThreshold: 2
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 3
      timeoutSeconds: 1
      failureThreshold: 1
    # Startup optimization
    startupProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 1
      timeoutSeconds: 1
      failureThreshold: 10
    # Performance-optimized volumes
    volumeMounts:
    - name: high-speed-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
  volumes:
  - name: high-speed-tmp
    emptyDir:
      medium: Memory
      sizeLimit: 128Mi
  - name: nginx-cache
    emptyDir:
      medium: Memory
      sizeLimit: 256Mi
  - name: nginx-run
    emptyDir:
      medium: Memory
      sizeLimit: 64Mi
```

**Performance Benchmarking Script:**
```bash
#!/bin/bash
# performance-benchmark.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

NAMESPACE="performance-lab"

# Deploy the performance lab
setup_lab() {
    log "Setting up performance lab..."
    kubectl apply -f performance-lab-setup.yaml
    
    log "Waiting for pods to be ready..."
    kubectl wait --for=condition=Ready pod/baseline-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/optimized-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/high-performance-app -n $NAMESPACE --timeout=120s
    
    success "Performance lab setup complete"
}

# Measure startup time
measure_startup_time() {
    local pod_name=$1
    log "Measuring startup time for $pod_name..."
    
    # Delete and recreate pod to measure startup
    kubectl delete pod $pod_name -n $NAMESPACE
    local start_time=$(date +%s.%N)
    
    # Recreate the pod (extract from original manifest)
    kubectl get pod $pod_name -n $NAMESPACE -o yaml --export 2>/dev/null | kubectl apply -f - 2>/dev/null || {
        warning "Couldn't recreate pod automatically, recreating from manifest"
        kubectl apply -f performance-lab-setup.yaml
    }
    
    # Wait for ready and measure time
    kubectl wait --for=condition=Ready pod/$pod_name -n $NAMESPACE --timeout=120s
    local end_time=$(date +%s.%N)
    
    local startup_time=$(echo "$end_time - $start_time" | bc -l)
    echo "$startup_time"
}

# Run load test on a pod
load_test_pod() {
    local pod_name=$1
    local duration=${2:-30}
    local concurrency=${3:-10}
    
    log "Running load test on $pod_name (${duration}s, ${concurrency} concurrent)"
    
    # Start port forwarding
    kubectl port-forward pod/$pod_name -n $NAMESPACE 8080:80 >/dev/null 2>&1 &
    local pf_pid=$!
    sleep 3
    
    # Use Apache Bench for load testing
    local results_file="/tmp/ab_results_${pod_name}.txt"
    
    if command -v ab >/dev/null; then
        ab -n $((duration * concurrency)) -c $concurrency -g /tmp/gnuplot_${pod_name}.dat \
           http://localhost:8080/ > $results_file 2>&1
        
        # Extract key metrics
        local rps=$(grep "Requests per second" $results_file | awk '{print $4}')
        local response_time=$(grep "Time per request.*mean" $results_file | head -1 | awk '{print $4}')
        local failed_requests=$(grep "Failed requests" $results_file | awk '{print $3}')
        
        echo "RPS:$rps,ResponseTime:$response_time,Failed:$failed_requests"
    else
        # Fallback to curl-based test
        local start_time=$(date +%s)
        local requests=0
        local total_time=0
        
        for i in $(seq 1 $((duration * concurrency))); do
            local req_start=$(date +%s.%N)
            if curl -s http://localhost:8080 >/dev/null 2>&1; then
                ((requests++))
            fi
            local req_end=$(date +%s.%N)
            local req_time=$(echo "$req_end - $req_start" | bc -l)
            total_time=$(echo "$total_time + $req_time" | bc -l)
            
            # Basic rate limiting
            sleep 0.1
        done
        
        local avg_response_time=$(echo "scale=3; $total_time / $requests" | bc -l)
        local rps=$(echo "scale=2; $requests / $duration" | bc -l)
        
        echo "RPS:$rps,ResponseTime:$avg_response_time,Failed:0"
    fi
    
    kill $pf_pid 2>/dev/null
}

# Get resource usage metrics
get_resource_usage() {
    local pod_name=$1
    log "Getting resource usage for $pod_name..."
    
    if kubectl top pod $pod_name -n $NAMESPACE >/dev/null 2>&1; then
        kubectl top pod $pod_name -n $NAMESPACE --no-headers | awk '{print "CPU:"$2",Memory:"$3}'
    else
        echo "CPU:N/A,Memory:N/A"
    fi
}

# Comprehensive benchmark
run_comprehensive_benchmark() {
    log "Running comprehensive performance benchmark..."
    
    declare -A results
    local pods=("baseline-app" "optimized-app" "high-performance-app")
    
    echo "=== Performance Benchmark Results ===" > benchmark_results.txt
    echo "Timestamp: $(date)" >> benchmark_results.txt
    echo "" >> benchmark_results.txt
    
    for pod in "${pods[@]}"; do
        log "Benchmarking $pod..."
        
        # Startup time measurement
        log "Measuring startup time for $pod..."
        # Skip startup measurement in this demo to avoid pod recreation issues
        startup_time="N/A"
        
        # Resource usage
        resource_usage=$(get_resource_usage $pod)
        
        # Load test
        load_results=$(load_test_pod $pod 30 10)
        
        # Pod status information
        pod_info=$(kubectl get pod $pod -n $NAMESPACE -o custom-columns=STATUS:.status.phase,READY:.status.conditions[?\(@.type==\"Ready\"\)].status,RESTARTS:.status.containerStatuses[0].restartCount --no-headers)
        
        # Store results
        results[$pod]="Startup:$startup_time,Resources:$resource_usage,Load:$load_results,Status:$pod_info"
        
        # Write to file
        cat >> benchmark_results.txt <<EOF

=== $pod ===
Startup Time: $startup_time seconds
Resource Usage: $resource_usage
Load Test Results: $load_results
Pod Status: $pod_info

EOF
    done
    
    # Generate comparison summary
    cat >> benchmark_results.txt <<EOF

=== Performance Summary ===
This benchmark compares three pod configurations:

1. Baseline App: Standard configuration with generous resource allocation
2. Optimized App: Resource-efficient with security hardening
3. High-Performance App: Maximum performance optimizations

Key Findings:
- Resource efficiency varies significantly between configurations
- Startup time impacts overall application availability
- Load handling capacity differs based on resource allocation
- Security optimizations may have performance trade-offs

Recommendations:
- Use optimized configuration for production workloads
- Consider high-performance setup for critical applications
- Monitor resource usage to fine-tune allocations
- Balance security and performance based on requirements

EOF
    
    success "Benchmark completed. Results saved to benchmark_results.txt"
    cat benchmark_results.txt
}

# Resource monitoring script
monitor_resources() {
    local duration=${1:-300}  # 5 minutes default
    log "Starting resource monitoring for ${duration} seconds..."
    
    local monitor_file="resource_monitor_$(date +%Y%m%d_%H%M%S).log"
    
    {
        echo "Timestamp,Pod,CPU,Memory,Status"
        local end_time=$(($(date +%s) + duration))
        
        while [ $(date +%s) -lt $end_time ]; do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            
            for pod in baseline-app optimized-app high-performance-app; do
                if kubectl get pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                    local status=$(kubectl get pod $pod -n $NAMESPACE -o jsonpath='{.status.phase}')
                    local usage="N/A,N/A"
                    
                    if kubectl top pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                        usage=$(kubectl top pod $pod -n $NAMESPACE --no-headers | awk '{print $2","$3}')
                    fi
                    
                    echo "$timestamp,$pod,$usage,$status"
                fi
            done
            
            sleep 10
        done
    } > $monitor_file
    
    success "Resource monitoring completed. Data saved to $monitor_file"
    
    # Generate simple analysis
    log "Generating resource usage analysis..."
    
    {
        echo "=== Resource Usage Analysis ==="
        echo ""
        
        for pod in baseline-app optimized-app high-performance-app; do
            echo "=== $pod ==="
            grep "$pod" $monitor_file | tail -10 | while IFS=',' read timestamp pod_name cpu memory status; do
                echo "[$timestamp] CPU: $cpu, Memory: $memory, Status: $status"
            done
            echo ""
        done
    } > resource_analysis.txt
    
    success "Analysis saved to resource_analysis.txt"
}

# Cleanup function
cleanup_lab() {
    log "Cleaning up performance lab..."
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -f benchmark_results.txt resource_*.log resource_analysis.txt
    rm -f /tmp/ab_results_*.txt /tmp/gnuplot_*.dat
    success "Cleanup completed"
}

# Main execution
main() {
    case "${1:-benchmark}" in
        "setup")
            setup_lab
            ;;
        "benchmark")
            setup_lab
            run_comprehensive_benchmark
            ;;
        "monitor")
            monitor_resources "${2:-300}"
            ;;
        "cleanup")
            cleanup_lab
            ;;
        "all")
            setup_lab
            run_comprehensive_benchmark
            monitor_resources 300
            echo ""
            success "Complete performance analysis finished!"
            echo "Files created:"
            echo "  - benchmark_results.txt"
            echo "  - resource_monitor_*.log"
            echo "  - resource_analysis.txt"
            ;;
        *)
            echo "Performance Lab - Pod Optimization Benchmark"
            echo ""
            echo "Usage: $0 <command> [options]"
            echo ""
            echo "Commands:"
            echo "  setup      - Set up the performance lab environment"
            echo "  benchmark  - Run comprehensive performance benchmark"
            echo "  monitor    - Monitor resource usage for specified duration"
            echo "  cleanup    - Remove all lab resources"
            echo "  all        - Run complete analysis (setup + benchmark + monitor)"
            echo ""
            echo "Examples:"
            echo "  $0 setup"
            echo "  $0 benchmark"
            echo "  $0 monitor 600  # Monitor for 10 minutes"
            echo "  $0 all          # Complete analysis"
            ;;
    esac
}

main "$@"
```

---

## Pod Troubleshooting Methodologies

### üîß Advanced Troubleshooting Toolkit

#### Example 8: Automated Diagnostic System

```bash
#!/bin/bash
# advanced-pod-diagnostics.sh

set -euo pipefail

# Enhanced diagnostic toolkit with automated problem detection
class PodDiagnostics {
    
# Configuration
NAMESPACE=${NAMESPACE:-default}
OUTPUT_DIR="./diagnostics-$(date +%Y%m%d-%H%M%S)"
VERBOSE=${VERBOSE:-false}

# Colors and formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'
BOLD='\033[1m'

# Logging functions with levels
log_debug() { [[ $VERBOSE == "true" ]] && echo -e "${CYAN}[DEBUG]${NC} $1"; }
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }

# Initialize diagnostics
init_diagnostics() {
    log_info "Initializing pod diagnostics system..."
    mkdir -p "$OUTPUT_DIR"/{logs,reports,metrics,manifests}
    
    # Create diagnostic report header
    cat > "$OUTPUT_DIR/diagnostic_report.md" <<EOF
# Pod Diagnostics Report

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)  
**Namespace:** $NAMESPACE  
**Output Directory:** $OUTPUT_DIR

---

EOF
    
    log_success "Diagnostics initialized in $OUTPUT_DIR"
}

# Comprehensive pod information gathering
gather_pod_info() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Gathering comprehensive information for pod: $pod_name"
    
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    mkdir -p "$pod_dir"
    
    # Basic pod information
    kubectl get pod "$pod_name" -n "$namespace" -o wide > "$pod_dir/basic_info.txt" 2>&1
    kubectl get pod "$pod_name" -n "$namespace" -o yaml > "$pod_dir/manifest.yaml" 2>&1
    
    # Detailed description
    kubectl describe pod "$pod_name" -n "$namespace" > "$pod_dir/description.txt" 2>&1
    
    # Events related to the pod
    kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
        --sort-by='.lastTimestamp' > "$pod_dir/events.txt" 2>&1
    
    # Container logs
    local containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}' 2>/dev/null)
    for container in $containers; do
        log_debug "Collecting logs for container: $container"
        kubectl logs "$pod_name" -n "$namespace" -c "$container" > "$pod_dir/logs_${container}.txt" 2>&1
        
        # Previous logs if container restarted
        kubectl logs "$pod_name" -n "$namespace" -c "$container" --previous > "$pod_dir/logs_${container}_previous.txt" 2>&1 || true
    done
    
    # Resource usage
    kubectl top pod "$pod_name" -n "$namespace" > "$pod_dir/resource_usage.txt" 2>&1 || echo "Metrics not available" > "$pod_dir/resource_usage.txt"
    
    log_success "Pod information gathered for $pod_name"
}

# Automated problem detection
detect_common_issues() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Running automated issue detection for $pod_name..."
    
    local issues_file="$pod_dir/detected_issues.md"
    echo "# Automated Issue Detection Report" > "$issues_file"
    echo "**Pod:** $pod_name" >> "$issues_file"
    echo "**Analysis Time:** $(date)" >> "$issues_file"
    echo "" >> "$issues_file"
    
    local issue_count=0
    
    # Check 1: Pod phase issues
    local phase=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.phase}' 2>/dev/null)
    if [[ "$phase" != "Running" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Pod Not Running
- **Severity:** High
- **Status:** Pod is in '$phase' phase instead of 'Running'
- **Impact:** Application unavailable
- **Investigation:** Check pod events and container status

EOF
    fi
    
    # Check 2: Container readiness issues
    local ready_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[?(@.ready==true)]}' | jq '. | length' 2>/dev/null || echo "0")
    local total_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers}' | jq '. | length' 2>/dev/null || echo "1")
    
    if [[ "$ready_containers" -lt "$total_containers" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Container Readiness Problems
- **Severity:** High
- **Status:** Only $ready_containers of $total_containers containers are ready
- **Impact:** Traffic routing may be affected
- **Investigation:** Check readiness probes and container logs

EOF
    fi
    
    # Check 3: Excessive restarts
    local restarts=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
    if [[ "$restarts" -gt 5 ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Excessive Container Restarts
- **Severity:** Medium
- **Status:** Container has restarted $restarts times
- **Impact:** Service instability and potential data loss
- **Investigation:** Check liveness probes, resource limits, and application logs

EOF
    fi
    
    # Check 4: Resource usage issues
    if kubectl top pod "$pod_name" -n "$namespace" >/dev/null 2>&1; then
        local cpu_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $2}' | sed 's/m$//')
        local memory_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $3}' | sed 's/Mi$//')
        
        if [[ "$cpu_usage" -gt 800 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High CPU Usage
- **Severity:** Medium
- **Status:** CPU usage is ${cpu_usage}m (> 800m threshold)
- **Impact:** Performance degradation and potential throttling
- **Investigation:** Check for CPU-intensive processes and consider scaling

EOF
        fi
        
        if [[ "$memory_usage" -gt 512 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High Memory Usage
- **Severity:** Medium  
- **Status:** Memory usage is ${memory_usage}Mi (> 512Mi threshold)
- **Impact:** Risk of OOM kills and service disruption
- **Investigation:** Check for memory leaks and optimize memory usage

EOF
        fi
    fi
    
    # Check 5: Image pull issues
    if grep -q "ImagePullBackOff\|ErrImagePull" "$pod_dir/description.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Image Pull Problems
- **Severity:** High
- **Status:** Unable to pull container image
- **Impact:** Pod cannot start
- **Investigation:** Check image name, registry access, and credentials

EOF
    fi
    
    # Check 6: Resource constraints
    if grep -q "Insufficient.*resources" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Resource Constraints
- **Severity:** High
- **Status:** Insufficient cluster resources for pod scheduling
- **Impact:** Pod cannot be scheduled
- **Investigation:** Check cluster capacity and node resources

EOF
    fi
    
    # Check 7: Network issues
    if grep -q "NetworkNotReady\|CNI.*error" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Network Configuration Problems
- **Severity:** High
- **Status:** Network setup issues detected
- **Impact:** Pod networking may not function correctly
- **Investigation:** Check CNI configuration and network policies

EOF
    fi
    
    # Summary
    if [[ $issue_count -eq 0 ]]; then
        echo "## Summary: No Critical Issues Detected ‚úÖ" >> "$issues_file"
        echo "The automated analysis found no obvious problems with this pod." >> "$issues_file"
        log_success "No critical issues detected for $pod_name"
    else
        echo "## Summary: $issue_count Issue(s) Detected ‚ö†Ô∏è" >> "$issues_file"
        echo "Review the issues above and follow the investigation recommendations." >> "$issues_file"
        log_warn "$issue_count issue(s) detected for $pod_name"
    fi
    
    return $issue_count
}

# Generate recommendations
generate_recommendations() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Generating recommendations for $pod_name..."
    
    local rec_file="$pod_dir/recommendations.md"
    echo "# Optimization Recommendations" > "$rec_file"
    echo "**Pod:** $pod_name" >> "$rec_file"
    echo "" >> "$rec_file"
    
    # Resource optimization recommendations
    echo "## Resource Optimization" >> "$rec_file"
    
    # Check current resource configuration
    local requests_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.memory}' 2>/dev/null || echo "not set")
    local requests_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.cpu}' 2>/dev/null || echo "not set")
    local limits_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.memory}' 2>/dev/null || echo "not set")
    local limits_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.cpu}' 2>/dev/null || echo "not set")
    
    cat >> "$rec_file" <<EOF
### Current Resource Configuration
- **Memory Request:** $requests_mem
- **CPU Request:** $requests_cpu  
- **Memory Limit:** $limits_mem
- **CPU Limit:** $limits_cpu

EOF
    
    # Security recommendations
    echo "## Security Hardening" >> "$rec_file"
    
    local security_context=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.securityContext}' 2>/dev/null)
    if [[ -z "$security_context" || "$security_context" == "null" ]]; then
        cat >> "$rec_file" <<EOF
### Security Context Improvements
- ‚úÖ **Add security context:** Configure runAsNonRoot, runAsUser, and fsGroup
- ‚úÖ **Drop capabilities:** Remove unnecessary Linux capabilities  
- ‚úÖ **Read-only root filesystem:** Set readOnlyRootFilesystem: true
- ‚úÖ **Prevent privilege escalation:** Set allowPrivilegeEscalation: false

EOF
    fi
    
    # Health check recommendations
    echo "## Health Check Optimization" >> "$rec_file"
    
    local has_liveness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].livenessProbe}' 2>/dev/null)
    local has_readiness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].readinessProbe}' 2>/dev/null)
    
    if [[ -z "$has_liveness" || "$has_liveness" == "null" ]]; then
        echo "- ‚úÖ **Add liveness probe:** Implement health checking for automatic restart" >> "$rec_file"
    fi
    
    if [[ -z "$has_readiness" || "$has_readiness" == "null" ]]; then
        echo "- ‚úÖ **Add readiness probe:** Control traffic routing based on application readiness" >> "$rec_file"
    fi
    
    # Performance recommendations
    echo "" >> "$rec_file"
    echo "## Performance Optimization" >> "$rec_file"
    cat >> "$rec_file" <<EOF
- ‚úÖ **Use Alpine images:** Reduce image size and startup time
- ‚úÖ **Implement resource requests:** Help scheduler make better placement decisions
- ‚úÖ **Optimize health check frequency:** Balance responsiveness with overhead
- ‚úÖ **Use memory-backed volumes:** For temporary files and caches
- ‚úÖ **Configure DNS caching:** Reduce DNS lookup overhead

EOF
    
    log_success "Recommendations generated for $pod_name"
}

# Interactive diagnostic session
interactive_diagnostics() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Starting interactive diagnostics for $pod_name..."
    
    echo -e "${BOLD}Interactive Pod Diagnostics${NC}"
    echo "Pod: $pod_name"
    echo "Namespace: $namespace"
    echo ""
    
    while true; do
        echo -e "${CYAN}Available actions:${NC}"
        echo "1) Show pod status"
        echo "2) View recent events"
        echo "3) Check container logs"
        echo "4) Execute command in pod"
        echo "5) Port forward to pod"
        echo "6) Resource usage"
        echo "7) Run full diagnostic"
        echo "8) Generate recommendations"
        echo "q) Quit"
        echo ""
        
        read -p "Select action [1-8,q]: " choice
        
        case $choice in
            1)
                echo "=== Pod Status ==="
                kubectl get pod "$pod_name" -n "$namespace" -o wide
```" \
        10
    
    check_item "CPU limits defined" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.spec.containers[0].resources.limits.cpu}' | grep -v '^
                kubectl describe pod "$pod_name" -n "$namespace" | grep -A 10 "Status\|Conditions"
                ;;
            2)
                echo "=== Recent Events ==="
                kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
                    --sort-by='.lastTimestamp' | tail -10
                ;;
            3)
                echo "=== Container Selection ==="
                local containers=($(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}'))
                if [[ ${#containers[@]} -eq 1 ]]; then
                    echo "Showing logs for container: ${containers[0]}"
                    kubectl logs "$pod_name" -n "$namespace" --tail=50
                else
                    echo "Available containers:"
                    for i in "${!containers[@]}"; do
                        echo "$((i+1))) ${containers[i]}"
                    done
                    read -p "Select container [1-${#containers[@]}]: " container_choice
                    if [[ $container_choice -ge 1 && $container_choice -le ${#containers[@]} ]]; then
                        local selected_container=${containers[$((container_choice-1))]}
                        echo "Showing logs for container: $selected_container"
                        kubectl logs "$pod_name" -n "$namespace" -c "$selected_container" --tail=50
                    fi
                fi
                ;;
            4)
                read -p "Enter command to execute: " exec_command
                kubectl exec -it "$pod_name" -n "$namespace" -- $exec_command
                ;;
            5)
                read -p "Enter local port: " local_port
                read -p "Enter pod port: " pod_port
                echo "Port forwarding $local_port:$pod_port - Press Ctrl+C to stop"
                kubectl port-forward "$pod_name" -n "$namespace" "$local_port:$pod_port"
                ;;
            6)
                echo "=== Resource Usage ==="
                kubectl top pod "$pod_name" -n "$namespace" 2>/dev/null || echo "Metrics not available"
                ;;
            7)
                gather_pod_info "$pod_name" "$namespace"
                detect_common_issues "$pod_name" "$namespace"
                generate_recommendations "$pod_name" "$namespace"
                echo "Full diagnostic completed. Check $OUTPUT_DIR/pods/$pod_name/"
                ;;
            8)
                generate_recommendations "$pod_name" "$namespace"
                echo "Recommendations generated. Check $OUTPUT_DIR/pods/$pod_name/recommendations.md"
                ;;
            q|Q)
                log_info "Exiting interactive diagnostics"
                break
                ;;
            *)
                echo "Invalid choice. Please try again."
                ;;
        esac
        
        echo ""
        read -p "Press Enter to continue..."
        echo ""
    done
}

# Cluster-wide pod health assessment
cluster_health_assessment() {
    log_info "Running cluster-wide pod health assessment..."
    
    local health_report="$OUTPUT_DIR/cluster_health_report.md"
    
    cat > "$health_report" <<EOF
# Cluster Pod Health Assessment

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)

---

EOF
    
    # Get all namespaces
    local namespaces=($(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'))
    
    local total_pods=0
    local healthy_pods=0
    local unhealthy_pods=0
    
    for ns in "${namespaces[@]}"; do
        log_info "Assessing namespace: $ns"
        
        local pods=($(kubectl get pods -n "$ns" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null))
        
        if [[ ${#pods[@]} -eq 0 ]]; then
            continue
        fi
        
        echo "## Namespace: $ns" >> "$health_report"
        echo "" >> "$health_report"
        
        local ns_healthy=0
        local ns_unhealthy=0
        
        for pod in "${pods[@]}"; do
            ((total_pods++))
            
            local phase=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.phase}')
            local ready_condition=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
            local restarts=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
            
            if [[ "$phase" == "Running" && "$ready_condition" == "True" && $restarts -lt 5 ]]; then
                ((healthy_pods++))
                ((ns_healthy++))
                echo "‚úÖ **$pod** - Healthy" >> "$health_report"
            else
                ((unhealthy_pods++))
                ((ns_unhealthy++))
                echo "‚ùå **$pod** - Issues detected (Phase: $phase, Ready: $ready_condition, Restarts: $restarts)" >> "$health_report"
                
                # Run quick diagnostics for unhealthy pods
                gather_pod_info "$pod" "$ns"
                detect_common_issues "$pod" "$ns"
            fi
        done
        
        echo "" >> "$health_report"
        echo "**Namespace Summary:** $ns_healthy healthy, $ns_unhealthy unhealthy" >> "$health_report"
        echo "" >> "$health_report"
    done
    
    # Overall summary
    local health_percentage=$((healthy_pods * 100 / total_pods))
    
    cat >> "$health_report" <<EOF

---

## Overall Cluster Health

- **Total Pods:** $total_pods
- **Healthy Pods:** $healthy_pods
- **Unhealthy Pods:** $unhealthy_pods
- **Health Percentage:** $health_percentage%

### Health Status
EOF
    
    if [[ $health_percentage -ge 90 ]]; then
        echo "üü¢ **EXCELLENT** - Cluster is in excellent health" >> "$health_report"
    elif [[ $health_percentage -ge 75 ]]; then
        echo "üü° **GOOD** - Cluster is in good health with minor issues" >> "$health_report"
    elif [[ $health_percentage -ge 50 ]]; then
        echo "üü† **WARNING** - Cluster has significant health issues" >> "$health_report"
    else
        echo "üî¥ **CRITICAL** - Cluster is in critical condition" >> "$health_report"
    fi
    
    log_success "Cluster health assessment completed. Report: $health_report"
}

# Generate comprehensive diagnostic report
generate_final_report() {
    log_info "Generating comprehensive diagnostic report..."
    
    local final_report="$OUTPUT_DIR/comprehensive_report.html"
    
    cat > "$final_report" <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Pod Diagnostics Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
        .header { background-color: #f4f4f4; padding: 20px; border-radius: 5px; margin-bottom: 30px; }
        .section { margin: 30px 0; }
        .pod-card { border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin: 10px 0; }
        .healthy { border-left: 5px solid #28a745; }
        .unhealthy { border-left: 5px solid #dc3545; }
        .warning { border-left: 5px solid #ffc107; }
        .metric { display: inline-block; margin: 10px 15px 10px 0; padding: 8px 12px; background-color: #e9ecef; border-radius: 3px; }
        .issue { background-color: #fff3cd; padding: 10px; border-radius: 3px; margin: 10px 0; }
        pre { background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }
        .tabs { border-bottom: 1px solid #ddd; margin-bottom: 20px; }
        .tab { display: inline-block; padding: 10px 20px; cursor: pointer; border-bottom: 2px solid transparent; }
        .tab.active { border-bottom-color: #007bff; color: #007bff; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }
    </style>
    <script>
        function showTab(tabName) {
            // Hide all tab contents
            var contents = document.getElementsByClassName('tab-content');
            for (var i = 0; i < contents.length; i++) {
                contents[i].classList.remove('active');
            }
            
            // Remove active class from all tabs
            var tabs = document.getElementsByClassName('tab');
            for (var i = 0; i < tabs.length; i++) {
                tabs[i].classList.remove('active');
            }
            
            // Show selected tab content and mark tab as active
            document.getElementById(tabName).classList.add('active');
            event.target.classList.add('active');
        }
    </script>
</head>
<body>
    <div class="header">
        <h1>üîç Pod Diagnostics Report</h1>
        <div class="metric">
            <strong>Generated:</strong> $(date)
        </div>
        <div class="metric">
            <strong>Cluster:</strong> $(kubectl config current-context)
        </div>
        <div class="metric">
            <strong>Diagnostics Version:</strong> 2.0
        </div>
    </div>
    
    <div class="tabs">
        <div class="tab active" onclick="showTab('overview')">Overview</div>
        <div class="tab" onclick="showTab('pods')">Pod Analysis</div>
        <div class="tab" onclick="showTab('issues')">Detected Issues</div>
        <div class="tab" onclick="showTab('recommendations')">Recommendations</div>
    </div>
    
    <div id="overview" class="tab-content active">
        <h2>üìä Cluster Overview</h2>
        <div class="section">
EOF
    
    # Add cluster metrics
    local total_nodes=$(kubectl get nodes --no-headers | wc -l)
    local ready_nodes=$(kubectl get nodes --no-headers | grep " Ready " | wc -l)
    local total_namespaces=$(kubectl get namespaces --no-headers | wc -l)
    
    cat >> "$final_report" <<EOF
            <div class="pod-card healthy">
                <h3>Cluster Metrics</h3>
                <div class="metric"><strong>Nodes:</strong> $ready_nodes/$total_nodes Ready</div>
                <div class="metric"><strong>Namespaces:</strong> $total_namespaces</div>
                <div class="metric"><strong>Kubernetes Version:</strong> $(kubectl version --short --client | cut -d' ' -f3)</div>
            </div>
        </div>
    </div>
    
    <div id="pods" class="tab-content">
        <h2>üöÄ Pod Analysis</h2>
EOF
    
    # Add pod analysis for each analyzed pod
    for pod_dir in "$OUTPUT_DIR"/pods/*/; do
        if [[ -d "$pod_dir" ]]; then
            local pod_name=$(basename "$pod_dir")
            local issues_count=0
            
            if [[ -f "$pod_dir/detected_issues.md" ]]; then
                issues_count=$(grep -c "## Issue" "$pod_dir/detected_issues.md" 2>/dev/null || echo "0")
            fi
            
            local card_class="healthy"
            if [[ $issues_count -gt 0 ]]; then
                card_class="unhealthy"
            fi
            
            cat >> "$final_report" <<EOF
        <div class="pod-card $card_class">
            <h3>üì¶ $pod_name</h3>
            <div class="metric"><strong>Issues Detected:</strong> $issues_count</div>
            <div class="metric"><strong>Analysis Files:</strong> $(ls "$pod_dir" | wc -l)</div>
            <div class="metric"><strong>Report Location:</strong> pods/$pod_name/</div>
        </div>
EOF
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="issues" class="tab-content">
        <h2>‚ö†Ô∏è Detected Issues</h2>
EOF
    
    # Aggregate all issues
    local total_issues=0
    for issues_file in "$OUTPUT_DIR"/pods/*/detected_issues.md; do
        if [[ -f "$issues_file" ]]; then
            local pod_issues=$(grep -c "## Issue" "$issues_file" 2>/dev/null || echo "0")
            ((total_issues += pod_issues))
            
            if [[ $pod_issues -gt 0 ]]; then
                local pod_name=$(basename "$(dirname "$issues_file")")
                echo "<h3>Issues for $pod_name</h3>" >> "$final_report"
                
                # Convert markdown issues to HTML
                grep "## Issue" "$issues_file" | while read -r line; do
                    echo "<div class=\"issue\">$line</div>" >> "$final_report"
                done
            fi
        fi
    done
    
    if [[ $total_issues -eq 0 ]]; then
        echo "<div class=\"pod-card healthy\"><h3>‚úÖ No Issues Detected</h3><p>All analyzed pods appear to be healthy!</p></div>" >> "$final_report"
    fi
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="recommendations" class="tab-content">
        <h2>üí° Recommendations</h2>
        <div class="section">
            <div class="pod-card warning">
                <h3>General Recommendations</h3>
                <ul>
                    <li>‚úÖ Implement comprehensive health checks for all pods</li>
                    <li>‚úÖ Set appropriate resource requests and limits</li>
                    <li>‚úÖ Use security contexts to harden pod security</li>
                    <li>‚úÖ Monitor resource usage and optimize accordingly</li>
                    <li>‚úÖ Implement graceful shutdown handling</li>
                    <li>‚úÖ Use multi-stage Docker builds for smaller images</li>
                    <li>‚úÖ Implement proper logging and observability</li>
                </ul>
            </div>
        </div>
EOF
    
    # Add pod-specific recommendations
    for rec_file in "$OUTPUT_DIR"/pods/*/recommendations.md; do
        if [[ -f "$rec_file" ]]; then
            local pod_name=$(basename "$(dirname "$rec_file")")
            echo "<div class=\"pod-card\"><h3>Recommendations for $pod_name</h3>" >> "$final_report"
            echo "<p>See detailed recommendations in: pods/$pod_name/recommendations.md</p></div>" >> "$final_report"
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div class="section">
        <hr>
        <p><em>Report generated by Pod Diagnostics Toolkit v2.0</em></p>
        <p><em>For detailed analysis, check individual files in the diagnostics output directory.</em></p>
    </div>
    
</body>
</html>
EOF
    
    log_success "Comprehensive report generated: $final_report"
    echo ""
    echo -e "${BOLD}üìã Diagnostic Summary:${NC}"
    echo "- Output Directory: $OUTPUT_DIR"
    echo "- HTML Report: $final_report"
    echo "- Total Issues Found: $total_issues"
    echo ""
    echo -e "${CYAN}üí° Next Steps:${NC}"
    echo "1. Open $final_report in your browser"
    echo "2. Review individual pod analysis in $OUTPUT_DIR/pods/"
    echo "3. Implement recommended fixes"
    echo "4. Re-run diagnostics to verify improvements"
}

# Main execution function
main() {
    local command=${1:-help}
    local pod_name=${2:-}
    local namespace=${3:-$NAMESPACE}
    
    case "$command" in
        "analyze")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for analysis"
                echo "Usage: $0 analyze <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            gather_pod_info "$pod_name" "$namespace"
            detect_common_issues "$pod_name" "$namespace"
            generate_recommendations "$pod_name" "$namespace"
            generate_final_report
            ;;
            
        "interactive")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for interactive mode"
                echo "Usage: $0 interactive <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            interactive_diagnostics "$pod_name" "$namespace"
            ;;
            
        "cluster-health")
            init_diagnostics
            cluster_health_assessment
            generate_final_report
            ;;
            
        "help"|*)
            cat <<EOF
üîç Advanced Pod Diagnostics Toolkit

Usage: $0 <command> [options]

Commands:
  analyze <pod-name> [namespace]     - Run comprehensive pod analysis
  interactive <pod-name> [namespace] - Start interactive diagnostic session
  cluster-health                     - Assess health of all pods in cluster
  help                              - Show this help message

Environment Variables:
  NAMESPACE - Default namespace (default: default)
  VERBOSE   - Enable verbose output (default: false)

Examples:
  $0 analyze nginx-pod production
  $0 interactive web-app-123
  $0 cluster-health
  VERBOSE=true $0 analyze problematic-pod

Output:
  All diagnostic data is saved to ./diagnostics-TIMESTAMP/
  HTML report provides comprehensive overview
  Individual pod analysis available in pods/ subdirectory

EOF
            ;;
    esac
}

# Execute main function
main "$@"
```

---

## Summary and Production-Ready Examples

### üèÜ Complete Production Workflow

Let's create a final comprehensive example that brings everything together:

```yaml
# complete-production-workflow.yaml
# This represents a complete production-ready pod deployment workflow

apiVersion: v1
kind: Namespace
metadata:
  name: production-workload
  labels:
    environment: production
    team: platform
---
# ConfigMap for application configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production-workload
data:
  app.properties: |
    server.port=8080
    management.port=8081
    logging.level=INFO
    metrics.enabled=true
  nginx.conf: |
    server {
        listen 80;
        location /health { return 200 'healthy\n'; }
        location /ready { return 200 'ready\n'; }
        location / {
            proxy_pass http://127.0.0.1:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
---
# Secret for sensitive configuration
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: production-workload
type: Opaque
data:
  database-password: c3VwZXJzZWNyZXQ=  # supersecret (base64)
  api-key: YWJjZGVmZ2hpams=  # abcdefghijk (base64)
---
# Production-ready pod with all best practices
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production-workload
  labels:
    app: production-app
    version: "2.1.0"
    environment: production
    team: platform
    component: backend
  annotations:
    description: "Production application with full observability"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/production-app"
    prometheus.io/scrape: "true"
    prometheus.io/port: "8081"
    prometheus.io/path: "/metrics"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Resource constraints and node placement
  nodeSelector:
    node-type: "application"
    performance-tier: "high"
    
  tolerations:
  - key: "dedicated-app"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
    
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: production-app
        topologyKey: kubernetes.io/hostname
        
  # DNS and network configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  # Init container for setup tasks
  initContainers:
  - name: setup
    image: busybox:1.35
    command:
    - /bin/sh
    - -c
    - |
      echo "Initializing application..."
      
      # Database migration simulation
      echo "Running database migrations..."
      sleep 5
      
      # Cache warming
      echo "Warming up caches..."
      sleep 3
      
      # Configuration validation
      echo "Validating configuration..."
      if [ -f /config/app.properties ]; then
        echo "‚úÖ Configuration file found"
      else
        echo "‚ùå Configuration file missing"
        exit 1
      fi
      
      echo "Initialization completed successfully"
      
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-init
      mountPath: /tmp
      
  # Main application containers
  containers:
  # Application container
  - name: app
    image: openjdk:11-jre-slim
    command:
    - /bin/bash
    - -c
    - |
      echo "Starting application..."
      
      # Simulated application startup
      java -Xmx200m -Xms100m -jar /app/application.jar \
        --spring.config.location=file:/config/app.properties \
        --server.port=8080 \
        --management.server.port=8081
        
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP
    - name: management
      containerPort: 8081
      protocol: TCP
      
    # Environment configuration
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # Sensitive configuration from secrets
    - name: DATABASE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: database-password
    - name: API_KEY
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: api-key
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security hardening
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    # Comprehensive health checks
    livenessProbe:
      httpGet:
        path: /actuator/health/liveness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /actuator/health/readiness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /actuator/health
        port: 8081
      initialDelaySeconds: 20
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle management
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Application started at $(date)" >> /tmp/startup.log
            # Custom post-start logic here
            
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Graceful shutdown initiated at $(date)" >> /tmp/shutdown.log
            # Send SIGTERM to application
            kill -TERM 1
            # Wait for graceful shutdown
            sleep 30
            
    # Volume mounts
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-volume
      mountPath: /tmp
    - name: app-logs
      mountPath: /app/logs
    - name: app-data
      mountPath: /app/data
      
  # Nginx reverse proxy sidecar
  - name: nginx-proxy
    image: nginx:1.21-alpine
    ports:
    - name: http-proxy
      containerPort: 80
      protocol: TCP
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        add: ["NET_BIND_SERVICE"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: nginx-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
      
  # Logging and monitoring sidecar
  - name: log-shipper
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: fluent-tmp
      mountPath: /tmp
      
  # Volumes
  volumes:
  - name: config-volume
    configMap:
      name: app-config
      items:
      - key: app.properties
        path: app.properties
  - name: nginx-config
    configMap:
      name: app-config
      items:
      - key: nginx.conf
        path: default.conf
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config  # Would be created separately
  # Temporary and cache volumes
  - name: tmp-volume
    emptyDir:
      sizeLimit: 256Mi
  - name: tmp-init
    emptyDir:
      sizeLimit: 64Mi
  - name: nginx-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: fluent-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: nginx-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: nginx-run
    emptyDir:
      sizeLimit: 32Mi
  # Application data volumes
  - name: app-logs
    emptyDir:
      sizeLimit: 1Gi
  - name: app-data
    emptyDir:
      sizeLimit: 2Gi
```

This comprehensive example demonstrates:

- **Complete security hardening** with proper contexts and capabilities
- **Multi-container architecture** with main app, proxy, and logging sidecars
- **Comprehensive health checks** for all containers
- **Resource optimization** with appropriate requests and limits
- **Configuration management** using ConfigMaps and Secrets
- **Observability** with structured logging and metrics endpoints
- **Production-ready networking** with reverse proxy
- **Graceful lifecycle management** with init containers and shutdown hooks

## üéì Key Learning Outcomes

By working through these enhanced examples, demos, and mini-projects, you've gained:

1. **Foundation Skills**: Basic pod creation, inspection, and management
2. **Intermediate Capabilities**: Multi-container patterns, health monitoring, and debugging
3. **Advanced Techniques**: Performance optimization, security hardening, and automation
4. **Expert-Level Mastery**: Custom controllers, comprehensive diagnostics, and production workflows

### üöÄ Next Steps for Continued Learning

1. **Practice the Examples**: Work through each example in your own cluster
2. **Customize for Your Use Cases**: Adapt the patterns to your specific applications
3. **Build Your Toolkit**: Create your own diagnostic and management scripts
4. **Share and Learn**: Contribute back to the community with your own improvements
5. **Scale Up**: Apply these pod management skills to higher-level controllers

The journey from basic pod creation to# 5. Working with Pods - From Fundamentals to Mastery (Enhanced Edition)

Understanding how to work with pods effectively forms the foundation of all Kubernetes operations. While you'll typically use higher-level controllers like Deployments in production environments, direct pod management skills are essential for debugging, troubleshooting, and truly understanding how Kubernetes applications function at their core. Think of this knowledge as learning to drive a manual transmission car‚Äîeven if you usually drive automatic, understanding the underlying mechanics makes you a better driver overall.

This enhanced guide provides progressive examples, hands-on demos, and real-world mini-projects to solidify your understanding through practical application.

## üéØ Learning Path Overview

- **Foundation Level**: Basic pod creation and inspection
- **Intermediate Level**: Multi-container patterns and health checks
- **Advanced Level**: Complex debugging and optimization
- **Expert Level**: Custom tooling and automation

---

## Understanding Pod Creation Strategies

Creating pods effectively requires understanding when to use imperative commands versus declarative configurations, and how different creation approaches serve different purposes.

### üìö Foundation Examples

Let's start with the absolute basics and progressively build complexity.

#### Example 1: Your First Pod
```bash
# Create the simplest possible pod
kubectl run hello-world --image=nginx --restart=Never

# Verify it's running
kubectl get pods

# Expected output:
# NAME          READY   STATUS    RESTARTS   AGE
# hello-world   1/1     Running   0          30s
```

#### Example 2: Pod with Custom Commands
```bash
# Create a pod that runs a custom command
kubectl run date-pod --image=busybox --restart=Never -- date

# This pod will run the date command and then exit
# Check the output
kubectl logs date-pod

# Clean up
kubectl delete pod date-pod
```

#### Example 3: Interactive Pod Session
```bash
# Create an interactive debugging pod
kubectl run -it debug-pod --image=busybox --restart=Never -- sh

# Inside the pod, try these commands:
# ls -la
# ps aux
# ping google.com
# nslookup kubernetes.default.svc.cluster.local

# Exit and clean up
# exit
kubectl delete pod debug-pod
```

### üõ†Ô∏è Demo: Pod Lifecycle Observation

Let's create a demo that shows the complete pod lifecycle in action:

```bash
#!/bin/bash
# pod-lifecycle-demo.sh

echo "=== Pod Lifecycle Demonstration ==="

# Terminal 1: Start watching pods
echo "In a separate terminal, run: kubectl get pods -w"
echo "Press Enter when ready..."
read

# Create a pod with a slow-starting application
echo "Creating pod with slow startup..."
kubectl run lifecycle-demo --image=nginx --restart=Never \
  --dry-run=client -o yaml > lifecycle-pod.yaml

# Add some customizations to make it more interesting
cat <<EOF >> lifecycle-pod.yaml
  containers:
  - name: nginx
    image: nginx:1.21
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod starting up...' && sleep 10"
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod shutting down...' && sleep 5"
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 5
EOF

echo "Applying pod configuration..."
kubectl apply -f lifecycle-pod.yaml

echo "Watch the pod states change from Pending -> ContainerCreating -> Running"
echo "Press Enter to continue when pod is Running..."
read

# Show detailed pod information
echo "=== Pod Details ==="
kubectl describe pod lifecycle-demo

echo "Press Enter to delete the pod and observe termination..."
read

# Delete and watch termination
kubectl delete pod lifecycle-demo

echo "Demo complete! Clean up the YAML file:"
echo "rm lifecycle-pod.yaml"
```

### üéØ Mini-Project 1: Pod Resource Monitor

Create a simple monitoring system using pods:

```yaml
# resource-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-monitor
  labels:
    app: monitor
    type: demo
spec:
  containers:
  - name: monitor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Starting Resource Monitor..."
      while true; do
        echo "=== $(date) ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "Load average:"
        uptime
        echo "Sleeping for 30 seconds..."
        sleep 30
      done
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
  restartPolicy: Always
```

```bash
# Deploy and monitor
kubectl apply -f resource-monitor-pod.yaml

# Watch the logs
kubectl logs -f resource-monitor

# In another terminal, check resource usage
kubectl top pod resource-monitor

# Clean up
kubectl delete -f resource-monitor-pod.yaml
```

---

## Deep Pod Inspection and Monitoring

### üîç Intermediate Examples

#### Example 4: Multi-Container Pod Investigation

```yaml
# multi-container-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-demo
  labels:
    demo: multi-container
spec:
  containers:
  - name: web-server
    image: nginx:1.21
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
    
  - name: log-processor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Log processor starting..."
      while true; do
        if [ -f /var/log/nginx/access.log ]; then
          echo "=== Access Log Summary $(date) ==="
          tail -10 /var/log/nginx/access.log | wc -l
          echo "Recent requests:"
          tail -5 /var/log/nginx/access.log
        else
          echo "Waiting for access.log..."
        fi
        sleep 30
      done
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
      
  - name: metrics-collector
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Metrics collector starting..."
      while true; do
        echo "=== Metrics $(date) ==="
        echo "Container count: 3"
        echo "Uptime: $(uptime)"
        echo "Memory: $(free -h | grep Mem)"
        sleep 60
      done
      
  volumes:
  - name: shared-logs
    emptyDir: {}
```

**Inspection Commands:**
```bash
# Apply the multi-container pod
kubectl apply -f multi-container-demo.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/multi-container-demo

# Inspect different aspects
echo "=== Basic Information ==="
kubectl get pod multi-container-demo -o wide

echo "=== Container Status ==="
kubectl get pod multi-container-demo -o jsonpath='{.status.containerStatuses[*].name}' | tr ' ' '\n'

echo "=== Logs from each container ==="
kubectl logs multi-container-demo -c web-server --tail=5
kubectl logs multi-container-demo -c log-processor --tail=5
kubectl logs multi-container-demo -c metrics-collector --tail=5

# Generate some traffic to see shared volume in action
kubectl port-forward multi-container-demo 8080:80 &
PF_PID=$!

# Generate requests
for i in {1..10}; do
  curl -s http://localhost:8080 > /dev/null
  echo "Request $i sent"
  sleep 1
done

kill $PF_PID

# Check log processor output
kubectl logs multi-container-demo -c log-processor --tail=10

# Clean up
kubectl delete -f multi-container-demo.yaml
```

### üõ†Ô∏è Demo: Advanced Pod Debugging Techniques

```bash
#!/bin/bash
# advanced-debugging-demo.sh

echo "=== Advanced Pod Debugging Demo ==="

# Create a problematic pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: problematic-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "2000m"  # This might cause scheduling issues
      limits:
        memory: "512Mi"  # Less than request - invalid!
        cpu: "500m"
    livenessProbe:
      httpGet:
        path: /nonexistent
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
EOF

echo "Created a pod with multiple issues. Let's debug it..."

# Wait a moment for issues to manifest
sleep 10

echo "=== Debugging Steps ==="

echo "1. Check pod status:"
kubectl get pod problematic-pod -o wide

echo "2. Look at events:"
kubectl describe pod problematic-pod | grep -A 10 Events:

echo "3. Check for resource issues:"
kubectl describe pod problematic-pod | grep -A 5 -B 5 "resource"

echo "4. Examine container status:"
kubectl get pod problematic-pod -o jsonpath='{.status.containerStatuses[0]}' | jq '.'

# Fix the pod
echo "5. Let's fix the issues..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: fixed-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
EOF

echo "6. Compare the fixed pod:"
kubectl wait --for=condition=Ready pod/fixed-pod --timeout=60s
kubectl get pods -l debug=demo

# Clean up
echo "Cleaning up..."
kubectl delete pod problematic-pod fixed-pod
```

### üéØ Mini-Project 2: Pod Health Monitoring Dashboard

Create a comprehensive health monitoring system:

```yaml
# health-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: health-dashboard
  labels:
    app: health-monitor
spec:
  containers:
  - name: health-checker
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Health Dashboard Starting..."
      
      # Create a simple HTML dashboard
      mkdir -p /tmp/dashboard
      
      while true; do
        cat > /tmp/dashboard/health.html <<EOF
      <!DOCTYPE html>
      <html>
      <head>
          <title>Pod Health Dashboard</title>
          <meta http-equiv="refresh" content="30">
          <style>
              body { font-family: Arial, sans-serif; margin: 40px; }
              .healthy { color: green; }
              .warning { color: orange; }
              .critical { color: red; }
              .metric { margin: 10px 0; padding: 10px; border: 1px solid #ccc; }
          </style>
      </head>
      <body>
          <h1>Pod Health Dashboard</h1>
          <p>Last Update: $(date)</p>
          
          <div class="metric">
              <h3>System Load</h3>
              <p>$(uptime)</p>
          </div>
          
          <div class="metric">
              <h3>Memory Usage</h3>
              <pre>$(free -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Disk Usage</h3>
              <pre>$(df -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Process Count</h3>
              <p>Running processes: $(ps aux | wc -l)</p>
          </div>
          
      </body>
      </html>
      EOF
        
        echo "Dashboard updated at $(date)"
        sleep 30
      done
    volumeMounts:
    - name: dashboard-storage
      mountPath: /tmp/dashboard
      
  - name: web-server
    image: nginx:alpine
    ports:
    - containerPort: 80
    command:
    - /bin/sh
    - -c
    - |
      # Configure nginx to serve our dashboard
      cat > /etc/nginx/conf.d/default.conf <<EOF
      server {
          listen 80;
          location / {
              root /usr/share/nginx/html;
              index health.html;
          }
      }
      EOF
      
      # Start nginx
      nginx -g "daemon off;"
    volumeMounts:
    - name: dashboard-storage
      mountPath: /usr/share/nginx/html
      
  volumes:
  - name: dashboard-storage
    emptyDir: {}
    
  restartPolicy: Always
```

**Usage:**
```bash
# Deploy the health dashboard
kubectl apply -f health-monitor-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/health-dashboard

# Access the dashboard
kubectl port-forward health-dashboard 8080:80

# Open browser to http://localhost:8080
echo "Open http://localhost:8080 in your browser"

# Monitor the pod's own health
kubectl top pod health-dashboard

# Check logs from both containers
kubectl logs health-dashboard -c health-checker --tail=10
kubectl logs health-dashboard -c web-server --tail=10

# Clean up
kubectl delete -f health-monitor-pod.yaml
```

---

## Interactive Pod Management and Debugging

### üîß Advanced Examples

#### Example 5: Network Debugging Pod

```yaml
# network-debug-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: network-debugger
  labels:
    purpose: network-debug
spec:
  containers:
  - name: nettools
    image: nicolaka/netshoot
    command: ["/bin/bash"]
    args:
    - -c
    - |
      echo "Network debugging tools ready!"
      echo "Available tools: dig, nslookup, ping, curl, wget, tcpdump, netstat"
      echo "Example commands:"
      echo "  dig kubernetes.default.svc.cluster.local"
      echo "  ping 8.8.8.8"
      echo "  curl -I http://httpbin.org/headers"
      echo "  netstat -tulpn"
      
      # Keep container running
      sleep 3600
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
  restartPolicy: Never
```

**Debugging Session:**
```bash
# Deploy the network debugger
kubectl apply -f network-debug-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/network-debugger

# Start interactive session
kubectl exec -it network-debugger -- bash

# Inside the pod, run network diagnostics:
# Test DNS resolution
# dig kubernetes.default.svc.cluster.local

# Test external connectivity
# ping -c 3 8.8.8.8

# Test HTTP services
# curl -I https://httpbin.org/headers

# Check network interfaces
# ip addr show

# Check routing table
# ip route show

# Test service discovery
# nslookup kubernetes.default

# Exit and clean up
# exit
kubectl delete -f network-debug-pod.yaml
```

### üõ†Ô∏è Demo: File Transfer and Volume Management

```bash
#!/bin/bash
# file-transfer-demo.sh

echo "=== File Transfer and Volume Demo ==="

# Create a pod with persistent data
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: file-demo
spec:
  containers:
  - name: app
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Creating sample files..."
      mkdir -p /data/logs /data/config
      
      # Generate some sample data
      for i in {1..5}; do
        echo "Log entry \$i at \$(date)" >> /data/logs/app.log
        sleep 1
      done
      
      echo "app_name=demo-app" > /data/config/settings.conf
      echo "version=1.0.0" >> /data/config/settings.conf
      echo "debug=true" >> /data/config/settings.conf
      
      echo "Files created. Keeping container running..."
      sleep 3600
    volumeMounts:
    - name: data-storage
      mountPath: /data
  volumes:
  - name: data-storage
    emptyDir: {}
EOF

echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/file-demo

# Demonstrate file operations
echo "=== File Operations Demo ==="

echo "1. List files in the pod:"
kubectl exec file-demo -- find /data -type f

echo "2. Copy file from pod to local:"
kubectl cp file-demo:/data/logs/app.log ./app.log.backup
echo "File copied to: app.log.backup"
cat app.log.backup

echo "3. Create local config file:"
cat > new-config.conf <<EOF
app_name=updated-demo-app
version=2.0.0
debug=false
environment=production
EOF

echo "4. Copy local file to pod:"
kubectl cp new-config.conf file-demo:/data/config/

echo "5. Verify file in pod:"
kubectl exec file-demo -- cat /data/config/new-config.conf

echo "6. Create a backup of all data:"
kubectl exec file-demo -- tar -czf /tmp/backup.tar.gz -C /data .
kubectl cp file-demo:/tmp/backup.tar.gz ./pod-data-backup.tar.gz
echo "Backup created: pod-data-backup.tar.gz"

# Clean up
echo "Cleaning up..."
kubectl delete pod file-demo
rm -f app.log.backup new-config.conf pod-data-backup.tar.gz

echo "Demo complete!"
```

### üéØ Mini-Project 3: Pod Security Scanner

Create a security scanning tool using pods:

```yaml
# security-scanner-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-scanner
  labels:
    app: security
    type: scanner
spec:
  serviceAccountName: default
  containers:
  - name: scanner
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "=== Pod Security Scanner Starting ==="
      
      # Function to check security configurations
      check_security() {
        echo "Checking security configurations..."
        
        # Check if running as root
        if [ "$(id -u)" -eq 0 ]; then
          echo "‚ö†Ô∏è  WARNING: Running as root user"
        else
          echo "‚úÖ GOOD: Running as non-root user ($(id -u))"
        fi
        
        # Check filesystem permissions
        if [ -w "/" ]; then
          echo "‚ö†Ô∏è  WARNING: Root filesystem is writable"
        else
          echo "‚úÖ GOOD: Root filesystem is read-only"
        fi
        
        # Check for sensitive mounts
        if mount | grep -q "/var/run/secrets"; then
          echo "‚ÑπÔ∏è  INFO: Service account token mounted"
        fi
        
        # Check available capabilities
        echo "Current capabilities:"
        if [ -f "/proc/self/status" ]; then
          grep Cap /proc/self/status
        fi
        
        # Check network access
        echo "Testing network access..."
        if ping -c 1 8.8.8.8 >/dev/null 2>&1; then
          echo "‚ÑπÔ∏è  INFO: External network access available"
        else
          echo "‚ÑπÔ∏è  INFO: No external network access"
        fi
        
        # Generate security report
        cat > /tmp/security-report.txt <<EOF
      === Security Scan Report ===
      Timestamp: $(date)
      User ID: $(id -u)
      Group ID: $(id -g)
      Working Directory: $(pwd)
      
      Filesystem Check:
      - Root writable: $([ -w "/" ] && echo "YES" || echo "NO")
      - /tmp writable: $([ -w "/tmp" ] && echo "YES" || echo "NO")
      
      Network Check:
      - External access: $(ping -c 1 8.8.8.8 >/dev/null 2>&1 && echo "YES" || echo "NO")
      
      Process Information:
      $(ps aux)
      EOF
        
        echo "Report generated at /tmp/security-report.txt"
      }
      
      # Run security check
      check_security
      
      # Keep running for inspection
      echo "Scanner complete. Container will stay running for inspection."
      sleep 3600
      
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 1000
      runAsGroup: 3000
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir: {}
    
  restartPolicy: Never
```

**Usage:**
```bash
# Deploy the security scanner
kubectl apply -f security-scanner-pod.yaml

# Monitor the scan
kubectl logs -f security-scanner

# Get the security report
kubectl cp security-scanner:/tmp/security-report.txt ./security-report.txt
cat security-report.txt

# Create a comparison with an insecure pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: insecure-pod
spec:
  containers:
  - name: insecure
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      runAsUser: 0  # Running as root
      privileged: true
EOF

# Compare security postures
echo "=== Security Comparison ==="
echo "Secure pod user:"
kubectl exec security-scanner -- id

echo "Insecure pod user:"
kubectl exec insecure-pod -- id

echo "Secure pod capabilities:"
kubectl exec security-scanner -- grep Cap /proc/self/status

echo "Insecure pod capabilities:"
kubectl exec insecure-pod -- grep Cap /proc/self/status

# Clean up
kubectl delete pod security-scanner insecure-pod
rm -f security-report.txt
```

---

## Declarative Pod Configuration and Management

### üèóÔ∏è Expert Examples

#### Example 6: Production-Ready Pod Template

```yaml
# production-pod-template.yaml
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production
  labels:
    app: web-server
    version: "2.1.0"
    environment: production
    team: platform
  annotations:
    description: "Production web server with full monitoring and security"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/web-server"
    version: "2.1.0"
    build-date: "2024-01-15T10:30:00Z"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Node selection
  nodeSelector:
    node-type: "application"
    zone: "us-west-2a"
    
  # Tolerations for dedicated nodes
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "application"
    effect: "NoSchedule"
    
  # Pod placement preferences
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: "node-type"
            operator: In
            values: ["application"]
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: web-server
          topologyKey: kubernetes.io/hostname
          
  # DNS configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  containers:
  - name: web-server
    image: nginx:1.21-alpine
    imagePullPolicy: IfNotPresent
    
    ports:
    - name: http
      containerPort: 80
      protocol: TCP
    - name: metrics
      containerPort: 9113
      protocol: TCP
      
    # Environment variables
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "info"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security context
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE
        
    # Health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 80
        scheme: HTTP
        httpHeaders:
        - name: Custom-Header
          value: liveness-check
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
        scheme: HTTP
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle hooks
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container started at $(date)" >> /tmp/startup.log
            # Custom initialization logic here
            
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container stopping at $(date)" >> /tmp/shutdown.log
            # Graceful shutdown logic here
            nginx -s quit
            sleep 15
            
    # Volume mounts
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  # Sidecar container for log processing
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  # Monitoring sidecar
  - name: nginx-exporter
    image: nginx/nginx-prometheus-exporter:0.10.0
    args:
    - -nginx.scrape-uri=http://localhost:80/nginx_status
    ports:
    - name: metrics
      containerPort: 9113
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
  # Shared volumes
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
      defaultMode: 0644
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
      defaultMode: 0644
  - name: html-content
    configMap:
      name: html-content
      defaultMode: 0644
  - name: tmp-dir
    emptyDir:
      sizeLimit: 256Mi
  - name: var-cache-nginx
    emptyDir:
      sizeLimit: 512Mi
  - name: var-run
    emptyDir:
      sizeLimit: 64Mi
  - name: logs
    emptyDir:
      sizeLimit: 1Gi
```

### üõ†Ô∏è Demo: Complex Pod Deployment Pipeline

```bash
#!/bin/bash
# production-pod-deployment.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

# Configuration
NAMESPACE="production-demo"
APP_NAME="web-server"
CONFIG_DIR="./config"

# Create namespace if it doesn't exist
create_namespace() {
    log "Creating namespace: $NAMESPACE"
    kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    success "Namespace $NAMESPACE ready"
}

# Create ConfigMaps for the application
create_configmaps() {
    log "Creating ConfigMaps..."
    
    mkdir -p $CONFIG_DIR
    
    # Nginx configuration
    cat > $CONFIG_DIR/nginx.conf <<EOF
server {
    listen 80;
    server_name localhost;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
    
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    location /ready {
        access_log off;
        return 200 "ready\n";
        add_header Content-Type text/plain;
    }
    
    location /nginx_status {
        stub_status on;
        access_log off;
        allow all;
    }
}
EOF

    # HTML content
    cat > $CONFIG_DIR/index.html <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Production Pod Demo</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .container { max-width: 800px; margin: 0 auto; }
        .status { padding: 20px; margin: 20px 0; border-radius: 5px; }
        .healthy { background-color: #d4edda; color: #155724; }
        .info { background-color: #d1ecf1; color: #0c5460; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Production Pod Demo</h1>
        <div class="status healthy">
            <h3>‚úÖ Application Status: Healthy</h3>
            <p>Pod is running successfully with full production configuration</p>
        </div>
        
        <div class="status info">
            <h3>üìä Features Enabled:</h3>
            <ul>
                <li>Multi-container architecture</li>
                <li>Comprehensive health checks</li>
                <li>Security hardening</li>
                <li>Log processing sidecar</li>
                <li>Prometheus metrics export</li>
                <li>Resource management</li>
            </ul>
        </div>
        
        <div class="status info">
            <h3>üîó Endpoints:</h3>
            <ul>
                <li><a href="/health">Health Check</a></li>
                <li><a href="/ready">Readiness Check</a></li>
                <li><a href="/nginx_status">Nginx Status</a></li>
            </ul>
        </div>
    </div>
</body>
</html>
EOF

    # Fluent Bit configuration
    cat > $CONFIG_DIR/fluent-bit.conf <<EOF
[SERVICE]
    Flush         1
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf

[INPUT]
    Name              tail
    Path              /var/log/nginx/access.log
    Parser            nginx
    Tag               nginx.access
    Refresh_Interval  5

[INPUT]
    Name              tail
    Path              /var/log/nginx/error.log
    Tag               nginx.error
    Refresh_Interval  5

[OUTPUT]
    Name  stdout
    Match nginx.*
EOF

    cat > $CONFIG_DIR/parsers.conf <<EOF
[PARSER]
    Name   nginx
    Format regex
    Regex  ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
    Time_Key time
    Time_Format %d/%b/%Y:%H:%M:%S %z
EOF

    # Create ConfigMaps
    kubectl create configmap nginx-config --from-file=$CONFIG_DIR/nginx.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap html-content --from-file=$CONFIG_DIR/index.html -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap fluent-bit-config --from-file=$CONFIG_DIR/fluent-bit.conf --from-file=$CONFIG_DIR/parsers.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    
    success "ConfigMaps created successfully"
}

# Deploy the production pod
deploy_pod() {
    log "Deploying production pod..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: $APP_NAME
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
    version: "1.0.0"
    environment: production
  annotations:
    deployment.kubernetes.io/revision: "1"
    deployed-by: "production-deployment-script"
    deployment-time: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    
  containers:
  - name: nginx
    image: nginx:1.21-alpine
    ports:
    - name: http
      containerPort: 80
    - name: metrics
      containerPort: 9113
      
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
  - name: html-content
    configMap:
      name: html-content
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
  - name: tmp-dir
    emptyDir: {}
  - name: var-cache-nginx
    emptyDir: {}
  - name: var-run
    emptyDir: {}
  - name: logs
    emptyDir: {}
EOF

    success "Pod deployed successfully"
}

# Wait for pod to be ready and perform health checks
verify_deployment() {
    log "Waiting for pod to be ready..."
    
    if kubectl wait --for=condition=Ready pod/$APP_NAME -n $NAMESPACE --timeout=120s; then
        success "Pod is ready!"
    else
        error "Pod failed to become ready within timeout"
    fi
    
    # Perform comprehensive health checks
    log "Performing health checks..."
    
    # Check pod status
    kubectl get pod $APP_NAME -n $NAMESPACE -o wide
    
    # Test health endpoints
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    if curl -s http://localhost:8080/health | grep -q "healthy"; then
        success "Health check passed"
    else
        warning "Health check failed"
    fi
    
    if curl -s http://localhost:8080/ready | grep -q "ready"; then
        success "Readiness check passed"
    else
        warning "Readiness check failed"
    fi
    
    # Test the main application
    if curl -s http://localhost:8080 | grep -q "Production Pod Demo"; then
        success "Application is serving content correctly"
    else
        warning "Application content check failed"
    fi
    
    kill $PF_PID 2>/dev/null
    
    # Check resource usage
    log "Checking resource usage..."
    if kubectl top pod $APP_NAME -n $NAMESPACE &>/dev/null; then
        kubectl top pod $APP_NAME -n $NAMESPACE
    else
        warning "Resource metrics not available"
    fi
    
    # Check logs from all containers
    log "Checking container logs..."
    echo "=== Nginx logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c nginx --tail=5
    echo "=== Log processor logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=5
}

# Generate load and monitor performance
performance_test() {
    log "Running performance test..."
    
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    # Generate some load
    for i in {1..50}; do
        curl -s http://localhost:8080 > /dev/null &
    done
    
    wait
    kill $PF_PID 2>/dev/null
    
    # Check logs after load test
    log "Logs after load test:"
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=10
    
    success "Performance test completed"
}

# Cleanup function
cleanup() {
    log "Cleaning up resources..."
    kubectl delete pod $APP_NAME -n $NAMESPACE --ignore-not-found
    kubectl delete configmap nginx-config html-content fluent-bit-config -n $NAMESPACE --ignore-not-found
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -rf $CONFIG_DIR
    success "Cleanup completed"
}

# Main execution
main() {
    echo "=== Production Pod Deployment Demo ==="
    
    case "${1:-deploy}" in
        "deploy")
            create_namespace
            create_configmaps
            deploy_pod
            verify_deployment
            performance_test
            
            echo ""
            success "Deployment completed successfully!"
            echo "Access the application:"
            echo "  kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80"
            echo "  Then open: http://localhost:8080"
            echo ""
            echo "Monitor the pod:"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c nginx"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c log-processor"
            echo ""
            echo "Run 'bash $0 cleanup' to remove all resources"
            ;;
        "cleanup")
            cleanup
            ;;
        "test")
            verify_deployment
            performance_test
            ;;
        *)
            echo "Usage: $0 [deploy|cleanup|test]"
            echo "  deploy  - Deploy the production pod (default)"
            echo "  cleanup - Remove all created resources"
            echo "  test    - Run verification and performance tests"
            ;;
    esac
}

main "$@"
```

### üéØ Mini-Project 4: Pod Chaos Engineering

Test pod resilience with chaos engineering principles:

```yaml
# chaos-test-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: chaos-resilient-app
  labels:
    app: chaos-test
    resilience: enabled
spec:
  containers:
  - name: main-app
    image: nginx:1.21-alpine
    ports:
    - containerPort: 80
    
    # Aggressive resource limits to test resilience
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    # Tight health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 2
      
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
      timeoutSeconds: 1
      failureThreshold: 2
      
    # Graceful shutdown
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 10"]
          
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  # Chaos monkey sidecar
  - name: chaos-monkey
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Chaos monkey starting..."
      
      # Function to create CPU load
      cpu_chaos() {
        echo "Creating CPU chaos..."
        for i in {1..4}; do
          yes > /dev/null &
        done
        sleep 30
        killall yes
      }
      
      # Function to create memory pressure
      memory_chaos() {
        echo "Creating memory chaos..."
        cat <(yes | tr \\n x | head -c 50000000) <(yes | tr \\n x | head -c 50000000) > /tmp/memory_eater &
        sleep 20
        rm -f /tmp/memory_eater
        killall cat
      }
      
      # Function to simulate network issues
      network_chaos() {
        echo "Creating network chaos..."
        # Simulate slow responses
        sleep $((RANDOM % 10 + 5))
      }
      
      # Function to create disk I/O pressure
      disk_chaos() {
        echo "Creating disk I/O chaos..."
        dd if=/dev/zero of=/tmp/disk_eater bs=1M count=10 2>/dev/null
        rm -f /tmp/disk_eater
      }
      
      # Main chaos loop
      while true; do
        chaos_type=$((RANDOM % 4))
        case $chaos_type in
          0) cpu_chaos ;;
          1) memory_chaos ;;
          2) network_chaos ;;
          3) disk_chaos ;;
        esac
        
        # Wait between chaos events
        sleep $((RANDOM % 60 + 30))
      done
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir:
      sizeLimit: 100Mi
      
  restartPolicy: Always
```

**Chaos Testing Script:**
```bash
#!/bin/bash
# chaos-engineering-test.sh

echo "=== Chaos Engineering Test ==="

# Deploy the chaos test pod
kubectl apply -f chaos-test-pod.yaml

# Wait for it to be ready
echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/chaos-resilient-app --timeout=60s

# Monitor pod resilience
echo "Starting resilience monitoring (Ctrl+C to stop)..."

monitor_resilience() {
    while true; do
        timestamp=$(date '+%H:%M:%S')
        
        # Check pod status
        status=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.phase}')
        ready=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
        restarts=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.containerStatuses[0].restartCount}')
        
        # Test application responsiveness
        kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
        PF_PID=$!
        sleep 2
        
        response_time=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8080 2>/dev/null || echo "FAIL")
        kill $PF_PID 2>/dev/null
        
        # Get resource usage if available
        resources=""
        if kubectl top pod chaos-resilient-app &>/dev/null; then
            resources=$(kubectl top pod chaos-resilient-app --no-headers 2>/dev/null | awk '{print $2" "$3}')
        fi
        
        printf "[$timestamp] Status: $status | Ready: $ready | Restarts: $restarts | Response: ${response_time}s | Resources: $resources\n"
        
        sleep 5
    done
}

# Start monitoring in background
monitor_resilience &
MONITOR_PID=$!

# Generate additional load to test resilience
echo "Generating load to test resilience..."
for i in {1..100}; do
    kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
    PF_PID=$!
    sleep 1
    
    curl -s http://localhost:8080 > /dev/null &
    
    kill $PF_PID 2>/dev/null
    sleep 2
done

# Stop monitoring
kill $MONITOR_PID 2>/dev/null

echo "Chaos test completed. Check pod logs:"
echo "kubectl logs chaos-resilient-app -c main-app --tail=20"
echo "kubectl logs chaos-resilient-app -c chaos-monkey --tail=20"

# Cleanup
read -p "Delete the chaos test pod? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    kubectl delete -f chaos-test-pod.yaml
fi
```

---

## Advanced Pod Management Techniques

### üî¨ Expert-Level Examples

#### Example 7: Custom Pod Controller

Create a custom controller for specialized pod management:

```python
#!/usr/bin/env python3
# custom-pod-controller.py

import time
import yaml
import subprocess
import json
from datetime import datetime, timedelta

class PodController:
    def __init__(self):
        self.managed_pods = {}
        self.check_interval = 30  # seconds
        
    def log(self, message):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"[{timestamp}] {message}")
        
    def run_kubectl(self, command):
        """Execute kubectl command and return JSON output"""
        try:
            result = subprocess.run(
                f"kubectl {command} -o json",
                shell=True,
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                self.log(f"kubectl error: {result.stderr}")
                return None
        except Exception as e:
            self.log(f"Command execution error: {e}")
            return None
            
    def get_pods_by_label(self, label_selector):
        """Get pods matching label selector"""
        command = f"get pods -l {label_selector}"
        result = self.run_kubectl(command)
        return result.get('items', []) if result else []
        
    def create_pod(self, name, spec):
        """Create a pod with given specification"""
        pod_manifest = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'name': name,
                'labels': {
                    'managed-by': 'custom-controller',
                    'created': datetime.now().strftime('%Y%m%d-%H%M%S')
                }
            },
            'spec': spec
        }
        
        # Write manifest to temporary file
        with open(f'/tmp/{name}.yaml', 'w') as f:
            yaml.dump(pod_manifest, f)
            
        # Apply the manifest
        result = subprocess.run(
            f"kubectl apply -f /tmp/{name}.yaml",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Created pod: {name}")
            return True
        else:
            self.log(f"Failed to create pod {name}: {result.stderr}")
            return False
            
    def delete_pod(self, name):
        """Delete a pod"""
        result = subprocess.run(
            f"kubectl delete pod {name} --grace-period=30",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Deleted pod: {name}")
            return True
        else:
            self.log(f"Failed to delete pod {name}: {result.stderr}")
            return False
            
    def check_pod_health(self, pod):
        """Check if a pod is healthy based on custom criteria"""
        name = pod['metadata']['name']
        status = pod['status']
        
        # Check if pod is running
        if status.get('phase') != 'Running':
            return False, f"Pod {name} is not running (phase: {status.get('phase')})"
            
        # Check container statuses
        container_statuses = status.get('containerStatuses', [])
        for container in container_statuses:
            if not container.get('ready'):
                return False, f"Container {container['name']} not ready in pod {name}"
                
            # Check restart count
            restart_count = container.get('restartCount', 0)
            if restart_count > 5:
                return False, f"Container {container['name']} restarted {restart_count} times"
                
        # Check resource usage (if metrics available)
        metrics = self.get_pod_metrics(name)
        if metrics:
            cpu_usage = self.parse_cpu_usage(metrics.get('cpu', '0m'))
            memory_usage = self.parse_memory_usage(metrics.get('memory', '0Mi'))
            
            if cpu_usage > 800:  # 800 millicores
                return False, f"Pod {name} CPU usage too high: {cpu_usage}m"
                
            if memory_usage > 512:  # 512 Mi
                return False, f"Pod {name} memory usage too high: {memory_usage}Mi"
                
        return True, f"Pod {name} is healthy"
        
    def get_pod_metrics(self, pod_name):
        """Get pod resource metrics if available"""
        result = subprocess.run(
            f"kubectl top pod {pod_name} --no-headers",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            parts = result.stdout.strip().split()
            if len(parts) >= 3:
                return {
                    'cpu': parts[1],
                    'memory': parts[2]
                }
        return None
        
    def parse_cpu_usage(self, cpu_str):
        """Parse CPU usage from string like '100m' to millicores"""
        if cpu_str.endswith('m'):
            return int(cpu_str[:-1])
        return int(cpu_str) * 1000
        
    def parse_memory_usage(self, memory_str):
        """Parse memory usage from string like '128Mi' to Mi"""
        if memory_str.endswith('Mi'):
            return int(memory_str[:-2])
        elif memory_str.endswith('Gi'):
            return int(memory_str[:-2]) * 1024
        return int(memory_str) // (1024 * 1024)
        
    def auto_heal_pod(self, pod_name, reason):
        """Attempt to heal an unhealthy pod"""
        self.log(f"Attempting to heal pod {pod_name}: {reason}")
        
        # Strategy 1: Restart the pod
        if "restart" in reason.lower():
            return self.delete_pod(pod_name)  # Pod will be recreated if managed by controller
            
        # Strategy 2: Scale resources if high usage
        if "usage too high" in reason.lower():
            self.log(f"High resource usage detected for {pod_name}, marking for recreation")
            return self.delete_pod(pod_name)
            
        # Strategy 3: Generic restart
        return self.delete_pod(pod_name)
        
    def manage_workload(self, workload_config):
        """Manage a workload with desired replica count"""
        app_name = workload_config['name']
        desired_replicas = workload_config['replicas']
        pod_spec = workload_config['pod_spec']
        
        # Get current pods for this workload
        current_pods = self.get_pods_by_label(f"app={app_name},managed-by=custom-controller")
        current_count = len(current_pods)
        
        self.log(f"Managing workload {app_name}: current={current_count}, desired={desired_replicas}")
        
        # Scale up if needed
        if current_count < desired_replicas:
            for i in range(current_count, desired_replicas):
                pod_name = f"{app_name}-{i}"
                pod_spec_copy = pod_spec.copy()
                pod_spec_copy.setdefault('containers', [{}])[0]['env'] = [
                    {'name': 'REPLICA_ID', 'value': str(i)},
                    {'name': 'APP_NAME', 'value': app_name}
                ]
                self.create_pod(pod_name, pod_spec_copy)
                
        # Scale down if needed
        elif current_count > desired_replicas:
            pods_to_delete = current_pods[desired_replicas:]
            for pod in pods_to_delete:
                self.delete_pod(pod['metadata']['name'])
                
        # Health check existing pods
        for pod in current_pods[:desired_replicas]:
            healthy, reason = self.check_pod_health(pod)
            if not healthy:
                self.log(f"Pod unhealthy: {reason}")
                self.auto_heal_pod(pod['metadata']['name'], reason)
                
    def run_control_loop(self):
        """Main control loop"""
        self.log("Starting custom pod controller...")
        
        # Sample workload configuration
        workloads = [
            {
                'name': 'web-app',
                'replicas': 2,
                'pod_spec': {
                    'containers': [{
                        'name': 'nginx',
                        'image': 'nginx:1.21-alpine',
                        'ports': [{'containerPort': 80}],
                        'resources': {
                            'requests': {'memory': '64Mi', 'cpu': '50m'},
                            'limits': {'memory': '128Mi', 'cpu': '100m'}
                        },
                        'livenessProbe': {
                            'httpGet': {'path': '/', 'port': 80},
                            'initialDelaySeconds': 10,
                            'periodSeconds': 30
                        }
                    }],
                    'restartPolicy': 'Always'
                }
            }
        ]
        
        try:
            while True:
                self.log("Running control loop...")
                
                for workload in workloads:
                    try:
                        self.manage_workload(workload)
                    except Exception as e:
                        self.log(f"Error managing workload {workload['name']}: {e}")
                        
                self.log(f"Sleeping for {self.check_interval} seconds...")
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            self.log("Shutting down controller...")
            
        except Exception as e:
            self.log(f"Controller error: {e}")
            
    def cleanup(self):
        """Clean up managed resources"""
        self.log("Cleaning up managed pods...")
        pods = self.get_pods_by_label("managed-by=custom-controller")
        for pod in pods:
            self.delete_pod(pod['metadata']['name'])

if __name__ == "__main__":
    import sys
    
    controller = PodController()
    
    if len(sys.argv) > 1 and sys.argv[1] == "cleanup":
        controller.cleanup()
    else:
        controller.run_control_loop()
```

**Usage:**
```bash
# Make the script executable
chmod +x custom-pod-controller.py

# Install dependencies
pip3 install pyyaml

# Run the controller
python3 custom-pod-controller.py

# In another terminal, watch the managed pods
watch kubectl get pods -l managed-by=custom-controller

# Simulate pod failures
kubectl delete pod web-app-0  # Controller will recreate it

# Clean up when done
python3 custom-pod-controller.py cleanup
```

### üéØ Mini-Project 5: Pod Performance Optimization Lab

Create a comprehensive performance optimization laboratory:

```yaml
# performance-lab-setup.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: performance-lab
---
# Baseline pod - unoptimized
apiVersion: v1
kind: Pod
metadata:
  name: baseline-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: baseline
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "1000m"
      limits:
        memory: "2Gi"
        cpu: "2000m"
---
# Optimized pod - resource-efficient
apiVersion: v1
kind: Pod
metadata:
  name: optimized-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: optimized
spec:
  containers:
  - name: app
    image: nginx:1.21-alpine  # Smaller image
    resources:
      requests:
        memory: "64Mi"        # Right-sized requests
        cpu: "100m"
      limits:
        memory: "128Mi"       # Conservative limits
        cpu: "200m"
    # Optimized health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5   # Faster startup
      periodSeconds: 30        # Less frequent checks
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
    # Security optimizations
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
    # Volume optimizations
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp-dir
    emptyDir:
      medium: Memory  # Use memory for temp files
      sizeLimit: 64Mi
  - name: var-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: var-run
    emptyDir:
      sizeLimit: 32Mi
---
# High-performance pod with advanced optimizations
apiVersion: v1
kind: Pod
metadata:
  name: high-performance-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: high-performance
spec:
  # Pod-level optimizations
  priorityClassName: high-priority
  nodeSelector:
    node-type: performance
  tolerations:
  - key: performance-node
    operator: Equal
    value: "true"
    effect: NoSchedule
  # Network optimizations
  dnsPolicy: ClusterFirstWithHostNet
  dnsConfig:
    options:
    - name: ndots
      value: "1"
    - name: edns0
  containers:
  - name: app
    image: nginx:1.21-alpine
    # Optimized resource allocation
    resources:
      requests:
        memory: "128Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "256Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
    # Performance-tuned environment
    env:
    - name: NGINX_WORKER_PROCESSES
      value: "auto"
    - name: NGINX_WORKER_CONNECTIONS
      value: "1024"
    # Aggressive health checks for faster recovery
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 15
      timeoutSeconds: 2
      failureThreshold: 2
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 3
      timeoutSeconds: 1
      failureThreshold: 1
    # Startup optimization
    startupProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 1
      timeoutSeconds: 1
      failureThreshold: 10
    # Performance-optimized volumes
    volumeMounts:
    - name: high-speed-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
  volumes:
  - name: high-speed-tmp
    emptyDir:
      medium: Memory
      sizeLimit: 128Mi
  - name: nginx-cache
    emptyDir:
      medium: Memory
      sizeLimit: 256Mi
  - name: nginx-run
    emptyDir:
      medium: Memory
      sizeLimit: 64Mi
```

**Performance Benchmarking Script:**
```bash
#!/bin/bash
# performance-benchmark.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

NAMESPACE="performance-lab"

# Deploy the performance lab
setup_lab() {
    log "Setting up performance lab..."
    kubectl apply -f performance-lab-setup.yaml
    
    log "Waiting for pods to be ready..."
    kubectl wait --for=condition=Ready pod/baseline-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/optimized-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/high-performance-app -n $NAMESPACE --timeout=120s
    
    success "Performance lab setup complete"
}

# Measure startup time
measure_startup_time() {
    local pod_name=$1
    log "Measuring startup time for $pod_name..."
    
    # Delete and recreate pod to measure startup
    kubectl delete pod $pod_name -n $NAMESPACE
    local start_time=$(date +%s.%N)
    
    # Recreate the pod (extract from original manifest)
    kubectl get pod $pod_name -n $NAMESPACE -o yaml --export 2>/dev/null | kubectl apply -f - 2>/dev/null || {
        warning "Couldn't recreate pod automatically, recreating from manifest"
        kubectl apply -f performance-lab-setup.yaml
    }
    
    # Wait for ready and measure time
    kubectl wait --for=condition=Ready pod/$pod_name -n $NAMESPACE --timeout=120s
    local end_time=$(date +%s.%N)
    
    local startup_time=$(echo "$end_time - $start_time" | bc -l)
    echo "$startup_time"
}

# Run load test on a pod
load_test_pod() {
    local pod_name=$1
    local duration=${2:-30}
    local concurrency=${3:-10}
    
    log "Running load test on $pod_name (${duration}s, ${concurrency} concurrent)"
    
    # Start port forwarding
    kubectl port-forward pod/$pod_name -n $NAMESPACE 8080:80 >/dev/null 2>&1 &
    local pf_pid=$!
    sleep 3
    
    # Use Apache Bench for load testing
    local results_file="/tmp/ab_results_${pod_name}.txt"
    
    if command -v ab >/dev/null; then
        ab -n $((duration * concurrency)) -c $concurrency -g /tmp/gnuplot_${pod_name}.dat \
           http://localhost:8080/ > $results_file 2>&1
        
        # Extract key metrics
        local rps=$(grep "Requests per second" $results_file | awk '{print $4}')
        local response_time=$(grep "Time per request.*mean" $results_file | head -1 | awk '{print $4}')
        local failed_requests=$(grep "Failed requests" $results_file | awk '{print $3}')
        
        echo "RPS:$rps,ResponseTime:$response_time,Failed:$failed_requests"
    else
        # Fallback to curl-based test
        local start_time=$(date +%s)
        local requests=0
        local total_time=0
        
        for i in $(seq 1 $((duration * concurrency))); do
            local req_start=$(date +%s.%N)
            if curl -s http://localhost:8080 >/dev/null 2>&1; then
                ((requests++))
            fi
            local req_end=$(date +%s.%N)
            local req_time=$(echo "$req_end - $req_start" | bc -l)
            total_time=$(echo "$total_time + $req_time" | bc -l)
            
            # Basic rate limiting
            sleep 0.1
        done
        
        local avg_response_time=$(echo "scale=3; $total_time / $requests" | bc -l)
        local rps=$(echo "scale=2; $requests / $duration" | bc -l)
        
        echo "RPS:$rps,ResponseTime:$avg_response_time,Failed:0"
    fi
    
    kill $pf_pid 2>/dev/null
}

# Get resource usage metrics
get_resource_usage() {
    local pod_name=$1
    log "Getting resource usage for $pod_name..."
    
    if kubectl top pod $pod_name -n $NAMESPACE >/dev/null 2>&1; then
        kubectl top pod $pod_name -n $NAMESPACE --no-headers | awk '{print "CPU:"$2",Memory:"$3}'
    else
        echo "CPU:N/A,Memory:N/A"
    fi
}

# Comprehensive benchmark
run_comprehensive_benchmark() {
    log "Running comprehensive performance benchmark..."
    
    declare -A results
    local pods=("baseline-app" "optimized-app" "high-performance-app")
    
    echo "=== Performance Benchmark Results ===" > benchmark_results.txt
    echo "Timestamp: $(date)" >> benchmark_results.txt
    echo "" >> benchmark_results.txt
    
    for pod in "${pods[@]}"; do
        log "Benchmarking $pod..."
        
        # Startup time measurement
        log "Measuring startup time for $pod..."
        # Skip startup measurement in this demo to avoid pod recreation issues
        startup_time="N/A"
        
        # Resource usage
        resource_usage=$(get_resource_usage $pod)
        
        # Load test
        load_results=$(load_test_pod $pod 30 10)
        
        # Pod status information
        pod_info=$(kubectl get pod $pod -n $NAMESPACE -o custom-columns=STATUS:.status.phase,READY:.status.conditions[?\(@.type==\"Ready\"\)].status,RESTARTS:.status.containerStatuses[0].restartCount --no-headers)
        
        # Store results
        results[$pod]="Startup:$startup_time,Resources:$resource_usage,Load:$load_results,Status:$pod_info"
        
        # Write to file
        cat >> benchmark_results.txt <<EOF

=== $pod ===
Startup Time: $startup_time seconds
Resource Usage: $resource_usage
Load Test Results: $load_results
Pod Status: $pod_info

EOF
    done
    
    # Generate comparison summary
    cat >> benchmark_results.txt <<EOF

=== Performance Summary ===
This benchmark compares three pod configurations:

1. Baseline App: Standard configuration with generous resource allocation
2. Optimized App: Resource-efficient with security hardening
3. High-Performance App: Maximum performance optimizations

Key Findings:
- Resource efficiency varies significantly between configurations
- Startup time impacts overall application availability
- Load handling capacity differs based on resource allocation
- Security optimizations may have performance trade-offs

Recommendations:
- Use optimized configuration for production workloads
- Consider high-performance setup for critical applications
- Monitor resource usage to fine-tune allocations
- Balance security and performance based on requirements

EOF
    
    success "Benchmark completed. Results saved to benchmark_results.txt"
    cat benchmark_results.txt
}

# Resource monitoring script
monitor_resources() {
    local duration=${1:-300}  # 5 minutes default
    log "Starting resource monitoring for ${duration} seconds..."
    
    local monitor_file="resource_monitor_$(date +%Y%m%d_%H%M%S).log"
    
    {
        echo "Timestamp,Pod,CPU,Memory,Status"
        local end_time=$(($(date +%s) + duration))
        
        while [ $(date +%s) -lt $end_time ]; do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            
            for pod in baseline-app optimized-app high-performance-app; do
                if kubectl get pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                    local status=$(kubectl get pod $pod -n $NAMESPACE -o jsonpath='{.status.phase}')
                    local usage="N/A,N/A"
                    
                    if kubectl top pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                        usage=$(kubectl top pod $pod -n $NAMESPACE --no-headers | awk '{print $2","$3}')
                    fi
                    
                    echo "$timestamp,$pod,$usage,$status"
                fi
            done
            
            sleep 10
        done
    } > $monitor_file
    
    success "Resource monitoring completed. Data saved to $monitor_file"
    
    # Generate simple analysis
    log "Generating resource usage analysis..."
    
    {
        echo "=== Resource Usage Analysis ==="
        echo ""
        
        for pod in baseline-app optimized-app high-performance-app; do
            echo "=== $pod ==="
            grep "$pod" $monitor_file | tail -10 | while IFS=',' read timestamp pod_name cpu memory status; do
                echo "[$timestamp] CPU: $cpu, Memory: $memory, Status: $status"
            done
            echo ""
        done
    } > resource_analysis.txt
    
    success "Analysis saved to resource_analysis.txt"
}

# Cleanup function
cleanup_lab() {
    log "Cleaning up performance lab..."
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -f benchmark_results.txt resource_*.log resource_analysis.txt
    rm -f /tmp/ab_results_*.txt /tmp/gnuplot_*.dat
    success "Cleanup completed"
}

# Main execution
main() {
    case "${1:-benchmark}" in
        "setup")
            setup_lab
            ;;
        "benchmark")
            setup_lab
            run_comprehensive_benchmark
            ;;
        "monitor")
            monitor_resources "${2:-300}"
            ;;
        "cleanup")
            cleanup_lab
            ;;
        "all")
            setup_lab
            run_comprehensive_benchmark
            monitor_resources 300
            echo ""
            success "Complete performance analysis finished!"
            echo "Files created:"
            echo "  - benchmark_results.txt"
            echo "  - resource_monitor_*.log"
            echo "  - resource_analysis.txt"
            ;;
        *)
            echo "Performance Lab - Pod Optimization Benchmark"
            echo ""
            echo "Usage: $0 <command> [options]"
            echo ""
            echo "Commands:"
            echo "  setup      - Set up the performance lab environment"
            echo "  benchmark  - Run comprehensive performance benchmark"
            echo "  monitor    - Monitor resource usage for specified duration"
            echo "  cleanup    - Remove all lab resources"
            echo "  all        - Run complete analysis (setup + benchmark + monitor)"
            echo ""
            echo "Examples:"
            echo "  $0 setup"
            echo "  $0 benchmark"
            echo "  $0 monitor 600  # Monitor for 10 minutes"
            echo "  $0 all          # Complete analysis"
            ;;
    esac
}

main "$@"
```

---

## Pod Troubleshooting Methodologies

### üîß Advanced Troubleshooting Toolkit

#### Example 8: Automated Diagnostic System

```bash
#!/bin/bash
# advanced-pod-diagnostics.sh

set -euo pipefail

# Enhanced diagnostic toolkit with automated problem detection
class PodDiagnostics {
    
# Configuration
NAMESPACE=${NAMESPACE:-default}
OUTPUT_DIR="./diagnostics-$(date +%Y%m%d-%H%M%S)"
VERBOSE=${VERBOSE:-false}

# Colors and formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'
BOLD='\033[1m'

# Logging functions with levels
log_debug() { [[ $VERBOSE == "true" ]] && echo -e "${CYAN}[DEBUG]${NC} $1"; }
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }

# Initialize diagnostics
init_diagnostics() {
    log_info "Initializing pod diagnostics system..."
    mkdir -p "$OUTPUT_DIR"/{logs,reports,metrics,manifests}
    
    # Create diagnostic report header
    cat > "$OUTPUT_DIR/diagnostic_report.md" <<EOF
# Pod Diagnostics Report

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)  
**Namespace:** $NAMESPACE  
**Output Directory:** $OUTPUT_DIR

---

EOF
    
    log_success "Diagnostics initialized in $OUTPUT_DIR"
}

# Comprehensive pod information gathering
gather_pod_info() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Gathering comprehensive information for pod: $pod_name"
    
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    mkdir -p "$pod_dir"
    
    # Basic pod information
    kubectl get pod "$pod_name" -n "$namespace" -o wide > "$pod_dir/basic_info.txt" 2>&1
    kubectl get pod "$pod_name" -n "$namespace" -o yaml > "$pod_dir/manifest.yaml" 2>&1
    
    # Detailed description
    kubectl describe pod "$pod_name" -n "$namespace" > "$pod_dir/description.txt" 2>&1
    
    # Events related to the pod
    kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
        --sort-by='.lastTimestamp' > "$pod_dir/events.txt" 2>&1
    
    # Container logs
    local containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}' 2>/dev/null)
    for container in $containers; do
        log_debug "Collecting logs for container: $container"
        kubectl logs "$pod_name" -n "$namespace" -c "$container" > "$pod_dir/logs_${container}.txt" 2>&1
        
        # Previous logs if container restarted
        kubectl logs "$pod_name" -n "$namespace" -c "$container" --previous > "$pod_dir/logs_${container}_previous.txt" 2>&1 || true
    done
    
    # Resource usage
    kubectl top pod "$pod_name" -n "$namespace" > "$pod_dir/resource_usage.txt" 2>&1 || echo "Metrics not available" > "$pod_dir/resource_usage.txt"
    
    log_success "Pod information gathered for $pod_name"
}

# Automated problem detection
detect_common_issues() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Running automated issue detection for $pod_name..."
    
    local issues_file="$pod_dir/detected_issues.md"
    echo "# Automated Issue Detection Report" > "$issues_file"
    echo "**Pod:** $pod_name" >> "$issues_file"
    echo "**Analysis Time:** $(date)" >> "$issues_file"
    echo "" >> "$issues_file"
    
    local issue_count=0
    
    # Check 1: Pod phase issues
    local phase=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.phase}' 2>/dev/null)
    if [[ "$phase" != "Running" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Pod Not Running
- **Severity:** High
- **Status:** Pod is in '$phase' phase instead of 'Running'
- **Impact:** Application unavailable
- **Investigation:** Check pod events and container status

EOF
    fi
    
    # Check 2: Container readiness issues
    local ready_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[?(@.ready==true)]}' | jq '. | length' 2>/dev/null || echo "0")
    local total_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers}' | jq '. | length' 2>/dev/null || echo "1")
    
    if [[ "$ready_containers" -lt "$total_containers" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Container Readiness Problems
- **Severity:** High
- **Status:** Only $ready_containers of $total_containers containers are ready
- **Impact:** Traffic routing may be affected
- **Investigation:** Check readiness probes and container logs

EOF
    fi
    
    # Check 3: Excessive restarts
    local restarts=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
    if [[ "$restarts" -gt 5 ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Excessive Container Restarts
- **Severity:** Medium
- **Status:** Container has restarted $restarts times
- **Impact:** Service instability and potential data loss
- **Investigation:** Check liveness probes, resource limits, and application logs

EOF
    fi
    
    # Check 4: Resource usage issues
    if kubectl top pod "$pod_name" -n "$namespace" >/dev/null 2>&1; then
        local cpu_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $2}' | sed 's/m$//')
        local memory_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $3}' | sed 's/Mi$//')
        
        if [[ "$cpu_usage" -gt 800 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High CPU Usage
- **Severity:** Medium
- **Status:** CPU usage is ${cpu_usage}m (> 800m threshold)
- **Impact:** Performance degradation and potential throttling
- **Investigation:** Check for CPU-intensive processes and consider scaling

EOF
        fi
        
        if [[ "$memory_usage" -gt 512 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High Memory Usage
- **Severity:** Medium  
- **Status:** Memory usage is ${memory_usage}Mi (> 512Mi threshold)
- **Impact:** Risk of OOM kills and service disruption
- **Investigation:** Check for memory leaks and optimize memory usage

EOF
        fi
    fi
    
    # Check 5: Image pull issues
    if grep -q "ImagePullBackOff\|ErrImagePull" "$pod_dir/description.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Image Pull Problems
- **Severity:** High
- **Status:** Unable to pull container image
- **Impact:** Pod cannot start
- **Investigation:** Check image name, registry access, and credentials

EOF
    fi
    
    # Check 6: Resource constraints
    if grep -q "Insufficient.*resources" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Resource Constraints
- **Severity:** High
- **Status:** Insufficient cluster resources for pod scheduling
- **Impact:** Pod cannot be scheduled
- **Investigation:** Check cluster capacity and node resources

EOF
    fi
    
    # Check 7: Network issues
    if grep -q "NetworkNotReady\|CNI.*error" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Network Configuration Problems
- **Severity:** High
- **Status:** Network setup issues detected
- **Impact:** Pod networking may not function correctly
- **Investigation:** Check CNI configuration and network policies

EOF
    fi
    
    # Summary
    if [[ $issue_count -eq 0 ]]; then
        echo "## Summary: No Critical Issues Detected ‚úÖ" >> "$issues_file"
        echo "The automated analysis found no obvious problems with this pod." >> "$issues_file"
        log_success "No critical issues detected for $pod_name"
    else
        echo "## Summary: $issue_count Issue(s) Detected ‚ö†Ô∏è" >> "$issues_file"
        echo "Review the issues above and follow the investigation recommendations." >> "$issues_file"
        log_warn "$issue_count issue(s) detected for $pod_name"
    fi
    
    return $issue_count
}

# Generate recommendations
generate_recommendations() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Generating recommendations for $pod_name..."
    
    local rec_file="$pod_dir/recommendations.md"
    echo "# Optimization Recommendations" > "$rec_file"
    echo "**Pod:** $pod_name" >> "$rec_file"
    echo "" >> "$rec_file"
    
    # Resource optimization recommendations
    echo "## Resource Optimization" >> "$rec_file"
    
    # Check current resource configuration
    local requests_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.memory}' 2>/dev/null || echo "not set")
    local requests_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.cpu}' 2>/dev/null || echo "not set")
    local limits_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.memory}' 2>/dev/null || echo "not set")
    local limits_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.cpu}' 2>/dev/null || echo "not set")
    
    cat >> "$rec_file" <<EOF
### Current Resource Configuration
- **Memory Request:** $requests_mem
- **CPU Request:** $requests_cpu  
- **Memory Limit:** $limits_mem
- **CPU Limit:** $limits_cpu

EOF
    
    # Security recommendations
    echo "## Security Hardening" >> "$rec_file"
    
    local security_context=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.securityContext}' 2>/dev/null)
    if [[ -z "$security_context" || "$security_context" == "null" ]]; then
        cat >> "$rec_file" <<EOF
### Security Context Improvements
- ‚úÖ **Add security context:** Configure runAsNonRoot, runAsUser, and fsGroup
- ‚úÖ **Drop capabilities:** Remove unnecessary Linux capabilities  
- ‚úÖ **Read-only root filesystem:** Set readOnlyRootFilesystem: true
- ‚úÖ **Prevent privilege escalation:** Set allowPrivilegeEscalation: false

EOF
    fi
    
    # Health check recommendations
    echo "## Health Check Optimization" >> "$rec_file"
    
    local has_liveness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].livenessProbe}' 2>/dev/null)
    local has_readiness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].readinessProbe}' 2>/dev/null)
    
    if [[ -z "$has_liveness" || "$has_liveness" == "null" ]]; then
        echo "- ‚úÖ **Add liveness probe:** Implement health checking for automatic restart" >> "$rec_file"
    fi
    
    if [[ -z "$has_readiness" || "$has_readiness" == "null" ]]; then
        echo "- ‚úÖ **Add readiness probe:** Control traffic routing based on application readiness" >> "$rec_file"
    fi
    
    # Performance recommendations
    echo "" >> "$rec_file"
    echo "## Performance Optimization" >> "$rec_file"
    cat >> "$rec_file" <<EOF
- ‚úÖ **Use Alpine images:** Reduce image size and startup time
- ‚úÖ **Implement resource requests:** Help scheduler make better placement decisions
- ‚úÖ **Optimize health check frequency:** Balance responsiveness with overhead
- ‚úÖ **Use memory-backed volumes:** For temporary files and caches
- ‚úÖ **Configure DNS caching:** Reduce DNS lookup overhead

EOF
    
    log_success "Recommendations generated for $pod_name"
}

# Interactive diagnostic session
interactive_diagnostics() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Starting interactive diagnostics for $pod_name..."
    
    echo -e "${BOLD}Interactive Pod Diagnostics${NC}"
    echo "Pod: $pod_name"
    echo "Namespace: $namespace"
    echo ""
    
    while true; do
        echo -e "${CYAN}Available actions:${NC}"
        echo "1) Show pod status"
        echo "2) View recent events"
        echo "3) Check container logs"
        echo "4) Execute command in pod"
        echo "5) Port forward to pod"
        echo "6) Resource usage"
        echo "7) Run full diagnostic"
        echo "8) Generate recommendations"
        echo "q) Quit"
        echo ""
        
        read -p "Select action [1-8,q]: " choice
        
        case $choice in
            1)
                echo "=== Pod Status ==="
                kubectl get pod "$pod_name" -n "$namespace" -o wide
```" \
        10
    
    check_item "Memory limits defined" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.spec.containers[0].resources.limits.memory}' | grep -v '^
                kubectl describe pod "$pod_name" -n "$namespace" | grep -A 10 "Status\|Conditions"
                ;;
            2)
                echo "=== Recent Events ==="
                kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
                    --sort-by='.lastTimestamp' | tail -10
                ;;
            3)
                echo "=== Container Selection ==="
                local containers=($(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}'))
                if [[ ${#containers[@]} -eq 1 ]]; then
                    echo "Showing logs for container: ${containers[0]}"
                    kubectl logs "$pod_name" -n "$namespace" --tail=50
                else
                    echo "Available containers:"
                    for i in "${!containers[@]}"; do
                        echo "$((i+1))) ${containers[i]}"
                    done
                    read -p "Select container [1-${#containers[@]}]: " container_choice
                    if [[ $container_choice -ge 1 && $container_choice -le ${#containers[@]} ]]; then
                        local selected_container=${containers[$((container_choice-1))]}
                        echo "Showing logs for container: $selected_container"
                        kubectl logs "$pod_name" -n "$namespace" -c "$selected_container" --tail=50
                    fi
                fi
                ;;
            4)
                read -p "Enter command to execute: " exec_command
                kubectl exec -it "$pod_name" -n "$namespace" -- $exec_command
                ;;
            5)
                read -p "Enter local port: " local_port
                read -p "Enter pod port: " pod_port
                echo "Port forwarding $local_port:$pod_port - Press Ctrl+C to stop"
                kubectl port-forward "$pod_name" -n "$namespace" "$local_port:$pod_port"
                ;;
            6)
                echo "=== Resource Usage ==="
                kubectl top pod "$pod_name" -n "$namespace" 2>/dev/null || echo "Metrics not available"
                ;;
            7)
                gather_pod_info "$pod_name" "$namespace"
                detect_common_issues "$pod_name" "$namespace"
                generate_recommendations "$pod_name" "$namespace"
                echo "Full diagnostic completed. Check $OUTPUT_DIR/pods/$pod_name/"
                ;;
            8)
                generate_recommendations "$pod_name" "$namespace"
                echo "Recommendations generated. Check $OUTPUT_DIR/pods/$pod_name/recommendations.md"
                ;;
            q|Q)
                log_info "Exiting interactive diagnostics"
                break
                ;;
            *)
                echo "Invalid choice. Please try again."
                ;;
        esac
        
        echo ""
        read -p "Press Enter to continue..."
        echo ""
    done
}

# Cluster-wide pod health assessment
cluster_health_assessment() {
    log_info "Running cluster-wide pod health assessment..."
    
    local health_report="$OUTPUT_DIR/cluster_health_report.md"
    
    cat > "$health_report" <<EOF
# Cluster Pod Health Assessment

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)

---

EOF
    
    # Get all namespaces
    local namespaces=($(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'))
    
    local total_pods=0
    local healthy_pods=0
    local unhealthy_pods=0
    
    for ns in "${namespaces[@]}"; do
        log_info "Assessing namespace: $ns"
        
        local pods=($(kubectl get pods -n "$ns" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null))
        
        if [[ ${#pods[@]} -eq 0 ]]; then
            continue
        fi
        
        echo "## Namespace: $ns" >> "$health_report"
        echo "" >> "$health_report"
        
        local ns_healthy=0
        local ns_unhealthy=0
        
        for pod in "${pods[@]}"; do
            ((total_pods++))
            
            local phase=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.phase}')
            local ready_condition=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
            local restarts=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
            
            if [[ "$phase" == "Running" && "$ready_condition" == "True" && $restarts -lt 5 ]]; then
                ((healthy_pods++))
                ((ns_healthy++))
                echo "‚úÖ **$pod** - Healthy" >> "$health_report"
            else
                ((unhealthy_pods++))
                ((ns_unhealthy++))
                echo "‚ùå **$pod** - Issues detected (Phase: $phase, Ready: $ready_condition, Restarts: $restarts)" >> "$health_report"
                
                # Run quick diagnostics for unhealthy pods
                gather_pod_info "$pod" "$ns"
                detect_common_issues "$pod" "$ns"
            fi
        done
        
        echo "" >> "$health_report"
        echo "**Namespace Summary:** $ns_healthy healthy, $ns_unhealthy unhealthy" >> "$health_report"
        echo "" >> "$health_report"
    done
    
    # Overall summary
    local health_percentage=$((healthy_pods * 100 / total_pods))
    
    cat >> "$health_report" <<EOF

---

## Overall Cluster Health

- **Total Pods:** $total_pods
- **Healthy Pods:** $healthy_pods
- **Unhealthy Pods:** $unhealthy_pods
- **Health Percentage:** $health_percentage%

### Health Status
EOF
    
    if [[ $health_percentage -ge 90 ]]; then
        echo "üü¢ **EXCELLENT** - Cluster is in excellent health" >> "$health_report"
    elif [[ $health_percentage -ge 75 ]]; then
        echo "üü° **GOOD** - Cluster is in good health with minor issues" >> "$health_report"
    elif [[ $health_percentage -ge 50 ]]; then
        echo "üü† **WARNING** - Cluster has significant health issues" >> "$health_report"
    else
        echo "üî¥ **CRITICAL** - Cluster is in critical condition" >> "$health_report"
    fi
    
    log_success "Cluster health assessment completed. Report: $health_report"
}

# Generate comprehensive diagnostic report
generate_final_report() {
    log_info "Generating comprehensive diagnostic report..."
    
    local final_report="$OUTPUT_DIR/comprehensive_report.html"
    
    cat > "$final_report" <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Pod Diagnostics Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
        .header { background-color: #f4f4f4; padding: 20px; border-radius: 5px; margin-bottom: 30px; }
        .section { margin: 30px 0; }
        .pod-card { border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin: 10px 0; }
        .healthy { border-left: 5px solid #28a745; }
        .unhealthy { border-left: 5px solid #dc3545; }
        .warning { border-left: 5px solid #ffc107; }
        .metric { display: inline-block; margin: 10px 15px 10px 0; padding: 8px 12px; background-color: #e9ecef; border-radius: 3px; }
        .issue { background-color: #fff3cd; padding: 10px; border-radius: 3px; margin: 10px 0; }
        pre { background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }
        .tabs { border-bottom: 1px solid #ddd; margin-bottom: 20px; }
        .tab { display: inline-block; padding: 10px 20px; cursor: pointer; border-bottom: 2px solid transparent; }
        .tab.active { border-bottom-color: #007bff; color: #007bff; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }
    </style>
    <script>
        function showTab(tabName) {
            // Hide all tab contents
            var contents = document.getElementsByClassName('tab-content');
            for (var i = 0; i < contents.length; i++) {
                contents[i].classList.remove('active');
            }
            
            // Remove active class from all tabs
            var tabs = document.getElementsByClassName('tab');
            for (var i = 0; i < tabs.length; i++) {
                tabs[i].classList.remove('active');
            }
            
            // Show selected tab content and mark tab as active
            document.getElementById(tabName).classList.add('active');
            event.target.classList.add('active');
        }
    </script>
</head>
<body>
    <div class="header">
        <h1>üîç Pod Diagnostics Report</h1>
        <div class="metric">
            <strong>Generated:</strong> $(date)
        </div>
        <div class="metric">
            <strong>Cluster:</strong> $(kubectl config current-context)
        </div>
        <div class="metric">
            <strong>Diagnostics Version:</strong> 2.0
        </div>
    </div>
    
    <div class="tabs">
        <div class="tab active" onclick="showTab('overview')">Overview</div>
        <div class="tab" onclick="showTab('pods')">Pod Analysis</div>
        <div class="tab" onclick="showTab('issues')">Detected Issues</div>
        <div class="tab" onclick="showTab('recommendations')">Recommendations</div>
    </div>
    
    <div id="overview" class="tab-content active">
        <h2>üìä Cluster Overview</h2>
        <div class="section">
EOF
    
    # Add cluster metrics
    local total_nodes=$(kubectl get nodes --no-headers | wc -l)
    local ready_nodes=$(kubectl get nodes --no-headers | grep " Ready " | wc -l)
    local total_namespaces=$(kubectl get namespaces --no-headers | wc -l)
    
    cat >> "$final_report" <<EOF
            <div class="pod-card healthy">
                <h3>Cluster Metrics</h3>
                <div class="metric"><strong>Nodes:</strong> $ready_nodes/$total_nodes Ready</div>
                <div class="metric"><strong>Namespaces:</strong> $total_namespaces</div>
                <div class="metric"><strong>Kubernetes Version:</strong> $(kubectl version --short --client | cut -d' ' -f3)</div>
            </div>
        </div>
    </div>
    
    <div id="pods" class="tab-content">
        <h2>üöÄ Pod Analysis</h2>
EOF
    
    # Add pod analysis for each analyzed pod
    for pod_dir in "$OUTPUT_DIR"/pods/*/; do
        if [[ -d "$pod_dir" ]]; then
            local pod_name=$(basename "$pod_dir")
            local issues_count=0
            
            if [[ -f "$pod_dir/detected_issues.md" ]]; then
                issues_count=$(grep -c "## Issue" "$pod_dir/detected_issues.md" 2>/dev/null || echo "0")
            fi
            
            local card_class="healthy"
            if [[ $issues_count -gt 0 ]]; then
                card_class="unhealthy"
            fi
            
            cat >> "$final_report" <<EOF
        <div class="pod-card $card_class">
            <h3>üì¶ $pod_name</h3>
            <div class="metric"><strong>Issues Detected:</strong> $issues_count</div>
            <div class="metric"><strong>Analysis Files:</strong> $(ls "$pod_dir" | wc -l)</div>
            <div class="metric"><strong>Report Location:</strong> pods/$pod_name/</div>
        </div>
EOF
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="issues" class="tab-content">
        <h2>‚ö†Ô∏è Detected Issues</h2>
EOF
    
    # Aggregate all issues
    local total_issues=0
    for issues_file in "$OUTPUT_DIR"/pods/*/detected_issues.md; do
        if [[ -f "$issues_file" ]]; then
            local pod_issues=$(grep -c "## Issue" "$issues_file" 2>/dev/null || echo "0")
            ((total_issues += pod_issues))
            
            if [[ $pod_issues -gt 0 ]]; then
                local pod_name=$(basename "$(dirname "$issues_file")")
                echo "<h3>Issues for $pod_name</h3>" >> "$final_report"
                
                # Convert markdown issues to HTML
                grep "## Issue" "$issues_file" | while read -r line; do
                    echo "<div class=\"issue\">$line</div>" >> "$final_report"
                done
            fi
        fi
    done
    
    if [[ $total_issues -eq 0 ]]; then
        echo "<div class=\"pod-card healthy\"><h3>‚úÖ No Issues Detected</h3><p>All analyzed pods appear to be healthy!</p></div>" >> "$final_report"
    fi
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="recommendations" class="tab-content">
        <h2>üí° Recommendations</h2>
        <div class="section">
            <div class="pod-card warning">
                <h3>General Recommendations</h3>
                <ul>
                    <li>‚úÖ Implement comprehensive health checks for all pods</li>
                    <li>‚úÖ Set appropriate resource requests and limits</li>
                    <li>‚úÖ Use security contexts to harden pod security</li>
                    <li>‚úÖ Monitor resource usage and optimize accordingly</li>
                    <li>‚úÖ Implement graceful shutdown handling</li>
                    <li>‚úÖ Use multi-stage Docker builds for smaller images</li>
                    <li>‚úÖ Implement proper logging and observability</li>
                </ul>
            </div>
        </div>
EOF
    
    # Add pod-specific recommendations
    for rec_file in "$OUTPUT_DIR"/pods/*/recommendations.md; do
        if [[ -f "$rec_file" ]]; then
            local pod_name=$(basename "$(dirname "$rec_file")")
            echo "<div class=\"pod-card\"><h3>Recommendations for $pod_name</h3>" >> "$final_report"
            echo "<p>See detailed recommendations in: pods/$pod_name/recommendations.md</p></div>" >> "$final_report"
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div class="section">
        <hr>
        <p><em>Report generated by Pod Diagnostics Toolkit v2.0</em></p>
        <p><em>For detailed analysis, check individual files in the diagnostics output directory.</em></p>
    </div>
    
</body>
</html>
EOF
    
    log_success "Comprehensive report generated: $final_report"
    echo ""
    echo -e "${BOLD}üìã Diagnostic Summary:${NC}"
    echo "- Output Directory: $OUTPUT_DIR"
    echo "- HTML Report: $final_report"
    echo "- Total Issues Found: $total_issues"
    echo ""
    echo -e "${CYAN}üí° Next Steps:${NC}"
    echo "1. Open $final_report in your browser"
    echo "2. Review individual pod analysis in $OUTPUT_DIR/pods/"
    echo "3. Implement recommended fixes"
    echo "4. Re-run diagnostics to verify improvements"
}

# Main execution function
main() {
    local command=${1:-help}
    local pod_name=${2:-}
    local namespace=${3:-$NAMESPACE}
    
    case "$command" in
        "analyze")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for analysis"
                echo "Usage: $0 analyze <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            gather_pod_info "$pod_name" "$namespace"
            detect_common_issues "$pod_name" "$namespace"
            generate_recommendations "$pod_name" "$namespace"
            generate_final_report
            ;;
            
        "interactive")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for interactive mode"
                echo "Usage: $0 interactive <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            interactive_diagnostics "$pod_name" "$namespace"
            ;;
            
        "cluster-health")
            init_diagnostics
            cluster_health_assessment
            generate_final_report
            ;;
            
        "help"|*)
            cat <<EOF
üîç Advanced Pod Diagnostics Toolkit

Usage: $0 <command> [options]

Commands:
  analyze <pod-name> [namespace]     - Run comprehensive pod analysis
  interactive <pod-name> [namespace] - Start interactive diagnostic session
  cluster-health                     - Assess health of all pods in cluster
  help                              - Show this help message

Environment Variables:
  NAMESPACE - Default namespace (default: default)
  VERBOSE   - Enable verbose output (default: false)

Examples:
  $0 analyze nginx-pod production
  $0 interactive web-app-123
  $0 cluster-health
  VERBOSE=true $0 analyze problematic-pod

Output:
  All diagnostic data is saved to ./diagnostics-TIMESTAMP/
  HTML report provides comprehensive overview
  Individual pod analysis available in pods/ subdirectory

EOF
            ;;
    esac
}

# Execute main function
main "$@"
```

---

## Summary and Production-Ready Examples

### üèÜ Complete Production Workflow

Let's create a final comprehensive example that brings everything together:

```yaml
# complete-production-workflow.yaml
# This represents a complete production-ready pod deployment workflow

apiVersion: v1
kind: Namespace
metadata:
  name: production-workload
  labels:
    environment: production
    team: platform
---
# ConfigMap for application configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production-workload
data:
  app.properties: |
    server.port=8080
    management.port=8081
    logging.level=INFO
    metrics.enabled=true
  nginx.conf: |
    server {
        listen 80;
        location /health { return 200 'healthy\n'; }
        location /ready { return 200 'ready\n'; }
        location / {
            proxy_pass http://127.0.0.1:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
---
# Secret for sensitive configuration
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: production-workload
type: Opaque
data:
  database-password: c3VwZXJzZWNyZXQ=  # supersecret (base64)
  api-key: YWJjZGVmZ2hpams=  # abcdefghijk (base64)
---
# Production-ready pod with all best practices
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production-workload
  labels:
    app: production-app
    version: "2.1.0"
    environment: production
    team: platform
    component: backend
  annotations:
    description: "Production application with full observability"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/production-app"
    prometheus.io/scrape: "true"
    prometheus.io/port: "8081"
    prometheus.io/path: "/metrics"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Resource constraints and node placement
  nodeSelector:
    node-type: "application"
    performance-tier: "high"
    
  tolerations:
  - key: "dedicated-app"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
    
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: production-app
        topologyKey: kubernetes.io/hostname
        
  # DNS and network configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  # Init container for setup tasks
  initContainers:
  - name: setup
    image: busybox:1.35
    command:
    - /bin/sh
    - -c
    - |
      echo "Initializing application..."
      
      # Database migration simulation
      echo "Running database migrations..."
      sleep 5
      
      # Cache warming
      echo "Warming up caches..."
      sleep 3
      
      # Configuration validation
      echo "Validating configuration..."
      if [ -f /config/app.properties ]; then
        echo "‚úÖ Configuration file found"
      else
        echo "‚ùå Configuration file missing"
        exit 1
      fi
      
      echo "Initialization completed successfully"
      
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-init
      mountPath: /tmp
      
  # Main application containers
  containers:
  # Application container
  - name: app
    image: openjdk:11-jre-slim
    command:
    - /bin/bash
    - -c
    - |
      echo "Starting application..."
      
      # Simulated application startup
      java -Xmx200m -Xms100m -jar /app/application.jar \
        --spring.config.location=file:/config/app.properties \
        --server.port=8080 \
        --management.server.port=8081
        
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP
    - name: management
      containerPort: 8081
      protocol: TCP
      
    # Environment configuration
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # Sensitive configuration from secrets
    - name: DATABASE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: database-password
    - name: API_KEY
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: api-key
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security hardening
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    # Comprehensive health checks
    livenessProbe:
      httpGet:
        path: /actuator/health/liveness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /actuator/health/readiness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /actuator/health
        port: 8081
      initialDelaySeconds: 20
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle management
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Application started at $(date)" >> /tmp/startup.log
            # Custom post-start logic here
            
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Graceful shutdown initiated at $(date)" >> /tmp/shutdown.log
            # Send SIGTERM to application
            kill -TERM 1
            # Wait for graceful shutdown
            sleep 30
            
    # Volume mounts
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-volume
      mountPath: /tmp
    - name: app-logs
      mountPath: /app/logs
    - name: app-data
      mountPath: /app/data
      
  # Nginx reverse proxy sidecar
  - name: nginx-proxy
    image: nginx:1.21-alpine
    ports:
    - name: http-proxy
      containerPort: 80
      protocol: TCP
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        add: ["NET_BIND_SERVICE"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: nginx-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
      
  # Logging and monitoring sidecar
  - name: log-shipper
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: fluent-tmp
      mountPath: /tmp
      
  # Volumes
  volumes:
  - name: config-volume
    configMap:
      name: app-config
      items:
      - key: app.properties
        path: app.properties
  - name: nginx-config
    configMap:
      name: app-config
      items:
      - key: nginx.conf
        path: default.conf
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config  # Would be created separately
  # Temporary and cache volumes
  - name: tmp-volume
    emptyDir:
      sizeLimit: 256Mi
  - name: tmp-init
    emptyDir:
      sizeLimit: 64Mi
  - name: nginx-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: fluent-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: nginx-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: nginx-run
    emptyDir:
      sizeLimit: 32Mi
  # Application data volumes
  - name: app-logs
    emptyDir:
      sizeLimit: 1Gi
  - name: app-data
    emptyDir:
      sizeLimit: 2Gi
```

This comprehensive example demonstrates:

- **Complete security hardening** with proper contexts and capabilities
- **Multi-container architecture** with main app, proxy, and logging sidecars
- **Comprehensive health checks** for all containers
- **Resource optimization** with appropriate requests and limits
- **Configuration management** using ConfigMaps and Secrets
- **Observability** with structured logging and metrics endpoints
- **Production-ready networking** with reverse proxy
- **Graceful lifecycle management** with init containers and shutdown hooks

## üéì Key Learning Outcomes

By working through these enhanced examples, demos, and mini-projects, you've gained:

1. **Foundation Skills**: Basic pod creation, inspection, and management
2. **Intermediate Capabilities**: Multi-container patterns, health monitoring, and debugging
3. **Advanced Techniques**: Performance optimization, security hardening, and automation
4. **Expert-Level Mastery**: Custom controllers, comprehensive diagnostics, and production workflows

### üöÄ Next Steps for Continued Learning

1. **Practice the Examples**: Work through each example in your own cluster
2. **Customize for Your Use Cases**: Adapt the patterns to your specific applications
3. **Build Your Toolkit**: Create your own diagnostic and management scripts
4. **Share and Learn**: Contribute back to the community with your own improvements
5. **Scale Up**: Apply these pod management skills to higher-level controllers

The journey from basic pod creation to# 5. Working with Pods - From Fundamentals to Mastery (Enhanced Edition)

Understanding how to work with pods effectively forms the foundation of all Kubernetes operations. While you'll typically use higher-level controllers like Deployments in production environments, direct pod management skills are essential for debugging, troubleshooting, and truly understanding how Kubernetes applications function at their core. Think of this knowledge as learning to drive a manual transmission car‚Äîeven if you usually drive automatic, understanding the underlying mechanics makes you a better driver overall.

This enhanced guide provides progressive examples, hands-on demos, and real-world mini-projects to solidify your understanding through practical application.

## üéØ Learning Path Overview

- **Foundation Level**: Basic pod creation and inspection
- **Intermediate Level**: Multi-container patterns and health checks
- **Advanced Level**: Complex debugging and optimization
- **Expert Level**: Custom tooling and automation

---

## Understanding Pod Creation Strategies

Creating pods effectively requires understanding when to use imperative commands versus declarative configurations, and how different creation approaches serve different purposes.

### üìö Foundation Examples

Let's start with the absolute basics and progressively build complexity.

#### Example 1: Your First Pod
```bash
# Create the simplest possible pod
kubectl run hello-world --image=nginx --restart=Never

# Verify it's running
kubectl get pods

# Expected output:
# NAME          READY   STATUS    RESTARTS   AGE
# hello-world   1/1     Running   0          30s
```

#### Example 2: Pod with Custom Commands
```bash
# Create a pod that runs a custom command
kubectl run date-pod --image=busybox --restart=Never -- date

# This pod will run the date command and then exit
# Check the output
kubectl logs date-pod

# Clean up
kubectl delete pod date-pod
```

#### Example 3: Interactive Pod Session
```bash
# Create an interactive debugging pod
kubectl run -it debug-pod --image=busybox --restart=Never -- sh

# Inside the pod, try these commands:
# ls -la
# ps aux
# ping google.com
# nslookup kubernetes.default.svc.cluster.local

# Exit and clean up
# exit
kubectl delete pod debug-pod
```

### üõ†Ô∏è Demo: Pod Lifecycle Observation

Let's create a demo that shows the complete pod lifecycle in action:

```bash
#!/bin/bash
# pod-lifecycle-demo.sh

echo "=== Pod Lifecycle Demonstration ==="

# Terminal 1: Start watching pods
echo "In a separate terminal, run: kubectl get pods -w"
echo "Press Enter when ready..."
read

# Create a pod with a slow-starting application
echo "Creating pod with slow startup..."
kubectl run lifecycle-demo --image=nginx --restart=Never \
  --dry-run=client -o yaml > lifecycle-pod.yaml

# Add some customizations to make it more interesting
cat <<EOF >> lifecycle-pod.yaml
  containers:
  - name: nginx
    image: nginx:1.21
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod starting up...' && sleep 10"
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod shutting down...' && sleep 5"
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 5
EOF

echo "Applying pod configuration..."
kubectl apply -f lifecycle-pod.yaml

echo "Watch the pod states change from Pending -> ContainerCreating -> Running"
echo "Press Enter to continue when pod is Running..."
read

# Show detailed pod information
echo "=== Pod Details ==="
kubectl describe pod lifecycle-demo

echo "Press Enter to delete the pod and observe termination..."
read

# Delete and watch termination
kubectl delete pod lifecycle-demo

echo "Demo complete! Clean up the YAML file:"
echo "rm lifecycle-pod.yaml"
```

### üéØ Mini-Project 1: Pod Resource Monitor

Create a simple monitoring system using pods:

```yaml
# resource-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-monitor
  labels:
    app: monitor
    type: demo
spec:
  containers:
  - name: monitor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Starting Resource Monitor..."
      while true; do
        echo "=== $(date) ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "Load average:"
        uptime
        echo "Sleeping for 30 seconds..."
        sleep 30
      done
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
  restartPolicy: Always
```

```bash
# Deploy and monitor
kubectl apply -f resource-monitor-pod.yaml

# Watch the logs
kubectl logs -f resource-monitor

# In another terminal, check resource usage
kubectl top pod resource-monitor

# Clean up
kubectl delete -f resource-monitor-pod.yaml
```

---

## Deep Pod Inspection and Monitoring

### üîç Intermediate Examples

#### Example 4: Multi-Container Pod Investigation

```yaml
# multi-container-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-demo
  labels:
    demo: multi-container
spec:
  containers:
  - name: web-server
    image: nginx:1.21
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
    
  - name: log-processor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Log processor starting..."
      while true; do
        if [ -f /var/log/nginx/access.log ]; then
          echo "=== Access Log Summary $(date) ==="
          tail -10 /var/log/nginx/access.log | wc -l
          echo "Recent requests:"
          tail -5 /var/log/nginx/access.log
        else
          echo "Waiting for access.log..."
        fi
        sleep 30
      done
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
      
  - name: metrics-collector
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Metrics collector starting..."
      while true; do
        echo "=== Metrics $(date) ==="
        echo "Container count: 3"
        echo "Uptime: $(uptime)"
        echo "Memory: $(free -h | grep Mem)"
        sleep 60
      done
      
  volumes:
  - name: shared-logs
    emptyDir: {}
```

**Inspection Commands:**
```bash
# Apply the multi-container pod
kubectl apply -f multi-container-demo.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/multi-container-demo

# Inspect different aspects
echo "=== Basic Information ==="
kubectl get pod multi-container-demo -o wide

echo "=== Container Status ==="
kubectl get pod multi-container-demo -o jsonpath='{.status.containerStatuses[*].name}' | tr ' ' '\n'

echo "=== Logs from each container ==="
kubectl logs multi-container-demo -c web-server --tail=5
kubectl logs multi-container-demo -c log-processor --tail=5
kubectl logs multi-container-demo -c metrics-collector --tail=5

# Generate some traffic to see shared volume in action
kubectl port-forward multi-container-demo 8080:80 &
PF_PID=$!

# Generate requests
for i in {1..10}; do
  curl -s http://localhost:8080 > /dev/null
  echo "Request $i sent"
  sleep 1
done

kill $PF_PID

# Check log processor output
kubectl logs multi-container-demo -c log-processor --tail=10

# Clean up
kubectl delete -f multi-container-demo.yaml
```

### üõ†Ô∏è Demo: Advanced Pod Debugging Techniques

```bash
#!/bin/bash
# advanced-debugging-demo.sh

echo "=== Advanced Pod Debugging Demo ==="

# Create a problematic pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: problematic-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "2000m"  # This might cause scheduling issues
      limits:
        memory: "512Mi"  # Less than request - invalid!
        cpu: "500m"
    livenessProbe:
      httpGet:
        path: /nonexistent
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
EOF

echo "Created a pod with multiple issues. Let's debug it..."

# Wait a moment for issues to manifest
sleep 10

echo "=== Debugging Steps ==="

echo "1. Check pod status:"
kubectl get pod problematic-pod -o wide

echo "2. Look at events:"
kubectl describe pod problematic-pod | grep -A 10 Events:

echo "3. Check for resource issues:"
kubectl describe pod problematic-pod | grep -A 5 -B 5 "resource"

echo "4. Examine container status:"
kubectl get pod problematic-pod -o jsonpath='{.status.containerStatuses[0]}' | jq '.'

# Fix the pod
echo "5. Let's fix the issues..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: fixed-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
EOF

echo "6. Compare the fixed pod:"
kubectl wait --for=condition=Ready pod/fixed-pod --timeout=60s
kubectl get pods -l debug=demo

# Clean up
echo "Cleaning up..."
kubectl delete pod problematic-pod fixed-pod
```

### üéØ Mini-Project 2: Pod Health Monitoring Dashboard

Create a comprehensive health monitoring system:

```yaml
# health-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: health-dashboard
  labels:
    app: health-monitor
spec:
  containers:
  - name: health-checker
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Health Dashboard Starting..."
      
      # Create a simple HTML dashboard
      mkdir -p /tmp/dashboard
      
      while true; do
        cat > /tmp/dashboard/health.html <<EOF
      <!DOCTYPE html>
      <html>
      <head>
          <title>Pod Health Dashboard</title>
          <meta http-equiv="refresh" content="30">
          <style>
              body { font-family: Arial, sans-serif; margin: 40px; }
              .healthy { color: green; }
              .warning { color: orange; }
              .critical { color: red; }
              .metric { margin: 10px 0; padding: 10px; border: 1px solid #ccc; }
          </style>
      </head>
      <body>
          <h1>Pod Health Dashboard</h1>
          <p>Last Update: $(date)</p>
          
          <div class="metric">
              <h3>System Load</h3>
              <p>$(uptime)</p>
          </div>
          
          <div class="metric">
              <h3>Memory Usage</h3>
              <pre>$(free -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Disk Usage</h3>
              <pre>$(df -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Process Count</h3>
              <p>Running processes: $(ps aux | wc -l)</p>
          </div>
          
      </body>
      </html>
      EOF
        
        echo "Dashboard updated at $(date)"
        sleep 30
      done
    volumeMounts:
    - name: dashboard-storage
      mountPath: /tmp/dashboard
      
  - name: web-server
    image: nginx:alpine
    ports:
    - containerPort: 80
    command:
    - /bin/sh
    - -c
    - |
      # Configure nginx to serve our dashboard
      cat > /etc/nginx/conf.d/default.conf <<EOF
      server {
          listen 80;
          location / {
              root /usr/share/nginx/html;
              index health.html;
          }
      }
      EOF
      
      # Start nginx
      nginx -g "daemon off;"
    volumeMounts:
    - name: dashboard-storage
      mountPath: /usr/share/nginx/html
      
  volumes:
  - name: dashboard-storage
    emptyDir: {}
    
  restartPolicy: Always
```

**Usage:**
```bash
# Deploy the health dashboard
kubectl apply -f health-monitor-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/health-dashboard

# Access the dashboard
kubectl port-forward health-dashboard 8080:80

# Open browser to http://localhost:8080
echo "Open http://localhost:8080 in your browser"

# Monitor the pod's own health
kubectl top pod health-dashboard

# Check logs from both containers
kubectl logs health-dashboard -c health-checker --tail=10
kubectl logs health-dashboard -c web-server --tail=10

# Clean up
kubectl delete -f health-monitor-pod.yaml
```

---

## Interactive Pod Management and Debugging

### üîß Advanced Examples

#### Example 5: Network Debugging Pod

```yaml
# network-debug-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: network-debugger
  labels:
    purpose: network-debug
spec:
  containers:
  - name: nettools
    image: nicolaka/netshoot
    command: ["/bin/bash"]
    args:
    - -c
    - |
      echo "Network debugging tools ready!"
      echo "Available tools: dig, nslookup, ping, curl, wget, tcpdump, netstat"
      echo "Example commands:"
      echo "  dig kubernetes.default.svc.cluster.local"
      echo "  ping 8.8.8.8"
      echo "  curl -I http://httpbin.org/headers"
      echo "  netstat -tulpn"
      
      # Keep container running
      sleep 3600
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
  restartPolicy: Never
```

**Debugging Session:**
```bash
# Deploy the network debugger
kubectl apply -f network-debug-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/network-debugger

# Start interactive session
kubectl exec -it network-debugger -- bash

# Inside the pod, run network diagnostics:
# Test DNS resolution
# dig kubernetes.default.svc.cluster.local

# Test external connectivity
# ping -c 3 8.8.8.8

# Test HTTP services
# curl -I https://httpbin.org/headers

# Check network interfaces
# ip addr show

# Check routing table
# ip route show

# Test service discovery
# nslookup kubernetes.default

# Exit and clean up
# exit
kubectl delete -f network-debug-pod.yaml
```

### üõ†Ô∏è Demo: File Transfer and Volume Management

```bash
#!/bin/bash
# file-transfer-demo.sh

echo "=== File Transfer and Volume Demo ==="

# Create a pod with persistent data
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: file-demo
spec:
  containers:
  - name: app
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Creating sample files..."
      mkdir -p /data/logs /data/config
      
      # Generate some sample data
      for i in {1..5}; do
        echo "Log entry \$i at \$(date)" >> /data/logs/app.log
        sleep 1
      done
      
      echo "app_name=demo-app" > /data/config/settings.conf
      echo "version=1.0.0" >> /data/config/settings.conf
      echo "debug=true" >> /data/config/settings.conf
      
      echo "Files created. Keeping container running..."
      sleep 3600
    volumeMounts:
    - name: data-storage
      mountPath: /data
  volumes:
  - name: data-storage
    emptyDir: {}
EOF

echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/file-demo

# Demonstrate file operations
echo "=== File Operations Demo ==="

echo "1. List files in the pod:"
kubectl exec file-demo -- find /data -type f

echo "2. Copy file from pod to local:"
kubectl cp file-demo:/data/logs/app.log ./app.log.backup
echo "File copied to: app.log.backup"
cat app.log.backup

echo "3. Create local config file:"
cat > new-config.conf <<EOF
app_name=updated-demo-app
version=2.0.0
debug=false
environment=production
EOF

echo "4. Copy local file to pod:"
kubectl cp new-config.conf file-demo:/data/config/

echo "5. Verify file in pod:"
kubectl exec file-demo -- cat /data/config/new-config.conf

echo "6. Create a backup of all data:"
kubectl exec file-demo -- tar -czf /tmp/backup.tar.gz -C /data .
kubectl cp file-demo:/tmp/backup.tar.gz ./pod-data-backup.tar.gz
echo "Backup created: pod-data-backup.tar.gz"

# Clean up
echo "Cleaning up..."
kubectl delete pod file-demo
rm -f app.log.backup new-config.conf pod-data-backup.tar.gz

echo "Demo complete!"
```

### üéØ Mini-Project 3: Pod Security Scanner

Create a security scanning tool using pods:

```yaml
# security-scanner-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-scanner
  labels:
    app: security
    type: scanner
spec:
  serviceAccountName: default
  containers:
  - name: scanner
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "=== Pod Security Scanner Starting ==="
      
      # Function to check security configurations
      check_security() {
        echo "Checking security configurations..."
        
        # Check if running as root
        if [ "$(id -u)" -eq 0 ]; then
          echo "‚ö†Ô∏è  WARNING: Running as root user"
        else
          echo "‚úÖ GOOD: Running as non-root user ($(id -u))"
        fi
        
        # Check filesystem permissions
        if [ -w "/" ]; then
          echo "‚ö†Ô∏è  WARNING: Root filesystem is writable"
        else
          echo "‚úÖ GOOD: Root filesystem is read-only"
        fi
        
        # Check for sensitive mounts
        if mount | grep -q "/var/run/secrets"; then
          echo "‚ÑπÔ∏è  INFO: Service account token mounted"
        fi
        
        # Check available capabilities
        echo "Current capabilities:"
        if [ -f "/proc/self/status" ]; then
          grep Cap /proc/self/status
        fi
        
        # Check network access
        echo "Testing network access..."
        if ping -c 1 8.8.8.8 >/dev/null 2>&1; then
          echo "‚ÑπÔ∏è  INFO: External network access available"
        else
          echo "‚ÑπÔ∏è  INFO: No external network access"
        fi
        
        # Generate security report
        cat > /tmp/security-report.txt <<EOF
      === Security Scan Report ===
      Timestamp: $(date)
      User ID: $(id -u)
      Group ID: $(id -g)
      Working Directory: $(pwd)
      
      Filesystem Check:
      - Root writable: $([ -w "/" ] && echo "YES" || echo "NO")
      - /tmp writable: $([ -w "/tmp" ] && echo "YES" || echo "NO")
      
      Network Check:
      - External access: $(ping -c 1 8.8.8.8 >/dev/null 2>&1 && echo "YES" || echo "NO")
      
      Process Information:
      $(ps aux)
      EOF
        
        echo "Report generated at /tmp/security-report.txt"
      }
      
      # Run security check
      check_security
      
      # Keep running for inspection
      echo "Scanner complete. Container will stay running for inspection."
      sleep 3600
      
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 1000
      runAsGroup: 3000
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir: {}
    
  restartPolicy: Never
```

**Usage:**
```bash
# Deploy the security scanner
kubectl apply -f security-scanner-pod.yaml

# Monitor the scan
kubectl logs -f security-scanner

# Get the security report
kubectl cp security-scanner:/tmp/security-report.txt ./security-report.txt
cat security-report.txt

# Create a comparison with an insecure pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: insecure-pod
spec:
  containers:
  - name: insecure
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      runAsUser: 0  # Running as root
      privileged: true
EOF

# Compare security postures
echo "=== Security Comparison ==="
echo "Secure pod user:"
kubectl exec security-scanner -- id

echo "Insecure pod user:"
kubectl exec insecure-pod -- id

echo "Secure pod capabilities:"
kubectl exec security-scanner -- grep Cap /proc/self/status

echo "Insecure pod capabilities:"
kubectl exec insecure-pod -- grep Cap /proc/self/status

# Clean up
kubectl delete pod security-scanner insecure-pod
rm -f security-report.txt
```

---

## Declarative Pod Configuration and Management

### üèóÔ∏è Expert Examples

#### Example 6: Production-Ready Pod Template

```yaml
# production-pod-template.yaml
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production
  labels:
    app: web-server
    version: "2.1.0"
    environment: production
    team: platform
  annotations:
    description: "Production web server with full monitoring and security"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/web-server"
    version: "2.1.0"
    build-date: "2024-01-15T10:30:00Z"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Node selection
  nodeSelector:
    node-type: "application"
    zone: "us-west-2a"
    
  # Tolerations for dedicated nodes
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "application"
    effect: "NoSchedule"
    
  # Pod placement preferences
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: "node-type"
            operator: In
            values: ["application"]
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: web-server
          topologyKey: kubernetes.io/hostname
          
  # DNS configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  containers:
  - name: web-server
    image: nginx:1.21-alpine
    imagePullPolicy: IfNotPresent
    
    ports:
    - name: http
      containerPort: 80
      protocol: TCP
    - name: metrics
      containerPort: 9113
      protocol: TCP
      
    # Environment variables
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "info"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security context
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE
        
    # Health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 80
        scheme: HTTP
        httpHeaders:
        - name: Custom-Header
          value: liveness-check
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
        scheme: HTTP
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle hooks
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container started at $(date)" >> /tmp/startup.log
            # Custom initialization logic here
            
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container stopping at $(date)" >> /tmp/shutdown.log
            # Graceful shutdown logic here
            nginx -s quit
            sleep 15
            
    # Volume mounts
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  # Sidecar container for log processing
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  # Monitoring sidecar
  - name: nginx-exporter
    image: nginx/nginx-prometheus-exporter:0.10.0
    args:
    - -nginx.scrape-uri=http://localhost:80/nginx_status
    ports:
    - name: metrics
      containerPort: 9113
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
  # Shared volumes
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
      defaultMode: 0644
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
      defaultMode: 0644
  - name: html-content
    configMap:
      name: html-content
      defaultMode: 0644
  - name: tmp-dir
    emptyDir:
      sizeLimit: 256Mi
  - name: var-cache-nginx
    emptyDir:
      sizeLimit: 512Mi
  - name: var-run
    emptyDir:
      sizeLimit: 64Mi
  - name: logs
    emptyDir:
      sizeLimit: 1Gi
```

### üõ†Ô∏è Demo: Complex Pod Deployment Pipeline

```bash
#!/bin/bash
# production-pod-deployment.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

# Configuration
NAMESPACE="production-demo"
APP_NAME="web-server"
CONFIG_DIR="./config"

# Create namespace if it doesn't exist
create_namespace() {
    log "Creating namespace: $NAMESPACE"
    kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    success "Namespace $NAMESPACE ready"
}

# Create ConfigMaps for the application
create_configmaps() {
    log "Creating ConfigMaps..."
    
    mkdir -p $CONFIG_DIR
    
    # Nginx configuration
    cat > $CONFIG_DIR/nginx.conf <<EOF
server {
    listen 80;
    server_name localhost;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
    
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    location /ready {
        access_log off;
        return 200 "ready\n";
        add_header Content-Type text/plain;
    }
    
    location /nginx_status {
        stub_status on;
        access_log off;
        allow all;
    }
}
EOF

    # HTML content
    cat > $CONFIG_DIR/index.html <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Production Pod Demo</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .container { max-width: 800px; margin: 0 auto; }
        .status { padding: 20px; margin: 20px 0; border-radius: 5px; }
        .healthy { background-color: #d4edda; color: #155724; }
        .info { background-color: #d1ecf1; color: #0c5460; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Production Pod Demo</h1>
        <div class="status healthy">
            <h3>‚úÖ Application Status: Healthy</h3>
            <p>Pod is running successfully with full production configuration</p>
        </div>
        
        <div class="status info">
            <h3>üìä Features Enabled:</h3>
            <ul>
                <li>Multi-container architecture</li>
                <li>Comprehensive health checks</li>
                <li>Security hardening</li>
                <li>Log processing sidecar</li>
                <li>Prometheus metrics export</li>
                <li>Resource management</li>
            </ul>
        </div>
        
        <div class="status info">
            <h3>üîó Endpoints:</h3>
            <ul>
                <li><a href="/health">Health Check</a></li>
                <li><a href="/ready">Readiness Check</a></li>
                <li><a href="/nginx_status">Nginx Status</a></li>
            </ul>
        </div>
    </div>
</body>
</html>
EOF

    # Fluent Bit configuration
    cat > $CONFIG_DIR/fluent-bit.conf <<EOF
[SERVICE]
    Flush         1
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf

[INPUT]
    Name              tail
    Path              /var/log/nginx/access.log
    Parser            nginx
    Tag               nginx.access
    Refresh_Interval  5

[INPUT]
    Name              tail
    Path              /var/log/nginx/error.log
    Tag               nginx.error
    Refresh_Interval  5

[OUTPUT]
    Name  stdout
    Match nginx.*
EOF

    cat > $CONFIG_DIR/parsers.conf <<EOF
[PARSER]
    Name   nginx
    Format regex
    Regex  ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
    Time_Key time
    Time_Format %d/%b/%Y:%H:%M:%S %z
EOF

    # Create ConfigMaps
    kubectl create configmap nginx-config --from-file=$CONFIG_DIR/nginx.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap html-content --from-file=$CONFIG_DIR/index.html -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap fluent-bit-config --from-file=$CONFIG_DIR/fluent-bit.conf --from-file=$CONFIG_DIR/parsers.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    
    success "ConfigMaps created successfully"
}

# Deploy the production pod
deploy_pod() {
    log "Deploying production pod..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: $APP_NAME
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
    version: "1.0.0"
    environment: production
  annotations:
    deployment.kubernetes.io/revision: "1"
    deployed-by: "production-deployment-script"
    deployment-time: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    
  containers:
  - name: nginx
    image: nginx:1.21-alpine
    ports:
    - name: http
      containerPort: 80
    - name: metrics
      containerPort: 9113
      
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
  - name: html-content
    configMap:
      name: html-content
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
  - name: tmp-dir
    emptyDir: {}
  - name: var-cache-nginx
    emptyDir: {}
  - name: var-run
    emptyDir: {}
  - name: logs
    emptyDir: {}
EOF

    success "Pod deployed successfully"
}

# Wait for pod to be ready and perform health checks
verify_deployment() {
    log "Waiting for pod to be ready..."
    
    if kubectl wait --for=condition=Ready pod/$APP_NAME -n $NAMESPACE --timeout=120s; then
        success "Pod is ready!"
    else
        error "Pod failed to become ready within timeout"
    fi
    
    # Perform comprehensive health checks
    log "Performing health checks..."
    
    # Check pod status
    kubectl get pod $APP_NAME -n $NAMESPACE -o wide
    
    # Test health endpoints
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    if curl -s http://localhost:8080/health | grep -q "healthy"; then
        success "Health check passed"
    else
        warning "Health check failed"
    fi
    
    if curl -s http://localhost:8080/ready | grep -q "ready"; then
        success "Readiness check passed"
    else
        warning "Readiness check failed"
    fi
    
    # Test the main application
    if curl -s http://localhost:8080 | grep -q "Production Pod Demo"; then
        success "Application is serving content correctly"
    else
        warning "Application content check failed"
    fi
    
    kill $PF_PID 2>/dev/null
    
    # Check resource usage
    log "Checking resource usage..."
    if kubectl top pod $APP_NAME -n $NAMESPACE &>/dev/null; then
        kubectl top pod $APP_NAME -n $NAMESPACE
    else
        warning "Resource metrics not available"
    fi
    
    # Check logs from all containers
    log "Checking container logs..."
    echo "=== Nginx logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c nginx --tail=5
    echo "=== Log processor logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=5
}

# Generate load and monitor performance
performance_test() {
    log "Running performance test..."
    
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    # Generate some load
    for i in {1..50}; do
        curl -s http://localhost:8080 > /dev/null &
    done
    
    wait
    kill $PF_PID 2>/dev/null
    
    # Check logs after load test
    log "Logs after load test:"
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=10
    
    success "Performance test completed"
}

# Cleanup function
cleanup() {
    log "Cleaning up resources..."
    kubectl delete pod $APP_NAME -n $NAMESPACE --ignore-not-found
    kubectl delete configmap nginx-config html-content fluent-bit-config -n $NAMESPACE --ignore-not-found
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -rf $CONFIG_DIR
    success "Cleanup completed"
}

# Main execution
main() {
    echo "=== Production Pod Deployment Demo ==="
    
    case "${1:-deploy}" in
        "deploy")
            create_namespace
            create_configmaps
            deploy_pod
            verify_deployment
            performance_test
            
            echo ""
            success "Deployment completed successfully!"
            echo "Access the application:"
            echo "  kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80"
            echo "  Then open: http://localhost:8080"
            echo ""
            echo "Monitor the pod:"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c nginx"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c log-processor"
            echo ""
            echo "Run 'bash $0 cleanup' to remove all resources"
            ;;
        "cleanup")
            cleanup
            ;;
        "test")
            verify_deployment
            performance_test
            ;;
        *)
            echo "Usage: $0 [deploy|cleanup|test]"
            echo "  deploy  - Deploy the production pod (default)"
            echo "  cleanup - Remove all created resources"
            echo "  test    - Run verification and performance tests"
            ;;
    esac
}

main "$@"
```

### üéØ Mini-Project 4: Pod Chaos Engineering

Test pod resilience with chaos engineering principles:

```yaml
# chaos-test-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: chaos-resilient-app
  labels:
    app: chaos-test
    resilience: enabled
spec:
  containers:
  - name: main-app
    image: nginx:1.21-alpine
    ports:
    - containerPort: 80
    
    # Aggressive resource limits to test resilience
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    # Tight health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 2
      
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
      timeoutSeconds: 1
      failureThreshold: 2
      
    # Graceful shutdown
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 10"]
          
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  # Chaos monkey sidecar
  - name: chaos-monkey
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Chaos monkey starting..."
      
      # Function to create CPU load
      cpu_chaos() {
        echo "Creating CPU chaos..."
        for i in {1..4}; do
          yes > /dev/null &
        done
        sleep 30
        killall yes
      }
      
      # Function to create memory pressure
      memory_chaos() {
        echo "Creating memory chaos..."
        cat <(yes | tr \\n x | head -c 50000000) <(yes | tr \\n x | head -c 50000000) > /tmp/memory_eater &
        sleep 20
        rm -f /tmp/memory_eater
        killall cat
      }
      
      # Function to simulate network issues
      network_chaos() {
        echo "Creating network chaos..."
        # Simulate slow responses
        sleep $((RANDOM % 10 + 5))
      }
      
      # Function to create disk I/O pressure
      disk_chaos() {
        echo "Creating disk I/O chaos..."
        dd if=/dev/zero of=/tmp/disk_eater bs=1M count=10 2>/dev/null
        rm -f /tmp/disk_eater
      }
      
      # Main chaos loop
      while true; do
        chaos_type=$((RANDOM % 4))
        case $chaos_type in
          0) cpu_chaos ;;
          1) memory_chaos ;;
          2) network_chaos ;;
          3) disk_chaos ;;
        esac
        
        # Wait between chaos events
        sleep $((RANDOM % 60 + 30))
      done
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir:
      sizeLimit: 100Mi
      
  restartPolicy: Always
```

**Chaos Testing Script:**
```bash
#!/bin/bash
# chaos-engineering-test.sh

echo "=== Chaos Engineering Test ==="

# Deploy the chaos test pod
kubectl apply -f chaos-test-pod.yaml

# Wait for it to be ready
echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/chaos-resilient-app --timeout=60s

# Monitor pod resilience
echo "Starting resilience monitoring (Ctrl+C to stop)..."

monitor_resilience() {
    while true; do
        timestamp=$(date '+%H:%M:%S')
        
        # Check pod status
        status=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.phase}')
        ready=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
        restarts=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.containerStatuses[0].restartCount}')
        
        # Test application responsiveness
        kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
        PF_PID=$!
        sleep 2
        
        response_time=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8080 2>/dev/null || echo "FAIL")
        kill $PF_PID 2>/dev/null
        
        # Get resource usage if available
        resources=""
        if kubectl top pod chaos-resilient-app &>/dev/null; then
            resources=$(kubectl top pod chaos-resilient-app --no-headers 2>/dev/null | awk '{print $2" "$3}')
        fi
        
        printf "[$timestamp] Status: $status | Ready: $ready | Restarts: $restarts | Response: ${response_time}s | Resources: $resources\n"
        
        sleep 5
    done
}

# Start monitoring in background
monitor_resilience &
MONITOR_PID=$!

# Generate additional load to test resilience
echo "Generating load to test resilience..."
for i in {1..100}; do
    kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
    PF_PID=$!
    sleep 1
    
    curl -s http://localhost:8080 > /dev/null &
    
    kill $PF_PID 2>/dev/null
    sleep 2
done

# Stop monitoring
kill $MONITOR_PID 2>/dev/null

echo "Chaos test completed. Check pod logs:"
echo "kubectl logs chaos-resilient-app -c main-app --tail=20"
echo "kubectl logs chaos-resilient-app -c chaos-monkey --tail=20"

# Cleanup
read -p "Delete the chaos test pod? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    kubectl delete -f chaos-test-pod.yaml
fi
```

---

## Advanced Pod Management Techniques

### üî¨ Expert-Level Examples

#### Example 7: Custom Pod Controller

Create a custom controller for specialized pod management:

```python
#!/usr/bin/env python3
# custom-pod-controller.py

import time
import yaml
import subprocess
import json
from datetime import datetime, timedelta

class PodController:
    def __init__(self):
        self.managed_pods = {}
        self.check_interval = 30  # seconds
        
    def log(self, message):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"[{timestamp}] {message}")
        
    def run_kubectl(self, command):
        """Execute kubectl command and return JSON output"""
        try:
            result = subprocess.run(
                f"kubectl {command} -o json",
                shell=True,
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                self.log(f"kubectl error: {result.stderr}")
                return None
        except Exception as e:
            self.log(f"Command execution error: {e}")
            return None
            
    def get_pods_by_label(self, label_selector):
        """Get pods matching label selector"""
        command = f"get pods -l {label_selector}"
        result = self.run_kubectl(command)
        return result.get('items', []) if result else []
        
    def create_pod(self, name, spec):
        """Create a pod with given specification"""
        pod_manifest = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'name': name,
                'labels': {
                    'managed-by': 'custom-controller',
                    'created': datetime.now().strftime('%Y%m%d-%H%M%S')
                }
            },
            'spec': spec
        }
        
        # Write manifest to temporary file
        with open(f'/tmp/{name}.yaml', 'w') as f:
            yaml.dump(pod_manifest, f)
            
        # Apply the manifest
        result = subprocess.run(
            f"kubectl apply -f /tmp/{name}.yaml",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Created pod: {name}")
            return True
        else:
            self.log(f"Failed to create pod {name}: {result.stderr}")
            return False
            
    def delete_pod(self, name):
        """Delete a pod"""
        result = subprocess.run(
            f"kubectl delete pod {name} --grace-period=30",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Deleted pod: {name}")
            return True
        else:
            self.log(f"Failed to delete pod {name}: {result.stderr}")
            return False
            
    def check_pod_health(self, pod):
        """Check if a pod is healthy based on custom criteria"""
        name = pod['metadata']['name']
        status = pod['status']
        
        # Check if pod is running
        if status.get('phase') != 'Running':
            return False, f"Pod {name} is not running (phase: {status.get('phase')})"
            
        # Check container statuses
        container_statuses = status.get('containerStatuses', [])
        for container in container_statuses:
            if not container.get('ready'):
                return False, f"Container {container['name']} not ready in pod {name}"
                
            # Check restart count
            restart_count = container.get('restartCount', 0)
            if restart_count > 5:
                return False, f"Container {container['name']} restarted {restart_count} times"
                
        # Check resource usage (if metrics available)
        metrics = self.get_pod_metrics(name)
        if metrics:
            cpu_usage = self.parse_cpu_usage(metrics.get('cpu', '0m'))
            memory_usage = self.parse_memory_usage(metrics.get('memory', '0Mi'))
            
            if cpu_usage > 800:  # 800 millicores
                return False, f"Pod {name} CPU usage too high: {cpu_usage}m"
                
            if memory_usage > 512:  # 512 Mi
                return False, f"Pod {name} memory usage too high: {memory_usage}Mi"
                
        return True, f"Pod {name} is healthy"
        
    def get_pod_metrics(self, pod_name):
        """Get pod resource metrics if available"""
        result = subprocess.run(
            f"kubectl top pod {pod_name} --no-headers",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            parts = result.stdout.strip().split()
            if len(parts) >= 3:
                return {
                    'cpu': parts[1],
                    'memory': parts[2]
                }
        return None
        
    def parse_cpu_usage(self, cpu_str):
        """Parse CPU usage from string like '100m' to millicores"""
        if cpu_str.endswith('m'):
            return int(cpu_str[:-1])
        return int(cpu_str) * 1000
        
    def parse_memory_usage(self, memory_str):
        """Parse memory usage from string like '128Mi' to Mi"""
        if memory_str.endswith('Mi'):
            return int(memory_str[:-2])
        elif memory_str.endswith('Gi'):
            return int(memory_str[:-2]) * 1024
        return int(memory_str) // (1024 * 1024)
        
    def auto_heal_pod(self, pod_name, reason):
        """Attempt to heal an unhealthy pod"""
        self.log(f"Attempting to heal pod {pod_name}: {reason}")
        
        # Strategy 1: Restart the pod
        if "restart" in reason.lower():
            return self.delete_pod(pod_name)  # Pod will be recreated if managed by controller
            
        # Strategy 2: Scale resources if high usage
        if "usage too high" in reason.lower():
            self.log(f"High resource usage detected for {pod_name}, marking for recreation")
            return self.delete_pod(pod_name)
            
        # Strategy 3: Generic restart
        return self.delete_pod(pod_name)
        
    def manage_workload(self, workload_config):
        """Manage a workload with desired replica count"""
        app_name = workload_config['name']
        desired_replicas = workload_config['replicas']
        pod_spec = workload_config['pod_spec']
        
        # Get current pods for this workload
        current_pods = self.get_pods_by_label(f"app={app_name},managed-by=custom-controller")
        current_count = len(current_pods)
        
        self.log(f"Managing workload {app_name}: current={current_count}, desired={desired_replicas}")
        
        # Scale up if needed
        if current_count < desired_replicas:
            for i in range(current_count, desired_replicas):
                pod_name = f"{app_name}-{i}"
                pod_spec_copy = pod_spec.copy()
                pod_spec_copy.setdefault('containers', [{}])[0]['env'] = [
                    {'name': 'REPLICA_ID', 'value': str(i)},
                    {'name': 'APP_NAME', 'value': app_name}
                ]
                self.create_pod(pod_name, pod_spec_copy)
                
        # Scale down if needed
        elif current_count > desired_replicas:
            pods_to_delete = current_pods[desired_replicas:]
            for pod in pods_to_delete:
                self.delete_pod(pod['metadata']['name'])
                
        # Health check existing pods
        for pod in current_pods[:desired_replicas]:
            healthy, reason = self.check_pod_health(pod)
            if not healthy:
                self.log(f"Pod unhealthy: {reason}")
                self.auto_heal_pod(pod['metadata']['name'], reason)
                
    def run_control_loop(self):
        """Main control loop"""
        self.log("Starting custom pod controller...")
        
        # Sample workload configuration
        workloads = [
            {
                'name': 'web-app',
                'replicas': 2,
                'pod_spec': {
                    'containers': [{
                        'name': 'nginx',
                        'image': 'nginx:1.21-alpine',
                        'ports': [{'containerPort': 80}],
                        'resources': {
                            'requests': {'memory': '64Mi', 'cpu': '50m'},
                            'limits': {'memory': '128Mi', 'cpu': '100m'}
                        },
                        'livenessProbe': {
                            'httpGet': {'path': '/', 'port': 80},
                            'initialDelaySeconds': 10,
                            'periodSeconds': 30
                        }
                    }],
                    'restartPolicy': 'Always'
                }
            }
        ]
        
        try:
            while True:
                self.log("Running control loop...")
                
                for workload in workloads:
                    try:
                        self.manage_workload(workload)
                    except Exception as e:
                        self.log(f"Error managing workload {workload['name']}: {e}")
                        
                self.log(f"Sleeping for {self.check_interval} seconds...")
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            self.log("Shutting down controller...")
            
        except Exception as e:
            self.log(f"Controller error: {e}")
            
    def cleanup(self):
        """Clean up managed resources"""
        self.log("Cleaning up managed pods...")
        pods = self.get_pods_by_label("managed-by=custom-controller")
        for pod in pods:
            self.delete_pod(pod['metadata']['name'])

if __name__ == "__main__":
    import sys
    
    controller = PodController()
    
    if len(sys.argv) > 1 and sys.argv[1] == "cleanup":
        controller.cleanup()
    else:
        controller.run_control_loop()
```

**Usage:**
```bash
# Make the script executable
chmod +x custom-pod-controller.py

# Install dependencies
pip3 install pyyaml

# Run the controller
python3 custom-pod-controller.py

# In another terminal, watch the managed pods
watch kubectl get pods -l managed-by=custom-controller

# Simulate pod failures
kubectl delete pod web-app-0  # Controller will recreate it

# Clean up when done
python3 custom-pod-controller.py cleanup
```

### üéØ Mini-Project 5: Pod Performance Optimization Lab

Create a comprehensive performance optimization laboratory:

```yaml
# performance-lab-setup.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: performance-lab
---
# Baseline pod - unoptimized
apiVersion: v1
kind: Pod
metadata:
  name: baseline-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: baseline
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "1000m"
      limits:
        memory: "2Gi"
        cpu: "2000m"
---
# Optimized pod - resource-efficient
apiVersion: v1
kind: Pod
metadata:
  name: optimized-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: optimized
spec:
  containers:
  - name: app
    image: nginx:1.21-alpine  # Smaller image
    resources:
      requests:
        memory: "64Mi"        # Right-sized requests
        cpu: "100m"
      limits:
        memory: "128Mi"       # Conservative limits
        cpu: "200m"
    # Optimized health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5   # Faster startup
      periodSeconds: 30        # Less frequent checks
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
    # Security optimizations
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
    # Volume optimizations
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp-dir
    emptyDir:
      medium: Memory  # Use memory for temp files
      sizeLimit: 64Mi
  - name: var-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: var-run
    emptyDir:
      sizeLimit: 32Mi
---
# High-performance pod with advanced optimizations
apiVersion: v1
kind: Pod
metadata:
  name: high-performance-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: high-performance
spec:
  # Pod-level optimizations
  priorityClassName: high-priority
  nodeSelector:
    node-type: performance
  tolerations:
  - key: performance-node
    operator: Equal
    value: "true"
    effect: NoSchedule
  # Network optimizations
  dnsPolicy: ClusterFirstWithHostNet
  dnsConfig:
    options:
    - name: ndots
      value: "1"
    - name: edns0
  containers:
  - name: app
    image: nginx:1.21-alpine
    # Optimized resource allocation
    resources:
      requests:
        memory: "128Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "256Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
    # Performance-tuned environment
    env:
    - name: NGINX_WORKER_PROCESSES
      value: "auto"
    - name: NGINX_WORKER_CONNECTIONS
      value: "1024"
    # Aggressive health checks for faster recovery
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 15
      timeoutSeconds: 2
      failureThreshold: 2
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 3
      timeoutSeconds: 1
      failureThreshold: 1
    # Startup optimization
    startupProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 1
      timeoutSeconds: 1
      failureThreshold: 10
    # Performance-optimized volumes
    volumeMounts:
    - name: high-speed-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
  volumes:
  - name: high-speed-tmp
    emptyDir:
      medium: Memory
      sizeLimit: 128Mi
  - name: nginx-cache
    emptyDir:
      medium: Memory
      sizeLimit: 256Mi
  - name: nginx-run
    emptyDir:
      medium: Memory
      sizeLimit: 64Mi
```

**Performance Benchmarking Script:**
```bash
#!/bin/bash
# performance-benchmark.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

NAMESPACE="performance-lab"

# Deploy the performance lab
setup_lab() {
    log "Setting up performance lab..."
    kubectl apply -f performance-lab-setup.yaml
    
    log "Waiting for pods to be ready..."
    kubectl wait --for=condition=Ready pod/baseline-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/optimized-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/high-performance-app -n $NAMESPACE --timeout=120s
    
    success "Performance lab setup complete"
}

# Measure startup time
measure_startup_time() {
    local pod_name=$1
    log "Measuring startup time for $pod_name..."
    
    # Delete and recreate pod to measure startup
    kubectl delete pod $pod_name -n $NAMESPACE
    local start_time=$(date +%s.%N)
    
    # Recreate the pod (extract from original manifest)
    kubectl get pod $pod_name -n $NAMESPACE -o yaml --export 2>/dev/null | kubectl apply -f - 2>/dev/null || {
        warning "Couldn't recreate pod automatically, recreating from manifest"
        kubectl apply -f performance-lab-setup.yaml
    }
    
    # Wait for ready and measure time
    kubectl wait --for=condition=Ready pod/$pod_name -n $NAMESPACE --timeout=120s
    local end_time=$(date +%s.%N)
    
    local startup_time=$(echo "$end_time - $start_time" | bc -l)
    echo "$startup_time"
}

# Run load test on a pod
load_test_pod() {
    local pod_name=$1
    local duration=${2:-30}
    local concurrency=${3:-10}
    
    log "Running load test on $pod_name (${duration}s, ${concurrency} concurrent)"
    
    # Start port forwarding
    kubectl port-forward pod/$pod_name -n $NAMESPACE 8080:80 >/dev/null 2>&1 &
    local pf_pid=$!
    sleep 3
    
    # Use Apache Bench for load testing
    local results_file="/tmp/ab_results_${pod_name}.txt"
    
    if command -v ab >/dev/null; then
        ab -n $((duration * concurrency)) -c $concurrency -g /tmp/gnuplot_${pod_name}.dat \
           http://localhost:8080/ > $results_file 2>&1
        
        # Extract key metrics
        local rps=$(grep "Requests per second" $results_file | awk '{print $4}')
        local response_time=$(grep "Time per request.*mean" $results_file | head -1 | awk '{print $4}')
        local failed_requests=$(grep "Failed requests" $results_file | awk '{print $3}')
        
        echo "RPS:$rps,ResponseTime:$response_time,Failed:$failed_requests"
    else
        # Fallback to curl-based test
        local start_time=$(date +%s)
        local requests=0
        local total_time=0
        
        for i in $(seq 1 $((duration * concurrency))); do
            local req_start=$(date +%s.%N)
            if curl -s http://localhost:8080 >/dev/null 2>&1; then
                ((requests++))
            fi
            local req_end=$(date +%s.%N)
            local req_time=$(echo "$req_end - $req_start" | bc -l)
            total_time=$(echo "$total_time + $req_time" | bc -l)
            
            # Basic rate limiting
            sleep 0.1
        done
        
        local avg_response_time=$(echo "scale=3; $total_time / $requests" | bc -l)
        local rps=$(echo "scale=2; $requests / $duration" | bc -l)
        
        echo "RPS:$rps,ResponseTime:$avg_response_time,Failed:0"
    fi
    
    kill $pf_pid 2>/dev/null
}

# Get resource usage metrics
get_resource_usage() {
    local pod_name=$1
    log "Getting resource usage for $pod_name..."
    
    if kubectl top pod $pod_name -n $NAMESPACE >/dev/null 2>&1; then
        kubectl top pod $pod_name -n $NAMESPACE --no-headers | awk '{print "CPU:"$2",Memory:"$3}'
    else
        echo "CPU:N/A,Memory:N/A"
    fi
}

# Comprehensive benchmark
run_comprehensive_benchmark() {
    log "Running comprehensive performance benchmark..."
    
    declare -A results
    local pods=("baseline-app" "optimized-app" "high-performance-app")
    
    echo "=== Performance Benchmark Results ===" > benchmark_results.txt
    echo "Timestamp: $(date)" >> benchmark_results.txt
    echo "" >> benchmark_results.txt
    
    for pod in "${pods[@]}"; do
        log "Benchmarking $pod..."
        
        # Startup time measurement
        log "Measuring startup time for $pod..."
        # Skip startup measurement in this demo to avoid pod recreation issues
        startup_time="N/A"
        
        # Resource usage
        resource_usage=$(get_resource_usage $pod)
        
        # Load test
        load_results=$(load_test_pod $pod 30 10)
        
        # Pod status information
        pod_info=$(kubectl get pod $pod -n $NAMESPACE -o custom-columns=STATUS:.status.phase,READY:.status.conditions[?\(@.type==\"Ready\"\)].status,RESTARTS:.status.containerStatuses[0].restartCount --no-headers)
        
        # Store results
        results[$pod]="Startup:$startup_time,Resources:$resource_usage,Load:$load_results,Status:$pod_info"
        
        # Write to file
        cat >> benchmark_results.txt <<EOF

=== $pod ===
Startup Time: $startup_time seconds
Resource Usage: $resource_usage
Load Test Results: $load_results
Pod Status: $pod_info

EOF
    done
    
    # Generate comparison summary
    cat >> benchmark_results.txt <<EOF

=== Performance Summary ===
This benchmark compares three pod configurations:

1. Baseline App: Standard configuration with generous resource allocation
2. Optimized App: Resource-efficient with security hardening
3. High-Performance App: Maximum performance optimizations

Key Findings:
- Resource efficiency varies significantly between configurations
- Startup time impacts overall application availability
- Load handling capacity differs based on resource allocation
- Security optimizations may have performance trade-offs

Recommendations:
- Use optimized configuration for production workloads
- Consider high-performance setup for critical applications
- Monitor resource usage to fine-tune allocations
- Balance security and performance based on requirements

EOF
    
    success "Benchmark completed. Results saved to benchmark_results.txt"
    cat benchmark_results.txt
}

# Resource monitoring script
monitor_resources() {
    local duration=${1:-300}  # 5 minutes default
    log "Starting resource monitoring for ${duration} seconds..."
    
    local monitor_file="resource_monitor_$(date +%Y%m%d_%H%M%S).log"
    
    {
        echo "Timestamp,Pod,CPU,Memory,Status"
        local end_time=$(($(date +%s) + duration))
        
        while [ $(date +%s) -lt $end_time ]; do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            
            for pod in baseline-app optimized-app high-performance-app; do
                if kubectl get pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                    local status=$(kubectl get pod $pod -n $NAMESPACE -o jsonpath='{.status.phase}')
                    local usage="N/A,N/A"
                    
                    if kubectl top pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                        usage=$(kubectl top pod $pod -n $NAMESPACE --no-headers | awk '{print $2","$3}')
                    fi
                    
                    echo "$timestamp,$pod,$usage,$status"
                fi
            done
            
            sleep 10
        done
    } > $monitor_file
    
    success "Resource monitoring completed. Data saved to $monitor_file"
    
    # Generate simple analysis
    log "Generating resource usage analysis..."
    
    {
        echo "=== Resource Usage Analysis ==="
        echo ""
        
        for pod in baseline-app optimized-app high-performance-app; do
            echo "=== $pod ==="
            grep "$pod" $monitor_file | tail -10 | while IFS=',' read timestamp pod_name cpu memory status; do
                echo "[$timestamp] CPU: $cpu, Memory: $memory, Status: $status"
            done
            echo ""
        done
    } > resource_analysis.txt
    
    success "Analysis saved to resource_analysis.txt"
}

# Cleanup function
cleanup_lab() {
    log "Cleaning up performance lab..."
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -f benchmark_results.txt resource_*.log resource_analysis.txt
    rm -f /tmp/ab_results_*.txt /tmp/gnuplot_*.dat
    success "Cleanup completed"
}

# Main execution
main() {
    case "${1:-benchmark}" in
        "setup")
            setup_lab
            ;;
        "benchmark")
            setup_lab
            run_comprehensive_benchmark
            ;;
        "monitor")
            monitor_resources "${2:-300}"
            ;;
        "cleanup")
            cleanup_lab
            ;;
        "all")
            setup_lab
            run_comprehensive_benchmark
            monitor_resources 300
            echo ""
            success "Complete performance analysis finished!"
            echo "Files created:"
            echo "  - benchmark_results.txt"
            echo "  - resource_monitor_*.log"
            echo "  - resource_analysis.txt"
            ;;
        *)
            echo "Performance Lab - Pod Optimization Benchmark"
            echo ""
            echo "Usage: $0 <command> [options]"
            echo ""
            echo "Commands:"
            echo "  setup      - Set up the performance lab environment"
            echo "  benchmark  - Run comprehensive performance benchmark"
            echo "  monitor    - Monitor resource usage for specified duration"
            echo "  cleanup    - Remove all lab resources"
            echo "  all        - Run complete analysis (setup + benchmark + monitor)"
            echo ""
            echo "Examples:"
            echo "  $0 setup"
            echo "  $0 benchmark"
            echo "  $0 monitor 600  # Monitor for 10 minutes"
            echo "  $0 all          # Complete analysis"
            ;;
    esac
}

main "$@"
```

---

## Pod Troubleshooting Methodologies

### üîß Advanced Troubleshooting Toolkit

#### Example 8: Automated Diagnostic System

```bash
#!/bin/bash
# advanced-pod-diagnostics.sh

set -euo pipefail

# Enhanced diagnostic toolkit with automated problem detection
class PodDiagnostics {
    
# Configuration
NAMESPACE=${NAMESPACE:-default}
OUTPUT_DIR="./diagnostics-$(date +%Y%m%d-%H%M%S)"
VERBOSE=${VERBOSE:-false}

# Colors and formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'
BOLD='\033[1m'

# Logging functions with levels
log_debug() { [[ $VERBOSE == "true" ]] && echo -e "${CYAN}[DEBUG]${NC} $1"; }
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }

# Initialize diagnostics
init_diagnostics() {
    log_info "Initializing pod diagnostics system..."
    mkdir -p "$OUTPUT_DIR"/{logs,reports,metrics,manifests}
    
    # Create diagnostic report header
    cat > "$OUTPUT_DIR/diagnostic_report.md" <<EOF
# Pod Diagnostics Report

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)  
**Namespace:** $NAMESPACE  
**Output Directory:** $OUTPUT_DIR

---

EOF
    
    log_success "Diagnostics initialized in $OUTPUT_DIR"
}

# Comprehensive pod information gathering
gather_pod_info() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Gathering comprehensive information for pod: $pod_name"
    
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    mkdir -p "$pod_dir"
    
    # Basic pod information
    kubectl get pod "$pod_name" -n "$namespace" -o wide > "$pod_dir/basic_info.txt" 2>&1
    kubectl get pod "$pod_name" -n "$namespace" -o yaml > "$pod_dir/manifest.yaml" 2>&1
    
    # Detailed description
    kubectl describe pod "$pod_name" -n "$namespace" > "$pod_dir/description.txt" 2>&1
    
    # Events related to the pod
    kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
        --sort-by='.lastTimestamp' > "$pod_dir/events.txt" 2>&1
    
    # Container logs
    local containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}' 2>/dev/null)
    for container in $containers; do
        log_debug "Collecting logs for container: $container"
        kubectl logs "$pod_name" -n "$namespace" -c "$container" > "$pod_dir/logs_${container}.txt" 2>&1
        
        # Previous logs if container restarted
        kubectl logs "$pod_name" -n "$namespace" -c "$container" --previous > "$pod_dir/logs_${container}_previous.txt" 2>&1 || true
    done
    
    # Resource usage
    kubectl top pod "$pod_name" -n "$namespace" > "$pod_dir/resource_usage.txt" 2>&1 || echo "Metrics not available" > "$pod_dir/resource_usage.txt"
    
    log_success "Pod information gathered for $pod_name"
}

# Automated problem detection
detect_common_issues() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Running automated issue detection for $pod_name..."
    
    local issues_file="$pod_dir/detected_issues.md"
    echo "# Automated Issue Detection Report" > "$issues_file"
    echo "**Pod:** $pod_name" >> "$issues_file"
    echo "**Analysis Time:** $(date)" >> "$issues_file"
    echo "" >> "$issues_file"
    
    local issue_count=0
    
    # Check 1: Pod phase issues
    local phase=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.phase}' 2>/dev/null)
    if [[ "$phase" != "Running" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Pod Not Running
- **Severity:** High
- **Status:** Pod is in '$phase' phase instead of 'Running'
- **Impact:** Application unavailable
- **Investigation:** Check pod events and container status

EOF
    fi
    
    # Check 2: Container readiness issues
    local ready_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[?(@.ready==true)]}' | jq '. | length' 2>/dev/null || echo "0")
    local total_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers}' | jq '. | length' 2>/dev/null || echo "1")
    
    if [[ "$ready_containers" -lt "$total_containers" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Container Readiness Problems
- **Severity:** High
- **Status:** Only $ready_containers of $total_containers containers are ready
- **Impact:** Traffic routing may be affected
- **Investigation:** Check readiness probes and container logs

EOF
    fi
    
    # Check 3: Excessive restarts
    local restarts=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
    if [[ "$restarts" -gt 5 ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Excessive Container Restarts
- **Severity:** Medium
- **Status:** Container has restarted $restarts times
- **Impact:** Service instability and potential data loss
- **Investigation:** Check liveness probes, resource limits, and application logs

EOF
    fi
    
    # Check 4: Resource usage issues
    if kubectl top pod "$pod_name" -n "$namespace" >/dev/null 2>&1; then
        local cpu_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $2}' | sed 's/m$//')
        local memory_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $3}' | sed 's/Mi$//')
        
        if [[ "$cpu_usage" -gt 800 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High CPU Usage
- **Severity:** Medium
- **Status:** CPU usage is ${cpu_usage}m (> 800m threshold)
- **Impact:** Performance degradation and potential throttling
- **Investigation:** Check for CPU-intensive processes and consider scaling

EOF
        fi
        
        if [[ "$memory_usage" -gt 512 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High Memory Usage
- **Severity:** Medium  
- **Status:** Memory usage is ${memory_usage}Mi (> 512Mi threshold)
- **Impact:** Risk of OOM kills and service disruption
- **Investigation:** Check for memory leaks and optimize memory usage

EOF
        fi
    fi
    
    # Check 5: Image pull issues
    if grep -q "ImagePullBackOff\|ErrImagePull" "$pod_dir/description.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Image Pull Problems
- **Severity:** High
- **Status:** Unable to pull container image
- **Impact:** Pod cannot start
- **Investigation:** Check image name, registry access, and credentials

EOF
    fi
    
    # Check 6: Resource constraints
    if grep -q "Insufficient.*resources" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Resource Constraints
- **Severity:** High
- **Status:** Insufficient cluster resources for pod scheduling
- **Impact:** Pod cannot be scheduled
- **Investigation:** Check cluster capacity and node resources

EOF
    fi
    
    # Check 7: Network issues
    if grep -q "NetworkNotReady\|CNI.*error" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Network Configuration Problems
- **Severity:** High
- **Status:** Network setup issues detected
- **Impact:** Pod networking may not function correctly
- **Investigation:** Check CNI configuration and network policies

EOF
    fi
    
    # Summary
    if [[ $issue_count -eq 0 ]]; then
        echo "## Summary: No Critical Issues Detected ‚úÖ" >> "$issues_file"
        echo "The automated analysis found no obvious problems with this pod." >> "$issues_file"
        log_success "No critical issues detected for $pod_name"
    else
        echo "## Summary: $issue_count Issue(s) Detected ‚ö†Ô∏è" >> "$issues_file"
        echo "Review the issues above and follow the investigation recommendations." >> "$issues_file"
        log_warn "$issue_count issue(s) detected for $pod_name"
    fi
    
    return $issue_count
}

# Generate recommendations
generate_recommendations() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Generating recommendations for $pod_name..."
    
    local rec_file="$pod_dir/recommendations.md"
    echo "# Optimization Recommendations" > "$rec_file"
    echo "**Pod:** $pod_name" >> "$rec_file"
    echo "" >> "$rec_file"
    
    # Resource optimization recommendations
    echo "## Resource Optimization" >> "$rec_file"
    
    # Check current resource configuration
    local requests_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.memory}' 2>/dev/null || echo "not set")
    local requests_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.cpu}' 2>/dev/null || echo "not set")
    local limits_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.memory}' 2>/dev/null || echo "not set")
    local limits_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.cpu}' 2>/dev/null || echo "not set")
    
    cat >> "$rec_file" <<EOF
### Current Resource Configuration
- **Memory Request:** $requests_mem
- **CPU Request:** $requests_cpu  
- **Memory Limit:** $limits_mem
- **CPU Limit:** $limits_cpu

EOF
    
    # Security recommendations
    echo "## Security Hardening" >> "$rec_file"
    
    local security_context=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.securityContext}' 2>/dev/null)
    if [[ -z "$security_context" || "$security_context" == "null" ]]; then
        cat >> "$rec_file" <<EOF
### Security Context Improvements
- ‚úÖ **Add security context:** Configure runAsNonRoot, runAsUser, and fsGroup
- ‚úÖ **Drop capabilities:** Remove unnecessary Linux capabilities  
- ‚úÖ **Read-only root filesystem:** Set readOnlyRootFilesystem: true
- ‚úÖ **Prevent privilege escalation:** Set allowPrivilegeEscalation: false

EOF
    fi
    
    # Health check recommendations
    echo "## Health Check Optimization" >> "$rec_file"
    
    local has_liveness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].livenessProbe}' 2>/dev/null)
    local has_readiness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].readinessProbe}' 2>/dev/null)
    
    if [[ -z "$has_liveness" || "$has_liveness" == "null" ]]; then
        echo "- ‚úÖ **Add liveness probe:** Implement health checking for automatic restart" >> "$rec_file"
    fi
    
    if [[ -z "$has_readiness" || "$has_readiness" == "null" ]]; then
        echo "- ‚úÖ **Add readiness probe:** Control traffic routing based on application readiness" >> "$rec_file"
    fi
    
    # Performance recommendations
    echo "" >> "$rec_file"
    echo "## Performance Optimization" >> "$rec_file"
    cat >> "$rec_file" <<EOF
- ‚úÖ **Use Alpine images:** Reduce image size and startup time
- ‚úÖ **Implement resource requests:** Help scheduler make better placement decisions
- ‚úÖ **Optimize health check frequency:** Balance responsiveness with overhead
- ‚úÖ **Use memory-backed volumes:** For temporary files and caches
- ‚úÖ **Configure DNS caching:** Reduce DNS lookup overhead

EOF
    
    log_success "Recommendations generated for $pod_name"
}

# Interactive diagnostic session
interactive_diagnostics() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Starting interactive diagnostics for $pod_name..."
    
    echo -e "${BOLD}Interactive Pod Diagnostics${NC}"
    echo "Pod: $pod_name"
    echo "Namespace: $namespace"
    echo ""
    
    while true; do
        echo -e "${CYAN}Available actions:${NC}"
        echo "1) Show pod status"
        echo "2) View recent events"
        echo "3) Check container logs"
        echo "4) Execute command in pod"
        echo "5) Port forward to pod"
        echo "6) Resource usage"
        echo "7) Run full diagnostic"
        echo "8) Generate recommendations"
        echo "q) Quit"
        echo ""
        
        read -p "Select action [1-8,q]: " choice
        
        case $choice in
            1)
                echo "=== Pod Status ==="
                kubectl get pod "$pod_name" -n "$namespace" -o wide
```" \
        10
    
    echo ""
    echo "üè• Health Monitoring"
    echo "------------------"
    
    check_item "Liveness probe configured" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.spec.containers[0].livenessProbe}' | grep -v '^null
                kubectl describe pod "$pod_name" -n "$namespace" | grep -A 10 "Status\|Conditions"
                ;;
            2)
                echo "=== Recent Events ==="
                kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
                    --sort-by='.lastTimestamp' | tail -10
                ;;
            3)
                echo "=== Container Selection ==="
                local containers=($(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}'))
                if [[ ${#containers[@]} -eq 1 ]]; then
                    echo "Showing logs for container: ${containers[0]}"
                    kubectl logs "$pod_name" -n "$namespace" --tail=50
                else
                    echo "Available containers:"
                    for i in "${!containers[@]}"; do
                        echo "$((i+1))) ${containers[i]}"
                    done
                    read -p "Select container [1-${#containers[@]}]: " container_choice
                    if [[ $container_choice -ge 1 && $container_choice -le ${#containers[@]} ]]; then
                        local selected_container=${containers[$((container_choice-1))]}
                        echo "Showing logs for container: $selected_container"
                        kubectl logs "$pod_name" -n "$namespace" -c "$selected_container" --tail=50
                    fi
                fi
                ;;
            4)
                read -p "Enter command to execute: " exec_command
                kubectl exec -it "$pod_name" -n "$namespace" -- $exec_command
                ;;
            5)
                read -p "Enter local port: " local_port
                read -p "Enter pod port: " pod_port
                echo "Port forwarding $local_port:$pod_port - Press Ctrl+C to stop"
                kubectl port-forward "$pod_name" -n "$namespace" "$local_port:$pod_port"
                ;;
            6)
                echo "=== Resource Usage ==="
                kubectl top pod "$pod_name" -n "$namespace" 2>/dev/null || echo "Metrics not available"
                ;;
            7)
                gather_pod_info "$pod_name" "$namespace"
                detect_common_issues "$pod_name" "$namespace"
                generate_recommendations "$pod_name" "$namespace"
                echo "Full diagnostic completed. Check $OUTPUT_DIR/pods/$pod_name/"
                ;;
            8)
                generate_recommendations "$pod_name" "$namespace"
                echo "Recommendations generated. Check $OUTPUT_DIR/pods/$pod_name/recommendations.md"
                ;;
            q|Q)
                log_info "Exiting interactive diagnostics"
                break
                ;;
            *)
                echo "Invalid choice. Please try again."
                ;;
        esac
        
        echo ""
        read -p "Press Enter to continue..."
        echo ""
    done
}

# Cluster-wide pod health assessment
cluster_health_assessment() {
    log_info "Running cluster-wide pod health assessment..."
    
    local health_report="$OUTPUT_DIR/cluster_health_report.md"
    
    cat > "$health_report" <<EOF
# Cluster Pod Health Assessment

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)

---

EOF
    
    # Get all namespaces
    local namespaces=($(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'))
    
    local total_pods=0
    local healthy_pods=0
    local unhealthy_pods=0
    
    for ns in "${namespaces[@]}"; do
        log_info "Assessing namespace: $ns"
        
        local pods=($(kubectl get pods -n "$ns" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null))
        
        if [[ ${#pods[@]} -eq 0 ]]; then
            continue
        fi
        
        echo "## Namespace: $ns" >> "$health_report"
        echo "" >> "$health_report"
        
        local ns_healthy=0
        local ns_unhealthy=0
        
        for pod in "${pods[@]}"; do
            ((total_pods++))
            
            local phase=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.phase}')
            local ready_condition=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
            local restarts=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
            
            if [[ "$phase" == "Running" && "$ready_condition" == "True" && $restarts -lt 5 ]]; then
                ((healthy_pods++))
                ((ns_healthy++))
                echo "‚úÖ **$pod** - Healthy" >> "$health_report"
            else
                ((unhealthy_pods++))
                ((ns_unhealthy++))
                echo "‚ùå **$pod** - Issues detected (Phase: $phase, Ready: $ready_condition, Restarts: $restarts)" >> "$health_report"
                
                # Run quick diagnostics for unhealthy pods
                gather_pod_info "$pod" "$ns"
                detect_common_issues "$pod" "$ns"
            fi
        done
        
        echo "" >> "$health_report"
        echo "**Namespace Summary:** $ns_healthy healthy, $ns_unhealthy unhealthy" >> "$health_report"
        echo "" >> "$health_report"
    done
    
    # Overall summary
    local health_percentage=$((healthy_pods * 100 / total_pods))
    
    cat >> "$health_report" <<EOF

---

## Overall Cluster Health

- **Total Pods:** $total_pods
- **Healthy Pods:** $healthy_pods
- **Unhealthy Pods:** $unhealthy_pods
- **Health Percentage:** $health_percentage%

### Health Status
EOF
    
    if [[ $health_percentage -ge 90 ]]; then
        echo "üü¢ **EXCELLENT** - Cluster is in excellent health" >> "$health_report"
    elif [[ $health_percentage -ge 75 ]]; then
        echo "üü° **GOOD** - Cluster is in good health with minor issues" >> "$health_report"
    elif [[ $health_percentage -ge 50 ]]; then
        echo "üü† **WARNING** - Cluster has significant health issues" >> "$health_report"
    else
        echo "üî¥ **CRITICAL** - Cluster is in critical condition" >> "$health_report"
    fi
    
    log_success "Cluster health assessment completed. Report: $health_report"
}

# Generate comprehensive diagnostic report
generate_final_report() {
    log_info "Generating comprehensive diagnostic report..."
    
    local final_report="$OUTPUT_DIR/comprehensive_report.html"
    
    cat > "$final_report" <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Pod Diagnostics Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
        .header { background-color: #f4f4f4; padding: 20px; border-radius: 5px; margin-bottom: 30px; }
        .section { margin: 30px 0; }
        .pod-card { border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin: 10px 0; }
        .healthy { border-left: 5px solid #28a745; }
        .unhealthy { border-left: 5px solid #dc3545; }
        .warning { border-left: 5px solid #ffc107; }
        .metric { display: inline-block; margin: 10px 15px 10px 0; padding: 8px 12px; background-color: #e9ecef; border-radius: 3px; }
        .issue { background-color: #fff3cd; padding: 10px; border-radius: 3px; margin: 10px 0; }
        pre { background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }
        .tabs { border-bottom: 1px solid #ddd; margin-bottom: 20px; }
        .tab { display: inline-block; padding: 10px 20px; cursor: pointer; border-bottom: 2px solid transparent; }
        .tab.active { border-bottom-color: #007bff; color: #007bff; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }
    </style>
    <script>
        function showTab(tabName) {
            // Hide all tab contents
            var contents = document.getElementsByClassName('tab-content');
            for (var i = 0; i < contents.length; i++) {
                contents[i].classList.remove('active');
            }
            
            // Remove active class from all tabs
            var tabs = document.getElementsByClassName('tab');
            for (var i = 0; i < tabs.length; i++) {
                tabs[i].classList.remove('active');
            }
            
            // Show selected tab content and mark tab as active
            document.getElementById(tabName).classList.add('active');
            event.target.classList.add('active');
        }
    </script>
</head>
<body>
    <div class="header">
        <h1>üîç Pod Diagnostics Report</h1>
        <div class="metric">
            <strong>Generated:</strong> $(date)
        </div>
        <div class="metric">
            <strong>Cluster:</strong> $(kubectl config current-context)
        </div>
        <div class="metric">
            <strong>Diagnostics Version:</strong> 2.0
        </div>
    </div>
    
    <div class="tabs">
        <div class="tab active" onclick="showTab('overview')">Overview</div>
        <div class="tab" onclick="showTab('pods')">Pod Analysis</div>
        <div class="tab" onclick="showTab('issues')">Detected Issues</div>
        <div class="tab" onclick="showTab('recommendations')">Recommendations</div>
    </div>
    
    <div id="overview" class="tab-content active">
        <h2>üìä Cluster Overview</h2>
        <div class="section">
EOF
    
    # Add cluster metrics
    local total_nodes=$(kubectl get nodes --no-headers | wc -l)
    local ready_nodes=$(kubectl get nodes --no-headers | grep " Ready " | wc -l)
    local total_namespaces=$(kubectl get namespaces --no-headers | wc -l)
    
    cat >> "$final_report" <<EOF
            <div class="pod-card healthy">
                <h3>Cluster Metrics</h3>
                <div class="metric"><strong>Nodes:</strong> $ready_nodes/$total_nodes Ready</div>
                <div class="metric"><strong>Namespaces:</strong> $total_namespaces</div>
                <div class="metric"><strong>Kubernetes Version:</strong> $(kubectl version --short --client | cut -d' ' -f3)</div>
            </div>
        </div>
    </div>
    
    <div id="pods" class="tab-content">
        <h2>üöÄ Pod Analysis</h2>
EOF
    
    # Add pod analysis for each analyzed pod
    for pod_dir in "$OUTPUT_DIR"/pods/*/; do
        if [[ -d "$pod_dir" ]]; then
            local pod_name=$(basename "$pod_dir")
            local issues_count=0
            
            if [[ -f "$pod_dir/detected_issues.md" ]]; then
                issues_count=$(grep -c "## Issue" "$pod_dir/detected_issues.md" 2>/dev/null || echo "0")
            fi
            
            local card_class="healthy"
            if [[ $issues_count -gt 0 ]]; then
                card_class="unhealthy"
            fi
            
            cat >> "$final_report" <<EOF
        <div class="pod-card $card_class">
            <h3>üì¶ $pod_name</h3>
            <div class="metric"><strong>Issues Detected:</strong> $issues_count</div>
            <div class="metric"><strong>Analysis Files:</strong> $(ls "$pod_dir" | wc -l)</div>
            <div class="metric"><strong>Report Location:</strong> pods/$pod_name/</div>
        </div>
EOF
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="issues" class="tab-content">
        <h2>‚ö†Ô∏è Detected Issues</h2>
EOF
    
    # Aggregate all issues
    local total_issues=0
    for issues_file in "$OUTPUT_DIR"/pods/*/detected_issues.md; do
        if [[ -f "$issues_file" ]]; then
            local pod_issues=$(grep -c "## Issue" "$issues_file" 2>/dev/null || echo "0")
            ((total_issues += pod_issues))
            
            if [[ $pod_issues -gt 0 ]]; then
                local pod_name=$(basename "$(dirname "$issues_file")")
                echo "<h3>Issues for $pod_name</h3>" >> "$final_report"
                
                # Convert markdown issues to HTML
                grep "## Issue" "$issues_file" | while read -r line; do
                    echo "<div class=\"issue\">$line</div>" >> "$final_report"
                done
            fi
        fi
    done
    
    if [[ $total_issues -eq 0 ]]; then
        echo "<div class=\"pod-card healthy\"><h3>‚úÖ No Issues Detected</h3><p>All analyzed pods appear to be healthy!</p></div>" >> "$final_report"
    fi
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="recommendations" class="tab-content">
        <h2>üí° Recommendations</h2>
        <div class="section">
            <div class="pod-card warning">
                <h3>General Recommendations</h3>
                <ul>
                    <li>‚úÖ Implement comprehensive health checks for all pods</li>
                    <li>‚úÖ Set appropriate resource requests and limits</li>
                    <li>‚úÖ Use security contexts to harden pod security</li>
                    <li>‚úÖ Monitor resource usage and optimize accordingly</li>
                    <li>‚úÖ Implement graceful shutdown handling</li>
                    <li>‚úÖ Use multi-stage Docker builds for smaller images</li>
                    <li>‚úÖ Implement proper logging and observability</li>
                </ul>
            </div>
        </div>
EOF
    
    # Add pod-specific recommendations
    for rec_file in "$OUTPUT_DIR"/pods/*/recommendations.md; do
        if [[ -f "$rec_file" ]]; then
            local pod_name=$(basename "$(dirname "$rec_file")")
            echo "<div class=\"pod-card\"><h3>Recommendations for $pod_name</h3>" >> "$final_report"
            echo "<p>See detailed recommendations in: pods/$pod_name/recommendations.md</p></div>" >> "$final_report"
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div class="section">
        <hr>
        <p><em>Report generated by Pod Diagnostics Toolkit v2.0</em></p>
        <p><em>For detailed analysis, check individual files in the diagnostics output directory.</em></p>
    </div>
    
</body>
</html>
EOF
    
    log_success "Comprehensive report generated: $final_report"
    echo ""
    echo -e "${BOLD}üìã Diagnostic Summary:${NC}"
    echo "- Output Directory: $OUTPUT_DIR"
    echo "- HTML Report: $final_report"
    echo "- Total Issues Found: $total_issues"
    echo ""
    echo -e "${CYAN}üí° Next Steps:${NC}"
    echo "1. Open $final_report in your browser"
    echo "2. Review individual pod analysis in $OUTPUT_DIR/pods/"
    echo "3. Implement recommended fixes"
    echo "4. Re-run diagnostics to verify improvements"
}

# Main execution function
main() {
    local command=${1:-help}
    local pod_name=${2:-}
    local namespace=${3:-$NAMESPACE}
    
    case "$command" in
        "analyze")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for analysis"
                echo "Usage: $0 analyze <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            gather_pod_info "$pod_name" "$namespace"
            detect_common_issues "$pod_name" "$namespace"
            generate_recommendations "$pod_name" "$namespace"
            generate_final_report
            ;;
            
        "interactive")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for interactive mode"
                echo "Usage: $0 interactive <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            interactive_diagnostics "$pod_name" "$namespace"
            ;;
            
        "cluster-health")
            init_diagnostics
            cluster_health_assessment
            generate_final_report
            ;;
            
        "help"|*)
            cat <<EOF
üîç Advanced Pod Diagnostics Toolkit

Usage: $0 <command> [options]

Commands:
  analyze <pod-name> [namespace]     - Run comprehensive pod analysis
  interactive <pod-name> [namespace] - Start interactive diagnostic session
  cluster-health                     - Assess health of all pods in cluster
  help                              - Show this help message

Environment Variables:
  NAMESPACE - Default namespace (default: default)
  VERBOSE   - Enable verbose output (default: false)

Examples:
  $0 analyze nginx-pod production
  $0 interactive web-app-123
  $0 cluster-health
  VERBOSE=true $0 analyze problematic-pod

Output:
  All diagnostic data is saved to ./diagnostics-TIMESTAMP/
  HTML report provides comprehensive overview
  Individual pod analysis available in pods/ subdirectory

EOF
            ;;
    esac
}

# Execute main function
main "$@"
```

---

## Summary and Production-Ready Examples

### üèÜ Complete Production Workflow

Let's create a final comprehensive example that brings everything together:

```yaml
# complete-production-workflow.yaml
# This represents a complete production-ready pod deployment workflow

apiVersion: v1
kind: Namespace
metadata:
  name: production-workload
  labels:
    environment: production
    team: platform
---
# ConfigMap for application configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production-workload
data:
  app.properties: |
    server.port=8080
    management.port=8081
    logging.level=INFO
    metrics.enabled=true
  nginx.conf: |
    server {
        listen 80;
        location /health { return 200 'healthy\n'; }
        location /ready { return 200 'ready\n'; }
        location / {
            proxy_pass http://127.0.0.1:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
---
# Secret for sensitive configuration
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: production-workload
type: Opaque
data:
  database-password: c3VwZXJzZWNyZXQ=  # supersecret (base64)
  api-key: YWJjZGVmZ2hpams=  # abcdefghijk (base64)
---
# Production-ready pod with all best practices
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production-workload
  labels:
    app: production-app
    version: "2.1.0"
    environment: production
    team: platform
    component: backend
  annotations:
    description: "Production application with full observability"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/production-app"
    prometheus.io/scrape: "true"
    prometheus.io/port: "8081"
    prometheus.io/path: "/metrics"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Resource constraints and node placement
  nodeSelector:
    node-type: "application"
    performance-tier: "high"
    
  tolerations:
  - key: "dedicated-app"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
    
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: production-app
        topologyKey: kubernetes.io/hostname
        
  # DNS and network configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  # Init container for setup tasks
  initContainers:
  - name: setup
    image: busybox:1.35
    command:
    - /bin/sh
    - -c
    - |
      echo "Initializing application..."
      
      # Database migration simulation
      echo "Running database migrations..."
      sleep 5
      
      # Cache warming
      echo "Warming up caches..."
      sleep 3
      
      # Configuration validation
      echo "Validating configuration..."
      if [ -f /config/app.properties ]; then
        echo "‚úÖ Configuration file found"
      else
        echo "‚ùå Configuration file missing"
        exit 1
      fi
      
      echo "Initialization completed successfully"
      
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-init
      mountPath: /tmp
      
  # Main application containers
  containers:
  # Application container
  - name: app
    image: openjdk:11-jre-slim
    command:
    - /bin/bash
    - -c
    - |
      echo "Starting application..."
      
      # Simulated application startup
      java -Xmx200m -Xms100m -jar /app/application.jar \
        --spring.config.location=file:/config/app.properties \
        --server.port=8080 \
        --management.server.port=8081
        
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP
    - name: management
      containerPort: 8081
      protocol: TCP
      
    # Environment configuration
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # Sensitive configuration from secrets
    - name: DATABASE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: database-password
    - name: API_KEY
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: api-key
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security hardening
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    # Comprehensive health checks
    livenessProbe:
      httpGet:
        path: /actuator/health/liveness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /actuator/health/readiness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /actuator/health
        port: 8081
      initialDelaySeconds: 20
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle management
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Application started at $(date)" >> /tmp/startup.log
            # Custom post-start logic here
            
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Graceful shutdown initiated at $(date)" >> /tmp/shutdown.log
            # Send SIGTERM to application
            kill -TERM 1
            # Wait for graceful shutdown
            sleep 30
            
    # Volume mounts
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-volume
      mountPath: /tmp
    - name: app-logs
      mountPath: /app/logs
    - name: app-data
      mountPath: /app/data
      
  # Nginx reverse proxy sidecar
  - name: nginx-proxy
    image: nginx:1.21-alpine
    ports:
    - name: http-proxy
      containerPort: 80
      protocol: TCP
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        add: ["NET_BIND_SERVICE"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: nginx-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
      
  # Logging and monitoring sidecar
  - name: log-shipper
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: fluent-tmp
      mountPath: /tmp
      
  # Volumes
  volumes:
  - name: config-volume
    configMap:
      name: app-config
      items:
      - key: app.properties
        path: app.properties
  - name: nginx-config
    configMap:
      name: app-config
      items:
      - key: nginx.conf
        path: default.conf
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config  # Would be created separately
  # Temporary and cache volumes
  - name: tmp-volume
    emptyDir:
      sizeLimit: 256Mi
  - name: tmp-init
    emptyDir:
      sizeLimit: 64Mi
  - name: nginx-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: fluent-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: nginx-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: nginx-run
    emptyDir:
      sizeLimit: 32Mi
  # Application data volumes
  - name: app-logs
    emptyDir:
      sizeLimit: 1Gi
  - name: app-data
    emptyDir:
      sizeLimit: 2Gi
```

This comprehensive example demonstrates:

- **Complete security hardening** with proper contexts and capabilities
- **Multi-container architecture** with main app, proxy, and logging sidecars
- **Comprehensive health checks** for all containers
- **Resource optimization** with appropriate requests and limits
- **Configuration management** using ConfigMaps and Secrets
- **Observability** with structured logging and metrics endpoints
- **Production-ready networking** with reverse proxy
- **Graceful lifecycle management** with init containers and shutdown hooks

## üéì Key Learning Outcomes

By working through these enhanced examples, demos, and mini-projects, you've gained:

1. **Foundation Skills**: Basic pod creation, inspection, and management
2. **Intermediate Capabilities**: Multi-container patterns, health monitoring, and debugging
3. **Advanced Techniques**: Performance optimization, security hardening, and automation
4. **Expert-Level Mastery**: Custom controllers, comprehensive diagnostics, and production workflows

### üöÄ Next Steps for Continued Learning

1. **Practice the Examples**: Work through each example in your own cluster
2. **Customize for Your Use Cases**: Adapt the patterns to your specific applications
3. **Build Your Toolkit**: Create your own diagnostic and management scripts
4. **Share and Learn**: Contribute back to the community with your own improvements
5. **Scale Up**: Apply these pod management skills to higher-level controllers

The journey from basic pod creation to# 5. Working with Pods - From Fundamentals to Mastery (Enhanced Edition)

Understanding how to work with pods effectively forms the foundation of all Kubernetes operations. While you'll typically use higher-level controllers like Deployments in production environments, direct pod management skills are essential for debugging, troubleshooting, and truly understanding how Kubernetes applications function at their core. Think of this knowledge as learning to drive a manual transmission car‚Äîeven if you usually drive automatic, understanding the underlying mechanics makes you a better driver overall.

This enhanced guide provides progressive examples, hands-on demos, and real-world mini-projects to solidify your understanding through practical application.

## üéØ Learning Path Overview

- **Foundation Level**: Basic pod creation and inspection
- **Intermediate Level**: Multi-container patterns and health checks
- **Advanced Level**: Complex debugging and optimization
- **Expert Level**: Custom tooling and automation

---

## Understanding Pod Creation Strategies

Creating pods effectively requires understanding when to use imperative commands versus declarative configurations, and how different creation approaches serve different purposes.

### üìö Foundation Examples

Let's start with the absolute basics and progressively build complexity.

#### Example 1: Your First Pod
```bash
# Create the simplest possible pod
kubectl run hello-world --image=nginx --restart=Never

# Verify it's running
kubectl get pods

# Expected output:
# NAME          READY   STATUS    RESTARTS   AGE
# hello-world   1/1     Running   0          30s
```

#### Example 2: Pod with Custom Commands
```bash
# Create a pod that runs a custom command
kubectl run date-pod --image=busybox --restart=Never -- date

# This pod will run the date command and then exit
# Check the output
kubectl logs date-pod

# Clean up
kubectl delete pod date-pod
```

#### Example 3: Interactive Pod Session
```bash
# Create an interactive debugging pod
kubectl run -it debug-pod --image=busybox --restart=Never -- sh

# Inside the pod, try these commands:
# ls -la
# ps aux
# ping google.com
# nslookup kubernetes.default.svc.cluster.local

# Exit and clean up
# exit
kubectl delete pod debug-pod
```

### üõ†Ô∏è Demo: Pod Lifecycle Observation

Let's create a demo that shows the complete pod lifecycle in action:

```bash
#!/bin/bash
# pod-lifecycle-demo.sh

echo "=== Pod Lifecycle Demonstration ==="

# Terminal 1: Start watching pods
echo "In a separate terminal, run: kubectl get pods -w"
echo "Press Enter when ready..."
read

# Create a pod with a slow-starting application
echo "Creating pod with slow startup..."
kubectl run lifecycle-demo --image=nginx --restart=Never \
  --dry-run=client -o yaml > lifecycle-pod.yaml

# Add some customizations to make it more interesting
cat <<EOF >> lifecycle-pod.yaml
  containers:
  - name: nginx
    image: nginx:1.21
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod starting up...' && sleep 10"
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod shutting down...' && sleep 5"
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 5
EOF

echo "Applying pod configuration..."
kubectl apply -f lifecycle-pod.yaml

echo "Watch the pod states change from Pending -> ContainerCreating -> Running"
echo "Press Enter to continue when pod is Running..."
read

# Show detailed pod information
echo "=== Pod Details ==="
kubectl describe pod lifecycle-demo

echo "Press Enter to delete the pod and observe termination..."
read

# Delete and watch termination
kubectl delete pod lifecycle-demo

echo "Demo complete! Clean up the YAML file:"
echo "rm lifecycle-pod.yaml"
```

### üéØ Mini-Project 1: Pod Resource Monitor

Create a simple monitoring system using pods:

```yaml
# resource-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-monitor
  labels:
    app: monitor
    type: demo
spec:
  containers:
  - name: monitor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Starting Resource Monitor..."
      while true; do
        echo "=== $(date) ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "Load average:"
        uptime
        echo "Sleeping for 30 seconds..."
        sleep 30
      done
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
  restartPolicy: Always
```

```bash
# Deploy and monitor
kubectl apply -f resource-monitor-pod.yaml

# Watch the logs
kubectl logs -f resource-monitor

# In another terminal, check resource usage
kubectl top pod resource-monitor

# Clean up
kubectl delete -f resource-monitor-pod.yaml
```

---

## Deep Pod Inspection and Monitoring

### üîç Intermediate Examples

#### Example 4: Multi-Container Pod Investigation

```yaml
# multi-container-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-demo
  labels:
    demo: multi-container
spec:
  containers:
  - name: web-server
    image: nginx:1.21
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
    
  - name: log-processor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Log processor starting..."
      while true; do
        if [ -f /var/log/nginx/access.log ]; then
          echo "=== Access Log Summary $(date) ==="
          tail -10 /var/log/nginx/access.log | wc -l
          echo "Recent requests:"
          tail -5 /var/log/nginx/access.log
        else
          echo "Waiting for access.log..."
        fi
        sleep 30
      done
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
      
  - name: metrics-collector
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Metrics collector starting..."
      while true; do
        echo "=== Metrics $(date) ==="
        echo "Container count: 3"
        echo "Uptime: $(uptime)"
        echo "Memory: $(free -h | grep Mem)"
        sleep 60
      done
      
  volumes:
  - name: shared-logs
    emptyDir: {}
```

**Inspection Commands:**
```bash
# Apply the multi-container pod
kubectl apply -f multi-container-demo.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/multi-container-demo

# Inspect different aspects
echo "=== Basic Information ==="
kubectl get pod multi-container-demo -o wide

echo "=== Container Status ==="
kubectl get pod multi-container-demo -o jsonpath='{.status.containerStatuses[*].name}' | tr ' ' '\n'

echo "=== Logs from each container ==="
kubectl logs multi-container-demo -c web-server --tail=5
kubectl logs multi-container-demo -c log-processor --tail=5
kubectl logs multi-container-demo -c metrics-collector --tail=5

# Generate some traffic to see shared volume in action
kubectl port-forward multi-container-demo 8080:80 &
PF_PID=$!

# Generate requests
for i in {1..10}; do
  curl -s http://localhost:8080 > /dev/null
  echo "Request $i sent"
  sleep 1
done

kill $PF_PID

# Check log processor output
kubectl logs multi-container-demo -c log-processor --tail=10

# Clean up
kubectl delete -f multi-container-demo.yaml
```

### üõ†Ô∏è Demo: Advanced Pod Debugging Techniques

```bash
#!/bin/bash
# advanced-debugging-demo.sh

echo "=== Advanced Pod Debugging Demo ==="

# Create a problematic pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: problematic-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "2000m"  # This might cause scheduling issues
      limits:
        memory: "512Mi"  # Less than request - invalid!
        cpu: "500m"
    livenessProbe:
      httpGet:
        path: /nonexistent
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
EOF

echo "Created a pod with multiple issues. Let's debug it..."

# Wait a moment for issues to manifest
sleep 10

echo "=== Debugging Steps ==="

echo "1. Check pod status:"
kubectl get pod problematic-pod -o wide

echo "2. Look at events:"
kubectl describe pod problematic-pod | grep -A 10 Events:

echo "3. Check for resource issues:"
kubectl describe pod problematic-pod | grep -A 5 -B 5 "resource"

echo "4. Examine container status:"
kubectl get pod problematic-pod -o jsonpath='{.status.containerStatuses[0]}' | jq '.'

# Fix the pod
echo "5. Let's fix the issues..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: fixed-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
EOF

echo "6. Compare the fixed pod:"
kubectl wait --for=condition=Ready pod/fixed-pod --timeout=60s
kubectl get pods -l debug=demo

# Clean up
echo "Cleaning up..."
kubectl delete pod problematic-pod fixed-pod
```

### üéØ Mini-Project 2: Pod Health Monitoring Dashboard

Create a comprehensive health monitoring system:

```yaml
# health-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: health-dashboard
  labels:
    app: health-monitor
spec:
  containers:
  - name: health-checker
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Health Dashboard Starting..."
      
      # Create a simple HTML dashboard
      mkdir -p /tmp/dashboard
      
      while true; do
        cat > /tmp/dashboard/health.html <<EOF
      <!DOCTYPE html>
      <html>
      <head>
          <title>Pod Health Dashboard</title>
          <meta http-equiv="refresh" content="30">
          <style>
              body { font-family: Arial, sans-serif; margin: 40px; }
              .healthy { color: green; }
              .warning { color: orange; }
              .critical { color: red; }
              .metric { margin: 10px 0; padding: 10px; border: 1px solid #ccc; }
          </style>
      </head>
      <body>
          <h1>Pod Health Dashboard</h1>
          <p>Last Update: $(date)</p>
          
          <div class="metric">
              <h3>System Load</h3>
              <p>$(uptime)</p>
          </div>
          
          <div class="metric">
              <h3>Memory Usage</h3>
              <pre>$(free -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Disk Usage</h3>
              <pre>$(df -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Process Count</h3>
              <p>Running processes: $(ps aux | wc -l)</p>
          </div>
          
      </body>
      </html>
      EOF
        
        echo "Dashboard updated at $(date)"
        sleep 30
      done
    volumeMounts:
    - name: dashboard-storage
      mountPath: /tmp/dashboard
      
  - name: web-server
    image: nginx:alpine
    ports:
    - containerPort: 80
    command:
    - /bin/sh
    - -c
    - |
      # Configure nginx to serve our dashboard
      cat > /etc/nginx/conf.d/default.conf <<EOF
      server {
          listen 80;
          location / {
              root /usr/share/nginx/html;
              index health.html;
          }
      }
      EOF
      
      # Start nginx
      nginx -g "daemon off;"
    volumeMounts:
    - name: dashboard-storage
      mountPath: /usr/share/nginx/html
      
  volumes:
  - name: dashboard-storage
    emptyDir: {}
    
  restartPolicy: Always
```

**Usage:**
```bash
# Deploy the health dashboard
kubectl apply -f health-monitor-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/health-dashboard

# Access the dashboard
kubectl port-forward health-dashboard 8080:80

# Open browser to http://localhost:8080
echo "Open http://localhost:8080 in your browser"

# Monitor the pod's own health
kubectl top pod health-dashboard

# Check logs from both containers
kubectl logs health-dashboard -c health-checker --tail=10
kubectl logs health-dashboard -c web-server --tail=10

# Clean up
kubectl delete -f health-monitor-pod.yaml
```

---

## Interactive Pod Management and Debugging

### üîß Advanced Examples

#### Example 5: Network Debugging Pod

```yaml
# network-debug-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: network-debugger
  labels:
    purpose: network-debug
spec:
  containers:
  - name: nettools
    image: nicolaka/netshoot
    command: ["/bin/bash"]
    args:
    - -c
    - |
      echo "Network debugging tools ready!"
      echo "Available tools: dig, nslookup, ping, curl, wget, tcpdump, netstat"
      echo "Example commands:"
      echo "  dig kubernetes.default.svc.cluster.local"
      echo "  ping 8.8.8.8"
      echo "  curl -I http://httpbin.org/headers"
      echo "  netstat -tulpn"
      
      # Keep container running
      sleep 3600
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
  restartPolicy: Never
```

**Debugging Session:**
```bash
# Deploy the network debugger
kubectl apply -f network-debug-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/network-debugger

# Start interactive session
kubectl exec -it network-debugger -- bash

# Inside the pod, run network diagnostics:
# Test DNS resolution
# dig kubernetes.default.svc.cluster.local

# Test external connectivity
# ping -c 3 8.8.8.8

# Test HTTP services
# curl -I https://httpbin.org/headers

# Check network interfaces
# ip addr show

# Check routing table
# ip route show

# Test service discovery
# nslookup kubernetes.default

# Exit and clean up
# exit
kubectl delete -f network-debug-pod.yaml
```

### üõ†Ô∏è Demo: File Transfer and Volume Management

```bash
#!/bin/bash
# file-transfer-demo.sh

echo "=== File Transfer and Volume Demo ==="

# Create a pod with persistent data
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: file-demo
spec:
  containers:
  - name: app
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Creating sample files..."
      mkdir -p /data/logs /data/config
      
      # Generate some sample data
      for i in {1..5}; do
        echo "Log entry \$i at \$(date)" >> /data/logs/app.log
        sleep 1
      done
      
      echo "app_name=demo-app" > /data/config/settings.conf
      echo "version=1.0.0" >> /data/config/settings.conf
      echo "debug=true" >> /data/config/settings.conf
      
      echo "Files created. Keeping container running..."
      sleep 3600
    volumeMounts:
    - name: data-storage
      mountPath: /data
  volumes:
  - name: data-storage
    emptyDir: {}
EOF

echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/file-demo

# Demonstrate file operations
echo "=== File Operations Demo ==="

echo "1. List files in the pod:"
kubectl exec file-demo -- find /data -type f

echo "2. Copy file from pod to local:"
kubectl cp file-demo:/data/logs/app.log ./app.log.backup
echo "File copied to: app.log.backup"
cat app.log.backup

echo "3. Create local config file:"
cat > new-config.conf <<EOF
app_name=updated-demo-app
version=2.0.0
debug=false
environment=production
EOF

echo "4. Copy local file to pod:"
kubectl cp new-config.conf file-demo:/data/config/

echo "5. Verify file in pod:"
kubectl exec file-demo -- cat /data/config/new-config.conf

echo "6. Create a backup of all data:"
kubectl exec file-demo -- tar -czf /tmp/backup.tar.gz -C /data .
kubectl cp file-demo:/tmp/backup.tar.gz ./pod-data-backup.tar.gz
echo "Backup created: pod-data-backup.tar.gz"

# Clean up
echo "Cleaning up..."
kubectl delete pod file-demo
rm -f app.log.backup new-config.conf pod-data-backup.tar.gz

echo "Demo complete!"
```

### üéØ Mini-Project 3: Pod Security Scanner

Create a security scanning tool using pods:

```yaml
# security-scanner-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-scanner
  labels:
    app: security
    type: scanner
spec:
  serviceAccountName: default
  containers:
  - name: scanner
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "=== Pod Security Scanner Starting ==="
      
      # Function to check security configurations
      check_security() {
        echo "Checking security configurations..."
        
        # Check if running as root
        if [ "$(id -u)" -eq 0 ]; then
          echo "‚ö†Ô∏è  WARNING: Running as root user"
        else
          echo "‚úÖ GOOD: Running as non-root user ($(id -u))"
        fi
        
        # Check filesystem permissions
        if [ -w "/" ]; then
          echo "‚ö†Ô∏è  WARNING: Root filesystem is writable"
        else
          echo "‚úÖ GOOD: Root filesystem is read-only"
        fi
        
        # Check for sensitive mounts
        if mount | grep -q "/var/run/secrets"; then
          echo "‚ÑπÔ∏è  INFO: Service account token mounted"
        fi
        
        # Check available capabilities
        echo "Current capabilities:"
        if [ -f "/proc/self/status" ]; then
          grep Cap /proc/self/status
        fi
        
        # Check network access
        echo "Testing network access..."
        if ping -c 1 8.8.8.8 >/dev/null 2>&1; then
          echo "‚ÑπÔ∏è  INFO: External network access available"
        else
          echo "‚ÑπÔ∏è  INFO: No external network access"
        fi
        
        # Generate security report
        cat > /tmp/security-report.txt <<EOF
      === Security Scan Report ===
      Timestamp: $(date)
      User ID: $(id -u)
      Group ID: $(id -g)
      Working Directory: $(pwd)
      
      Filesystem Check:
      - Root writable: $([ -w "/" ] && echo "YES" || echo "NO")
      - /tmp writable: $([ -w "/tmp" ] && echo "YES" || echo "NO")
      
      Network Check:
      - External access: $(ping -c 1 8.8.8.8 >/dev/null 2>&1 && echo "YES" || echo "NO")
      
      Process Information:
      $(ps aux)
      EOF
        
        echo "Report generated at /tmp/security-report.txt"
      }
      
      # Run security check
      check_security
      
      # Keep running for inspection
      echo "Scanner complete. Container will stay running for inspection."
      sleep 3600
      
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 1000
      runAsGroup: 3000
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir: {}
    
  restartPolicy: Never
```

**Usage:**
```bash
# Deploy the security scanner
kubectl apply -f security-scanner-pod.yaml

# Monitor the scan
kubectl logs -f security-scanner

# Get the security report
kubectl cp security-scanner:/tmp/security-report.txt ./security-report.txt
cat security-report.txt

# Create a comparison with an insecure pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: insecure-pod
spec:
  containers:
  - name: insecure
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      runAsUser: 0  # Running as root
      privileged: true
EOF

# Compare security postures
echo "=== Security Comparison ==="
echo "Secure pod user:"
kubectl exec security-scanner -- id

echo "Insecure pod user:"
kubectl exec insecure-pod -- id

echo "Secure pod capabilities:"
kubectl exec security-scanner -- grep Cap /proc/self/status

echo "Insecure pod capabilities:"
kubectl exec insecure-pod -- grep Cap /proc/self/status

# Clean up
kubectl delete pod security-scanner insecure-pod
rm -f security-report.txt
```

---

## Declarative Pod Configuration and Management

### üèóÔ∏è Expert Examples

#### Example 6: Production-Ready Pod Template

```yaml
# production-pod-template.yaml
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production
  labels:
    app: web-server
    version: "2.1.0"
    environment: production
    team: platform
  annotations:
    description: "Production web server with full monitoring and security"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/web-server"
    version: "2.1.0"
    build-date: "2024-01-15T10:30:00Z"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Node selection
  nodeSelector:
    node-type: "application"
    zone: "us-west-2a"
    
  # Tolerations for dedicated nodes
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "application"
    effect: "NoSchedule"
    
  # Pod placement preferences
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: "node-type"
            operator: In
            values: ["application"]
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: web-server
          topologyKey: kubernetes.io/hostname
          
  # DNS configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  containers:
  - name: web-server
    image: nginx:1.21-alpine
    imagePullPolicy: IfNotPresent
    
    ports:
    - name: http
      containerPort: 80
      protocol: TCP
    - name: metrics
      containerPort: 9113
      protocol: TCP
      
    # Environment variables
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "info"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security context
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE
        
    # Health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 80
        scheme: HTTP
        httpHeaders:
        - name: Custom-Header
          value: liveness-check
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
        scheme: HTTP
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle hooks
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container started at $(date)" >> /tmp/startup.log
            # Custom initialization logic here
            
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container stopping at $(date)" >> /tmp/shutdown.log
            # Graceful shutdown logic here
            nginx -s quit
            sleep 15
            
    # Volume mounts
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  # Sidecar container for log processing
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  # Monitoring sidecar
  - name: nginx-exporter
    image: nginx/nginx-prometheus-exporter:0.10.0
    args:
    - -nginx.scrape-uri=http://localhost:80/nginx_status
    ports:
    - name: metrics
      containerPort: 9113
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
  # Shared volumes
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
      defaultMode: 0644
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
      defaultMode: 0644
  - name: html-content
    configMap:
      name: html-content
      defaultMode: 0644
  - name: tmp-dir
    emptyDir:
      sizeLimit: 256Mi
  - name: var-cache-nginx
    emptyDir:
      sizeLimit: 512Mi
  - name: var-run
    emptyDir:
      sizeLimit: 64Mi
  - name: logs
    emptyDir:
      sizeLimit: 1Gi
```

### üõ†Ô∏è Demo: Complex Pod Deployment Pipeline

```bash
#!/bin/bash
# production-pod-deployment.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

# Configuration
NAMESPACE="production-demo"
APP_NAME="web-server"
CONFIG_DIR="./config"

# Create namespace if it doesn't exist
create_namespace() {
    log "Creating namespace: $NAMESPACE"
    kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    success "Namespace $NAMESPACE ready"
}

# Create ConfigMaps for the application
create_configmaps() {
    log "Creating ConfigMaps..."
    
    mkdir -p $CONFIG_DIR
    
    # Nginx configuration
    cat > $CONFIG_DIR/nginx.conf <<EOF
server {
    listen 80;
    server_name localhost;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
    
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    location /ready {
        access_log off;
        return 200 "ready\n";
        add_header Content-Type text/plain;
    }
    
    location /nginx_status {
        stub_status on;
        access_log off;
        allow all;
    }
}
EOF

    # HTML content
    cat > $CONFIG_DIR/index.html <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Production Pod Demo</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .container { max-width: 800px; margin: 0 auto; }
        .status { padding: 20px; margin: 20px 0; border-radius: 5px; }
        .healthy { background-color: #d4edda; color: #155724; }
        .info { background-color: #d1ecf1; color: #0c5460; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Production Pod Demo</h1>
        <div class="status healthy">
            <h3>‚úÖ Application Status: Healthy</h3>
            <p>Pod is running successfully with full production configuration</p>
        </div>
        
        <div class="status info">
            <h3>üìä Features Enabled:</h3>
            <ul>
                <li>Multi-container architecture</li>
                <li>Comprehensive health checks</li>
                <li>Security hardening</li>
                <li>Log processing sidecar</li>
                <li>Prometheus metrics export</li>
                <li>Resource management</li>
            </ul>
        </div>
        
        <div class="status info">
            <h3>üîó Endpoints:</h3>
            <ul>
                <li><a href="/health">Health Check</a></li>
                <li><a href="/ready">Readiness Check</a></li>
                <li><a href="/nginx_status">Nginx Status</a></li>
            </ul>
        </div>
    </div>
</body>
</html>
EOF

    # Fluent Bit configuration
    cat > $CONFIG_DIR/fluent-bit.conf <<EOF
[SERVICE]
    Flush         1
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf

[INPUT]
    Name              tail
    Path              /var/log/nginx/access.log
    Parser            nginx
    Tag               nginx.access
    Refresh_Interval  5

[INPUT]
    Name              tail
    Path              /var/log/nginx/error.log
    Tag               nginx.error
    Refresh_Interval  5

[OUTPUT]
    Name  stdout
    Match nginx.*
EOF

    cat > $CONFIG_DIR/parsers.conf <<EOF
[PARSER]
    Name   nginx
    Format regex
    Regex  ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
    Time_Key time
    Time_Format %d/%b/%Y:%H:%M:%S %z
EOF

    # Create ConfigMaps
    kubectl create configmap nginx-config --from-file=$CONFIG_DIR/nginx.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap html-content --from-file=$CONFIG_DIR/index.html -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap fluent-bit-config --from-file=$CONFIG_DIR/fluent-bit.conf --from-file=$CONFIG_DIR/parsers.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    
    success "ConfigMaps created successfully"
}

# Deploy the production pod
deploy_pod() {
    log "Deploying production pod..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: $APP_NAME
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
    version: "1.0.0"
    environment: production
  annotations:
    deployment.kubernetes.io/revision: "1"
    deployed-by: "production-deployment-script"
    deployment-time: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    
  containers:
  - name: nginx
    image: nginx:1.21-alpine
    ports:
    - name: http
      containerPort: 80
    - name: metrics
      containerPort: 9113
      
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
  - name: html-content
    configMap:
      name: html-content
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
  - name: tmp-dir
    emptyDir: {}
  - name: var-cache-nginx
    emptyDir: {}
  - name: var-run
    emptyDir: {}
  - name: logs
    emptyDir: {}
EOF

    success "Pod deployed successfully"
}

# Wait for pod to be ready and perform health checks
verify_deployment() {
    log "Waiting for pod to be ready..."
    
    if kubectl wait --for=condition=Ready pod/$APP_NAME -n $NAMESPACE --timeout=120s; then
        success "Pod is ready!"
    else
        error "Pod failed to become ready within timeout"
    fi
    
    # Perform comprehensive health checks
    log "Performing health checks..."
    
    # Check pod status
    kubectl get pod $APP_NAME -n $NAMESPACE -o wide
    
    # Test health endpoints
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    if curl -s http://localhost:8080/health | grep -q "healthy"; then
        success "Health check passed"
    else
        warning "Health check failed"
    fi
    
    if curl -s http://localhost:8080/ready | grep -q "ready"; then
        success "Readiness check passed"
    else
        warning "Readiness check failed"
    fi
    
    # Test the main application
    if curl -s http://localhost:8080 | grep -q "Production Pod Demo"; then
        success "Application is serving content correctly"
    else
        warning "Application content check failed"
    fi
    
    kill $PF_PID 2>/dev/null
    
    # Check resource usage
    log "Checking resource usage..."
    if kubectl top pod $APP_NAME -n $NAMESPACE &>/dev/null; then
        kubectl top pod $APP_NAME -n $NAMESPACE
    else
        warning "Resource metrics not available"
    fi
    
    # Check logs from all containers
    log "Checking container logs..."
    echo "=== Nginx logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c nginx --tail=5
    echo "=== Log processor logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=5
}

# Generate load and monitor performance
performance_test() {
    log "Running performance test..."
    
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    # Generate some load
    for i in {1..50}; do
        curl -s http://localhost:8080 > /dev/null &
    done
    
    wait
    kill $PF_PID 2>/dev/null
    
    # Check logs after load test
    log "Logs after load test:"
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=10
    
    success "Performance test completed"
}

# Cleanup function
cleanup() {
    log "Cleaning up resources..."
    kubectl delete pod $APP_NAME -n $NAMESPACE --ignore-not-found
    kubectl delete configmap nginx-config html-content fluent-bit-config -n $NAMESPACE --ignore-not-found
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -rf $CONFIG_DIR
    success "Cleanup completed"
}

# Main execution
main() {
    echo "=== Production Pod Deployment Demo ==="
    
    case "${1:-deploy}" in
        "deploy")
            create_namespace
            create_configmaps
            deploy_pod
            verify_deployment
            performance_test
            
            echo ""
            success "Deployment completed successfully!"
            echo "Access the application:"
            echo "  kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80"
            echo "  Then open: http://localhost:8080"
            echo ""
            echo "Monitor the pod:"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c nginx"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c log-processor"
            echo ""
            echo "Run 'bash $0 cleanup' to remove all resources"
            ;;
        "cleanup")
            cleanup
            ;;
        "test")
            verify_deployment
            performance_test
            ;;
        *)
            echo "Usage: $0 [deploy|cleanup|test]"
            echo "  deploy  - Deploy the production pod (default)"
            echo "  cleanup - Remove all created resources"
            echo "  test    - Run verification and performance tests"
            ;;
    esac
}

main "$@"
```

### üéØ Mini-Project 4: Pod Chaos Engineering

Test pod resilience with chaos engineering principles:

```yaml
# chaos-test-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: chaos-resilient-app
  labels:
    app: chaos-test
    resilience: enabled
spec:
  containers:
  - name: main-app
    image: nginx:1.21-alpine
    ports:
    - containerPort: 80
    
    # Aggressive resource limits to test resilience
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    # Tight health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 2
      
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
      timeoutSeconds: 1
      failureThreshold: 2
      
    # Graceful shutdown
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 10"]
          
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  # Chaos monkey sidecar
  - name: chaos-monkey
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Chaos monkey starting..."
      
      # Function to create CPU load
      cpu_chaos() {
        echo "Creating CPU chaos..."
        for i in {1..4}; do
          yes > /dev/null &
        done
        sleep 30
        killall yes
      }
      
      # Function to create memory pressure
      memory_chaos() {
        echo "Creating memory chaos..."
        cat <(yes | tr \\n x | head -c 50000000) <(yes | tr \\n x | head -c 50000000) > /tmp/memory_eater &
        sleep 20
        rm -f /tmp/memory_eater
        killall cat
      }
      
      # Function to simulate network issues
      network_chaos() {
        echo "Creating network chaos..."
        # Simulate slow responses
        sleep $((RANDOM % 10 + 5))
      }
      
      # Function to create disk I/O pressure
      disk_chaos() {
        echo "Creating disk I/O chaos..."
        dd if=/dev/zero of=/tmp/disk_eater bs=1M count=10 2>/dev/null
        rm -f /tmp/disk_eater
      }
      
      # Main chaos loop
      while true; do
        chaos_type=$((RANDOM % 4))
        case $chaos_type in
          0) cpu_chaos ;;
          1) memory_chaos ;;
          2) network_chaos ;;
          3) disk_chaos ;;
        esac
        
        # Wait between chaos events
        sleep $((RANDOM % 60 + 30))
      done
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir:
      sizeLimit: 100Mi
      
  restartPolicy: Always
```

**Chaos Testing Script:**
```bash
#!/bin/bash
# chaos-engineering-test.sh

echo "=== Chaos Engineering Test ==="

# Deploy the chaos test pod
kubectl apply -f chaos-test-pod.yaml

# Wait for it to be ready
echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/chaos-resilient-app --timeout=60s

# Monitor pod resilience
echo "Starting resilience monitoring (Ctrl+C to stop)..."

monitor_resilience() {
    while true; do
        timestamp=$(date '+%H:%M:%S')
        
        # Check pod status
        status=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.phase}')
        ready=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
        restarts=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.containerStatuses[0].restartCount}')
        
        # Test application responsiveness
        kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
        PF_PID=$!
        sleep 2
        
        response_time=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8080 2>/dev/null || echo "FAIL")
        kill $PF_PID 2>/dev/null
        
        # Get resource usage if available
        resources=""
        if kubectl top pod chaos-resilient-app &>/dev/null; then
            resources=$(kubectl top pod chaos-resilient-app --no-headers 2>/dev/null | awk '{print $2" "$3}')
        fi
        
        printf "[$timestamp] Status: $status | Ready: $ready | Restarts: $restarts | Response: ${response_time}s | Resources: $resources\n"
        
        sleep 5
    done
}

# Start monitoring in background
monitor_resilience &
MONITOR_PID=$!

# Generate additional load to test resilience
echo "Generating load to test resilience..."
for i in {1..100}; do
    kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
    PF_PID=$!
    sleep 1
    
    curl -s http://localhost:8080 > /dev/null &
    
    kill $PF_PID 2>/dev/null
    sleep 2
done

# Stop monitoring
kill $MONITOR_PID 2>/dev/null

echo "Chaos test completed. Check pod logs:"
echo "kubectl logs chaos-resilient-app -c main-app --tail=20"
echo "kubectl logs chaos-resilient-app -c chaos-monkey --tail=20"

# Cleanup
read -p "Delete the chaos test pod? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    kubectl delete -f chaos-test-pod.yaml
fi
```

---

## Advanced Pod Management Techniques

### üî¨ Expert-Level Examples

#### Example 7: Custom Pod Controller

Create a custom controller for specialized pod management:

```python
#!/usr/bin/env python3
# custom-pod-controller.py

import time
import yaml
import subprocess
import json
from datetime import datetime, timedelta

class PodController:
    def __init__(self):
        self.managed_pods = {}
        self.check_interval = 30  # seconds
        
    def log(self, message):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"[{timestamp}] {message}")
        
    def run_kubectl(self, command):
        """Execute kubectl command and return JSON output"""
        try:
            result = subprocess.run(
                f"kubectl {command} -o json",
                shell=True,
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                self.log(f"kubectl error: {result.stderr}")
                return None
        except Exception as e:
            self.log(f"Command execution error: {e}")
            return None
            
    def get_pods_by_label(self, label_selector):
        """Get pods matching label selector"""
        command = f"get pods -l {label_selector}"
        result = self.run_kubectl(command)
        return result.get('items', []) if result else []
        
    def create_pod(self, name, spec):
        """Create a pod with given specification"""
        pod_manifest = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'name': name,
                'labels': {
                    'managed-by': 'custom-controller',
                    'created': datetime.now().strftime('%Y%m%d-%H%M%S')
                }
            },
            'spec': spec
        }
        
        # Write manifest to temporary file
        with open(f'/tmp/{name}.yaml', 'w') as f:
            yaml.dump(pod_manifest, f)
            
        # Apply the manifest
        result = subprocess.run(
            f"kubectl apply -f /tmp/{name}.yaml",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Created pod: {name}")
            return True
        else:
            self.log(f"Failed to create pod {name}: {result.stderr}")
            return False
            
    def delete_pod(self, name):
        """Delete a pod"""
        result = subprocess.run(
            f"kubectl delete pod {name} --grace-period=30",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Deleted pod: {name}")
            return True
        else:
            self.log(f"Failed to delete pod {name}: {result.stderr}")
            return False
            
    def check_pod_health(self, pod):
        """Check if a pod is healthy based on custom criteria"""
        name = pod['metadata']['name']
        status = pod['status']
        
        # Check if pod is running
        if status.get('phase') != 'Running':
            return False, f"Pod {name} is not running (phase: {status.get('phase')})"
            
        # Check container statuses
        container_statuses = status.get('containerStatuses', [])
        for container in container_statuses:
            if not container.get('ready'):
                return False, f"Container {container['name']} not ready in pod {name}"
                
            # Check restart count
            restart_count = container.get('restartCount', 0)
            if restart_count > 5:
                return False, f"Container {container['name']} restarted {restart_count} times"
                
        # Check resource usage (if metrics available)
        metrics = self.get_pod_metrics(name)
        if metrics:
            cpu_usage = self.parse_cpu_usage(metrics.get('cpu', '0m'))
            memory_usage = self.parse_memory_usage(metrics.get('memory', '0Mi'))
            
            if cpu_usage > 800:  # 800 millicores
                return False, f"Pod {name} CPU usage too high: {cpu_usage}m"
                
            if memory_usage > 512:  # 512 Mi
                return False, f"Pod {name} memory usage too high: {memory_usage}Mi"
                
        return True, f"Pod {name} is healthy"
        
    def get_pod_metrics(self, pod_name):
        """Get pod resource metrics if available"""
        result = subprocess.run(
            f"kubectl top pod {pod_name} --no-headers",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            parts = result.stdout.strip().split()
            if len(parts) >= 3:
                return {
                    'cpu': parts[1],
                    'memory': parts[2]
                }
        return None
        
    def parse_cpu_usage(self, cpu_str):
        """Parse CPU usage from string like '100m' to millicores"""
        if cpu_str.endswith('m'):
            return int(cpu_str[:-1])
        return int(cpu_str) * 1000
        
    def parse_memory_usage(self, memory_str):
        """Parse memory usage from string like '128Mi' to Mi"""
        if memory_str.endswith('Mi'):
            return int(memory_str[:-2])
        elif memory_str.endswith('Gi'):
            return int(memory_str[:-2]) * 1024
        return int(memory_str) // (1024 * 1024)
        
    def auto_heal_pod(self, pod_name, reason):
        """Attempt to heal an unhealthy pod"""
        self.log(f"Attempting to heal pod {pod_name}: {reason}")
        
        # Strategy 1: Restart the pod
        if "restart" in reason.lower():
            return self.delete_pod(pod_name)  # Pod will be recreated if managed by controller
            
        # Strategy 2: Scale resources if high usage
        if "usage too high" in reason.lower():
            self.log(f"High resource usage detected for {pod_name}, marking for recreation")
            return self.delete_pod(pod_name)
            
        # Strategy 3: Generic restart
        return self.delete_pod(pod_name)
        
    def manage_workload(self, workload_config):
        """Manage a workload with desired replica count"""
        app_name = workload_config['name']
        desired_replicas = workload_config['replicas']
        pod_spec = workload_config['pod_spec']
        
        # Get current pods for this workload
        current_pods = self.get_pods_by_label(f"app={app_name},managed-by=custom-controller")
        current_count = len(current_pods)
        
        self.log(f"Managing workload {app_name}: current={current_count}, desired={desired_replicas}")
        
        # Scale up if needed
        if current_count < desired_replicas:
            for i in range(current_count, desired_replicas):
                pod_name = f"{app_name}-{i}"
                pod_spec_copy = pod_spec.copy()
                pod_spec_copy.setdefault('containers', [{}])[0]['env'] = [
                    {'name': 'REPLICA_ID', 'value': str(i)},
                    {'name': 'APP_NAME', 'value': app_name}
                ]
                self.create_pod(pod_name, pod_spec_copy)
                
        # Scale down if needed
        elif current_count > desired_replicas:
            pods_to_delete = current_pods[desired_replicas:]
            for pod in pods_to_delete:
                self.delete_pod(pod['metadata']['name'])
                
        # Health check existing pods
        for pod in current_pods[:desired_replicas]:
            healthy, reason = self.check_pod_health(pod)
            if not healthy:
                self.log(f"Pod unhealthy: {reason}")
                self.auto_heal_pod(pod['metadata']['name'], reason)
                
    def run_control_loop(self):
        """Main control loop"""
        self.log("Starting custom pod controller...")
        
        # Sample workload configuration
        workloads = [
            {
                'name': 'web-app',
                'replicas': 2,
                'pod_spec': {
                    'containers': [{
                        'name': 'nginx',
                        'image': 'nginx:1.21-alpine',
                        'ports': [{'containerPort': 80}],
                        'resources': {
                            'requests': {'memory': '64Mi', 'cpu': '50m'},
                            'limits': {'memory': '128Mi', 'cpu': '100m'}
                        },
                        'livenessProbe': {
                            'httpGet': {'path': '/', 'port': 80},
                            'initialDelaySeconds': 10,
                            'periodSeconds': 30
                        }
                    }],
                    'restartPolicy': 'Always'
                }
            }
        ]
        
        try:
            while True:
                self.log("Running control loop...")
                
                for workload in workloads:
                    try:
                        self.manage_workload(workload)
                    except Exception as e:
                        self.log(f"Error managing workload {workload['name']}: {e}")
                        
                self.log(f"Sleeping for {self.check_interval} seconds...")
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            self.log("Shutting down controller...")
            
        except Exception as e:
            self.log(f"Controller error: {e}")
            
    def cleanup(self):
        """Clean up managed resources"""
        self.log("Cleaning up managed pods...")
        pods = self.get_pods_by_label("managed-by=custom-controller")
        for pod in pods:
            self.delete_pod(pod['metadata']['name'])

if __name__ == "__main__":
    import sys
    
    controller = PodController()
    
    if len(sys.argv) > 1 and sys.argv[1] == "cleanup":
        controller.cleanup()
    else:
        controller.run_control_loop()
```

**Usage:**
```bash
# Make the script executable
chmod +x custom-pod-controller.py

# Install dependencies
pip3 install pyyaml

# Run the controller
python3 custom-pod-controller.py

# In another terminal, watch the managed pods
watch kubectl get pods -l managed-by=custom-controller

# Simulate pod failures
kubectl delete pod web-app-0  # Controller will recreate it

# Clean up when done
python3 custom-pod-controller.py cleanup
```

### üéØ Mini-Project 5: Pod Performance Optimization Lab

Create a comprehensive performance optimization laboratory:

```yaml
# performance-lab-setup.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: performance-lab
---
# Baseline pod - unoptimized
apiVersion: v1
kind: Pod
metadata:
  name: baseline-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: baseline
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "1000m"
      limits:
        memory: "2Gi"
        cpu: "2000m"
---
# Optimized pod - resource-efficient
apiVersion: v1
kind: Pod
metadata:
  name: optimized-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: optimized
spec:
  containers:
  - name: app
    image: nginx:1.21-alpine  # Smaller image
    resources:
      requests:
        memory: "64Mi"        # Right-sized requests
        cpu: "100m"
      limits:
        memory: "128Mi"       # Conservative limits
        cpu: "200m"
    # Optimized health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5   # Faster startup
      periodSeconds: 30        # Less frequent checks
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
    # Security optimizations
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
    # Volume optimizations
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp-dir
    emptyDir:
      medium: Memory  # Use memory for temp files
      sizeLimit: 64Mi
  - name: var-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: var-run
    emptyDir:
      sizeLimit: 32Mi
---
# High-performance pod with advanced optimizations
apiVersion: v1
kind: Pod
metadata:
  name: high-performance-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: high-performance
spec:
  # Pod-level optimizations
  priorityClassName: high-priority
  nodeSelector:
    node-type: performance
  tolerations:
  - key: performance-node
    operator: Equal
    value: "true"
    effect: NoSchedule
  # Network optimizations
  dnsPolicy: ClusterFirstWithHostNet
  dnsConfig:
    options:
    - name: ndots
      value: "1"
    - name: edns0
  containers:
  - name: app
    image: nginx:1.21-alpine
    # Optimized resource allocation
    resources:
      requests:
        memory: "128Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "256Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
    # Performance-tuned environment
    env:
    - name: NGINX_WORKER_PROCESSES
      value: "auto"
    - name: NGINX_WORKER_CONNECTIONS
      value: "1024"
    # Aggressive health checks for faster recovery
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 15
      timeoutSeconds: 2
      failureThreshold: 2
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 3
      timeoutSeconds: 1
      failureThreshold: 1
    # Startup optimization
    startupProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 1
      timeoutSeconds: 1
      failureThreshold: 10
    # Performance-optimized volumes
    volumeMounts:
    - name: high-speed-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
  volumes:
  - name: high-speed-tmp
    emptyDir:
      medium: Memory
      sizeLimit: 128Mi
  - name: nginx-cache
    emptyDir:
      medium: Memory
      sizeLimit: 256Mi
  - name: nginx-run
    emptyDir:
      medium: Memory
      sizeLimit: 64Mi
```

**Performance Benchmarking Script:**
```bash
#!/bin/bash
# performance-benchmark.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

NAMESPACE="performance-lab"

# Deploy the performance lab
setup_lab() {
    log "Setting up performance lab..."
    kubectl apply -f performance-lab-setup.yaml
    
    log "Waiting for pods to be ready..."
    kubectl wait --for=condition=Ready pod/baseline-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/optimized-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/high-performance-app -n $NAMESPACE --timeout=120s
    
    success "Performance lab setup complete"
}

# Measure startup time
measure_startup_time() {
    local pod_name=$1
    log "Measuring startup time for $pod_name..."
    
    # Delete and recreate pod to measure startup
    kubectl delete pod $pod_name -n $NAMESPACE
    local start_time=$(date +%s.%N)
    
    # Recreate the pod (extract from original manifest)
    kubectl get pod $pod_name -n $NAMESPACE -o yaml --export 2>/dev/null | kubectl apply -f - 2>/dev/null || {
        warning "Couldn't recreate pod automatically, recreating from manifest"
        kubectl apply -f performance-lab-setup.yaml
    }
    
    # Wait for ready and measure time
    kubectl wait --for=condition=Ready pod/$pod_name -n $NAMESPACE --timeout=120s
    local end_time=$(date +%s.%N)
    
    local startup_time=$(echo "$end_time - $start_time" | bc -l)
    echo "$startup_time"
}

# Run load test on a pod
load_test_pod() {
    local pod_name=$1
    local duration=${2:-30}
    local concurrency=${3:-10}
    
    log "Running load test on $pod_name (${duration}s, ${concurrency} concurrent)"
    
    # Start port forwarding
    kubectl port-forward pod/$pod_name -n $NAMESPACE 8080:80 >/dev/null 2>&1 &
    local pf_pid=$!
    sleep 3
    
    # Use Apache Bench for load testing
    local results_file="/tmp/ab_results_${pod_name}.txt"
    
    if command -v ab >/dev/null; then
        ab -n $((duration * concurrency)) -c $concurrency -g /tmp/gnuplot_${pod_name}.dat \
           http://localhost:8080/ > $results_file 2>&1
        
        # Extract key metrics
        local rps=$(grep "Requests per second" $results_file | awk '{print $4}')
        local response_time=$(grep "Time per request.*mean" $results_file | head -1 | awk '{print $4}')
        local failed_requests=$(grep "Failed requests" $results_file | awk '{print $3}')
        
        echo "RPS:$rps,ResponseTime:$response_time,Failed:$failed_requests"
    else
        # Fallback to curl-based test
        local start_time=$(date +%s)
        local requests=0
        local total_time=0
        
        for i in $(seq 1 $((duration * concurrency))); do
            local req_start=$(date +%s.%N)
            if curl -s http://localhost:8080 >/dev/null 2>&1; then
                ((requests++))
            fi
            local req_end=$(date +%s.%N)
            local req_time=$(echo "$req_end - $req_start" | bc -l)
            total_time=$(echo "$total_time + $req_time" | bc -l)
            
            # Basic rate limiting
            sleep 0.1
        done
        
        local avg_response_time=$(echo "scale=3; $total_time / $requests" | bc -l)
        local rps=$(echo "scale=2; $requests / $duration" | bc -l)
        
        echo "RPS:$rps,ResponseTime:$avg_response_time,Failed:0"
    fi
    
    kill $pf_pid 2>/dev/null
}

# Get resource usage metrics
get_resource_usage() {
    local pod_name=$1
    log "Getting resource usage for $pod_name..."
    
    if kubectl top pod $pod_name -n $NAMESPACE >/dev/null 2>&1; then
        kubectl top pod $pod_name -n $NAMESPACE --no-headers | awk '{print "CPU:"$2",Memory:"$3}'
    else
        echo "CPU:N/A,Memory:N/A"
    fi
}

# Comprehensive benchmark
run_comprehensive_benchmark() {
    log "Running comprehensive performance benchmark..."
    
    declare -A results
    local pods=("baseline-app" "optimized-app" "high-performance-app")
    
    echo "=== Performance Benchmark Results ===" > benchmark_results.txt
    echo "Timestamp: $(date)" >> benchmark_results.txt
    echo "" >> benchmark_results.txt
    
    for pod in "${pods[@]}"; do
        log "Benchmarking $pod..."
        
        # Startup time measurement
        log "Measuring startup time for $pod..."
        # Skip startup measurement in this demo to avoid pod recreation issues
        startup_time="N/A"
        
        # Resource usage
        resource_usage=$(get_resource_usage $pod)
        
        # Load test
        load_results=$(load_test_pod $pod 30 10)
        
        # Pod status information
        pod_info=$(kubectl get pod $pod -n $NAMESPACE -o custom-columns=STATUS:.status.phase,READY:.status.conditions[?\(@.type==\"Ready\"\)].status,RESTARTS:.status.containerStatuses[0].restartCount --no-headers)
        
        # Store results
        results[$pod]="Startup:$startup_time,Resources:$resource_usage,Load:$load_results,Status:$pod_info"
        
        # Write to file
        cat >> benchmark_results.txt <<EOF

=== $pod ===
Startup Time: $startup_time seconds
Resource Usage: $resource_usage
Load Test Results: $load_results
Pod Status: $pod_info

EOF
    done
    
    # Generate comparison summary
    cat >> benchmark_results.txt <<EOF

=== Performance Summary ===
This benchmark compares three pod configurations:

1. Baseline App: Standard configuration with generous resource allocation
2. Optimized App: Resource-efficient with security hardening
3. High-Performance App: Maximum performance optimizations

Key Findings:
- Resource efficiency varies significantly between configurations
- Startup time impacts overall application availability
- Load handling capacity differs based on resource allocation
- Security optimizations may have performance trade-offs

Recommendations:
- Use optimized configuration for production workloads
- Consider high-performance setup for critical applications
- Monitor resource usage to fine-tune allocations
- Balance security and performance based on requirements

EOF
    
    success "Benchmark completed. Results saved to benchmark_results.txt"
    cat benchmark_results.txt
}

# Resource monitoring script
monitor_resources() {
    local duration=${1:-300}  # 5 minutes default
    log "Starting resource monitoring for ${duration} seconds..."
    
    local monitor_file="resource_monitor_$(date +%Y%m%d_%H%M%S).log"
    
    {
        echo "Timestamp,Pod,CPU,Memory,Status"
        local end_time=$(($(date +%s) + duration))
        
        while [ $(date +%s) -lt $end_time ]; do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            
            for pod in baseline-app optimized-app high-performance-app; do
                if kubectl get pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                    local status=$(kubectl get pod $pod -n $NAMESPACE -o jsonpath='{.status.phase}')
                    local usage="N/A,N/A"
                    
                    if kubectl top pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                        usage=$(kubectl top pod $pod -n $NAMESPACE --no-headers | awk '{print $2","$3}')
                    fi
                    
                    echo "$timestamp,$pod,$usage,$status"
                fi
            done
            
            sleep 10
        done
    } > $monitor_file
    
    success "Resource monitoring completed. Data saved to $monitor_file"
    
    # Generate simple analysis
    log "Generating resource usage analysis..."
    
    {
        echo "=== Resource Usage Analysis ==="
        echo ""
        
        for pod in baseline-app optimized-app high-performance-app; do
            echo "=== $pod ==="
            grep "$pod" $monitor_file | tail -10 | while IFS=',' read timestamp pod_name cpu memory status; do
                echo "[$timestamp] CPU: $cpu, Memory: $memory, Status: $status"
            done
            echo ""
        done
    } > resource_analysis.txt
    
    success "Analysis saved to resource_analysis.txt"
}

# Cleanup function
cleanup_lab() {
    log "Cleaning up performance lab..."
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -f benchmark_results.txt resource_*.log resource_analysis.txt
    rm -f /tmp/ab_results_*.txt /tmp/gnuplot_*.dat
    success "Cleanup completed"
}

# Main execution
main() {
    case "${1:-benchmark}" in
        "setup")
            setup_lab
            ;;
        "benchmark")
            setup_lab
            run_comprehensive_benchmark
            ;;
        "monitor")
            monitor_resources "${2:-300}"
            ;;
        "cleanup")
            cleanup_lab
            ;;
        "all")
            setup_lab
            run_comprehensive_benchmark
            monitor_resources 300
            echo ""
            success "Complete performance analysis finished!"
            echo "Files created:"
            echo "  - benchmark_results.txt"
            echo "  - resource_monitor_*.log"
            echo "  - resource_analysis.txt"
            ;;
        *)
            echo "Performance Lab - Pod Optimization Benchmark"
            echo ""
            echo "Usage: $0 <command> [options]"
            echo ""
            echo "Commands:"
            echo "  setup      - Set up the performance lab environment"
            echo "  benchmark  - Run comprehensive performance benchmark"
            echo "  monitor    - Monitor resource usage for specified duration"
            echo "  cleanup    - Remove all lab resources"
            echo "  all        - Run complete analysis (setup + benchmark + monitor)"
            echo ""
            echo "Examples:"
            echo "  $0 setup"
            echo "  $0 benchmark"
            echo "  $0 monitor 600  # Monitor for 10 minutes"
            echo "  $0 all          # Complete analysis"
            ;;
    esac
}

main "$@"
```

---

## Pod Troubleshooting Methodologies

### üîß Advanced Troubleshooting Toolkit

#### Example 8: Automated Diagnostic System

```bash
#!/bin/bash
# advanced-pod-diagnostics.sh

set -euo pipefail

# Enhanced diagnostic toolkit with automated problem detection
class PodDiagnostics {
    
# Configuration
NAMESPACE=${NAMESPACE:-default}
OUTPUT_DIR="./diagnostics-$(date +%Y%m%d-%H%M%S)"
VERBOSE=${VERBOSE:-false}

# Colors and formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'
BOLD='\033[1m'

# Logging functions with levels
log_debug() { [[ $VERBOSE == "true" ]] && echo -e "${CYAN}[DEBUG]${NC} $1"; }
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }

# Initialize diagnostics
init_diagnostics() {
    log_info "Initializing pod diagnostics system..."
    mkdir -p "$OUTPUT_DIR"/{logs,reports,metrics,manifests}
    
    # Create diagnostic report header
    cat > "$OUTPUT_DIR/diagnostic_report.md" <<EOF
# Pod Diagnostics Report

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)  
**Namespace:** $NAMESPACE  
**Output Directory:** $OUTPUT_DIR

---

EOF
    
    log_success "Diagnostics initialized in $OUTPUT_DIR"
}

# Comprehensive pod information gathering
gather_pod_info() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Gathering comprehensive information for pod: $pod_name"
    
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    mkdir -p "$pod_dir"
    
    # Basic pod information
    kubectl get pod "$pod_name" -n "$namespace" -o wide > "$pod_dir/basic_info.txt" 2>&1
    kubectl get pod "$pod_name" -n "$namespace" -o yaml > "$pod_dir/manifest.yaml" 2>&1
    
    # Detailed description
    kubectl describe pod "$pod_name" -n "$namespace" > "$pod_dir/description.txt" 2>&1
    
    # Events related to the pod
    kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
        --sort-by='.lastTimestamp' > "$pod_dir/events.txt" 2>&1
    
    # Container logs
    local containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}' 2>/dev/null)
    for container in $containers; do
        log_debug "Collecting logs for container: $container"
        kubectl logs "$pod_name" -n "$namespace" -c "$container" > "$pod_dir/logs_${container}.txt" 2>&1
        
        # Previous logs if container restarted
        kubectl logs "$pod_name" -n "$namespace" -c "$container" --previous > "$pod_dir/logs_${container}_previous.txt" 2>&1 || true
    done
    
    # Resource usage
    kubectl top pod "$pod_name" -n "$namespace" > "$pod_dir/resource_usage.txt" 2>&1 || echo "Metrics not available" > "$pod_dir/resource_usage.txt"
    
    log_success "Pod information gathered for $pod_name"
}

# Automated problem detection
detect_common_issues() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Running automated issue detection for $pod_name..."
    
    local issues_file="$pod_dir/detected_issues.md"
    echo "# Automated Issue Detection Report" > "$issues_file"
    echo "**Pod:** $pod_name" >> "$issues_file"
    echo "**Analysis Time:** $(date)" >> "$issues_file"
    echo "" >> "$issues_file"
    
    local issue_count=0
    
    # Check 1: Pod phase issues
    local phase=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.phase}' 2>/dev/null)
    if [[ "$phase" != "Running" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Pod Not Running
- **Severity:** High
- **Status:** Pod is in '$phase' phase instead of 'Running'
- **Impact:** Application unavailable
- **Investigation:** Check pod events and container status

EOF
    fi
    
    # Check 2: Container readiness issues
    local ready_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[?(@.ready==true)]}' | jq '. | length' 2>/dev/null || echo "0")
    local total_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers}' | jq '. | length' 2>/dev/null || echo "1")
    
    if [[ "$ready_containers" -lt "$total_containers" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Container Readiness Problems
- **Severity:** High
- **Status:** Only $ready_containers of $total_containers containers are ready
- **Impact:** Traffic routing may be affected
- **Investigation:** Check readiness probes and container logs

EOF
    fi
    
    # Check 3: Excessive restarts
    local restarts=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
    if [[ "$restarts" -gt 5 ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Excessive Container Restarts
- **Severity:** Medium
- **Status:** Container has restarted $restarts times
- **Impact:** Service instability and potential data loss
- **Investigation:** Check liveness probes, resource limits, and application logs

EOF
    fi
    
    # Check 4: Resource usage issues
    if kubectl top pod "$pod_name" -n "$namespace" >/dev/null 2>&1; then
        local cpu_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $2}' | sed 's/m$//')
        local memory_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $3}' | sed 's/Mi$//')
        
        if [[ "$cpu_usage" -gt 800 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High CPU Usage
- **Severity:** Medium
- **Status:** CPU usage is ${cpu_usage}m (> 800m threshold)
- **Impact:** Performance degradation and potential throttling
- **Investigation:** Check for CPU-intensive processes and consider scaling

EOF
        fi
        
        if [[ "$memory_usage" -gt 512 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High Memory Usage
- **Severity:** Medium  
- **Status:** Memory usage is ${memory_usage}Mi (> 512Mi threshold)
- **Impact:** Risk of OOM kills and service disruption
- **Investigation:** Check for memory leaks and optimize memory usage

EOF
        fi
    fi
    
    # Check 5: Image pull issues
    if grep -q "ImagePullBackOff\|ErrImagePull" "$pod_dir/description.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Image Pull Problems
- **Severity:** High
- **Status:** Unable to pull container image
- **Impact:** Pod cannot start
- **Investigation:** Check image name, registry access, and credentials

EOF
    fi
    
    # Check 6: Resource constraints
    if grep -q "Insufficient.*resources" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Resource Constraints
- **Severity:** High
- **Status:** Insufficient cluster resources for pod scheduling
- **Impact:** Pod cannot be scheduled
- **Investigation:** Check cluster capacity and node resources

EOF
    fi
    
    # Check 7: Network issues
    if grep -q "NetworkNotReady\|CNI.*error" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Network Configuration Problems
- **Severity:** High
- **Status:** Network setup issues detected
- **Impact:** Pod networking may not function correctly
- **Investigation:** Check CNI configuration and network policies

EOF
    fi
    
    # Summary
    if [[ $issue_count -eq 0 ]]; then
        echo "## Summary: No Critical Issues Detected ‚úÖ" >> "$issues_file"
        echo "The automated analysis found no obvious problems with this pod." >> "$issues_file"
        log_success "No critical issues detected for $pod_name"
    else
        echo "## Summary: $issue_count Issue(s) Detected ‚ö†Ô∏è" >> "$issues_file"
        echo "Review the issues above and follow the investigation recommendations." >> "$issues_file"
        log_warn "$issue_count issue(s) detected for $pod_name"
    fi
    
    return $issue_count
}

# Generate recommendations
generate_recommendations() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Generating recommendations for $pod_name..."
    
    local rec_file="$pod_dir/recommendations.md"
    echo "# Optimization Recommendations" > "$rec_file"
    echo "**Pod:** $pod_name" >> "$rec_file"
    echo "" >> "$rec_file"
    
    # Resource optimization recommendations
    echo "## Resource Optimization" >> "$rec_file"
    
    # Check current resource configuration
    local requests_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.memory}' 2>/dev/null || echo "not set")
    local requests_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.cpu}' 2>/dev/null || echo "not set")
    local limits_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.memory}' 2>/dev/null || echo "not set")
    local limits_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.cpu}' 2>/dev/null || echo "not set")
    
    cat >> "$rec_file" <<EOF
### Current Resource Configuration
- **Memory Request:** $requests_mem
- **CPU Request:** $requests_cpu  
- **Memory Limit:** $limits_mem
- **CPU Limit:** $limits_cpu

EOF
    
    # Security recommendations
    echo "## Security Hardening" >> "$rec_file"
    
    local security_context=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.securityContext}' 2>/dev/null)
    if [[ -z "$security_context" || "$security_context" == "null" ]]; then
        cat >> "$rec_file" <<EOF
### Security Context Improvements
- ‚úÖ **Add security context:** Configure runAsNonRoot, runAsUser, and fsGroup
- ‚úÖ **Drop capabilities:** Remove unnecessary Linux capabilities  
- ‚úÖ **Read-only root filesystem:** Set readOnlyRootFilesystem: true
- ‚úÖ **Prevent privilege escalation:** Set allowPrivilegeEscalation: false

EOF
    fi
    
    # Health check recommendations
    echo "## Health Check Optimization" >> "$rec_file"
    
    local has_liveness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].livenessProbe}' 2>/dev/null)
    local has_readiness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].readinessProbe}' 2>/dev/null)
    
    if [[ -z "$has_liveness" || "$has_liveness" == "null" ]]; then
        echo "- ‚úÖ **Add liveness probe:** Implement health checking for automatic restart" >> "$rec_file"
    fi
    
    if [[ -z "$has_readiness" || "$has_readiness" == "null" ]]; then
        echo "- ‚úÖ **Add readiness probe:** Control traffic routing based on application readiness" >> "$rec_file"
    fi
    
    # Performance recommendations
    echo "" >> "$rec_file"
    echo "## Performance Optimization" >> "$rec_file"
    cat >> "$rec_file" <<EOF
- ‚úÖ **Use Alpine images:** Reduce image size and startup time
- ‚úÖ **Implement resource requests:** Help scheduler make better placement decisions
- ‚úÖ **Optimize health check frequency:** Balance responsiveness with overhead
- ‚úÖ **Use memory-backed volumes:** For temporary files and caches
- ‚úÖ **Configure DNS caching:** Reduce DNS lookup overhead

EOF
    
    log_success "Recommendations generated for $pod_name"
}

# Interactive diagnostic session
interactive_diagnostics() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Starting interactive diagnostics for $pod_name..."
    
    echo -e "${BOLD}Interactive Pod Diagnostics${NC}"
    echo "Pod: $pod_name"
    echo "Namespace: $namespace"
    echo ""
    
    while true; do
        echo -e "${CYAN}Available actions:${NC}"
        echo "1) Show pod status"
        echo "2) View recent events"
        echo "3) Check container logs"
        echo "4) Execute command in pod"
        echo "5) Port forward to pod"
        echo "6) Resource usage"
        echo "7) Run full diagnostic"
        echo "8) Generate recommendations"
        echo "q) Quit"
        echo ""
        
        read -p "Select action [1-8,q]: " choice
        
        case $choice in
            1)
                echo "=== Pod Status ==="
                kubectl get pod "$pod_name" -n "$namespace" -o wide
```" \
        15
    
    check_item "Readiness probe configured" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.spec.containers[0].readinessProbe}' | grep -v '^null
                kubectl describe pod "$pod_name" -n "$namespace" | grep -A 10 "Status\|Conditions"
                ;;
            2)
                echo "=== Recent Events ==="
                kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
                    --sort-by='.lastTimestamp' | tail -10
                ;;
            3)
                echo "=== Container Selection ==="
                local containers=($(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}'))
                if [[ ${#containers[@]} -eq 1 ]]; then
                    echo "Showing logs for container: ${containers[0]}"
                    kubectl logs "$pod_name" -n "$namespace" --tail=50
                else
                    echo "Available containers:"
                    for i in "${!containers[@]}"; do
                        echo "$((i+1))) ${containers[i]}"
                    done
                    read -p "Select container [1-${#containers[@]}]: " container_choice
                    if [[ $container_choice -ge 1 && $container_choice -le ${#containers[@]} ]]; then
                        local selected_container=${containers[$((container_choice-1))]}
                        echo "Showing logs for container: $selected_container"
                        kubectl logs "$pod_name" -n "$namespace" -c "$selected_container" --tail=50
                    fi
                fi
                ;;
            4)
                read -p "Enter command to execute: " exec_command
                kubectl exec -it "$pod_name" -n "$namespace" -- $exec_command
                ;;
            5)
                read -p "Enter local port: " local_port
                read -p "Enter pod port: " pod_port
                echo "Port forwarding $local_port:$pod_port - Press Ctrl+C to stop"
                kubectl port-forward "$pod_name" -n "$namespace" "$local_port:$pod_port"
                ;;
            6)
                echo "=== Resource Usage ==="
                kubectl top pod "$pod_name" -n "$namespace" 2>/dev/null || echo "Metrics not available"
                ;;
            7)
                gather_pod_info "$pod_name" "$namespace"
                detect_common_issues "$pod_name" "$namespace"
                generate_recommendations "$pod_name" "$namespace"
                echo "Full diagnostic completed. Check $OUTPUT_DIR/pods/$pod_name/"
                ;;
            8)
                generate_recommendations "$pod_name" "$namespace"
                echo "Recommendations generated. Check $OUTPUT_DIR/pods/$pod_name/recommendations.md"
                ;;
            q|Q)
                log_info "Exiting interactive diagnostics"
                break
                ;;
            *)
                echo "Invalid choice. Please try again."
                ;;
        esac
        
        echo ""
        read -p "Press Enter to continue..."
        echo ""
    done
}

# Cluster-wide pod health assessment
cluster_health_assessment() {
    log_info "Running cluster-wide pod health assessment..."
    
    local health_report="$OUTPUT_DIR/cluster_health_report.md"
    
    cat > "$health_report" <<EOF
# Cluster Pod Health Assessment

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)

---

EOF
    
    # Get all namespaces
    local namespaces=($(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'))
    
    local total_pods=0
    local healthy_pods=0
    local unhealthy_pods=0
    
    for ns in "${namespaces[@]}"; do
        log_info "Assessing namespace: $ns"
        
        local pods=($(kubectl get pods -n "$ns" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null))
        
        if [[ ${#pods[@]} -eq 0 ]]; then
            continue
        fi
        
        echo "## Namespace: $ns" >> "$health_report"
        echo "" >> "$health_report"
        
        local ns_healthy=0
        local ns_unhealthy=0
        
        for pod in "${pods[@]}"; do
            ((total_pods++))
            
            local phase=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.phase}')
            local ready_condition=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
            local restarts=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
            
            if [[ "$phase" == "Running" && "$ready_condition" == "True" && $restarts -lt 5 ]]; then
                ((healthy_pods++))
                ((ns_healthy++))
                echo "‚úÖ **$pod** - Healthy" >> "$health_report"
            else
                ((unhealthy_pods++))
                ((ns_unhealthy++))
                echo "‚ùå **$pod** - Issues detected (Phase: $phase, Ready: $ready_condition, Restarts: $restarts)" >> "$health_report"
                
                # Run quick diagnostics for unhealthy pods
                gather_pod_info "$pod" "$ns"
                detect_common_issues "$pod" "$ns"
            fi
        done
        
        echo "" >> "$health_report"
        echo "**Namespace Summary:** $ns_healthy healthy, $ns_unhealthy unhealthy" >> "$health_report"
        echo "" >> "$health_report"
    done
    
    # Overall summary
    local health_percentage=$((healthy_pods * 100 / total_pods))
    
    cat >> "$health_report" <<EOF

---

## Overall Cluster Health

- **Total Pods:** $total_pods
- **Healthy Pods:** $healthy_pods
- **Unhealthy Pods:** $unhealthy_pods
- **Health Percentage:** $health_percentage%

### Health Status
EOF
    
    if [[ $health_percentage -ge 90 ]]; then
        echo "üü¢ **EXCELLENT** - Cluster is in excellent health" >> "$health_report"
    elif [[ $health_percentage -ge 75 ]]; then
        echo "üü° **GOOD** - Cluster is in good health with minor issues" >> "$health_report"
    elif [[ $health_percentage -ge 50 ]]; then
        echo "üü† **WARNING** - Cluster has significant health issues" >> "$health_report"
    else
        echo "üî¥ **CRITICAL** - Cluster is in critical condition" >> "$health_report"
    fi
    
    log_success "Cluster health assessment completed. Report: $health_report"
}

# Generate comprehensive diagnostic report
generate_final_report() {
    log_info "Generating comprehensive diagnostic report..."
    
    local final_report="$OUTPUT_DIR/comprehensive_report.html"
    
    cat > "$final_report" <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Pod Diagnostics Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
        .header { background-color: #f4f4f4; padding: 20px; border-radius: 5px; margin-bottom: 30px; }
        .section { margin: 30px 0; }
        .pod-card { border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin: 10px 0; }
        .healthy { border-left: 5px solid #28a745; }
        .unhealthy { border-left: 5px solid #dc3545; }
        .warning { border-left: 5px solid #ffc107; }
        .metric { display: inline-block; margin: 10px 15px 10px 0; padding: 8px 12px; background-color: #e9ecef; border-radius: 3px; }
        .issue { background-color: #fff3cd; padding: 10px; border-radius: 3px; margin: 10px 0; }
        pre { background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }
        .tabs { border-bottom: 1px solid #ddd; margin-bottom: 20px; }
        .tab { display: inline-block; padding: 10px 20px; cursor: pointer; border-bottom: 2px solid transparent; }
        .tab.active { border-bottom-color: #007bff; color: #007bff; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }
    </style>
    <script>
        function showTab(tabName) {
            // Hide all tab contents
            var contents = document.getElementsByClassName('tab-content');
            for (var i = 0; i < contents.length; i++) {
                contents[i].classList.remove('active');
            }
            
            // Remove active class from all tabs
            var tabs = document.getElementsByClassName('tab');
            for (var i = 0; i < tabs.length; i++) {
                tabs[i].classList.remove('active');
            }
            
            // Show selected tab content and mark tab as active
            document.getElementById(tabName).classList.add('active');
            event.target.classList.add('active');
        }
    </script>
</head>
<body>
    <div class="header">
        <h1>üîç Pod Diagnostics Report</h1>
        <div class="metric">
            <strong>Generated:</strong> $(date)
        </div>
        <div class="metric">
            <strong>Cluster:</strong> $(kubectl config current-context)
        </div>
        <div class="metric">
            <strong>Diagnostics Version:</strong> 2.0
        </div>
    </div>
    
    <div class="tabs">
        <div class="tab active" onclick="showTab('overview')">Overview</div>
        <div class="tab" onclick="showTab('pods')">Pod Analysis</div>
        <div class="tab" onclick="showTab('issues')">Detected Issues</div>
        <div class="tab" onclick="showTab('recommendations')">Recommendations</div>
    </div>
    
    <div id="overview" class="tab-content active">
        <h2>üìä Cluster Overview</h2>
        <div class="section">
EOF
    
    # Add cluster metrics
    local total_nodes=$(kubectl get nodes --no-headers | wc -l)
    local ready_nodes=$(kubectl get nodes --no-headers | grep " Ready " | wc -l)
    local total_namespaces=$(kubectl get namespaces --no-headers | wc -l)
    
    cat >> "$final_report" <<EOF
            <div class="pod-card healthy">
                <h3>Cluster Metrics</h3>
                <div class="metric"><strong>Nodes:</strong> $ready_nodes/$total_nodes Ready</div>
                <div class="metric"><strong>Namespaces:</strong> $total_namespaces</div>
                <div class="metric"><strong>Kubernetes Version:</strong> $(kubectl version --short --client | cut -d' ' -f3)</div>
            </div>
        </div>
    </div>
    
    <div id="pods" class="tab-content">
        <h2>üöÄ Pod Analysis</h2>
EOF
    
    # Add pod analysis for each analyzed pod
    for pod_dir in "$OUTPUT_DIR"/pods/*/; do
        if [[ -d "$pod_dir" ]]; then
            local pod_name=$(basename "$pod_dir")
            local issues_count=0
            
            if [[ -f "$pod_dir/detected_issues.md" ]]; then
                issues_count=$(grep -c "## Issue" "$pod_dir/detected_issues.md" 2>/dev/null || echo "0")
            fi
            
            local card_class="healthy"
            if [[ $issues_count -gt 0 ]]; then
                card_class="unhealthy"
            fi
            
            cat >> "$final_report" <<EOF
        <div class="pod-card $card_class">
            <h3>üì¶ $pod_name</h3>
            <div class="metric"><strong>Issues Detected:</strong> $issues_count</div>
            <div class="metric"><strong>Analysis Files:</strong> $(ls "$pod_dir" | wc -l)</div>
            <div class="metric"><strong>Report Location:</strong> pods/$pod_name/</div>
        </div>
EOF
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="issues" class="tab-content">
        <h2>‚ö†Ô∏è Detected Issues</h2>
EOF
    
    # Aggregate all issues
    local total_issues=0
    for issues_file in "$OUTPUT_DIR"/pods/*/detected_issues.md; do
        if [[ -f "$issues_file" ]]; then
            local pod_issues=$(grep -c "## Issue" "$issues_file" 2>/dev/null || echo "0")
            ((total_issues += pod_issues))
            
            if [[ $pod_issues -gt 0 ]]; then
                local pod_name=$(basename "$(dirname "$issues_file")")
                echo "<h3>Issues for $pod_name</h3>" >> "$final_report"
                
                # Convert markdown issues to HTML
                grep "## Issue" "$issues_file" | while read -r line; do
                    echo "<div class=\"issue\">$line</div>" >> "$final_report"
                done
            fi
        fi
    done
    
    if [[ $total_issues -eq 0 ]]; then
        echo "<div class=\"pod-card healthy\"><h3>‚úÖ No Issues Detected</h3><p>All analyzed pods appear to be healthy!</p></div>" >> "$final_report"
    fi
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="recommendations" class="tab-content">
        <h2>üí° Recommendations</h2>
        <div class="section">
            <div class="pod-card warning">
                <h3>General Recommendations</h3>
                <ul>
                    <li>‚úÖ Implement comprehensive health checks for all pods</li>
                    <li>‚úÖ Set appropriate resource requests and limits</li>
                    <li>‚úÖ Use security contexts to harden pod security</li>
                    <li>‚úÖ Monitor resource usage and optimize accordingly</li>
                    <li>‚úÖ Implement graceful shutdown handling</li>
                    <li>‚úÖ Use multi-stage Docker builds for smaller images</li>
                    <li>‚úÖ Implement proper logging and observability</li>
                </ul>
            </div>
        </div>
EOF
    
    # Add pod-specific recommendations
    for rec_file in "$OUTPUT_DIR"/pods/*/recommendations.md; do
        if [[ -f "$rec_file" ]]; then
            local pod_name=$(basename "$(dirname "$rec_file")")
            echo "<div class=\"pod-card\"><h3>Recommendations for $pod_name</h3>" >> "$final_report"
            echo "<p>See detailed recommendations in: pods/$pod_name/recommendations.md</p></div>" >> "$final_report"
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div class="section">
        <hr>
        <p><em>Report generated by Pod Diagnostics Toolkit v2.0</em></p>
        <p><em>For detailed analysis, check individual files in the diagnostics output directory.</em></p>
    </div>
    
</body>
</html>
EOF
    
    log_success "Comprehensive report generated: $final_report"
    echo ""
    echo -e "${BOLD}üìã Diagnostic Summary:${NC}"
    echo "- Output Directory: $OUTPUT_DIR"
    echo "- HTML Report: $final_report"
    echo "- Total Issues Found: $total_issues"
    echo ""
    echo -e "${CYAN}üí° Next Steps:${NC}"
    echo "1. Open $final_report in your browser"
    echo "2. Review individual pod analysis in $OUTPUT_DIR/pods/"
    echo "3. Implement recommended fixes"
    echo "4. Re-run diagnostics to verify improvements"
}

# Main execution function
main() {
    local command=${1:-help}
    local pod_name=${2:-}
    local namespace=${3:-$NAMESPACE}
    
    case "$command" in
        "analyze")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for analysis"
                echo "Usage: $0 analyze <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            gather_pod_info "$pod_name" "$namespace"
            detect_common_issues "$pod_name" "$namespace"
            generate_recommendations "$pod_name" "$namespace"
            generate_final_report
            ;;
            
        "interactive")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for interactive mode"
                echo "Usage: $0 interactive <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            interactive_diagnostics "$pod_name" "$namespace"
            ;;
            
        "cluster-health")
            init_diagnostics
            cluster_health_assessment
            generate_final_report
            ;;
            
        "help"|*)
            cat <<EOF
üîç Advanced Pod Diagnostics Toolkit

Usage: $0 <command> [options]

Commands:
  analyze <pod-name> [namespace]     - Run comprehensive pod analysis
  interactive <pod-name> [namespace] - Start interactive diagnostic session
  cluster-health                     - Assess health of all pods in cluster
  help                              - Show this help message

Environment Variables:
  NAMESPACE - Default namespace (default: default)
  VERBOSE   - Enable verbose output (default: false)

Examples:
  $0 analyze nginx-pod production
  $0 interactive web-app-123
  $0 cluster-health
  VERBOSE=true $0 analyze problematic-pod

Output:
  All diagnostic data is saved to ./diagnostics-TIMESTAMP/
  HTML report provides comprehensive overview
  Individual pod analysis available in pods/ subdirectory

EOF
            ;;
    esac
}

# Execute main function
main "$@"
```

---

## Summary and Production-Ready Examples

### üèÜ Complete Production Workflow

Let's create a final comprehensive example that brings everything together:

```yaml
# complete-production-workflow.yaml
# This represents a complete production-ready pod deployment workflow

apiVersion: v1
kind: Namespace
metadata:
  name: production-workload
  labels:
    environment: production
    team: platform
---
# ConfigMap for application configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production-workload
data:
  app.properties: |
    server.port=8080
    management.port=8081
    logging.level=INFO
    metrics.enabled=true
  nginx.conf: |
    server {
        listen 80;
        location /health { return 200 'healthy\n'; }
        location /ready { return 200 'ready\n'; }
        location / {
            proxy_pass http://127.0.0.1:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
---
# Secret for sensitive configuration
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: production-workload
type: Opaque
data:
  database-password: c3VwZXJzZWNyZXQ=  # supersecret (base64)
  api-key: YWJjZGVmZ2hpams=  # abcdefghijk (base64)
---
# Production-ready pod with all best practices
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production-workload
  labels:
    app: production-app
    version: "2.1.0"
    environment: production
    team: platform
    component: backend
  annotations:
    description: "Production application with full observability"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/production-app"
    prometheus.io/scrape: "true"
    prometheus.io/port: "8081"
    prometheus.io/path: "/metrics"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Resource constraints and node placement
  nodeSelector:
    node-type: "application"
    performance-tier: "high"
    
  tolerations:
  - key: "dedicated-app"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
    
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: production-app
        topologyKey: kubernetes.io/hostname
        
  # DNS and network configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  # Init container for setup tasks
  initContainers:
  - name: setup
    image: busybox:1.35
    command:
    - /bin/sh
    - -c
    - |
      echo "Initializing application..."
      
      # Database migration simulation
      echo "Running database migrations..."
      sleep 5
      
      # Cache warming
      echo "Warming up caches..."
      sleep 3
      
      # Configuration validation
      echo "Validating configuration..."
      if [ -f /config/app.properties ]; then
        echo "‚úÖ Configuration file found"
      else
        echo "‚ùå Configuration file missing"
        exit 1
      fi
      
      echo "Initialization completed successfully"
      
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-init
      mountPath: /tmp
      
  # Main application containers
  containers:
  # Application container
  - name: app
    image: openjdk:11-jre-slim
    command:
    - /bin/bash
    - -c
    - |
      echo "Starting application..."
      
      # Simulated application startup
      java -Xmx200m -Xms100m -jar /app/application.jar \
        --spring.config.location=file:/config/app.properties \
        --server.port=8080 \
        --management.server.port=8081
        
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP
    - name: management
      containerPort: 8081
      protocol: TCP
      
    # Environment configuration
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # Sensitive configuration from secrets
    - name: DATABASE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: database-password
    - name: API_KEY
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: api-key
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security hardening
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    # Comprehensive health checks
    livenessProbe:
      httpGet:
        path: /actuator/health/liveness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /actuator/health/readiness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /actuator/health
        port: 8081
      initialDelaySeconds: 20
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle management
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Application started at $(date)" >> /tmp/startup.log
            # Custom post-start logic here
            
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Graceful shutdown initiated at $(date)" >> /tmp/shutdown.log
            # Send SIGTERM to application
            kill -TERM 1
            # Wait for graceful shutdown
            sleep 30
            
    # Volume mounts
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-volume
      mountPath: /tmp
    - name: app-logs
      mountPath: /app/logs
    - name: app-data
      mountPath: /app/data
      
  # Nginx reverse proxy sidecar
  - name: nginx-proxy
    image: nginx:1.21-alpine
    ports:
    - name: http-proxy
      containerPort: 80
      protocol: TCP
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        add: ["NET_BIND_SERVICE"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: nginx-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
      
  # Logging and monitoring sidecar
  - name: log-shipper
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: fluent-tmp
      mountPath: /tmp
      
  # Volumes
  volumes:
  - name: config-volume
    configMap:
      name: app-config
      items:
      - key: app.properties
        path: app.properties
  - name: nginx-config
    configMap:
      name: app-config
      items:
      - key: nginx.conf
        path: default.conf
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config  # Would be created separately
  # Temporary and cache volumes
  - name: tmp-volume
    emptyDir:
      sizeLimit: 256Mi
  - name: tmp-init
    emptyDir:
      sizeLimit: 64Mi
  - name: nginx-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: fluent-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: nginx-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: nginx-run
    emptyDir:
      sizeLimit: 32Mi
  # Application data volumes
  - name: app-logs
    emptyDir:
      sizeLimit: 1Gi
  - name: app-data
    emptyDir:
      sizeLimit: 2Gi
```

This comprehensive example demonstrates:

- **Complete security hardening** with proper contexts and capabilities
- **Multi-container architecture** with main app, proxy, and logging sidecars
- **Comprehensive health checks** for all containers
- **Resource optimization** with appropriate requests and limits
- **Configuration management** using ConfigMaps and Secrets
- **Observability** with structured logging and metrics endpoints
- **Production-ready networking** with reverse proxy
- **Graceful lifecycle management** with init containers and shutdown hooks

## üéì Key Learning Outcomes

By working through these enhanced examples, demos, and mini-projects, you've gained:

1. **Foundation Skills**: Basic pod creation, inspection, and management
2. **Intermediate Capabilities**: Multi-container patterns, health monitoring, and debugging
3. **Advanced Techniques**: Performance optimization, security hardening, and automation
4. **Expert-Level Mastery**: Custom controllers, comprehensive diagnostics, and production workflows

### üöÄ Next Steps for Continued Learning

1. **Practice the Examples**: Work through each example in your own cluster
2. **Customize for Your Use Cases**: Adapt the patterns to your specific applications
3. **Build Your Toolkit**: Create your own diagnostic and management scripts
4. **Share and Learn**: Contribute back to the community with your own improvements
5. **Scale Up**: Apply these pod management skills to higher-level controllers

The journey from basic pod creation to# 5. Working with Pods - From Fundamentals to Mastery (Enhanced Edition)

Understanding how to work with pods effectively forms the foundation of all Kubernetes operations. While you'll typically use higher-level controllers like Deployments in production environments, direct pod management skills are essential for debugging, troubleshooting, and truly understanding how Kubernetes applications function at their core. Think of this knowledge as learning to drive a manual transmission car‚Äîeven if you usually drive automatic, understanding the underlying mechanics makes you a better driver overall.

This enhanced guide provides progressive examples, hands-on demos, and real-world mini-projects to solidify your understanding through practical application.

## üéØ Learning Path Overview

- **Foundation Level**: Basic pod creation and inspection
- **Intermediate Level**: Multi-container patterns and health checks
- **Advanced Level**: Complex debugging and optimization
- **Expert Level**: Custom tooling and automation

---

## Understanding Pod Creation Strategies

Creating pods effectively requires understanding when to use imperative commands versus declarative configurations, and how different creation approaches serve different purposes.

### üìö Foundation Examples

Let's start with the absolute basics and progressively build complexity.

#### Example 1: Your First Pod
```bash
# Create the simplest possible pod
kubectl run hello-world --image=nginx --restart=Never

# Verify it's running
kubectl get pods

# Expected output:
# NAME          READY   STATUS    RESTARTS   AGE
# hello-world   1/1     Running   0          30s
```

#### Example 2: Pod with Custom Commands
```bash
# Create a pod that runs a custom command
kubectl run date-pod --image=busybox --restart=Never -- date

# This pod will run the date command and then exit
# Check the output
kubectl logs date-pod

# Clean up
kubectl delete pod date-pod
```

#### Example 3: Interactive Pod Session
```bash
# Create an interactive debugging pod
kubectl run -it debug-pod --image=busybox --restart=Never -- sh

# Inside the pod, try these commands:
# ls -la
# ps aux
# ping google.com
# nslookup kubernetes.default.svc.cluster.local

# Exit and clean up
# exit
kubectl delete pod debug-pod
```

### üõ†Ô∏è Demo: Pod Lifecycle Observation

Let's create a demo that shows the complete pod lifecycle in action:

```bash
#!/bin/bash
# pod-lifecycle-demo.sh

echo "=== Pod Lifecycle Demonstration ==="

# Terminal 1: Start watching pods
echo "In a separate terminal, run: kubectl get pods -w"
echo "Press Enter when ready..."
read

# Create a pod with a slow-starting application
echo "Creating pod with slow startup..."
kubectl run lifecycle-demo --image=nginx --restart=Never \
  --dry-run=client -o yaml > lifecycle-pod.yaml

# Add some customizations to make it more interesting
cat <<EOF >> lifecycle-pod.yaml
  containers:
  - name: nginx
    image: nginx:1.21
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod starting up...' && sleep 10"
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod shutting down...' && sleep 5"
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 5
EOF

echo "Applying pod configuration..."
kubectl apply -f lifecycle-pod.yaml

echo "Watch the pod states change from Pending -> ContainerCreating -> Running"
echo "Press Enter to continue when pod is Running..."
read

# Show detailed pod information
echo "=== Pod Details ==="
kubectl describe pod lifecycle-demo

echo "Press Enter to delete the pod and observe termination..."
read

# Delete and watch termination
kubectl delete pod lifecycle-demo

echo "Demo complete! Clean up the YAML file:"
echo "rm lifecycle-pod.yaml"
```

### üéØ Mini-Project 1: Pod Resource Monitor

Create a simple monitoring system using pods:

```yaml
# resource-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-monitor
  labels:
    app: monitor
    type: demo
spec:
  containers:
  - name: monitor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Starting Resource Monitor..."
      while true; do
        echo "=== $(date) ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "Load average:"
        uptime
        echo "Sleeping for 30 seconds..."
        sleep 30
      done
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
  restartPolicy: Always
```

```bash
# Deploy and monitor
kubectl apply -f resource-monitor-pod.yaml

# Watch the logs
kubectl logs -f resource-monitor

# In another terminal, check resource usage
kubectl top pod resource-monitor

# Clean up
kubectl delete -f resource-monitor-pod.yaml
```

---

## Deep Pod Inspection and Monitoring

### üîç Intermediate Examples

#### Example 4: Multi-Container Pod Investigation

```yaml
# multi-container-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-demo
  labels:
    demo: multi-container
spec:
  containers:
  - name: web-server
    image: nginx:1.21
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
    
  - name: log-processor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Log processor starting..."
      while true; do
        if [ -f /var/log/nginx/access.log ]; then
          echo "=== Access Log Summary $(date) ==="
          tail -10 /var/log/nginx/access.log | wc -l
          echo "Recent requests:"
          tail -5 /var/log/nginx/access.log
        else
          echo "Waiting for access.log..."
        fi
        sleep 30
      done
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
      
  - name: metrics-collector
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Metrics collector starting..."
      while true; do
        echo "=== Metrics $(date) ==="
        echo "Container count: 3"
        echo "Uptime: $(uptime)"
        echo "Memory: $(free -h | grep Mem)"
        sleep 60
      done
      
  volumes:
  - name: shared-logs
    emptyDir: {}
```

**Inspection Commands:**
```bash
# Apply the multi-container pod
kubectl apply -f multi-container-demo.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/multi-container-demo

# Inspect different aspects
echo "=== Basic Information ==="
kubectl get pod multi-container-demo -o wide

echo "=== Container Status ==="
kubectl get pod multi-container-demo -o jsonpath='{.status.containerStatuses[*].name}' | tr ' ' '\n'

echo "=== Logs from each container ==="
kubectl logs multi-container-demo -c web-server --tail=5
kubectl logs multi-container-demo -c log-processor --tail=5
kubectl logs multi-container-demo -c metrics-collector --tail=5

# Generate some traffic to see shared volume in action
kubectl port-forward multi-container-demo 8080:80 &
PF_PID=$!

# Generate requests
for i in {1..10}; do
  curl -s http://localhost:8080 > /dev/null
  echo "Request $i sent"
  sleep 1
done

kill $PF_PID

# Check log processor output
kubectl logs multi-container-demo -c log-processor --tail=10

# Clean up
kubectl delete -f multi-container-demo.yaml
```

### üõ†Ô∏è Demo: Advanced Pod Debugging Techniques

```bash
#!/bin/bash
# advanced-debugging-demo.sh

echo "=== Advanced Pod Debugging Demo ==="

# Create a problematic pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: problematic-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "2000m"  # This might cause scheduling issues
      limits:
        memory: "512Mi"  # Less than request - invalid!
        cpu: "500m"
    livenessProbe:
      httpGet:
        path: /nonexistent
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
EOF

echo "Created a pod with multiple issues. Let's debug it..."

# Wait a moment for issues to manifest
sleep 10

echo "=== Debugging Steps ==="

echo "1. Check pod status:"
kubectl get pod problematic-pod -o wide

echo "2. Look at events:"
kubectl describe pod problematic-pod | grep -A 10 Events:

echo "3. Check for resource issues:"
kubectl describe pod problematic-pod | grep -A 5 -B 5 "resource"

echo "4. Examine container status:"
kubectl get pod problematic-pod -o jsonpath='{.status.containerStatuses[0]}' | jq '.'

# Fix the pod
echo "5. Let's fix the issues..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: fixed-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
EOF

echo "6. Compare the fixed pod:"
kubectl wait --for=condition=Ready pod/fixed-pod --timeout=60s
kubectl get pods -l debug=demo

# Clean up
echo "Cleaning up..."
kubectl delete pod problematic-pod fixed-pod
```

### üéØ Mini-Project 2: Pod Health Monitoring Dashboard

Create a comprehensive health monitoring system:

```yaml
# health-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: health-dashboard
  labels:
    app: health-monitor
spec:
  containers:
  - name: health-checker
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Health Dashboard Starting..."
      
      # Create a simple HTML dashboard
      mkdir -p /tmp/dashboard
      
      while true; do
        cat > /tmp/dashboard/health.html <<EOF
      <!DOCTYPE html>
      <html>
      <head>
          <title>Pod Health Dashboard</title>
          <meta http-equiv="refresh" content="30">
          <style>
              body { font-family: Arial, sans-serif; margin: 40px; }
              .healthy { color: green; }
              .warning { color: orange; }
              .critical { color: red; }
              .metric { margin: 10px 0; padding: 10px; border: 1px solid #ccc; }
          </style>
      </head>
      <body>
          <h1>Pod Health Dashboard</h1>
          <p>Last Update: $(date)</p>
          
          <div class="metric">
              <h3>System Load</h3>
              <p>$(uptime)</p>
          </div>
          
          <div class="metric">
              <h3>Memory Usage</h3>
              <pre>$(free -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Disk Usage</h3>
              <pre>$(df -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Process Count</h3>
              <p>Running processes: $(ps aux | wc -l)</p>
          </div>
          
      </body>
      </html>
      EOF
        
        echo "Dashboard updated at $(date)"
        sleep 30
      done
    volumeMounts:
    - name: dashboard-storage
      mountPath: /tmp/dashboard
      
  - name: web-server
    image: nginx:alpine
    ports:
    - containerPort: 80
    command:
    - /bin/sh
    - -c
    - |
      # Configure nginx to serve our dashboard
      cat > /etc/nginx/conf.d/default.conf <<EOF
      server {
          listen 80;
          location / {
              root /usr/share/nginx/html;
              index health.html;
          }
      }
      EOF
      
      # Start nginx
      nginx -g "daemon off;"
    volumeMounts:
    - name: dashboard-storage
      mountPath: /usr/share/nginx/html
      
  volumes:
  - name: dashboard-storage
    emptyDir: {}
    
  restartPolicy: Always
```

**Usage:**
```bash
# Deploy the health dashboard
kubectl apply -f health-monitor-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/health-dashboard

# Access the dashboard
kubectl port-forward health-dashboard 8080:80

# Open browser to http://localhost:8080
echo "Open http://localhost:8080 in your browser"

# Monitor the pod's own health
kubectl top pod health-dashboard

# Check logs from both containers
kubectl logs health-dashboard -c health-checker --tail=10
kubectl logs health-dashboard -c web-server --tail=10

# Clean up
kubectl delete -f health-monitor-pod.yaml
```

---

## Interactive Pod Management and Debugging

### üîß Advanced Examples

#### Example 5: Network Debugging Pod

```yaml
# network-debug-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: network-debugger
  labels:
    purpose: network-debug
spec:
  containers:
  - name: nettools
    image: nicolaka/netshoot
    command: ["/bin/bash"]
    args:
    - -c
    - |
      echo "Network debugging tools ready!"
      echo "Available tools: dig, nslookup, ping, curl, wget, tcpdump, netstat"
      echo "Example commands:"
      echo "  dig kubernetes.default.svc.cluster.local"
      echo "  ping 8.8.8.8"
      echo "  curl -I http://httpbin.org/headers"
      echo "  netstat -tulpn"
      
      # Keep container running
      sleep 3600
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
  restartPolicy: Never
```

**Debugging Session:**
```bash
# Deploy the network debugger
kubectl apply -f network-debug-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/network-debugger

# Start interactive session
kubectl exec -it network-debugger -- bash

# Inside the pod, run network diagnostics:
# Test DNS resolution
# dig kubernetes.default.svc.cluster.local

# Test external connectivity
# ping -c 3 8.8.8.8

# Test HTTP services
# curl -I https://httpbin.org/headers

# Check network interfaces
# ip addr show

# Check routing table
# ip route show

# Test service discovery
# nslookup kubernetes.default

# Exit and clean up
# exit
kubectl delete -f network-debug-pod.yaml
```

### üõ†Ô∏è Demo: File Transfer and Volume Management

```bash
#!/bin/bash
# file-transfer-demo.sh

echo "=== File Transfer and Volume Demo ==="

# Create a pod with persistent data
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: file-demo
spec:
  containers:
  - name: app
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Creating sample files..."
      mkdir -p /data/logs /data/config
      
      # Generate some sample data
      for i in {1..5}; do
        echo "Log entry \$i at \$(date)" >> /data/logs/app.log
        sleep 1
      done
      
      echo "app_name=demo-app" > /data/config/settings.conf
      echo "version=1.0.0" >> /data/config/settings.conf
      echo "debug=true" >> /data/config/settings.conf
      
      echo "Files created. Keeping container running..."
      sleep 3600
    volumeMounts:
    - name: data-storage
      mountPath: /data
  volumes:
  - name: data-storage
    emptyDir: {}
EOF

echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/file-demo

# Demonstrate file operations
echo "=== File Operations Demo ==="

echo "1. List files in the pod:"
kubectl exec file-demo -- find /data -type f

echo "2. Copy file from pod to local:"
kubectl cp file-demo:/data/logs/app.log ./app.log.backup
echo "File copied to: app.log.backup"
cat app.log.backup

echo "3. Create local config file:"
cat > new-config.conf <<EOF
app_name=updated-demo-app
version=2.0.0
debug=false
environment=production
EOF

echo "4. Copy local file to pod:"
kubectl cp new-config.conf file-demo:/data/config/

echo "5. Verify file in pod:"
kubectl exec file-demo -- cat /data/config/new-config.conf

echo "6. Create a backup of all data:"
kubectl exec file-demo -- tar -czf /tmp/backup.tar.gz -C /data .
kubectl cp file-demo:/tmp/backup.tar.gz ./pod-data-backup.tar.gz
echo "Backup created: pod-data-backup.tar.gz"

# Clean up
echo "Cleaning up..."
kubectl delete pod file-demo
rm -f app.log.backup new-config.conf pod-data-backup.tar.gz

echo "Demo complete!"
```

### üéØ Mini-Project 3: Pod Security Scanner

Create a security scanning tool using pods:

```yaml
# security-scanner-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-scanner
  labels:
    app: security
    type: scanner
spec:
  serviceAccountName: default
  containers:
  - name: scanner
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "=== Pod Security Scanner Starting ==="
      
      # Function to check security configurations
      check_security() {
        echo "Checking security configurations..."
        
        # Check if running as root
        if [ "$(id -u)" -eq 0 ]; then
          echo "‚ö†Ô∏è  WARNING: Running as root user"
        else
          echo "‚úÖ GOOD: Running as non-root user ($(id -u))"
        fi
        
        # Check filesystem permissions
        if [ -w "/" ]; then
          echo "‚ö†Ô∏è  WARNING: Root filesystem is writable"
        else
          echo "‚úÖ GOOD: Root filesystem is read-only"
        fi
        
        # Check for sensitive mounts
        if mount | grep -q "/var/run/secrets"; then
          echo "‚ÑπÔ∏è  INFO: Service account token mounted"
        fi
        
        # Check available capabilities
        echo "Current capabilities:"
        if [ -f "/proc/self/status" ]; then
          grep Cap /proc/self/status
        fi
        
        # Check network access
        echo "Testing network access..."
        if ping -c 1 8.8.8.8 >/dev/null 2>&1; then
          echo "‚ÑπÔ∏è  INFO: External network access available"
        else
          echo "‚ÑπÔ∏è  INFO: No external network access"
        fi
        
        # Generate security report
        cat > /tmp/security-report.txt <<EOF
      === Security Scan Report ===
      Timestamp: $(date)
      User ID: $(id -u)
      Group ID: $(id -g)
      Working Directory: $(pwd)
      
      Filesystem Check:
      - Root writable: $([ -w "/" ] && echo "YES" || echo "NO")
      - /tmp writable: $([ -w "/tmp" ] && echo "YES" || echo "NO")
      
      Network Check:
      - External access: $(ping -c 1 8.8.8.8 >/dev/null 2>&1 && echo "YES" || echo "NO")
      
      Process Information:
      $(ps aux)
      EOF
        
        echo "Report generated at /tmp/security-report.txt"
      }
      
      # Run security check
      check_security
      
      # Keep running for inspection
      echo "Scanner complete. Container will stay running for inspection."
      sleep 3600
      
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 1000
      runAsGroup: 3000
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir: {}
    
  restartPolicy: Never
```

**Usage:**
```bash
# Deploy the security scanner
kubectl apply -f security-scanner-pod.yaml

# Monitor the scan
kubectl logs -f security-scanner

# Get the security report
kubectl cp security-scanner:/tmp/security-report.txt ./security-report.txt
cat security-report.txt

# Create a comparison with an insecure pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: insecure-pod
spec:
  containers:
  - name: insecure
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      runAsUser: 0  # Running as root
      privileged: true
EOF

# Compare security postures
echo "=== Security Comparison ==="
echo "Secure pod user:"
kubectl exec security-scanner -- id

echo "Insecure pod user:"
kubectl exec insecure-pod -- id

echo "Secure pod capabilities:"
kubectl exec security-scanner -- grep Cap /proc/self/status

echo "Insecure pod capabilities:"
kubectl exec insecure-pod -- grep Cap /proc/self/status

# Clean up
kubectl delete pod security-scanner insecure-pod
rm -f security-report.txt
```

---

## Declarative Pod Configuration and Management

### üèóÔ∏è Expert Examples

#### Example 6: Production-Ready Pod Template

```yaml
# production-pod-template.yaml
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production
  labels:
    app: web-server
    version: "2.1.0"
    environment: production
    team: platform
  annotations:
    description: "Production web server with full monitoring and security"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/web-server"
    version: "2.1.0"
    build-date: "2024-01-15T10:30:00Z"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Node selection
  nodeSelector:
    node-type: "application"
    zone: "us-west-2a"
    
  # Tolerations for dedicated nodes
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "application"
    effect: "NoSchedule"
    
  # Pod placement preferences
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: "node-type"
            operator: In
            values: ["application"]
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: web-server
          topologyKey: kubernetes.io/hostname
          
  # DNS configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  containers:
  - name: web-server
    image: nginx:1.21-alpine
    imagePullPolicy: IfNotPresent
    
    ports:
    - name: http
      containerPort: 80
      protocol: TCP
    - name: metrics
      containerPort: 9113
      protocol: TCP
      
    # Environment variables
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "info"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security context
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE
        
    # Health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 80
        scheme: HTTP
        httpHeaders:
        - name: Custom-Header
          value: liveness-check
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
        scheme: HTTP
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle hooks
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container started at $(date)" >> /tmp/startup.log
            # Custom initialization logic here
            
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container stopping at $(date)" >> /tmp/shutdown.log
            # Graceful shutdown logic here
            nginx -s quit
            sleep 15
            
    # Volume mounts
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  # Sidecar container for log processing
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  # Monitoring sidecar
  - name: nginx-exporter
    image: nginx/nginx-prometheus-exporter:0.10.0
    args:
    - -nginx.scrape-uri=http://localhost:80/nginx_status
    ports:
    - name: metrics
      containerPort: 9113
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
  # Shared volumes
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
      defaultMode: 0644
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
      defaultMode: 0644
  - name: html-content
    configMap:
      name: html-content
      defaultMode: 0644
  - name: tmp-dir
    emptyDir:
      sizeLimit: 256Mi
  - name: var-cache-nginx
    emptyDir:
      sizeLimit: 512Mi
  - name: var-run
    emptyDir:
      sizeLimit: 64Mi
  - name: logs
    emptyDir:
      sizeLimit: 1Gi
```

### üõ†Ô∏è Demo: Complex Pod Deployment Pipeline

```bash
#!/bin/bash
# production-pod-deployment.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

# Configuration
NAMESPACE="production-demo"
APP_NAME="web-server"
CONFIG_DIR="./config"

# Create namespace if it doesn't exist
create_namespace() {
    log "Creating namespace: $NAMESPACE"
    kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    success "Namespace $NAMESPACE ready"
}

# Create ConfigMaps for the application
create_configmaps() {
    log "Creating ConfigMaps..."
    
    mkdir -p $CONFIG_DIR
    
    # Nginx configuration
    cat > $CONFIG_DIR/nginx.conf <<EOF
server {
    listen 80;
    server_name localhost;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
    
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    location /ready {
        access_log off;
        return 200 "ready\n";
        add_header Content-Type text/plain;
    }
    
    location /nginx_status {
        stub_status on;
        access_log off;
        allow all;
    }
}
EOF

    # HTML content
    cat > $CONFIG_DIR/index.html <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Production Pod Demo</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .container { max-width: 800px; margin: 0 auto; }
        .status { padding: 20px; margin: 20px 0; border-radius: 5px; }
        .healthy { background-color: #d4edda; color: #155724; }
        .info { background-color: #d1ecf1; color: #0c5460; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Production Pod Demo</h1>
        <div class="status healthy">
            <h3>‚úÖ Application Status: Healthy</h3>
            <p>Pod is running successfully with full production configuration</p>
        </div>
        
        <div class="status info">
            <h3>üìä Features Enabled:</h3>
            <ul>
                <li>Multi-container architecture</li>
                <li>Comprehensive health checks</li>
                <li>Security hardening</li>
                <li>Log processing sidecar</li>
                <li>Prometheus metrics export</li>
                <li>Resource management</li>
            </ul>
        </div>
        
        <div class="status info">
            <h3>üîó Endpoints:</h3>
            <ul>
                <li><a href="/health">Health Check</a></li>
                <li><a href="/ready">Readiness Check</a></li>
                <li><a href="/nginx_status">Nginx Status</a></li>
            </ul>
        </div>
    </div>
</body>
</html>
EOF

    # Fluent Bit configuration
    cat > $CONFIG_DIR/fluent-bit.conf <<EOF
[SERVICE]
    Flush         1
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf

[INPUT]
    Name              tail
    Path              /var/log/nginx/access.log
    Parser            nginx
    Tag               nginx.access
    Refresh_Interval  5

[INPUT]
    Name              tail
    Path              /var/log/nginx/error.log
    Tag               nginx.error
    Refresh_Interval  5

[OUTPUT]
    Name  stdout
    Match nginx.*
EOF

    cat > $CONFIG_DIR/parsers.conf <<EOF
[PARSER]
    Name   nginx
    Format regex
    Regex  ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
    Time_Key time
    Time_Format %d/%b/%Y:%H:%M:%S %z
EOF

    # Create ConfigMaps
    kubectl create configmap nginx-config --from-file=$CONFIG_DIR/nginx.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap html-content --from-file=$CONFIG_DIR/index.html -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap fluent-bit-config --from-file=$CONFIG_DIR/fluent-bit.conf --from-file=$CONFIG_DIR/parsers.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    
    success "ConfigMaps created successfully"
}

# Deploy the production pod
deploy_pod() {
    log "Deploying production pod..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: $APP_NAME
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
    version: "1.0.0"
    environment: production
  annotations:
    deployment.kubernetes.io/revision: "1"
    deployed-by: "production-deployment-script"
    deployment-time: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    
  containers:
  - name: nginx
    image: nginx:1.21-alpine
    ports:
    - name: http
      containerPort: 80
    - name: metrics
      containerPort: 9113
      
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
  - name: html-content
    configMap:
      name: html-content
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
  - name: tmp-dir
    emptyDir: {}
  - name: var-cache-nginx
    emptyDir: {}
  - name: var-run
    emptyDir: {}
  - name: logs
    emptyDir: {}
EOF

    success "Pod deployed successfully"
}

# Wait for pod to be ready and perform health checks
verify_deployment() {
    log "Waiting for pod to be ready..."
    
    if kubectl wait --for=condition=Ready pod/$APP_NAME -n $NAMESPACE --timeout=120s; then
        success "Pod is ready!"
    else
        error "Pod failed to become ready within timeout"
    fi
    
    # Perform comprehensive health checks
    log "Performing health checks..."
    
    # Check pod status
    kubectl get pod $APP_NAME -n $NAMESPACE -o wide
    
    # Test health endpoints
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    if curl -s http://localhost:8080/health | grep -q "healthy"; then
        success "Health check passed"
    else
        warning "Health check failed"
    fi
    
    if curl -s http://localhost:8080/ready | grep -q "ready"; then
        success "Readiness check passed"
    else
        warning "Readiness check failed"
    fi
    
    # Test the main application
    if curl -s http://localhost:8080 | grep -q "Production Pod Demo"; then
        success "Application is serving content correctly"
    else
        warning "Application content check failed"
    fi
    
    kill $PF_PID 2>/dev/null
    
    # Check resource usage
    log "Checking resource usage..."
    if kubectl top pod $APP_NAME -n $NAMESPACE &>/dev/null; then
        kubectl top pod $APP_NAME -n $NAMESPACE
    else
        warning "Resource metrics not available"
    fi
    
    # Check logs from all containers
    log "Checking container logs..."
    echo "=== Nginx logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c nginx --tail=5
    echo "=== Log processor logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=5
}

# Generate load and monitor performance
performance_test() {
    log "Running performance test..."
    
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    # Generate some load
    for i in {1..50}; do
        curl -s http://localhost:8080 > /dev/null &
    done
    
    wait
    kill $PF_PID 2>/dev/null
    
    # Check logs after load test
    log "Logs after load test:"
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=10
    
    success "Performance test completed"
}

# Cleanup function
cleanup() {
    log "Cleaning up resources..."
    kubectl delete pod $APP_NAME -n $NAMESPACE --ignore-not-found
    kubectl delete configmap nginx-config html-content fluent-bit-config -n $NAMESPACE --ignore-not-found
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -rf $CONFIG_DIR
    success "Cleanup completed"
}

# Main execution
main() {
    echo "=== Production Pod Deployment Demo ==="
    
    case "${1:-deploy}" in
        "deploy")
            create_namespace
            create_configmaps
            deploy_pod
            verify_deployment
            performance_test
            
            echo ""
            success "Deployment completed successfully!"
            echo "Access the application:"
            echo "  kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80"
            echo "  Then open: http://localhost:8080"
            echo ""
            echo "Monitor the pod:"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c nginx"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c log-processor"
            echo ""
            echo "Run 'bash $0 cleanup' to remove all resources"
            ;;
        "cleanup")
            cleanup
            ;;
        "test")
            verify_deployment
            performance_test
            ;;
        *)
            echo "Usage: $0 [deploy|cleanup|test]"
            echo "  deploy  - Deploy the production pod (default)"
            echo "  cleanup - Remove all created resources"
            echo "  test    - Run verification and performance tests"
            ;;
    esac
}

main "$@"
```

### üéØ Mini-Project 4: Pod Chaos Engineering

Test pod resilience with chaos engineering principles:

```yaml
# chaos-test-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: chaos-resilient-app
  labels:
    app: chaos-test
    resilience: enabled
spec:
  containers:
  - name: main-app
    image: nginx:1.21-alpine
    ports:
    - containerPort: 80
    
    # Aggressive resource limits to test resilience
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    # Tight health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 2
      
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
      timeoutSeconds: 1
      failureThreshold: 2
      
    # Graceful shutdown
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 10"]
          
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  # Chaos monkey sidecar
  - name: chaos-monkey
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Chaos monkey starting..."
      
      # Function to create CPU load
      cpu_chaos() {
        echo "Creating CPU chaos..."
        for i in {1..4}; do
          yes > /dev/null &
        done
        sleep 30
        killall yes
      }
      
      # Function to create memory pressure
      memory_chaos() {
        echo "Creating memory chaos..."
        cat <(yes | tr \\n x | head -c 50000000) <(yes | tr \\n x | head -c 50000000) > /tmp/memory_eater &
        sleep 20
        rm -f /tmp/memory_eater
        killall cat
      }
      
      # Function to simulate network issues
      network_chaos() {
        echo "Creating network chaos..."
        # Simulate slow responses
        sleep $((RANDOM % 10 + 5))
      }
      
      # Function to create disk I/O pressure
      disk_chaos() {
        echo "Creating disk I/O chaos..."
        dd if=/dev/zero of=/tmp/disk_eater bs=1M count=10 2>/dev/null
        rm -f /tmp/disk_eater
      }
      
      # Main chaos loop
      while true; do
        chaos_type=$((RANDOM % 4))
        case $chaos_type in
          0) cpu_chaos ;;
          1) memory_chaos ;;
          2) network_chaos ;;
          3) disk_chaos ;;
        esac
        
        # Wait between chaos events
        sleep $((RANDOM % 60 + 30))
      done
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir:
      sizeLimit: 100Mi
      
  restartPolicy: Always
```

**Chaos Testing Script:**
```bash
#!/bin/bash
# chaos-engineering-test.sh

echo "=== Chaos Engineering Test ==="

# Deploy the chaos test pod
kubectl apply -f chaos-test-pod.yaml

# Wait for it to be ready
echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/chaos-resilient-app --timeout=60s

# Monitor pod resilience
echo "Starting resilience monitoring (Ctrl+C to stop)..."

monitor_resilience() {
    while true; do
        timestamp=$(date '+%H:%M:%S')
        
        # Check pod status
        status=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.phase}')
        ready=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
        restarts=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.containerStatuses[0].restartCount}')
        
        # Test application responsiveness
        kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
        PF_PID=$!
        sleep 2
        
        response_time=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8080 2>/dev/null || echo "FAIL")
        kill $PF_PID 2>/dev/null
        
        # Get resource usage if available
        resources=""
        if kubectl top pod chaos-resilient-app &>/dev/null; then
            resources=$(kubectl top pod chaos-resilient-app --no-headers 2>/dev/null | awk '{print $2" "$3}')
        fi
        
        printf "[$timestamp] Status: $status | Ready: $ready | Restarts: $restarts | Response: ${response_time}s | Resources: $resources\n"
        
        sleep 5
    done
}

# Start monitoring in background
monitor_resilience &
MONITOR_PID=$!

# Generate additional load to test resilience
echo "Generating load to test resilience..."
for i in {1..100}; do
    kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
    PF_PID=$!
    sleep 1
    
    curl -s http://localhost:8080 > /dev/null &
    
    kill $PF_PID 2>/dev/null
    sleep 2
done

# Stop monitoring
kill $MONITOR_PID 2>/dev/null

echo "Chaos test completed. Check pod logs:"
echo "kubectl logs chaos-resilient-app -c main-app --tail=20"
echo "kubectl logs chaos-resilient-app -c chaos-monkey --tail=20"

# Cleanup
read -p "Delete the chaos test pod? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    kubectl delete -f chaos-test-pod.yaml
fi
```

---

## Advanced Pod Management Techniques

### üî¨ Expert-Level Examples

#### Example 7: Custom Pod Controller

Create a custom controller for specialized pod management:

```python
#!/usr/bin/env python3
# custom-pod-controller.py

import time
import yaml
import subprocess
import json
from datetime import datetime, timedelta

class PodController:
    def __init__(self):
        self.managed_pods = {}
        self.check_interval = 30  # seconds
        
    def log(self, message):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"[{timestamp}] {message}")
        
    def run_kubectl(self, command):
        """Execute kubectl command and return JSON output"""
        try:
            result = subprocess.run(
                f"kubectl {command} -o json",
                shell=True,
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                self.log(f"kubectl error: {result.stderr}")
                return None
        except Exception as e:
            self.log(f"Command execution error: {e}")
            return None
            
    def get_pods_by_label(self, label_selector):
        """Get pods matching label selector"""
        command = f"get pods -l {label_selector}"
        result = self.run_kubectl(command)
        return result.get('items', []) if result else []
        
    def create_pod(self, name, spec):
        """Create a pod with given specification"""
        pod_manifest = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'name': name,
                'labels': {
                    'managed-by': 'custom-controller',
                    'created': datetime.now().strftime('%Y%m%d-%H%M%S')
                }
            },
            'spec': spec
        }
        
        # Write manifest to temporary file
        with open(f'/tmp/{name}.yaml', 'w') as f:
            yaml.dump(pod_manifest, f)
            
        # Apply the manifest
        result = subprocess.run(
            f"kubectl apply -f /tmp/{name}.yaml",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Created pod: {name}")
            return True
        else:
            self.log(f"Failed to create pod {name}: {result.stderr}")
            return False
            
    def delete_pod(self, name):
        """Delete a pod"""
        result = subprocess.run(
            f"kubectl delete pod {name} --grace-period=30",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Deleted pod: {name}")
            return True
        else:
            self.log(f"Failed to delete pod {name}: {result.stderr}")
            return False
            
    def check_pod_health(self, pod):
        """Check if a pod is healthy based on custom criteria"""
        name = pod['metadata']['name']
        status = pod['status']
        
        # Check if pod is running
        if status.get('phase') != 'Running':
            return False, f"Pod {name} is not running (phase: {status.get('phase')})"
            
        # Check container statuses
        container_statuses = status.get('containerStatuses', [])
        for container in container_statuses:
            if not container.get('ready'):
                return False, f"Container {container['name']} not ready in pod {name}"
                
            # Check restart count
            restart_count = container.get('restartCount', 0)
            if restart_count > 5:
                return False, f"Container {container['name']} restarted {restart_count} times"
                
        # Check resource usage (if metrics available)
        metrics = self.get_pod_metrics(name)
        if metrics:
            cpu_usage = self.parse_cpu_usage(metrics.get('cpu', '0m'))
            memory_usage = self.parse_memory_usage(metrics.get('memory', '0Mi'))
            
            if cpu_usage > 800:  # 800 millicores
                return False, f"Pod {name} CPU usage too high: {cpu_usage}m"
                
            if memory_usage > 512:  # 512 Mi
                return False, f"Pod {name} memory usage too high: {memory_usage}Mi"
                
        return True, f"Pod {name} is healthy"
        
    def get_pod_metrics(self, pod_name):
        """Get pod resource metrics if available"""
        result = subprocess.run(
            f"kubectl top pod {pod_name} --no-headers",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            parts = result.stdout.strip().split()
            if len(parts) >= 3:
                return {
                    'cpu': parts[1],
                    'memory': parts[2]
                }
        return None
        
    def parse_cpu_usage(self, cpu_str):
        """Parse CPU usage from string like '100m' to millicores"""
        if cpu_str.endswith('m'):
            return int(cpu_str[:-1])
        return int(cpu_str) * 1000
        
    def parse_memory_usage(self, memory_str):
        """Parse memory usage from string like '128Mi' to Mi"""
        if memory_str.endswith('Mi'):
            return int(memory_str[:-2])
        elif memory_str.endswith('Gi'):
            return int(memory_str[:-2]) * 1024
        return int(memory_str) // (1024 * 1024)
        
    def auto_heal_pod(self, pod_name, reason):
        """Attempt to heal an unhealthy pod"""
        self.log(f"Attempting to heal pod {pod_name}: {reason}")
        
        # Strategy 1: Restart the pod
        if "restart" in reason.lower():
            return self.delete_pod(pod_name)  # Pod will be recreated if managed by controller
            
        # Strategy 2: Scale resources if high usage
        if "usage too high" in reason.lower():
            self.log(f"High resource usage detected for {pod_name}, marking for recreation")
            return self.delete_pod(pod_name)
            
        # Strategy 3: Generic restart
        return self.delete_pod(pod_name)
        
    def manage_workload(self, workload_config):
        """Manage a workload with desired replica count"""
        app_name = workload_config['name']
        desired_replicas = workload_config['replicas']
        pod_spec = workload_config['pod_spec']
        
        # Get current pods for this workload
        current_pods = self.get_pods_by_label(f"app={app_name},managed-by=custom-controller")
        current_count = len(current_pods)
        
        self.log(f"Managing workload {app_name}: current={current_count}, desired={desired_replicas}")
        
        # Scale up if needed
        if current_count < desired_replicas:
            for i in range(current_count, desired_replicas):
                pod_name = f"{app_name}-{i}"
                pod_spec_copy = pod_spec.copy()
                pod_spec_copy.setdefault('containers', [{}])[0]['env'] = [
                    {'name': 'REPLICA_ID', 'value': str(i)},
                    {'name': 'APP_NAME', 'value': app_name}
                ]
                self.create_pod(pod_name, pod_spec_copy)
                
        # Scale down if needed
        elif current_count > desired_replicas:
            pods_to_delete = current_pods[desired_replicas:]
            for pod in pods_to_delete:
                self.delete_pod(pod['metadata']['name'])
                
        # Health check existing pods
        for pod in current_pods[:desired_replicas]:
            healthy, reason = self.check_pod_health(pod)
            if not healthy:
                self.log(f"Pod unhealthy: {reason}")
                self.auto_heal_pod(pod['metadata']['name'], reason)
                
    def run_control_loop(self):
        """Main control loop"""
        self.log("Starting custom pod controller...")
        
        # Sample workload configuration
        workloads = [
            {
                'name': 'web-app',
                'replicas': 2,
                'pod_spec': {
                    'containers': [{
                        'name': 'nginx',
                        'image': 'nginx:1.21-alpine',
                        'ports': [{'containerPort': 80}],
                        'resources': {
                            'requests': {'memory': '64Mi', 'cpu': '50m'},
                            'limits': {'memory': '128Mi', 'cpu': '100m'}
                        },
                        'livenessProbe': {
                            'httpGet': {'path': '/', 'port': 80},
                            'initialDelaySeconds': 10,
                            'periodSeconds': 30
                        }
                    }],
                    'restartPolicy': 'Always'
                }
            }
        ]
        
        try:
            while True:
                self.log("Running control loop...")
                
                for workload in workloads:
                    try:
                        self.manage_workload(workload)
                    except Exception as e:
                        self.log(f"Error managing workload {workload['name']}: {e}")
                        
                self.log(f"Sleeping for {self.check_interval} seconds...")
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            self.log("Shutting down controller...")
            
        except Exception as e:
            self.log(f"Controller error: {e}")
            
    def cleanup(self):
        """Clean up managed resources"""
        self.log("Cleaning up managed pods...")
        pods = self.get_pods_by_label("managed-by=custom-controller")
        for pod in pods:
            self.delete_pod(pod['metadata']['name'])

if __name__ == "__main__":
    import sys
    
    controller = PodController()
    
    if len(sys.argv) > 1 and sys.argv[1] == "cleanup":
        controller.cleanup()
    else:
        controller.run_control_loop()
```

**Usage:**
```bash
# Make the script executable
chmod +x custom-pod-controller.py

# Install dependencies
pip3 install pyyaml

# Run the controller
python3 custom-pod-controller.py

# In another terminal, watch the managed pods
watch kubectl get pods -l managed-by=custom-controller

# Simulate pod failures
kubectl delete pod web-app-0  # Controller will recreate it

# Clean up when done
python3 custom-pod-controller.py cleanup
```

### üéØ Mini-Project 5: Pod Performance Optimization Lab

Create a comprehensive performance optimization laboratory:

```yaml
# performance-lab-setup.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: performance-lab
---
# Baseline pod - unoptimized
apiVersion: v1
kind: Pod
metadata:
  name: baseline-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: baseline
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "1000m"
      limits:
        memory: "2Gi"
        cpu: "2000m"
---
# Optimized pod - resource-efficient
apiVersion: v1
kind: Pod
metadata:
  name: optimized-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: optimized
spec:
  containers:
  - name: app
    image: nginx:1.21-alpine  # Smaller image
    resources:
      requests:
        memory: "64Mi"        # Right-sized requests
        cpu: "100m"
      limits:
        memory: "128Mi"       # Conservative limits
        cpu: "200m"
    # Optimized health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5   # Faster startup
      periodSeconds: 30        # Less frequent checks
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
    # Security optimizations
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
    # Volume optimizations
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp-dir
    emptyDir:
      medium: Memory  # Use memory for temp files
      sizeLimit: 64Mi
  - name: var-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: var-run
    emptyDir:
      sizeLimit: 32Mi
---
# High-performance pod with advanced optimizations
apiVersion: v1
kind: Pod
metadata:
  name: high-performance-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: high-performance
spec:
  # Pod-level optimizations
  priorityClassName: high-priority
  nodeSelector:
    node-type: performance
  tolerations:
  - key: performance-node
    operator: Equal
    value: "true"
    effect: NoSchedule
  # Network optimizations
  dnsPolicy: ClusterFirstWithHostNet
  dnsConfig:
    options:
    - name: ndots
      value: "1"
    - name: edns0
  containers:
  - name: app
    image: nginx:1.21-alpine
    # Optimized resource allocation
    resources:
      requests:
        memory: "128Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "256Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
    # Performance-tuned environment
    env:
    - name: NGINX_WORKER_PROCESSES
      value: "auto"
    - name: NGINX_WORKER_CONNECTIONS
      value: "1024"
    # Aggressive health checks for faster recovery
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 15
      timeoutSeconds: 2
      failureThreshold: 2
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 3
      timeoutSeconds: 1
      failureThreshold: 1
    # Startup optimization
    startupProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 1
      timeoutSeconds: 1
      failureThreshold: 10
    # Performance-optimized volumes
    volumeMounts:
    - name: high-speed-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
  volumes:
  - name: high-speed-tmp
    emptyDir:
      medium: Memory
      sizeLimit: 128Mi
  - name: nginx-cache
    emptyDir:
      medium: Memory
      sizeLimit: 256Mi
  - name: nginx-run
    emptyDir:
      medium: Memory
      sizeLimit: 64Mi
```

**Performance Benchmarking Script:**
```bash
#!/bin/bash
# performance-benchmark.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

NAMESPACE="performance-lab"

# Deploy the performance lab
setup_lab() {
    log "Setting up performance lab..."
    kubectl apply -f performance-lab-setup.yaml
    
    log "Waiting for pods to be ready..."
    kubectl wait --for=condition=Ready pod/baseline-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/optimized-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/high-performance-app -n $NAMESPACE --timeout=120s
    
    success "Performance lab setup complete"
}

# Measure startup time
measure_startup_time() {
    local pod_name=$1
    log "Measuring startup time for $pod_name..."
    
    # Delete and recreate pod to measure startup
    kubectl delete pod $pod_name -n $NAMESPACE
    local start_time=$(date +%s.%N)
    
    # Recreate the pod (extract from original manifest)
    kubectl get pod $pod_name -n $NAMESPACE -o yaml --export 2>/dev/null | kubectl apply -f - 2>/dev/null || {
        warning "Couldn't recreate pod automatically, recreating from manifest"
        kubectl apply -f performance-lab-setup.yaml
    }
    
    # Wait for ready and measure time
    kubectl wait --for=condition=Ready pod/$pod_name -n $NAMESPACE --timeout=120s
    local end_time=$(date +%s.%N)
    
    local startup_time=$(echo "$end_time - $start_time" | bc -l)
    echo "$startup_time"
}

# Run load test on a pod
load_test_pod() {
    local pod_name=$1
    local duration=${2:-30}
    local concurrency=${3:-10}
    
    log "Running load test on $pod_name (${duration}s, ${concurrency} concurrent)"
    
    # Start port forwarding
    kubectl port-forward pod/$pod_name -n $NAMESPACE 8080:80 >/dev/null 2>&1 &
    local pf_pid=$!
    sleep 3
    
    # Use Apache Bench for load testing
    local results_file="/tmp/ab_results_${pod_name}.txt"
    
    if command -v ab >/dev/null; then
        ab -n $((duration * concurrency)) -c $concurrency -g /tmp/gnuplot_${pod_name}.dat \
           http://localhost:8080/ > $results_file 2>&1
        
        # Extract key metrics
        local rps=$(grep "Requests per second" $results_file | awk '{print $4}')
        local response_time=$(grep "Time per request.*mean" $results_file | head -1 | awk '{print $4}')
        local failed_requests=$(grep "Failed requests" $results_file | awk '{print $3}')
        
        echo "RPS:$rps,ResponseTime:$response_time,Failed:$failed_requests"
    else
        # Fallback to curl-based test
        local start_time=$(date +%s)
        local requests=0
        local total_time=0
        
        for i in $(seq 1 $((duration * concurrency))); do
            local req_start=$(date +%s.%N)
            if curl -s http://localhost:8080 >/dev/null 2>&1; then
                ((requests++))
            fi
            local req_end=$(date +%s.%N)
            local req_time=$(echo "$req_end - $req_start" | bc -l)
            total_time=$(echo "$total_time + $req_time" | bc -l)
            
            # Basic rate limiting
            sleep 0.1
        done
        
        local avg_response_time=$(echo "scale=3; $total_time / $requests" | bc -l)
        local rps=$(echo "scale=2; $requests / $duration" | bc -l)
        
        echo "RPS:$rps,ResponseTime:$avg_response_time,Failed:0"
    fi
    
    kill $pf_pid 2>/dev/null
}

# Get resource usage metrics
get_resource_usage() {
    local pod_name=$1
    log "Getting resource usage for $pod_name..."
    
    if kubectl top pod $pod_name -n $NAMESPACE >/dev/null 2>&1; then
        kubectl top pod $pod_name -n $NAMESPACE --no-headers | awk '{print "CPU:"$2",Memory:"$3}'
    else
        echo "CPU:N/A,Memory:N/A"
    fi
}

# Comprehensive benchmark
run_comprehensive_benchmark() {
    log "Running comprehensive performance benchmark..."
    
    declare -A results
    local pods=("baseline-app" "optimized-app" "high-performance-app")
    
    echo "=== Performance Benchmark Results ===" > benchmark_results.txt
    echo "Timestamp: $(date)" >> benchmark_results.txt
    echo "" >> benchmark_results.txt
    
    for pod in "${pods[@]}"; do
        log "Benchmarking $pod..."
        
        # Startup time measurement
        log "Measuring startup time for $pod..."
        # Skip startup measurement in this demo to avoid pod recreation issues
        startup_time="N/A"
        
        # Resource usage
        resource_usage=$(get_resource_usage $pod)
        
        # Load test
        load_results=$(load_test_pod $pod 30 10)
        
        # Pod status information
        pod_info=$(kubectl get pod $pod -n $NAMESPACE -o custom-columns=STATUS:.status.phase,READY:.status.conditions[?\(@.type==\"Ready\"\)].status,RESTARTS:.status.containerStatuses[0].restartCount --no-headers)
        
        # Store results
        results[$pod]="Startup:$startup_time,Resources:$resource_usage,Load:$load_results,Status:$pod_info"
        
        # Write to file
        cat >> benchmark_results.txt <<EOF

=== $pod ===
Startup Time: $startup_time seconds
Resource Usage: $resource_usage
Load Test Results: $load_results
Pod Status: $pod_info

EOF
    done
    
    # Generate comparison summary
    cat >> benchmark_results.txt <<EOF

=== Performance Summary ===
This benchmark compares three pod configurations:

1. Baseline App: Standard configuration with generous resource allocation
2. Optimized App: Resource-efficient with security hardening
3. High-Performance App: Maximum performance optimizations

Key Findings:
- Resource efficiency varies significantly between configurations
- Startup time impacts overall application availability
- Load handling capacity differs based on resource allocation
- Security optimizations may have performance trade-offs

Recommendations:
- Use optimized configuration for production workloads
- Consider high-performance setup for critical applications
- Monitor resource usage to fine-tune allocations
- Balance security and performance based on requirements

EOF
    
    success "Benchmark completed. Results saved to benchmark_results.txt"
    cat benchmark_results.txt
}

# Resource monitoring script
monitor_resources() {
    local duration=${1:-300}  # 5 minutes default
    log "Starting resource monitoring for ${duration} seconds..."
    
    local monitor_file="resource_monitor_$(date +%Y%m%d_%H%M%S).log"
    
    {
        echo "Timestamp,Pod,CPU,Memory,Status"
        local end_time=$(($(date +%s) + duration))
        
        while [ $(date +%s) -lt $end_time ]; do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            
            for pod in baseline-app optimized-app high-performance-app; do
                if kubectl get pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                    local status=$(kubectl get pod $pod -n $NAMESPACE -o jsonpath='{.status.phase}')
                    local usage="N/A,N/A"
                    
                    if kubectl top pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                        usage=$(kubectl top pod $pod -n $NAMESPACE --no-headers | awk '{print $2","$3}')
                    fi
                    
                    echo "$timestamp,$pod,$usage,$status"
                fi
            done
            
            sleep 10
        done
    } > $monitor_file
    
    success "Resource monitoring completed. Data saved to $monitor_file"
    
    # Generate simple analysis
    log "Generating resource usage analysis..."
    
    {
        echo "=== Resource Usage Analysis ==="
        echo ""
        
        for pod in baseline-app optimized-app high-performance-app; do
            echo "=== $pod ==="
            grep "$pod" $monitor_file | tail -10 | while IFS=',' read timestamp pod_name cpu memory status; do
                echo "[$timestamp] CPU: $cpu, Memory: $memory, Status: $status"
            done
            echo ""
        done
    } > resource_analysis.txt
    
    success "Analysis saved to resource_analysis.txt"
}

# Cleanup function
cleanup_lab() {
    log "Cleaning up performance lab..."
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -f benchmark_results.txt resource_*.log resource_analysis.txt
    rm -f /tmp/ab_results_*.txt /tmp/gnuplot_*.dat
    success "Cleanup completed"
}

# Main execution
main() {
    case "${1:-benchmark}" in
        "setup")
            setup_lab
            ;;
        "benchmark")
            setup_lab
            run_comprehensive_benchmark
            ;;
        "monitor")
            monitor_resources "${2:-300}"
            ;;
        "cleanup")
            cleanup_lab
            ;;
        "all")
            setup_lab
            run_comprehensive_benchmark
            monitor_resources 300
            echo ""
            success "Complete performance analysis finished!"
            echo "Files created:"
            echo "  - benchmark_results.txt"
            echo "  - resource_monitor_*.log"
            echo "  - resource_analysis.txt"
            ;;
        *)
            echo "Performance Lab - Pod Optimization Benchmark"
            echo ""
            echo "Usage: $0 <command> [options]"
            echo ""
            echo "Commands:"
            echo "  setup      - Set up the performance lab environment"
            echo "  benchmark  - Run comprehensive performance benchmark"
            echo "  monitor    - Monitor resource usage for specified duration"
            echo "  cleanup    - Remove all lab resources"
            echo "  all        - Run complete analysis (setup + benchmark + monitor)"
            echo ""
            echo "Examples:"
            echo "  $0 setup"
            echo "  $0 benchmark"
            echo "  $0 monitor 600  # Monitor for 10 minutes"
            echo "  $0 all          # Complete analysis"
            ;;
    esac
}

main "$@"
```

---

## Pod Troubleshooting Methodologies

### üîß Advanced Troubleshooting Toolkit

#### Example 8: Automated Diagnostic System

```bash
#!/bin/bash
# advanced-pod-diagnostics.sh

set -euo pipefail

# Enhanced diagnostic toolkit with automated problem detection
class PodDiagnostics {
    
# Configuration
NAMESPACE=${NAMESPACE:-default}
OUTPUT_DIR="./diagnostics-$(date +%Y%m%d-%H%M%S)"
VERBOSE=${VERBOSE:-false}

# Colors and formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'
BOLD='\033[1m'

# Logging functions with levels
log_debug() { [[ $VERBOSE == "true" ]] && echo -e "${CYAN}[DEBUG]${NC} $1"; }
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }

# Initialize diagnostics
init_diagnostics() {
    log_info "Initializing pod diagnostics system..."
    mkdir -p "$OUTPUT_DIR"/{logs,reports,metrics,manifests}
    
    # Create diagnostic report header
    cat > "$OUTPUT_DIR/diagnostic_report.md" <<EOF
# Pod Diagnostics Report

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)  
**Namespace:** $NAMESPACE  
**Output Directory:** $OUTPUT_DIR

---

EOF
    
    log_success "Diagnostics initialized in $OUTPUT_DIR"
}

# Comprehensive pod information gathering
gather_pod_info() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Gathering comprehensive information for pod: $pod_name"
    
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    mkdir -p "$pod_dir"
    
    # Basic pod information
    kubectl get pod "$pod_name" -n "$namespace" -o wide > "$pod_dir/basic_info.txt" 2>&1
    kubectl get pod "$pod_name" -n "$namespace" -o yaml > "$pod_dir/manifest.yaml" 2>&1
    
    # Detailed description
    kubectl describe pod "$pod_name" -n "$namespace" > "$pod_dir/description.txt" 2>&1
    
    # Events related to the pod
    kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
        --sort-by='.lastTimestamp' > "$pod_dir/events.txt" 2>&1
    
    # Container logs
    local containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}' 2>/dev/null)
    for container in $containers; do
        log_debug "Collecting logs for container: $container"
        kubectl logs "$pod_name" -n "$namespace" -c "$container" > "$pod_dir/logs_${container}.txt" 2>&1
        
        # Previous logs if container restarted
        kubectl logs "$pod_name" -n "$namespace" -c "$container" --previous > "$pod_dir/logs_${container}_previous.txt" 2>&1 || true
    done
    
    # Resource usage
    kubectl top pod "$pod_name" -n "$namespace" > "$pod_dir/resource_usage.txt" 2>&1 || echo "Metrics not available" > "$pod_dir/resource_usage.txt"
    
    log_success "Pod information gathered for $pod_name"
}

# Automated problem detection
detect_common_issues() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Running automated issue detection for $pod_name..."
    
    local issues_file="$pod_dir/detected_issues.md"
    echo "# Automated Issue Detection Report" > "$issues_file"
    echo "**Pod:** $pod_name" >> "$issues_file"
    echo "**Analysis Time:** $(date)" >> "$issues_file"
    echo "" >> "$issues_file"
    
    local issue_count=0
    
    # Check 1: Pod phase issues
    local phase=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.phase}' 2>/dev/null)
    if [[ "$phase" != "Running" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Pod Not Running
- **Severity:** High
- **Status:** Pod is in '$phase' phase instead of 'Running'
- **Impact:** Application unavailable
- **Investigation:** Check pod events and container status

EOF
    fi
    
    # Check 2: Container readiness issues
    local ready_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[?(@.ready==true)]}' | jq '. | length' 2>/dev/null || echo "0")
    local total_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers}' | jq '. | length' 2>/dev/null || echo "1")
    
    if [[ "$ready_containers" -lt "$total_containers" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Container Readiness Problems
- **Severity:** High
- **Status:** Only $ready_containers of $total_containers containers are ready
- **Impact:** Traffic routing may be affected
- **Investigation:** Check readiness probes and container logs

EOF
    fi
    
    # Check 3: Excessive restarts
    local restarts=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
    if [[ "$restarts" -gt 5 ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Excessive Container Restarts
- **Severity:** Medium
- **Status:** Container has restarted $restarts times
- **Impact:** Service instability and potential data loss
- **Investigation:** Check liveness probes, resource limits, and application logs

EOF
    fi
    
    # Check 4: Resource usage issues
    if kubectl top pod "$pod_name" -n "$namespace" >/dev/null 2>&1; then
        local cpu_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $2}' | sed 's/m$//')
        local memory_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $3}' | sed 's/Mi$//')
        
        if [[ "$cpu_usage" -gt 800 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High CPU Usage
- **Severity:** Medium
- **Status:** CPU usage is ${cpu_usage}m (> 800m threshold)
- **Impact:** Performance degradation and potential throttling
- **Investigation:** Check for CPU-intensive processes and consider scaling

EOF
        fi
        
        if [[ "$memory_usage" -gt 512 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High Memory Usage
- **Severity:** Medium  
- **Status:** Memory usage is ${memory_usage}Mi (> 512Mi threshold)
- **Impact:** Risk of OOM kills and service disruption
- **Investigation:** Check for memory leaks and optimize memory usage

EOF
        fi
    fi
    
    # Check 5: Image pull issues
    if grep -q "ImagePullBackOff\|ErrImagePull" "$pod_dir/description.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Image Pull Problems
- **Severity:** High
- **Status:** Unable to pull container image
- **Impact:** Pod cannot start
- **Investigation:** Check image name, registry access, and credentials

EOF
    fi
    
    # Check 6: Resource constraints
    if grep -q "Insufficient.*resources" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Resource Constraints
- **Severity:** High
- **Status:** Insufficient cluster resources for pod scheduling
- **Impact:** Pod cannot be scheduled
- **Investigation:** Check cluster capacity and node resources

EOF
    fi
    
    # Check 7: Network issues
    if grep -q "NetworkNotReady\|CNI.*error" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Network Configuration Problems
- **Severity:** High
- **Status:** Network setup issues detected
- **Impact:** Pod networking may not function correctly
- **Investigation:** Check CNI configuration and network policies

EOF
    fi
    
    # Summary
    if [[ $issue_count -eq 0 ]]; then
        echo "## Summary: No Critical Issues Detected ‚úÖ" >> "$issues_file"
        echo "The automated analysis found no obvious problems with this pod." >> "$issues_file"
        log_success "No critical issues detected for $pod_name"
    else
        echo "## Summary: $issue_count Issue(s) Detected ‚ö†Ô∏è" >> "$issues_file"
        echo "Review the issues above and follow the investigation recommendations." >> "$issues_file"
        log_warn "$issue_count issue(s) detected for $pod_name"
    fi
    
    return $issue_count
}

# Generate recommendations
generate_recommendations() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Generating recommendations for $pod_name..."
    
    local rec_file="$pod_dir/recommendations.md"
    echo "# Optimization Recommendations" > "$rec_file"
    echo "**Pod:** $pod_name" >> "$rec_file"
    echo "" >> "$rec_file"
    
    # Resource optimization recommendations
    echo "## Resource Optimization" >> "$rec_file"
    
    # Check current resource configuration
    local requests_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.memory}' 2>/dev/null || echo "not set")
    local requests_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.cpu}' 2>/dev/null || echo "not set")
    local limits_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.memory}' 2>/dev/null || echo "not set")
    local limits_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.cpu}' 2>/dev/null || echo "not set")
    
    cat >> "$rec_file" <<EOF
### Current Resource Configuration
- **Memory Request:** $requests_mem
- **CPU Request:** $requests_cpu  
- **Memory Limit:** $limits_mem
- **CPU Limit:** $limits_cpu

EOF
    
    # Security recommendations
    echo "## Security Hardening" >> "$rec_file"
    
    local security_context=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.securityContext}' 2>/dev/null)
    if [[ -z "$security_context" || "$security_context" == "null" ]]; then
        cat >> "$rec_file" <<EOF
### Security Context Improvements
- ‚úÖ **Add security context:** Configure runAsNonRoot, runAsUser, and fsGroup
- ‚úÖ **Drop capabilities:** Remove unnecessary Linux capabilities  
- ‚úÖ **Read-only root filesystem:** Set readOnlyRootFilesystem: true
- ‚úÖ **Prevent privilege escalation:** Set allowPrivilegeEscalation: false

EOF
    fi
    
    # Health check recommendations
    echo "## Health Check Optimization" >> "$rec_file"
    
    local has_liveness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].livenessProbe}' 2>/dev/null)
    local has_readiness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].readinessProbe}' 2>/dev/null)
    
    if [[ -z "$has_liveness" || "$has_liveness" == "null" ]]; then
        echo "- ‚úÖ **Add liveness probe:** Implement health checking for automatic restart" >> "$rec_file"
    fi
    
    if [[ -z "$has_readiness" || "$has_readiness" == "null" ]]; then
        echo "- ‚úÖ **Add readiness probe:** Control traffic routing based on application readiness" >> "$rec_file"
    fi
    
    # Performance recommendations
    echo "" >> "$rec_file"
    echo "## Performance Optimization" >> "$rec_file"
    cat >> "$rec_file" <<EOF
- ‚úÖ **Use Alpine images:** Reduce image size and startup time
- ‚úÖ **Implement resource requests:** Help scheduler make better placement decisions
- ‚úÖ **Optimize health check frequency:** Balance responsiveness with overhead
- ‚úÖ **Use memory-backed volumes:** For temporary files and caches
- ‚úÖ **Configure DNS caching:** Reduce DNS lookup overhead

EOF
    
    log_success "Recommendations generated for $pod_name"
}

# Interactive diagnostic session
interactive_diagnostics() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Starting interactive diagnostics for $pod_name..."
    
    echo -e "${BOLD}Interactive Pod Diagnostics${NC}"
    echo "Pod: $pod_name"
    echo "Namespace: $namespace"
    echo ""
    
    while true; do
        echo -e "${CYAN}Available actions:${NC}"
        echo "1) Show pod status"
        echo "2) View recent events"
        echo "3) Check container logs"
        echo "4) Execute command in pod"
        echo "5) Port forward to pod"
        echo "6) Resource usage"
        echo "7) Run full diagnostic"
        echo "8) Generate recommendations"
        echo "q) Quit"
        echo ""
        
        read -p "Select action [1-8,q]: " choice
        
        case $choice in
            1)
                echo "=== Pod Status ==="
                kubectl get pod "$pod_name" -n "$namespace" -o wide
```" \
        15
    
    echo ""
    echo "üè∑Ô∏è  Metadata and Labels"
    echo "----------------------"
    
    check_item "App label present" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.metadata.labels.app}' | grep -v '^
                kubectl describe pod "$pod_name" -n "$namespace" | grep -A 10 "Status\|Conditions"
                ;;
            2)
                echo "=== Recent Events ==="
                kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
                    --sort-by='.lastTimestamp' | tail -10
                ;;
            3)
                echo "=== Container Selection ==="
                local containers=($(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}'))
                if [[ ${#containers[@]} -eq 1 ]]; then
                    echo "Showing logs for container: ${containers[0]}"
                    kubectl logs "$pod_name" -n "$namespace" --tail=50
                else
                    echo "Available containers:"
                    for i in "${!containers[@]}"; do
                        echo "$((i+1))) ${containers[i]}"
                    done
                    read -p "Select container [1-${#containers[@]}]: " container_choice
                    if [[ $container_choice -ge 1 && $container_choice -le ${#containers[@]} ]]; then
                        local selected_container=${containers[$((container_choice-1))]}
                        echo "Showing logs for container: $selected_container"
                        kubectl logs "$pod_name" -n "$namespace" -c "$selected_container" --tail=50
                    fi
                fi
                ;;
            4)
                read -p "Enter command to execute: " exec_command
                kubectl exec -it "$pod_name" -n "$namespace" -- $exec_command
                ;;
            5)
                read -p "Enter local port: " local_port
                read -p "Enter pod port: " pod_port
                echo "Port forwarding $local_port:$pod_port - Press Ctrl+C to stop"
                kubectl port-forward "$pod_name" -n "$namespace" "$local_port:$pod_port"
                ;;
            6)
                echo "=== Resource Usage ==="
                kubectl top pod "$pod_name" -n "$namespace" 2>/dev/null || echo "Metrics not available"
                ;;
            7)
                gather_pod_info "$pod_name" "$namespace"
                detect_common_issues "$pod_name" "$namespace"
                generate_recommendations "$pod_name" "$namespace"
                echo "Full diagnostic completed. Check $OUTPUT_DIR/pods/$pod_name/"
                ;;
            8)
                generate_recommendations "$pod_name" "$namespace"
                echo "Recommendations generated. Check $OUTPUT_DIR/pods/$pod_name/recommendations.md"
                ;;
            q|Q)
                log_info "Exiting interactive diagnostics"
                break
                ;;
            *)
                echo "Invalid choice. Please try again."
                ;;
        esac
        
        echo ""
        read -p "Press Enter to continue..."
        echo ""
    done
}

# Cluster-wide pod health assessment
cluster_health_assessment() {
    log_info "Running cluster-wide pod health assessment..."
    
    local health_report="$OUTPUT_DIR/cluster_health_report.md"
    
    cat > "$health_report" <<EOF
# Cluster Pod Health Assessment

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)

---

EOF
    
    # Get all namespaces
    local namespaces=($(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'))
    
    local total_pods=0
    local healthy_pods=0
    local unhealthy_pods=0
    
    for ns in "${namespaces[@]}"; do
        log_info "Assessing namespace: $ns"
        
        local pods=($(kubectl get pods -n "$ns" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null))
        
        if [[ ${#pods[@]} -eq 0 ]]; then
            continue
        fi
        
        echo "## Namespace: $ns" >> "$health_report"
        echo "" >> "$health_report"
        
        local ns_healthy=0
        local ns_unhealthy=0
        
        for pod in "${pods[@]}"; do
            ((total_pods++))
            
            local phase=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.phase}')
            local ready_condition=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
            local restarts=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
            
            if [[ "$phase" == "Running" && "$ready_condition" == "True" && $restarts -lt 5 ]]; then
                ((healthy_pods++))
                ((ns_healthy++))
                echo "‚úÖ **$pod** - Healthy" >> "$health_report"
            else
                ((unhealthy_pods++))
                ((ns_unhealthy++))
                echo "‚ùå **$pod** - Issues detected (Phase: $phase, Ready: $ready_condition, Restarts: $restarts)" >> "$health_report"
                
                # Run quick diagnostics for unhealthy pods
                gather_pod_info "$pod" "$ns"
                detect_common_issues "$pod" "$ns"
            fi
        done
        
        echo "" >> "$health_report"
        echo "**Namespace Summary:** $ns_healthy healthy, $ns_unhealthy unhealthy" >> "$health_report"
        echo "" >> "$health_report"
    done
    
    # Overall summary
    local health_percentage=$((healthy_pods * 100 / total_pods))
    
    cat >> "$health_report" <<EOF

---

## Overall Cluster Health

- **Total Pods:** $total_pods
- **Healthy Pods:** $healthy_pods
- **Unhealthy Pods:** $unhealthy_pods
- **Health Percentage:** $health_percentage%

### Health Status
EOF
    
    if [[ $health_percentage -ge 90 ]]; then
        echo "üü¢ **EXCELLENT** - Cluster is in excellent health" >> "$health_report"
    elif [[ $health_percentage -ge 75 ]]; then
        echo "üü° **GOOD** - Cluster is in good health with minor issues" >> "$health_report"
    elif [[ $health_percentage -ge 50 ]]; then
        echo "üü† **WARNING** - Cluster has significant health issues" >> "$health_report"
    else
        echo "üî¥ **CRITICAL** - Cluster is in critical condition" >> "$health_report"
    fi
    
    log_success "Cluster health assessment completed. Report: $health_report"
}

# Generate comprehensive diagnostic report
generate_final_report() {
    log_info "Generating comprehensive diagnostic report..."
    
    local final_report="$OUTPUT_DIR/comprehensive_report.html"
    
    cat > "$final_report" <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Pod Diagnostics Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
        .header { background-color: #f4f4f4; padding: 20px; border-radius: 5px; margin-bottom: 30px; }
        .section { margin: 30px 0; }
        .pod-card { border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin: 10px 0; }
        .healthy { border-left: 5px solid #28a745; }
        .unhealthy { border-left: 5px solid #dc3545; }
        .warning { border-left: 5px solid #ffc107; }
        .metric { display: inline-block; margin: 10px 15px 10px 0; padding: 8px 12px; background-color: #e9ecef; border-radius: 3px; }
        .issue { background-color: #fff3cd; padding: 10px; border-radius: 3px; margin: 10px 0; }
        pre { background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }
        .tabs { border-bottom: 1px solid #ddd; margin-bottom: 20px; }
        .tab { display: inline-block; padding: 10px 20px; cursor: pointer; border-bottom: 2px solid transparent; }
        .tab.active { border-bottom-color: #007bff; color: #007bff; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }
    </style>
    <script>
        function showTab(tabName) {
            // Hide all tab contents
            var contents = document.getElementsByClassName('tab-content');
            for (var i = 0; i < contents.length; i++) {
                contents[i].classList.remove('active');
            }
            
            // Remove active class from all tabs
            var tabs = document.getElementsByClassName('tab');
            for (var i = 0; i < tabs.length; i++) {
                tabs[i].classList.remove('active');
            }
            
            // Show selected tab content and mark tab as active
            document.getElementById(tabName).classList.add('active');
            event.target.classList.add('active');
        }
    </script>
</head>
<body>
    <div class="header">
        <h1>üîç Pod Diagnostics Report</h1>
        <div class="metric">
            <strong>Generated:</strong> $(date)
        </div>
        <div class="metric">
            <strong>Cluster:</strong> $(kubectl config current-context)
        </div>
        <div class="metric">
            <strong>Diagnostics Version:</strong> 2.0
        </div>
    </div>
    
    <div class="tabs">
        <div class="tab active" onclick="showTab('overview')">Overview</div>
        <div class="tab" onclick="showTab('pods')">Pod Analysis</div>
        <div class="tab" onclick="showTab('issues')">Detected Issues</div>
        <div class="tab" onclick="showTab('recommendations')">Recommendations</div>
    </div>
    
    <div id="overview" class="tab-content active">
        <h2>üìä Cluster Overview</h2>
        <div class="section">
EOF
    
    # Add cluster metrics
    local total_nodes=$(kubectl get nodes --no-headers | wc -l)
    local ready_nodes=$(kubectl get nodes --no-headers | grep " Ready " | wc -l)
    local total_namespaces=$(kubectl get namespaces --no-headers | wc -l)
    
    cat >> "$final_report" <<EOF
            <div class="pod-card healthy">
                <h3>Cluster Metrics</h3>
                <div class="metric"><strong>Nodes:</strong> $ready_nodes/$total_nodes Ready</div>
                <div class="metric"><strong>Namespaces:</strong> $total_namespaces</div>
                <div class="metric"><strong>Kubernetes Version:</strong> $(kubectl version --short --client | cut -d' ' -f3)</div>
            </div>
        </div>
    </div>
    
    <div id="pods" class="tab-content">
        <h2>üöÄ Pod Analysis</h2>
EOF
    
    # Add pod analysis for each analyzed pod
    for pod_dir in "$OUTPUT_DIR"/pods/*/; do
        if [[ -d "$pod_dir" ]]; then
            local pod_name=$(basename "$pod_dir")
            local issues_count=0
            
            if [[ -f "$pod_dir/detected_issues.md" ]]; then
                issues_count=$(grep -c "## Issue" "$pod_dir/detected_issues.md" 2>/dev/null || echo "0")
            fi
            
            local card_class="healthy"
            if [[ $issues_count -gt 0 ]]; then
                card_class="unhealthy"
            fi
            
            cat >> "$final_report" <<EOF
        <div class="pod-card $card_class">
            <h3>üì¶ $pod_name</h3>
            <div class="metric"><strong>Issues Detected:</strong> $issues_count</div>
            <div class="metric"><strong>Analysis Files:</strong> $(ls "$pod_dir" | wc -l)</div>
            <div class="metric"><strong>Report Location:</strong> pods/$pod_name/</div>
        </div>
EOF
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="issues" class="tab-content">
        <h2>‚ö†Ô∏è Detected Issues</h2>
EOF
    
    # Aggregate all issues
    local total_issues=0
    for issues_file in "$OUTPUT_DIR"/pods/*/detected_issues.md; do
        if [[ -f "$issues_file" ]]; then
            local pod_issues=$(grep -c "## Issue" "$issues_file" 2>/dev/null || echo "0")
            ((total_issues += pod_issues))
            
            if [[ $pod_issues -gt 0 ]]; then
                local pod_name=$(basename "$(dirname "$issues_file")")
                echo "<h3>Issues for $pod_name</h3>" >> "$final_report"
                
                # Convert markdown issues to HTML
                grep "## Issue" "$issues_file" | while read -r line; do
                    echo "<div class=\"issue\">$line</div>" >> "$final_report"
                done
            fi
        fi
    done
    
    if [[ $total_issues -eq 0 ]]; then
        echo "<div class=\"pod-card healthy\"><h3>‚úÖ No Issues Detected</h3><p>All analyzed pods appear to be healthy!</p></div>" >> "$final_report"
    fi
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="recommendations" class="tab-content">
        <h2>üí° Recommendations</h2>
        <div class="section">
            <div class="pod-card warning">
                <h3>General Recommendations</h3>
                <ul>
                    <li>‚úÖ Implement comprehensive health checks for all pods</li>
                    <li>‚úÖ Set appropriate resource requests and limits</li>
                    <li>‚úÖ Use security contexts to harden pod security</li>
                    <li>‚úÖ Monitor resource usage and optimize accordingly</li>
                    <li>‚úÖ Implement graceful shutdown handling</li>
                    <li>‚úÖ Use multi-stage Docker builds for smaller images</li>
                    <li>‚úÖ Implement proper logging and observability</li>
                </ul>
            </div>
        </div>
EOF
    
    # Add pod-specific recommendations
    for rec_file in "$OUTPUT_DIR"/pods/*/recommendations.md; do
        if [[ -f "$rec_file" ]]; then
            local pod_name=$(basename "$(dirname "$rec_file")")
            echo "<div class=\"pod-card\"><h3>Recommendations for $pod_name</h3>" >> "$final_report"
            echo "<p>See detailed recommendations in: pods/$pod_name/recommendations.md</p></div>" >> "$final_report"
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div class="section">
        <hr>
        <p><em>Report generated by Pod Diagnostics Toolkit v2.0</em></p>
        <p><em>For detailed analysis, check individual files in the diagnostics output directory.</em></p>
    </div>
    
</body>
</html>
EOF
    
    log_success "Comprehensive report generated: $final_report"
    echo ""
    echo -e "${BOLD}üìã Diagnostic Summary:${NC}"
    echo "- Output Directory: $OUTPUT_DIR"
    echo "- HTML Report: $final_report"
    echo "- Total Issues Found: $total_issues"
    echo ""
    echo -e "${CYAN}üí° Next Steps:${NC}"
    echo "1. Open $final_report in your browser"
    echo "2. Review individual pod analysis in $OUTPUT_DIR/pods/"
    echo "3. Implement recommended fixes"
    echo "4. Re-run diagnostics to verify improvements"
}

# Main execution function
main() {
    local command=${1:-help}
    local pod_name=${2:-}
    local namespace=${3:-$NAMESPACE}
    
    case "$command" in
        "analyze")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for analysis"
                echo "Usage: $0 analyze <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            gather_pod_info "$pod_name" "$namespace"
            detect_common_issues "$pod_name" "$namespace"
            generate_recommendations "$pod_name" "$namespace"
            generate_final_report
            ;;
            
        "interactive")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for interactive mode"
                echo "Usage: $0 interactive <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            interactive_diagnostics "$pod_name" "$namespace"
            ;;
            
        "cluster-health")
            init_diagnostics
            cluster_health_assessment
            generate_final_report
            ;;
            
        "help"|*)
            cat <<EOF
üîç Advanced Pod Diagnostics Toolkit

Usage: $0 <command> [options]

Commands:
  analyze <pod-name> [namespace]     - Run comprehensive pod analysis
  interactive <pod-name> [namespace] - Start interactive diagnostic session
  cluster-health                     - Assess health of all pods in cluster
  help                              - Show this help message

Environment Variables:
  NAMESPACE - Default namespace (default: default)
  VERBOSE   - Enable verbose output (default: false)

Examples:
  $0 analyze nginx-pod production
  $0 interactive web-app-123
  $0 cluster-health
  VERBOSE=true $0 analyze problematic-pod

Output:
  All diagnostic data is saved to ./diagnostics-TIMESTAMP/
  HTML report provides comprehensive overview
  Individual pod analysis available in pods/ subdirectory

EOF
            ;;
    esac
}

# Execute main function
main "$@"
```

---

## Summary and Production-Ready Examples

### üèÜ Complete Production Workflow

Let's create a final comprehensive example that brings everything together:

```yaml
# complete-production-workflow.yaml
# This represents a complete production-ready pod deployment workflow

apiVersion: v1
kind: Namespace
metadata:
  name: production-workload
  labels:
    environment: production
    team: platform
---
# ConfigMap for application configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production-workload
data:
  app.properties: |
    server.port=8080
    management.port=8081
    logging.level=INFO
    metrics.enabled=true
  nginx.conf: |
    server {
        listen 80;
        location /health { return 200 'healthy\n'; }
        location /ready { return 200 'ready\n'; }
        location / {
            proxy_pass http://127.0.0.1:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
---
# Secret for sensitive configuration
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: production-workload
type: Opaque
data:
  database-password: c3VwZXJzZWNyZXQ=  # supersecret (base64)
  api-key: YWJjZGVmZ2hpams=  # abcdefghijk (base64)
---
# Production-ready pod with all best practices
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production-workload
  labels:
    app: production-app
    version: "2.1.0"
    environment: production
    team: platform
    component: backend
  annotations:
    description: "Production application with full observability"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/production-app"
    prometheus.io/scrape: "true"
    prometheus.io/port: "8081"
    prometheus.io/path: "/metrics"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Resource constraints and node placement
  nodeSelector:
    node-type: "application"
    performance-tier: "high"
    
  tolerations:
  - key: "dedicated-app"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
    
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: production-app
        topologyKey: kubernetes.io/hostname
        
  # DNS and network configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  # Init container for setup tasks
  initContainers:
  - name: setup
    image: busybox:1.35
    command:
    - /bin/sh
    - -c
    - |
      echo "Initializing application..."
      
      # Database migration simulation
      echo "Running database migrations..."
      sleep 5
      
      # Cache warming
      echo "Warming up caches..."
      sleep 3
      
      # Configuration validation
      echo "Validating configuration..."
      if [ -f /config/app.properties ]; then
        echo "‚úÖ Configuration file found"
      else
        echo "‚ùå Configuration file missing"
        exit 1
      fi
      
      echo "Initialization completed successfully"
      
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-init
      mountPath: /tmp
      
  # Main application containers
  containers:
  # Application container
  - name: app
    image: openjdk:11-jre-slim
    command:
    - /bin/bash
    - -c
    - |
      echo "Starting application..."
      
      # Simulated application startup
      java -Xmx200m -Xms100m -jar /app/application.jar \
        --spring.config.location=file:/config/app.properties \
        --server.port=8080 \
        --management.server.port=8081
        
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP
    - name: management
      containerPort: 8081
      protocol: TCP
      
    # Environment configuration
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # Sensitive configuration from secrets
    - name: DATABASE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: database-password
    - name: API_KEY
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: api-key
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security hardening
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    # Comprehensive health checks
    livenessProbe:
      httpGet:
        path: /actuator/health/liveness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /actuator/health/readiness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /actuator/health
        port: 8081
      initialDelaySeconds: 20
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle management
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Application started at $(date)" >> /tmp/startup.log
            # Custom post-start logic here
            
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Graceful shutdown initiated at $(date)" >> /tmp/shutdown.log
            # Send SIGTERM to application
            kill -TERM 1
            # Wait for graceful shutdown
            sleep 30
            
    # Volume mounts
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-volume
      mountPath: /tmp
    - name: app-logs
      mountPath: /app/logs
    - name: app-data
      mountPath: /app/data
      
  # Nginx reverse proxy sidecar
  - name: nginx-proxy
    image: nginx:1.21-alpine
    ports:
    - name: http-proxy
      containerPort: 80
      protocol: TCP
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        add: ["NET_BIND_SERVICE"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: nginx-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
      
  # Logging and monitoring sidecar
  - name: log-shipper
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: fluent-tmp
      mountPath: /tmp
      
  # Volumes
  volumes:
  - name: config-volume
    configMap:
      name: app-config
      items:
      - key: app.properties
        path: app.properties
  - name: nginx-config
    configMap:
      name: app-config
      items:
      - key: nginx.conf
        path: default.conf
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config  # Would be created separately
  # Temporary and cache volumes
  - name: tmp-volume
    emptyDir:
      sizeLimit: 256Mi
  - name: tmp-init
    emptyDir:
      sizeLimit: 64Mi
  - name: nginx-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: fluent-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: nginx-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: nginx-run
    emptyDir:
      sizeLimit: 32Mi
  # Application data volumes
  - name: app-logs
    emptyDir:
      sizeLimit: 1Gi
  - name: app-data
    emptyDir:
      sizeLimit: 2Gi
```

This comprehensive example demonstrates:

- **Complete security hardening** with proper contexts and capabilities
- **Multi-container architecture** with main app, proxy, and logging sidecars
- **Comprehensive health checks** for all containers
- **Resource optimization** with appropriate requests and limits
- **Configuration management** using ConfigMaps and Secrets
- **Observability** with structured logging and metrics endpoints
- **Production-ready networking** with reverse proxy
- **Graceful lifecycle management** with init containers and shutdown hooks

## üéì Key Learning Outcomes

By working through these enhanced examples, demos, and mini-projects, you've gained:

1. **Foundation Skills**: Basic pod creation, inspection, and management
2. **Intermediate Capabilities**: Multi-container patterns, health monitoring, and debugging
3. **Advanced Techniques**: Performance optimization, security hardening, and automation
4. **Expert-Level Mastery**: Custom controllers, comprehensive diagnostics, and production workflows

### üöÄ Next Steps for Continued Learning

1. **Practice the Examples**: Work through each example in your own cluster
2. **Customize for Your Use Cases**: Adapt the patterns to your specific applications
3. **Build Your Toolkit**: Create your own diagnostic and management scripts
4. **Share and Learn**: Contribute back to the community with your own improvements
5. **Scale Up**: Apply these pod management skills to higher-level controllers

The journey from basic pod creation to# 5. Working with Pods - From Fundamentals to Mastery (Enhanced Edition)

Understanding how to work with pods effectively forms the foundation of all Kubernetes operations. While you'll typically use higher-level controllers like Deployments in production environments, direct pod management skills are essential for debugging, troubleshooting, and truly understanding how Kubernetes applications function at their core. Think of this knowledge as learning to drive a manual transmission car‚Äîeven if you usually drive automatic, understanding the underlying mechanics makes you a better driver overall.

This enhanced guide provides progressive examples, hands-on demos, and real-world mini-projects to solidify your understanding through practical application.

## üéØ Learning Path Overview

- **Foundation Level**: Basic pod creation and inspection
- **Intermediate Level**: Multi-container patterns and health checks
- **Advanced Level**: Complex debugging and optimization
- **Expert Level**: Custom tooling and automation

---

## Understanding Pod Creation Strategies

Creating pods effectively requires understanding when to use imperative commands versus declarative configurations, and how different creation approaches serve different purposes.

### üìö Foundation Examples

Let's start with the absolute basics and progressively build complexity.

#### Example 1: Your First Pod
```bash
# Create the simplest possible pod
kubectl run hello-world --image=nginx --restart=Never

# Verify it's running
kubectl get pods

# Expected output:
# NAME          READY   STATUS    RESTARTS   AGE
# hello-world   1/1     Running   0          30s
```

#### Example 2: Pod with Custom Commands
```bash
# Create a pod that runs a custom command
kubectl run date-pod --image=busybox --restart=Never -- date

# This pod will run the date command and then exit
# Check the output
kubectl logs date-pod

# Clean up
kubectl delete pod date-pod
```

#### Example 3: Interactive Pod Session
```bash
# Create an interactive debugging pod
kubectl run -it debug-pod --image=busybox --restart=Never -- sh

# Inside the pod, try these commands:
# ls -la
# ps aux
# ping google.com
# nslookup kubernetes.default.svc.cluster.local

# Exit and clean up
# exit
kubectl delete pod debug-pod
```

### üõ†Ô∏è Demo: Pod Lifecycle Observation

Let's create a demo that shows the complete pod lifecycle in action:

```bash
#!/bin/bash
# pod-lifecycle-demo.sh

echo "=== Pod Lifecycle Demonstration ==="

# Terminal 1: Start watching pods
echo "In a separate terminal, run: kubectl get pods -w"
echo "Press Enter when ready..."
read

# Create a pod with a slow-starting application
echo "Creating pod with slow startup..."
kubectl run lifecycle-demo --image=nginx --restart=Never \
  --dry-run=client -o yaml > lifecycle-pod.yaml

# Add some customizations to make it more interesting
cat <<EOF >> lifecycle-pod.yaml
  containers:
  - name: nginx
    image: nginx:1.21
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod starting up...' && sleep 10"
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod shutting down...' && sleep 5"
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 5
EOF

echo "Applying pod configuration..."
kubectl apply -f lifecycle-pod.yaml

echo "Watch the pod states change from Pending -> ContainerCreating -> Running"
echo "Press Enter to continue when pod is Running..."
read

# Show detailed pod information
echo "=== Pod Details ==="
kubectl describe pod lifecycle-demo

echo "Press Enter to delete the pod and observe termination..."
read

# Delete and watch termination
kubectl delete pod lifecycle-demo

echo "Demo complete! Clean up the YAML file:"
echo "rm lifecycle-pod.yaml"
```

### üéØ Mini-Project 1: Pod Resource Monitor

Create a simple monitoring system using pods:

```yaml
# resource-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-monitor
  labels:
    app: monitor
    type: demo
spec:
  containers:
  - name: monitor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Starting Resource Monitor..."
      while true; do
        echo "=== $(date) ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "Load average:"
        uptime
        echo "Sleeping for 30 seconds..."
        sleep 30
      done
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
  restartPolicy: Always
```

```bash
# Deploy and monitor
kubectl apply -f resource-monitor-pod.yaml

# Watch the logs
kubectl logs -f resource-monitor

# In another terminal, check resource usage
kubectl top pod resource-monitor

# Clean up
kubectl delete -f resource-monitor-pod.yaml
```

---

## Deep Pod Inspection and Monitoring

### üîç Intermediate Examples

#### Example 4: Multi-Container Pod Investigation

```yaml
# multi-container-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-demo
  labels:
    demo: multi-container
spec:
  containers:
  - name: web-server
    image: nginx:1.21
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
    
  - name: log-processor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Log processor starting..."
      while true; do
        if [ -f /var/log/nginx/access.log ]; then
          echo "=== Access Log Summary $(date) ==="
          tail -10 /var/log/nginx/access.log | wc -l
          echo "Recent requests:"
          tail -5 /var/log/nginx/access.log
        else
          echo "Waiting for access.log..."
        fi
        sleep 30
      done
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
      
  - name: metrics-collector
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Metrics collector starting..."
      while true; do
        echo "=== Metrics $(date) ==="
        echo "Container count: 3"
        echo "Uptime: $(uptime)"
        echo "Memory: $(free -h | grep Mem)"
        sleep 60
      done
      
  volumes:
  - name: shared-logs
    emptyDir: {}
```

**Inspection Commands:**
```bash
# Apply the multi-container pod
kubectl apply -f multi-container-demo.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/multi-container-demo

# Inspect different aspects
echo "=== Basic Information ==="
kubectl get pod multi-container-demo -o wide

echo "=== Container Status ==="
kubectl get pod multi-container-demo -o jsonpath='{.status.containerStatuses[*].name}' | tr ' ' '\n'

echo "=== Logs from each container ==="
kubectl logs multi-container-demo -c web-server --tail=5
kubectl logs multi-container-demo -c log-processor --tail=5
kubectl logs multi-container-demo -c metrics-collector --tail=5

# Generate some traffic to see shared volume in action
kubectl port-forward multi-container-demo 8080:80 &
PF_PID=$!

# Generate requests
for i in {1..10}; do
  curl -s http://localhost:8080 > /dev/null
  echo "Request $i sent"
  sleep 1
done

kill $PF_PID

# Check log processor output
kubectl logs multi-container-demo -c log-processor --tail=10

# Clean up
kubectl delete -f multi-container-demo.yaml
```

### üõ†Ô∏è Demo: Advanced Pod Debugging Techniques

```bash
#!/bin/bash
# advanced-debugging-demo.sh

echo "=== Advanced Pod Debugging Demo ==="

# Create a problematic pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: problematic-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "2000m"  # This might cause scheduling issues
      limits:
        memory: "512Mi"  # Less than request - invalid!
        cpu: "500m"
    livenessProbe:
      httpGet:
        path: /nonexistent
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
EOF

echo "Created a pod with multiple issues. Let's debug it..."

# Wait a moment for issues to manifest
sleep 10

echo "=== Debugging Steps ==="

echo "1. Check pod status:"
kubectl get pod problematic-pod -o wide

echo "2. Look at events:"
kubectl describe pod problematic-pod | grep -A 10 Events:

echo "3. Check for resource issues:"
kubectl describe pod problematic-pod | grep -A 5 -B 5 "resource"

echo "4. Examine container status:"
kubectl get pod problematic-pod -o jsonpath='{.status.containerStatuses[0]}' | jq '.'

# Fix the pod
echo "5. Let's fix the issues..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: fixed-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
EOF

echo "6. Compare the fixed pod:"
kubectl wait --for=condition=Ready pod/fixed-pod --timeout=60s
kubectl get pods -l debug=demo

# Clean up
echo "Cleaning up..."
kubectl delete pod problematic-pod fixed-pod
```

### üéØ Mini-Project 2: Pod Health Monitoring Dashboard

Create a comprehensive health monitoring system:

```yaml
# health-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: health-dashboard
  labels:
    app: health-monitor
spec:
  containers:
  - name: health-checker
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Health Dashboard Starting..."
      
      # Create a simple HTML dashboard
      mkdir -p /tmp/dashboard
      
      while true; do
        cat > /tmp/dashboard/health.html <<EOF
      <!DOCTYPE html>
      <html>
      <head>
          <title>Pod Health Dashboard</title>
          <meta http-equiv="refresh" content="30">
          <style>
              body { font-family: Arial, sans-serif; margin: 40px; }
              .healthy { color: green; }
              .warning { color: orange; }
              .critical { color: red; }
              .metric { margin: 10px 0; padding: 10px; border: 1px solid #ccc; }
          </style>
      </head>
      <body>
          <h1>Pod Health Dashboard</h1>
          <p>Last Update: $(date)</p>
          
          <div class="metric">
              <h3>System Load</h3>
              <p>$(uptime)</p>
          </div>
          
          <div class="metric">
              <h3>Memory Usage</h3>
              <pre>$(free -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Disk Usage</h3>
              <pre>$(df -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Process Count</h3>
              <p>Running processes: $(ps aux | wc -l)</p>
          </div>
          
      </body>
      </html>
      EOF
        
        echo "Dashboard updated at $(date)"
        sleep 30
      done
    volumeMounts:
    - name: dashboard-storage
      mountPath: /tmp/dashboard
      
  - name: web-server
    image: nginx:alpine
    ports:
    - containerPort: 80
    command:
    - /bin/sh
    - -c
    - |
      # Configure nginx to serve our dashboard
      cat > /etc/nginx/conf.d/default.conf <<EOF
      server {
          listen 80;
          location / {
              root /usr/share/nginx/html;
              index health.html;
          }
      }
      EOF
      
      # Start nginx
      nginx -g "daemon off;"
    volumeMounts:
    - name: dashboard-storage
      mountPath: /usr/share/nginx/html
      
  volumes:
  - name: dashboard-storage
    emptyDir: {}
    
  restartPolicy: Always
```

**Usage:**
```bash
# Deploy the health dashboard
kubectl apply -f health-monitor-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/health-dashboard

# Access the dashboard
kubectl port-forward health-dashboard 8080:80

# Open browser to http://localhost:8080
echo "Open http://localhost:8080 in your browser"

# Monitor the pod's own health
kubectl top pod health-dashboard

# Check logs from both containers
kubectl logs health-dashboard -c health-checker --tail=10
kubectl logs health-dashboard -c web-server --tail=10

# Clean up
kubectl delete -f health-monitor-pod.yaml
```

---

## Interactive Pod Management and Debugging

### üîß Advanced Examples

#### Example 5: Network Debugging Pod

```yaml
# network-debug-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: network-debugger
  labels:
    purpose: network-debug
spec:
  containers:
  - name: nettools
    image: nicolaka/netshoot
    command: ["/bin/bash"]
    args:
    - -c
    - |
      echo "Network debugging tools ready!"
      echo "Available tools: dig, nslookup, ping, curl, wget, tcpdump, netstat"
      echo "Example commands:"
      echo "  dig kubernetes.default.svc.cluster.local"
      echo "  ping 8.8.8.8"
      echo "  curl -I http://httpbin.org/headers"
      echo "  netstat -tulpn"
      
      # Keep container running
      sleep 3600
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
  restartPolicy: Never
```

**Debugging Session:**
```bash
# Deploy the network debugger
kubectl apply -f network-debug-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/network-debugger

# Start interactive session
kubectl exec -it network-debugger -- bash

# Inside the pod, run network diagnostics:
# Test DNS resolution
# dig kubernetes.default.svc.cluster.local

# Test external connectivity
# ping -c 3 8.8.8.8

# Test HTTP services
# curl -I https://httpbin.org/headers

# Check network interfaces
# ip addr show

# Check routing table
# ip route show

# Test service discovery
# nslookup kubernetes.default

# Exit and clean up
# exit
kubectl delete -f network-debug-pod.yaml
```

### üõ†Ô∏è Demo: File Transfer and Volume Management

```bash
#!/bin/bash
# file-transfer-demo.sh

echo "=== File Transfer and Volume Demo ==="

# Create a pod with persistent data
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: file-demo
spec:
  containers:
  - name: app
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Creating sample files..."
      mkdir -p /data/logs /data/config
      
      # Generate some sample data
      for i in {1..5}; do
        echo "Log entry \$i at \$(date)" >> /data/logs/app.log
        sleep 1
      done
      
      echo "app_name=demo-app" > /data/config/settings.conf
      echo "version=1.0.0" >> /data/config/settings.conf
      echo "debug=true" >> /data/config/settings.conf
      
      echo "Files created. Keeping container running..."
      sleep 3600
    volumeMounts:
    - name: data-storage
      mountPath: /data
  volumes:
  - name: data-storage
    emptyDir: {}
EOF

echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/file-demo

# Demonstrate file operations
echo "=== File Operations Demo ==="

echo "1. List files in the pod:"
kubectl exec file-demo -- find /data -type f

echo "2. Copy file from pod to local:"
kubectl cp file-demo:/data/logs/app.log ./app.log.backup
echo "File copied to: app.log.backup"
cat app.log.backup

echo "3. Create local config file:"
cat > new-config.conf <<EOF
app_name=updated-demo-app
version=2.0.0
debug=false
environment=production
EOF

echo "4. Copy local file to pod:"
kubectl cp new-config.conf file-demo:/data/config/

echo "5. Verify file in pod:"
kubectl exec file-demo -- cat /data/config/new-config.conf

echo "6. Create a backup of all data:"
kubectl exec file-demo -- tar -czf /tmp/backup.tar.gz -C /data .
kubectl cp file-demo:/tmp/backup.tar.gz ./pod-data-backup.tar.gz
echo "Backup created: pod-data-backup.tar.gz"

# Clean up
echo "Cleaning up..."
kubectl delete pod file-demo
rm -f app.log.backup new-config.conf pod-data-backup.tar.gz

echo "Demo complete!"
```

### üéØ Mini-Project 3: Pod Security Scanner

Create a security scanning tool using pods:

```yaml
# security-scanner-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-scanner
  labels:
    app: security
    type: scanner
spec:
  serviceAccountName: default
  containers:
  - name: scanner
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "=== Pod Security Scanner Starting ==="
      
      # Function to check security configurations
      check_security() {
        echo "Checking security configurations..."
        
        # Check if running as root
        if [ "$(id -u)" -eq 0 ]; then
          echo "‚ö†Ô∏è  WARNING: Running as root user"
        else
          echo "‚úÖ GOOD: Running as non-root user ($(id -u))"
        fi
        
        # Check filesystem permissions
        if [ -w "/" ]; then
          echo "‚ö†Ô∏è  WARNING: Root filesystem is writable"
        else
          echo "‚úÖ GOOD: Root filesystem is read-only"
        fi
        
        # Check for sensitive mounts
        if mount | grep -q "/var/run/secrets"; then
          echo "‚ÑπÔ∏è  INFO: Service account token mounted"
        fi
        
        # Check available capabilities
        echo "Current capabilities:"
        if [ -f "/proc/self/status" ]; then
          grep Cap /proc/self/status
        fi
        
        # Check network access
        echo "Testing network access..."
        if ping -c 1 8.8.8.8 >/dev/null 2>&1; then
          echo "‚ÑπÔ∏è  INFO: External network access available"
        else
          echo "‚ÑπÔ∏è  INFO: No external network access"
        fi
        
        # Generate security report
        cat > /tmp/security-report.txt <<EOF
      === Security Scan Report ===
      Timestamp: $(date)
      User ID: $(id -u)
      Group ID: $(id -g)
      Working Directory: $(pwd)
      
      Filesystem Check:
      - Root writable: $([ -w "/" ] && echo "YES" || echo "NO")
      - /tmp writable: $([ -w "/tmp" ] && echo "YES" || echo "NO")
      
      Network Check:
      - External access: $(ping -c 1 8.8.8.8 >/dev/null 2>&1 && echo "YES" || echo "NO")
      
      Process Information:
      $(ps aux)
      EOF
        
        echo "Report generated at /tmp/security-report.txt"
      }
      
      # Run security check
      check_security
      
      # Keep running for inspection
      echo "Scanner complete. Container will stay running for inspection."
      sleep 3600
      
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 1000
      runAsGroup: 3000
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir: {}
    
  restartPolicy: Never
```

**Usage:**
```bash
# Deploy the security scanner
kubectl apply -f security-scanner-pod.yaml

# Monitor the scan
kubectl logs -f security-scanner

# Get the security report
kubectl cp security-scanner:/tmp/security-report.txt ./security-report.txt
cat security-report.txt

# Create a comparison with an insecure pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: insecure-pod
spec:
  containers:
  - name: insecure
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      runAsUser: 0  # Running as root
      privileged: true
EOF

# Compare security postures
echo "=== Security Comparison ==="
echo "Secure pod user:"
kubectl exec security-scanner -- id

echo "Insecure pod user:"
kubectl exec insecure-pod -- id

echo "Secure pod capabilities:"
kubectl exec security-scanner -- grep Cap /proc/self/status

echo "Insecure pod capabilities:"
kubectl exec insecure-pod -- grep Cap /proc/self/status

# Clean up
kubectl delete pod security-scanner insecure-pod
rm -f security-report.txt
```

---

## Declarative Pod Configuration and Management

### üèóÔ∏è Expert Examples

#### Example 6: Production-Ready Pod Template

```yaml
# production-pod-template.yaml
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production
  labels:
    app: web-server
    version: "2.1.0"
    environment: production
    team: platform
  annotations:
    description: "Production web server with full monitoring and security"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/web-server"
    version: "2.1.0"
    build-date: "2024-01-15T10:30:00Z"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Node selection
  nodeSelector:
    node-type: "application"
    zone: "us-west-2a"
    
  # Tolerations for dedicated nodes
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "application"
    effect: "NoSchedule"
    
  # Pod placement preferences
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: "node-type"
            operator: In
            values: ["application"]
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: web-server
          topologyKey: kubernetes.io/hostname
          
  # DNS configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  containers:
  - name: web-server
    image: nginx:1.21-alpine
    imagePullPolicy: IfNotPresent
    
    ports:
    - name: http
      containerPort: 80
      protocol: TCP
    - name: metrics
      containerPort: 9113
      protocol: TCP
      
    # Environment variables
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "info"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security context
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE
        
    # Health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 80
        scheme: HTTP
        httpHeaders:
        - name: Custom-Header
          value: liveness-check
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
        scheme: HTTP
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle hooks
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container started at $(date)" >> /tmp/startup.log
            # Custom initialization logic here
            
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container stopping at $(date)" >> /tmp/shutdown.log
            # Graceful shutdown logic here
            nginx -s quit
            sleep 15
            
    # Volume mounts
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  # Sidecar container for log processing
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  # Monitoring sidecar
  - name: nginx-exporter
    image: nginx/nginx-prometheus-exporter:0.10.0
    args:
    - -nginx.scrape-uri=http://localhost:80/nginx_status
    ports:
    - name: metrics
      containerPort: 9113
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
  # Shared volumes
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
      defaultMode: 0644
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
      defaultMode: 0644
  - name: html-content
    configMap:
      name: html-content
      defaultMode: 0644
  - name: tmp-dir
    emptyDir:
      sizeLimit: 256Mi
  - name: var-cache-nginx
    emptyDir:
      sizeLimit: 512Mi
  - name: var-run
    emptyDir:
      sizeLimit: 64Mi
  - name: logs
    emptyDir:
      sizeLimit: 1Gi
```

### üõ†Ô∏è Demo: Complex Pod Deployment Pipeline

```bash
#!/bin/bash
# production-pod-deployment.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

# Configuration
NAMESPACE="production-demo"
APP_NAME="web-server"
CONFIG_DIR="./config"

# Create namespace if it doesn't exist
create_namespace() {
    log "Creating namespace: $NAMESPACE"
    kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    success "Namespace $NAMESPACE ready"
}

# Create ConfigMaps for the application
create_configmaps() {
    log "Creating ConfigMaps..."
    
    mkdir -p $CONFIG_DIR
    
    # Nginx configuration
    cat > $CONFIG_DIR/nginx.conf <<EOF
server {
    listen 80;
    server_name localhost;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
    
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    location /ready {
        access_log off;
        return 200 "ready\n";
        add_header Content-Type text/plain;
    }
    
    location /nginx_status {
        stub_status on;
        access_log off;
        allow all;
    }
}
EOF

    # HTML content
    cat > $CONFIG_DIR/index.html <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Production Pod Demo</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .container { max-width: 800px; margin: 0 auto; }
        .status { padding: 20px; margin: 20px 0; border-radius: 5px; }
        .healthy { background-color: #d4edda; color: #155724; }
        .info { background-color: #d1ecf1; color: #0c5460; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Production Pod Demo</h1>
        <div class="status healthy">
            <h3>‚úÖ Application Status: Healthy</h3>
            <p>Pod is running successfully with full production configuration</p>
        </div>
        
        <div class="status info">
            <h3>üìä Features Enabled:</h3>
            <ul>
                <li>Multi-container architecture</li>
                <li>Comprehensive health checks</li>
                <li>Security hardening</li>
                <li>Log processing sidecar</li>
                <li>Prometheus metrics export</li>
                <li>Resource management</li>
            </ul>
        </div>
        
        <div class="status info">
            <h3>üîó Endpoints:</h3>
            <ul>
                <li><a href="/health">Health Check</a></li>
                <li><a href="/ready">Readiness Check</a></li>
                <li><a href="/nginx_status">Nginx Status</a></li>
            </ul>
        </div>
    </div>
</body>
</html>
EOF

    # Fluent Bit configuration
    cat > $CONFIG_DIR/fluent-bit.conf <<EOF
[SERVICE]
    Flush         1
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf

[INPUT]
    Name              tail
    Path              /var/log/nginx/access.log
    Parser            nginx
    Tag               nginx.access
    Refresh_Interval  5

[INPUT]
    Name              tail
    Path              /var/log/nginx/error.log
    Tag               nginx.error
    Refresh_Interval  5

[OUTPUT]
    Name  stdout
    Match nginx.*
EOF

    cat > $CONFIG_DIR/parsers.conf <<EOF
[PARSER]
    Name   nginx
    Format regex
    Regex  ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
    Time_Key time
    Time_Format %d/%b/%Y:%H:%M:%S %z
EOF

    # Create ConfigMaps
    kubectl create configmap nginx-config --from-file=$CONFIG_DIR/nginx.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap html-content --from-file=$CONFIG_DIR/index.html -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap fluent-bit-config --from-file=$CONFIG_DIR/fluent-bit.conf --from-file=$CONFIG_DIR/parsers.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    
    success "ConfigMaps created successfully"
}

# Deploy the production pod
deploy_pod() {
    log "Deploying production pod..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: $APP_NAME
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
    version: "1.0.0"
    environment: production
  annotations:
    deployment.kubernetes.io/revision: "1"
    deployed-by: "production-deployment-script"
    deployment-time: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    
  containers:
  - name: nginx
    image: nginx:1.21-alpine
    ports:
    - name: http
      containerPort: 80
    - name: metrics
      containerPort: 9113
      
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
  - name: html-content
    configMap:
      name: html-content
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
  - name: tmp-dir
    emptyDir: {}
  - name: var-cache-nginx
    emptyDir: {}
  - name: var-run
    emptyDir: {}
  - name: logs
    emptyDir: {}
EOF

    success "Pod deployed successfully"
}

# Wait for pod to be ready and perform health checks
verify_deployment() {
    log "Waiting for pod to be ready..."
    
    if kubectl wait --for=condition=Ready pod/$APP_NAME -n $NAMESPACE --timeout=120s; then
        success "Pod is ready!"
    else
        error "Pod failed to become ready within timeout"
    fi
    
    # Perform comprehensive health checks
    log "Performing health checks..."
    
    # Check pod status
    kubectl get pod $APP_NAME -n $NAMESPACE -o wide
    
    # Test health endpoints
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    if curl -s http://localhost:8080/health | grep -q "healthy"; then
        success "Health check passed"
    else
        warning "Health check failed"
    fi
    
    if curl -s http://localhost:8080/ready | grep -q "ready"; then
        success "Readiness check passed"
    else
        warning "Readiness check failed"
    fi
    
    # Test the main application
    if curl -s http://localhost:8080 | grep -q "Production Pod Demo"; then
        success "Application is serving content correctly"
    else
        warning "Application content check failed"
    fi
    
    kill $PF_PID 2>/dev/null
    
    # Check resource usage
    log "Checking resource usage..."
    if kubectl top pod $APP_NAME -n $NAMESPACE &>/dev/null; then
        kubectl top pod $APP_NAME -n $NAMESPACE
    else
        warning "Resource metrics not available"
    fi
    
    # Check logs from all containers
    log "Checking container logs..."
    echo "=== Nginx logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c nginx --tail=5
    echo "=== Log processor logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=5
}

# Generate load and monitor performance
performance_test() {
    log "Running performance test..."
    
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    # Generate some load
    for i in {1..50}; do
        curl -s http://localhost:8080 > /dev/null &
    done
    
    wait
    kill $PF_PID 2>/dev/null
    
    # Check logs after load test
    log "Logs after load test:"
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=10
    
    success "Performance test completed"
}

# Cleanup function
cleanup() {
    log "Cleaning up resources..."
    kubectl delete pod $APP_NAME -n $NAMESPACE --ignore-not-found
    kubectl delete configmap nginx-config html-content fluent-bit-config -n $NAMESPACE --ignore-not-found
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -rf $CONFIG_DIR
    success "Cleanup completed"
}

# Main execution
main() {
    echo "=== Production Pod Deployment Demo ==="
    
    case "${1:-deploy}" in
        "deploy")
            create_namespace
            create_configmaps
            deploy_pod
            verify_deployment
            performance_test
            
            echo ""
            success "Deployment completed successfully!"
            echo "Access the application:"
            echo "  kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80"
            echo "  Then open: http://localhost:8080"
            echo ""
            echo "Monitor the pod:"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c nginx"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c log-processor"
            echo ""
            echo "Run 'bash $0 cleanup' to remove all resources"
            ;;
        "cleanup")
            cleanup
            ;;
        "test")
            verify_deployment
            performance_test
            ;;
        *)
            echo "Usage: $0 [deploy|cleanup|test]"
            echo "  deploy  - Deploy the production pod (default)"
            echo "  cleanup - Remove all created resources"
            echo "  test    - Run verification and performance tests"
            ;;
    esac
}

main "$@"
```

### üéØ Mini-Project 4: Pod Chaos Engineering

Test pod resilience with chaos engineering principles:

```yaml
# chaos-test-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: chaos-resilient-app
  labels:
    app: chaos-test
    resilience: enabled
spec:
  containers:
  - name: main-app
    image: nginx:1.21-alpine
    ports:
    - containerPort: 80
    
    # Aggressive resource limits to test resilience
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    # Tight health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 2
      
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
      timeoutSeconds: 1
      failureThreshold: 2
      
    # Graceful shutdown
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 10"]
          
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  # Chaos monkey sidecar
  - name: chaos-monkey
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Chaos monkey starting..."
      
      # Function to create CPU load
      cpu_chaos() {
        echo "Creating CPU chaos..."
        for i in {1..4}; do
          yes > /dev/null &
        done
        sleep 30
        killall yes
      }
      
      # Function to create memory pressure
      memory_chaos() {
        echo "Creating memory chaos..."
        cat <(yes | tr \\n x | head -c 50000000) <(yes | tr \\n x | head -c 50000000) > /tmp/memory_eater &
        sleep 20
        rm -f /tmp/memory_eater
        killall cat
      }
      
      # Function to simulate network issues
      network_chaos() {
        echo "Creating network chaos..."
        # Simulate slow responses
        sleep $((RANDOM % 10 + 5))
      }
      
      # Function to create disk I/O pressure
      disk_chaos() {
        echo "Creating disk I/O chaos..."
        dd if=/dev/zero of=/tmp/disk_eater bs=1M count=10 2>/dev/null
        rm -f /tmp/disk_eater
      }
      
      # Main chaos loop
      while true; do
        chaos_type=$((RANDOM % 4))
        case $chaos_type in
          0) cpu_chaos ;;
          1) memory_chaos ;;
          2) network_chaos ;;
          3) disk_chaos ;;
        esac
        
        # Wait between chaos events
        sleep $((RANDOM % 60 + 30))
      done
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir:
      sizeLimit: 100Mi
      
  restartPolicy: Always
```

**Chaos Testing Script:**
```bash
#!/bin/bash
# chaos-engineering-test.sh

echo "=== Chaos Engineering Test ==="

# Deploy the chaos test pod
kubectl apply -f chaos-test-pod.yaml

# Wait for it to be ready
echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/chaos-resilient-app --timeout=60s

# Monitor pod resilience
echo "Starting resilience monitoring (Ctrl+C to stop)..."

monitor_resilience() {
    while true; do
        timestamp=$(date '+%H:%M:%S')
        
        # Check pod status
        status=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.phase}')
        ready=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
        restarts=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.containerStatuses[0].restartCount}')
        
        # Test application responsiveness
        kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
        PF_PID=$!
        sleep 2
        
        response_time=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8080 2>/dev/null || echo "FAIL")
        kill $PF_PID 2>/dev/null
        
        # Get resource usage if available
        resources=""
        if kubectl top pod chaos-resilient-app &>/dev/null; then
            resources=$(kubectl top pod chaos-resilient-app --no-headers 2>/dev/null | awk '{print $2" "$3}')
        fi
        
        printf "[$timestamp] Status: $status | Ready: $ready | Restarts: $restarts | Response: ${response_time}s | Resources: $resources\n"
        
        sleep 5
    done
}

# Start monitoring in background
monitor_resilience &
MONITOR_PID=$!

# Generate additional load to test resilience
echo "Generating load to test resilience..."
for i in {1..100}; do
    kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
    PF_PID=$!
    sleep 1
    
    curl -s http://localhost:8080 > /dev/null &
    
    kill $PF_PID 2>/dev/null
    sleep 2
done

# Stop monitoring
kill $MONITOR_PID 2>/dev/null

echo "Chaos test completed. Check pod logs:"
echo "kubectl logs chaos-resilient-app -c main-app --tail=20"
echo "kubectl logs chaos-resilient-app -c chaos-monkey --tail=20"

# Cleanup
read -p "Delete the chaos test pod? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    kubectl delete -f chaos-test-pod.yaml
fi
```

---

## Advanced Pod Management Techniques

### üî¨ Expert-Level Examples

#### Example 7: Custom Pod Controller

Create a custom controller for specialized pod management:

```python
#!/usr/bin/env python3
# custom-pod-controller.py

import time
import yaml
import subprocess
import json
from datetime import datetime, timedelta

class PodController:
    def __init__(self):
        self.managed_pods = {}
        self.check_interval = 30  # seconds
        
    def log(self, message):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"[{timestamp}] {message}")
        
    def run_kubectl(self, command):
        """Execute kubectl command and return JSON output"""
        try:
            result = subprocess.run(
                f"kubectl {command} -o json",
                shell=True,
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                self.log(f"kubectl error: {result.stderr}")
                return None
        except Exception as e:
            self.log(f"Command execution error: {e}")
            return None
            
    def get_pods_by_label(self, label_selector):
        """Get pods matching label selector"""
        command = f"get pods -l {label_selector}"
        result = self.run_kubectl(command)
        return result.get('items', []) if result else []
        
    def create_pod(self, name, spec):
        """Create a pod with given specification"""
        pod_manifest = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'name': name,
                'labels': {
                    'managed-by': 'custom-controller',
                    'created': datetime.now().strftime('%Y%m%d-%H%M%S')
                }
            },
            'spec': spec
        }
        
        # Write manifest to temporary file
        with open(f'/tmp/{name}.yaml', 'w') as f:
            yaml.dump(pod_manifest, f)
            
        # Apply the manifest
        result = subprocess.run(
            f"kubectl apply -f /tmp/{name}.yaml",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Created pod: {name}")
            return True
        else:
            self.log(f"Failed to create pod {name}: {result.stderr}")
            return False
            
    def delete_pod(self, name):
        """Delete a pod"""
        result = subprocess.run(
            f"kubectl delete pod {name} --grace-period=30",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Deleted pod: {name}")
            return True
        else:
            self.log(f"Failed to delete pod {name}: {result.stderr}")
            return False
            
    def check_pod_health(self, pod):
        """Check if a pod is healthy based on custom criteria"""
        name = pod['metadata']['name']
        status = pod['status']
        
        # Check if pod is running
        if status.get('phase') != 'Running':
            return False, f"Pod {name} is not running (phase: {status.get('phase')})"
            
        # Check container statuses
        container_statuses = status.get('containerStatuses', [])
        for container in container_statuses:
            if not container.get('ready'):
                return False, f"Container {container['name']} not ready in pod {name}"
                
            # Check restart count
            restart_count = container.get('restartCount', 0)
            if restart_count > 5:
                return False, f"Container {container['name']} restarted {restart_count} times"
                
        # Check resource usage (if metrics available)
        metrics = self.get_pod_metrics(name)
        if metrics:
            cpu_usage = self.parse_cpu_usage(metrics.get('cpu', '0m'))
            memory_usage = self.parse_memory_usage(metrics.get('memory', '0Mi'))
            
            if cpu_usage > 800:  # 800 millicores
                return False, f"Pod {name} CPU usage too high: {cpu_usage}m"
                
            if memory_usage > 512:  # 512 Mi
                return False, f"Pod {name} memory usage too high: {memory_usage}Mi"
                
        return True, f"Pod {name} is healthy"
        
    def get_pod_metrics(self, pod_name):
        """Get pod resource metrics if available"""
        result = subprocess.run(
            f"kubectl top pod {pod_name} --no-headers",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            parts = result.stdout.strip().split()
            if len(parts) >= 3:
                return {
                    'cpu': parts[1],
                    'memory': parts[2]
                }
        return None
        
    def parse_cpu_usage(self, cpu_str):
        """Parse CPU usage from string like '100m' to millicores"""
        if cpu_str.endswith('m'):
            return int(cpu_str[:-1])
        return int(cpu_str) * 1000
        
    def parse_memory_usage(self, memory_str):
        """Parse memory usage from string like '128Mi' to Mi"""
        if memory_str.endswith('Mi'):
            return int(memory_str[:-2])
        elif memory_str.endswith('Gi'):
            return int(memory_str[:-2]) * 1024
        return int(memory_str) // (1024 * 1024)
        
    def auto_heal_pod(self, pod_name, reason):
        """Attempt to heal an unhealthy pod"""
        self.log(f"Attempting to heal pod {pod_name}: {reason}")
        
        # Strategy 1: Restart the pod
        if "restart" in reason.lower():
            return self.delete_pod(pod_name)  # Pod will be recreated if managed by controller
            
        # Strategy 2: Scale resources if high usage
        if "usage too high" in reason.lower():
            self.log(f"High resource usage detected for {pod_name}, marking for recreation")
            return self.delete_pod(pod_name)
            
        # Strategy 3: Generic restart
        return self.delete_pod(pod_name)
        
    def manage_workload(self, workload_config):
        """Manage a workload with desired replica count"""
        app_name = workload_config['name']
        desired_replicas = workload_config['replicas']
        pod_spec = workload_config['pod_spec']
        
        # Get current pods for this workload
        current_pods = self.get_pods_by_label(f"app={app_name},managed-by=custom-controller")
        current_count = len(current_pods)
        
        self.log(f"Managing workload {app_name}: current={current_count}, desired={desired_replicas}")
        
        # Scale up if needed
        if current_count < desired_replicas:
            for i in range(current_count, desired_replicas):
                pod_name = f"{app_name}-{i}"
                pod_spec_copy = pod_spec.copy()
                pod_spec_copy.setdefault('containers', [{}])[0]['env'] = [
                    {'name': 'REPLICA_ID', 'value': str(i)},
                    {'name': 'APP_NAME', 'value': app_name}
                ]
                self.create_pod(pod_name, pod_spec_copy)
                
        # Scale down if needed
        elif current_count > desired_replicas:
            pods_to_delete = current_pods[desired_replicas:]
            for pod in pods_to_delete:
                self.delete_pod(pod['metadata']['name'])
                
        # Health check existing pods
        for pod in current_pods[:desired_replicas]:
            healthy, reason = self.check_pod_health(pod)
            if not healthy:
                self.log(f"Pod unhealthy: {reason}")
                self.auto_heal_pod(pod['metadata']['name'], reason)
                
    def run_control_loop(self):
        """Main control loop"""
        self.log("Starting custom pod controller...")
        
        # Sample workload configuration
        workloads = [
            {
                'name': 'web-app',
                'replicas': 2,
                'pod_spec': {
                    'containers': [{
                        'name': 'nginx',
                        'image': 'nginx:1.21-alpine',
                        'ports': [{'containerPort': 80}],
                        'resources': {
                            'requests': {'memory': '64Mi', 'cpu': '50m'},
                            'limits': {'memory': '128Mi', 'cpu': '100m'}
                        },
                        'livenessProbe': {
                            'httpGet': {'path': '/', 'port': 80},
                            'initialDelaySeconds': 10,
                            'periodSeconds': 30
                        }
                    }],
                    'restartPolicy': 'Always'
                }
            }
        ]
        
        try:
            while True:
                self.log("Running control loop...")
                
                for workload in workloads:
                    try:
                        self.manage_workload(workload)
                    except Exception as e:
                        self.log(f"Error managing workload {workload['name']}: {e}")
                        
                self.log(f"Sleeping for {self.check_interval} seconds...")
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            self.log("Shutting down controller...")
            
        except Exception as e:
            self.log(f"Controller error: {e}")
            
    def cleanup(self):
        """Clean up managed resources"""
        self.log("Cleaning up managed pods...")
        pods = self.get_pods_by_label("managed-by=custom-controller")
        for pod in pods:
            self.delete_pod(pod['metadata']['name'])

if __name__ == "__main__":
    import sys
    
    controller = PodController()
    
    if len(sys.argv) > 1 and sys.argv[1] == "cleanup":
        controller.cleanup()
    else:
        controller.run_control_loop()
```

**Usage:**
```bash
# Make the script executable
chmod +x custom-pod-controller.py

# Install dependencies
pip3 install pyyaml

# Run the controller
python3 custom-pod-controller.py

# In another terminal, watch the managed pods
watch kubectl get pods -l managed-by=custom-controller

# Simulate pod failures
kubectl delete pod web-app-0  # Controller will recreate it

# Clean up when done
python3 custom-pod-controller.py cleanup
```

### üéØ Mini-Project 5: Pod Performance Optimization Lab

Create a comprehensive performance optimization laboratory:

```yaml
# performance-lab-setup.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: performance-lab
---
# Baseline pod - unoptimized
apiVersion: v1
kind: Pod
metadata:
  name: baseline-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: baseline
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "1000m"
      limits:
        memory: "2Gi"
        cpu: "2000m"
---
# Optimized pod - resource-efficient
apiVersion: v1
kind: Pod
metadata:
  name: optimized-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: optimized
spec:
  containers:
  - name: app
    image: nginx:1.21-alpine  # Smaller image
    resources:
      requests:
        memory: "64Mi"        # Right-sized requests
        cpu: "100m"
      limits:
        memory: "128Mi"       # Conservative limits
        cpu: "200m"
    # Optimized health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5   # Faster startup
      periodSeconds: 30        # Less frequent checks
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
    # Security optimizations
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
    # Volume optimizations
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp-dir
    emptyDir:
      medium: Memory  # Use memory for temp files
      sizeLimit: 64Mi
  - name: var-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: var-run
    emptyDir:
      sizeLimit: 32Mi
---
# High-performance pod with advanced optimizations
apiVersion: v1
kind: Pod
metadata:
  name: high-performance-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: high-performance
spec:
  # Pod-level optimizations
  priorityClassName: high-priority
  nodeSelector:
    node-type: performance
  tolerations:
  - key: performance-node
    operator: Equal
    value: "true"
    effect: NoSchedule
  # Network optimizations
  dnsPolicy: ClusterFirstWithHostNet
  dnsConfig:
    options:
    - name: ndots
      value: "1"
    - name: edns0
  containers:
  - name: app
    image: nginx:1.21-alpine
    # Optimized resource allocation
    resources:
      requests:
        memory: "128Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "256Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
    # Performance-tuned environment
    env:
    - name: NGINX_WORKER_PROCESSES
      value: "auto"
    - name: NGINX_WORKER_CONNECTIONS
      value: "1024"
    # Aggressive health checks for faster recovery
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 15
      timeoutSeconds: 2
      failureThreshold: 2
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 3
      timeoutSeconds: 1
      failureThreshold: 1
    # Startup optimization
    startupProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 1
      timeoutSeconds: 1
      failureThreshold: 10
    # Performance-optimized volumes
    volumeMounts:
    - name: high-speed-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
  volumes:
  - name: high-speed-tmp
    emptyDir:
      medium: Memory
      sizeLimit: 128Mi
  - name: nginx-cache
    emptyDir:
      medium: Memory
      sizeLimit: 256Mi
  - name: nginx-run
    emptyDir:
      medium: Memory
      sizeLimit: 64Mi
```

**Performance Benchmarking Script:**
```bash
#!/bin/bash
# performance-benchmark.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

NAMESPACE="performance-lab"

# Deploy the performance lab
setup_lab() {
    log "Setting up performance lab..."
    kubectl apply -f performance-lab-setup.yaml
    
    log "Waiting for pods to be ready..."
    kubectl wait --for=condition=Ready pod/baseline-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/optimized-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/high-performance-app -n $NAMESPACE --timeout=120s
    
    success "Performance lab setup complete"
}

# Measure startup time
measure_startup_time() {
    local pod_name=$1
    log "Measuring startup time for $pod_name..."
    
    # Delete and recreate pod to measure startup
    kubectl delete pod $pod_name -n $NAMESPACE
    local start_time=$(date +%s.%N)
    
    # Recreate the pod (extract from original manifest)
    kubectl get pod $pod_name -n $NAMESPACE -o yaml --export 2>/dev/null | kubectl apply -f - 2>/dev/null || {
        warning "Couldn't recreate pod automatically, recreating from manifest"
        kubectl apply -f performance-lab-setup.yaml
    }
    
    # Wait for ready and measure time
    kubectl wait --for=condition=Ready pod/$pod_name -n $NAMESPACE --timeout=120s
    local end_time=$(date +%s.%N)
    
    local startup_time=$(echo "$end_time - $start_time" | bc -l)
    echo "$startup_time"
}

# Run load test on a pod
load_test_pod() {
    local pod_name=$1
    local duration=${2:-30}
    local concurrency=${3:-10}
    
    log "Running load test on $pod_name (${duration}s, ${concurrency} concurrent)"
    
    # Start port forwarding
    kubectl port-forward pod/$pod_name -n $NAMESPACE 8080:80 >/dev/null 2>&1 &
    local pf_pid=$!
    sleep 3
    
    # Use Apache Bench for load testing
    local results_file="/tmp/ab_results_${pod_name}.txt"
    
    if command -v ab >/dev/null; then
        ab -n $((duration * concurrency)) -c $concurrency -g /tmp/gnuplot_${pod_name}.dat \
           http://localhost:8080/ > $results_file 2>&1
        
        # Extract key metrics
        local rps=$(grep "Requests per second" $results_file | awk '{print $4}')
        local response_time=$(grep "Time per request.*mean" $results_file | head -1 | awk '{print $4}')
        local failed_requests=$(grep "Failed requests" $results_file | awk '{print $3}')
        
        echo "RPS:$rps,ResponseTime:$response_time,Failed:$failed_requests"
    else
        # Fallback to curl-based test
        local start_time=$(date +%s)
        local requests=0
        local total_time=0
        
        for i in $(seq 1 $((duration * concurrency))); do
            local req_start=$(date +%s.%N)
            if curl -s http://localhost:8080 >/dev/null 2>&1; then
                ((requests++))
            fi
            local req_end=$(date +%s.%N)
            local req_time=$(echo "$req_end - $req_start" | bc -l)
            total_time=$(echo "$total_time + $req_time" | bc -l)
            
            # Basic rate limiting
            sleep 0.1
        done
        
        local avg_response_time=$(echo "scale=3; $total_time / $requests" | bc -l)
        local rps=$(echo "scale=2; $requests / $duration" | bc -l)
        
        echo "RPS:$rps,ResponseTime:$avg_response_time,Failed:0"
    fi
    
    kill $pf_pid 2>/dev/null
}

# Get resource usage metrics
get_resource_usage() {
    local pod_name=$1
    log "Getting resource usage for $pod_name..."
    
    if kubectl top pod $pod_name -n $NAMESPACE >/dev/null 2>&1; then
        kubectl top pod $pod_name -n $NAMESPACE --no-headers | awk '{print "CPU:"$2",Memory:"$3}'
    else
        echo "CPU:N/A,Memory:N/A"
    fi
}

# Comprehensive benchmark
run_comprehensive_benchmark() {
    log "Running comprehensive performance benchmark..."
    
    declare -A results
    local pods=("baseline-app" "optimized-app" "high-performance-app")
    
    echo "=== Performance Benchmark Results ===" > benchmark_results.txt
    echo "Timestamp: $(date)" >> benchmark_results.txt
    echo "" >> benchmark_results.txt
    
    for pod in "${pods[@]}"; do
        log "Benchmarking $pod..."
        
        # Startup time measurement
        log "Measuring startup time for $pod..."
        # Skip startup measurement in this demo to avoid pod recreation issues
        startup_time="N/A"
        
        # Resource usage
        resource_usage=$(get_resource_usage $pod)
        
        # Load test
        load_results=$(load_test_pod $pod 30 10)
        
        # Pod status information
        pod_info=$(kubectl get pod $pod -n $NAMESPACE -o custom-columns=STATUS:.status.phase,READY:.status.conditions[?\(@.type==\"Ready\"\)].status,RESTARTS:.status.containerStatuses[0].restartCount --no-headers)
        
        # Store results
        results[$pod]="Startup:$startup_time,Resources:$resource_usage,Load:$load_results,Status:$pod_info"
        
        # Write to file
        cat >> benchmark_results.txt <<EOF

=== $pod ===
Startup Time: $startup_time seconds
Resource Usage: $resource_usage
Load Test Results: $load_results
Pod Status: $pod_info

EOF
    done
    
    # Generate comparison summary
    cat >> benchmark_results.txt <<EOF

=== Performance Summary ===
This benchmark compares three pod configurations:

1. Baseline App: Standard configuration with generous resource allocation
2. Optimized App: Resource-efficient with security hardening
3. High-Performance App: Maximum performance optimizations

Key Findings:
- Resource efficiency varies significantly between configurations
- Startup time impacts overall application availability
- Load handling capacity differs based on resource allocation
- Security optimizations may have performance trade-offs

Recommendations:
- Use optimized configuration for production workloads
- Consider high-performance setup for critical applications
- Monitor resource usage to fine-tune allocations
- Balance security and performance based on requirements

EOF
    
    success "Benchmark completed. Results saved to benchmark_results.txt"
    cat benchmark_results.txt
}

# Resource monitoring script
monitor_resources() {
    local duration=${1:-300}  # 5 minutes default
    log "Starting resource monitoring for ${duration} seconds..."
    
    local monitor_file="resource_monitor_$(date +%Y%m%d_%H%M%S).log"
    
    {
        echo "Timestamp,Pod,CPU,Memory,Status"
        local end_time=$(($(date +%s) + duration))
        
        while [ $(date +%s) -lt $end_time ]; do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            
            for pod in baseline-app optimized-app high-performance-app; do
                if kubectl get pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                    local status=$(kubectl get pod $pod -n $NAMESPACE -o jsonpath='{.status.phase}')
                    local usage="N/A,N/A"
                    
                    if kubectl top pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                        usage=$(kubectl top pod $pod -n $NAMESPACE --no-headers | awk '{print $2","$3}')
                    fi
                    
                    echo "$timestamp,$pod,$usage,$status"
                fi
            done
            
            sleep 10
        done
    } > $monitor_file
    
    success "Resource monitoring completed. Data saved to $monitor_file"
    
    # Generate simple analysis
    log "Generating resource usage analysis..."
    
    {
        echo "=== Resource Usage Analysis ==="
        echo ""
        
        for pod in baseline-app optimized-app high-performance-app; do
            echo "=== $pod ==="
            grep "$pod" $monitor_file | tail -10 | while IFS=',' read timestamp pod_name cpu memory status; do
                echo "[$timestamp] CPU: $cpu, Memory: $memory, Status: $status"
            done
            echo ""
        done
    } > resource_analysis.txt
    
    success "Analysis saved to resource_analysis.txt"
}

# Cleanup function
cleanup_lab() {
    log "Cleaning up performance lab..."
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -f benchmark_results.txt resource_*.log resource_analysis.txt
    rm -f /tmp/ab_results_*.txt /tmp/gnuplot_*.dat
    success "Cleanup completed"
}

# Main execution
main() {
    case "${1:-benchmark}" in
        "setup")
            setup_lab
            ;;
        "benchmark")
            setup_lab
            run_comprehensive_benchmark
            ;;
        "monitor")
            monitor_resources "${2:-300}"
            ;;
        "cleanup")
            cleanup_lab
            ;;
        "all")
            setup_lab
            run_comprehensive_benchmark
            monitor_resources 300
            echo ""
            success "Complete performance analysis finished!"
            echo "Files created:"
            echo "  - benchmark_results.txt"
            echo "  - resource_monitor_*.log"
            echo "  - resource_analysis.txt"
            ;;
        *)
            echo "Performance Lab - Pod Optimization Benchmark"
            echo ""
            echo "Usage: $0 <command> [options]"
            echo ""
            echo "Commands:"
            echo "  setup      - Set up the performance lab environment"
            echo "  benchmark  - Run comprehensive performance benchmark"
            echo "  monitor    - Monitor resource usage for specified duration"
            echo "  cleanup    - Remove all lab resources"
            echo "  all        - Run complete analysis (setup + benchmark + monitor)"
            echo ""
            echo "Examples:"
            echo "  $0 setup"
            echo "  $0 benchmark"
            echo "  $0 monitor 600  # Monitor for 10 minutes"
            echo "  $0 all          # Complete analysis"
            ;;
    esac
}

main "$@"
```

---

## Pod Troubleshooting Methodologies

### üîß Advanced Troubleshooting Toolkit

#### Example 8: Automated Diagnostic System

```bash
#!/bin/bash
# advanced-pod-diagnostics.sh

set -euo pipefail

# Enhanced diagnostic toolkit with automated problem detection
class PodDiagnostics {
    
# Configuration
NAMESPACE=${NAMESPACE:-default}
OUTPUT_DIR="./diagnostics-$(date +%Y%m%d-%H%M%S)"
VERBOSE=${VERBOSE:-false}

# Colors and formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'
BOLD='\033[1m'

# Logging functions with levels
log_debug() { [[ $VERBOSE == "true" ]] && echo -e "${CYAN}[DEBUG]${NC} $1"; }
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }

# Initialize diagnostics
init_diagnostics() {
    log_info "Initializing pod diagnostics system..."
    mkdir -p "$OUTPUT_DIR"/{logs,reports,metrics,manifests}
    
    # Create diagnostic report header
    cat > "$OUTPUT_DIR/diagnostic_report.md" <<EOF
# Pod Diagnostics Report

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)  
**Namespace:** $NAMESPACE  
**Output Directory:** $OUTPUT_DIR

---

EOF
    
    log_success "Diagnostics initialized in $OUTPUT_DIR"
}

# Comprehensive pod information gathering
gather_pod_info() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Gathering comprehensive information for pod: $pod_name"
    
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    mkdir -p "$pod_dir"
    
    # Basic pod information
    kubectl get pod "$pod_name" -n "$namespace" -o wide > "$pod_dir/basic_info.txt" 2>&1
    kubectl get pod "$pod_name" -n "$namespace" -o yaml > "$pod_dir/manifest.yaml" 2>&1
    
    # Detailed description
    kubectl describe pod "$pod_name" -n "$namespace" > "$pod_dir/description.txt" 2>&1
    
    # Events related to the pod
    kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
        --sort-by='.lastTimestamp' > "$pod_dir/events.txt" 2>&1
    
    # Container logs
    local containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}' 2>/dev/null)
    for container in $containers; do
        log_debug "Collecting logs for container: $container"
        kubectl logs "$pod_name" -n "$namespace" -c "$container" > "$pod_dir/logs_${container}.txt" 2>&1
        
        # Previous logs if container restarted
        kubectl logs "$pod_name" -n "$namespace" -c "$container" --previous > "$pod_dir/logs_${container}_previous.txt" 2>&1 || true
    done
    
    # Resource usage
    kubectl top pod "$pod_name" -n "$namespace" > "$pod_dir/resource_usage.txt" 2>&1 || echo "Metrics not available" > "$pod_dir/resource_usage.txt"
    
    log_success "Pod information gathered for $pod_name"
}

# Automated problem detection
detect_common_issues() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Running automated issue detection for $pod_name..."
    
    local issues_file="$pod_dir/detected_issues.md"
    echo "# Automated Issue Detection Report" > "$issues_file"
    echo "**Pod:** $pod_name" >> "$issues_file"
    echo "**Analysis Time:** $(date)" >> "$issues_file"
    echo "" >> "$issues_file"
    
    local issue_count=0
    
    # Check 1: Pod phase issues
    local phase=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.phase}' 2>/dev/null)
    if [[ "$phase" != "Running" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Pod Not Running
- **Severity:** High
- **Status:** Pod is in '$phase' phase instead of 'Running'
- **Impact:** Application unavailable
- **Investigation:** Check pod events and container status

EOF
    fi
    
    # Check 2: Container readiness issues
    local ready_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[?(@.ready==true)]}' | jq '. | length' 2>/dev/null || echo "0")
    local total_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers}' | jq '. | length' 2>/dev/null || echo "1")
    
    if [[ "$ready_containers" -lt "$total_containers" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Container Readiness Problems
- **Severity:** High
- **Status:** Only $ready_containers of $total_containers containers are ready
- **Impact:** Traffic routing may be affected
- **Investigation:** Check readiness probes and container logs

EOF
    fi
    
    # Check 3: Excessive restarts
    local restarts=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
    if [[ "$restarts" -gt 5 ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Excessive Container Restarts
- **Severity:** Medium
- **Status:** Container has restarted $restarts times
- **Impact:** Service instability and potential data loss
- **Investigation:** Check liveness probes, resource limits, and application logs

EOF
    fi
    
    # Check 4: Resource usage issues
    if kubectl top pod "$pod_name" -n "$namespace" >/dev/null 2>&1; then
        local cpu_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $2}' | sed 's/m$//')
        local memory_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $3}' | sed 's/Mi$//')
        
        if [[ "$cpu_usage" -gt 800 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High CPU Usage
- **Severity:** Medium
- **Status:** CPU usage is ${cpu_usage}m (> 800m threshold)
- **Impact:** Performance degradation and potential throttling
- **Investigation:** Check for CPU-intensive processes and consider scaling

EOF
        fi
        
        if [[ "$memory_usage" -gt 512 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High Memory Usage
- **Severity:** Medium  
- **Status:** Memory usage is ${memory_usage}Mi (> 512Mi threshold)
- **Impact:** Risk of OOM kills and service disruption
- **Investigation:** Check for memory leaks and optimize memory usage

EOF
        fi
    fi
    
    # Check 5: Image pull issues
    if grep -q "ImagePullBackOff\|ErrImagePull" "$pod_dir/description.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Image Pull Problems
- **Severity:** High
- **Status:** Unable to pull container image
- **Impact:** Pod cannot start
- **Investigation:** Check image name, registry access, and credentials

EOF
    fi
    
    # Check 6: Resource constraints
    if grep -q "Insufficient.*resources" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Resource Constraints
- **Severity:** High
- **Status:** Insufficient cluster resources for pod scheduling
- **Impact:** Pod cannot be scheduled
- **Investigation:** Check cluster capacity and node resources

EOF
    fi
    
    # Check 7: Network issues
    if grep -q "NetworkNotReady\|CNI.*error" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Network Configuration Problems
- **Severity:** High
- **Status:** Network setup issues detected
- **Impact:** Pod networking may not function correctly
- **Investigation:** Check CNI configuration and network policies

EOF
    fi
    
    # Summary
    if [[ $issue_count -eq 0 ]]; then
        echo "## Summary: No Critical Issues Detected ‚úÖ" >> "$issues_file"
        echo "The automated analysis found no obvious problems with this pod." >> "$issues_file"
        log_success "No critical issues detected for $pod_name"
    else
        echo "## Summary: $issue_count Issue(s) Detected ‚ö†Ô∏è" >> "$issues_file"
        echo "Review the issues above and follow the investigation recommendations." >> "$issues_file"
        log_warn "$issue_count issue(s) detected for $pod_name"
    fi
    
    return $issue_count
}

# Generate recommendations
generate_recommendations() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Generating recommendations for $pod_name..."
    
    local rec_file="$pod_dir/recommendations.md"
    echo "# Optimization Recommendations" > "$rec_file"
    echo "**Pod:** $pod_name" >> "$rec_file"
    echo "" >> "$rec_file"
    
    # Resource optimization recommendations
    echo "## Resource Optimization" >> "$rec_file"
    
    # Check current resource configuration
    local requests_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.memory}' 2>/dev/null || echo "not set")
    local requests_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.cpu}' 2>/dev/null || echo "not set")
    local limits_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.memory}' 2>/dev/null || echo "not set")
    local limits_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.cpu}' 2>/dev/null || echo "not set")
    
    cat >> "$rec_file" <<EOF
### Current Resource Configuration
- **Memory Request:** $requests_mem
- **CPU Request:** $requests_cpu  
- **Memory Limit:** $limits_mem
- **CPU Limit:** $limits_cpu

EOF
    
    # Security recommendations
    echo "## Security Hardening" >> "$rec_file"
    
    local security_context=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.securityContext}' 2>/dev/null)
    if [[ -z "$security_context" || "$security_context" == "null" ]]; then
        cat >> "$rec_file" <<EOF
### Security Context Improvements
- ‚úÖ **Add security context:** Configure runAsNonRoot, runAsUser, and fsGroup
- ‚úÖ **Drop capabilities:** Remove unnecessary Linux capabilities  
- ‚úÖ **Read-only root filesystem:** Set readOnlyRootFilesystem: true
- ‚úÖ **Prevent privilege escalation:** Set allowPrivilegeEscalation: false

EOF
    fi
    
    # Health check recommendations
    echo "## Health Check Optimization" >> "$rec_file"
    
    local has_liveness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].livenessProbe}' 2>/dev/null)
    local has_readiness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].readinessProbe}' 2>/dev/null)
    
    if [[ -z "$has_liveness" || "$has_liveness" == "null" ]]; then
        echo "- ‚úÖ **Add liveness probe:** Implement health checking for automatic restart" >> "$rec_file"
    fi
    
    if [[ -z "$has_readiness" || "$has_readiness" == "null" ]]; then
        echo "- ‚úÖ **Add readiness probe:** Control traffic routing based on application readiness" >> "$rec_file"
    fi
    
    # Performance recommendations
    echo "" >> "$rec_file"
    echo "## Performance Optimization" >> "$rec_file"
    cat >> "$rec_file" <<EOF
- ‚úÖ **Use Alpine images:** Reduce image size and startup time
- ‚úÖ **Implement resource requests:** Help scheduler make better placement decisions
- ‚úÖ **Optimize health check frequency:** Balance responsiveness with overhead
- ‚úÖ **Use memory-backed volumes:** For temporary files and caches
- ‚úÖ **Configure DNS caching:** Reduce DNS lookup overhead

EOF
    
    log_success "Recommendations generated for $pod_name"
}

# Interactive diagnostic session
interactive_diagnostics() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Starting interactive diagnostics for $pod_name..."
    
    echo -e "${BOLD}Interactive Pod Diagnostics${NC}"
    echo "Pod: $pod_name"
    echo "Namespace: $namespace"
    echo ""
    
    while true; do
        echo -e "${CYAN}Available actions:${NC}"
        echo "1) Show pod status"
        echo "2) View recent events"
        echo "3) Check container logs"
        echo "4) Execute command in pod"
        echo "5) Port forward to pod"
        echo "6) Resource usage"
        echo "7) Run full diagnostic"
        echo "8) Generate recommendations"
        echo "q) Quit"
        echo ""
        
        read -p "Select action [1-8,q]: " choice
        
        case $choice in
            1)
                echo "=== Pod Status ==="
                kubectl get pod "$pod_name" -n "$namespace" -o wide
```" \
        5
    
    check_item "Version label present" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.metadata.labels.version}' | grep -v '^
                kubectl describe pod "$pod_name" -n "$namespace" | grep -A 10 "Status\|Conditions"
                ;;
            2)
                echo "=== Recent Events ==="
                kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
                    --sort-by='.lastTimestamp' | tail -10
                ;;
            3)
                echo "=== Container Selection ==="
                local containers=($(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}'))
                if [[ ${#containers[@]} -eq 1 ]]; then
                    echo "Showing logs for container: ${containers[0]}"
                    kubectl logs "$pod_name" -n "$namespace" --tail=50
                else
                    echo "Available containers:"
                    for i in "${!containers[@]}"; do
                        echo "$((i+1))) ${containers[i]}"
                    done
                    read -p "Select container [1-${#containers[@]}]: " container_choice
                    if [[ $container_choice -ge 1 && $container_choice -le ${#containers[@]} ]]; then
                        local selected_container=${containers[$((container_choice-1))]}
                        echo "Showing logs for container: $selected_container"
                        kubectl logs "$pod_name" -n "$namespace" -c "$selected_container" --tail=50
                    fi
                fi
                ;;
            4)
                read -p "Enter command to execute: " exec_command
                kubectl exec -it "$pod_name" -n "$namespace" -- $exec_command
                ;;
            5)
                read -p "Enter local port: " local_port
                read -p "Enter pod port: " pod_port
                echo "Port forwarding $local_port:$pod_port - Press Ctrl+C to stop"
                kubectl port-forward "$pod_name" -n "$namespace" "$local_port:$pod_port"
                ;;
            6)
                echo "=== Resource Usage ==="
                kubectl top pod "$pod_name" -n "$namespace" 2>/dev/null || echo "Metrics not available"
                ;;
            7)
                gather_pod_info "$pod_name" "$namespace"
                detect_common_issues "$pod_name" "$namespace"
                generate_recommendations "$pod_name" "$namespace"
                echo "Full diagnostic completed. Check $OUTPUT_DIR/pods/$pod_name/"
                ;;
            8)
                generate_recommendations "$pod_name" "$namespace"
                echo "Recommendations generated. Check $OUTPUT_DIR/pods/$pod_name/recommendations.md"
                ;;
            q|Q)
                log_info "Exiting interactive diagnostics"
                break
                ;;
            *)
                echo "Invalid choice. Please try again."
                ;;
        esac
        
        echo ""
        read -p "Press Enter to continue..."
        echo ""
    done
}

# Cluster-wide pod health assessment
cluster_health_assessment() {
    log_info "Running cluster-wide pod health assessment..."
    
    local health_report="$OUTPUT_DIR/cluster_health_report.md"
    
    cat > "$health_report" <<EOF
# Cluster Pod Health Assessment

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)

---

EOF
    
    # Get all namespaces
    local namespaces=($(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'))
    
    local total_pods=0
    local healthy_pods=0
    local unhealthy_pods=0
    
    for ns in "${namespaces[@]}"; do
        log_info "Assessing namespace: $ns"
        
        local pods=($(kubectl get pods -n "$ns" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null))
        
        if [[ ${#pods[@]} -eq 0 ]]; then
            continue
        fi
        
        echo "## Namespace: $ns" >> "$health_report"
        echo "" >> "$health_report"
        
        local ns_healthy=0
        local ns_unhealthy=0
        
        for pod in "${pods[@]}"; do
            ((total_pods++))
            
            local phase=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.phase}')
            local ready_condition=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
            local restarts=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
            
            if [[ "$phase" == "Running" && "$ready_condition" == "True" && $restarts -lt 5 ]]; then
                ((healthy_pods++))
                ((ns_healthy++))
                echo "‚úÖ **$pod** - Healthy" >> "$health_report"
            else
                ((unhealthy_pods++))
                ((ns_unhealthy++))
                echo "‚ùå **$pod** - Issues detected (Phase: $phase, Ready: $ready_condition, Restarts: $restarts)" >> "$health_report"
                
                # Run quick diagnostics for unhealthy pods
                gather_pod_info "$pod" "$ns"
                detect_common_issues "$pod" "$ns"
            fi
        done
        
        echo "" >> "$health_report"
        echo "**Namespace Summary:** $ns_healthy healthy, $ns_unhealthy unhealthy" >> "$health_report"
        echo "" >> "$health_report"
    done
    
    # Overall summary
    local health_percentage=$((healthy_pods * 100 / total_pods))
    
    cat >> "$health_report" <<EOF

---

## Overall Cluster Health

- **Total Pods:** $total_pods
- **Healthy Pods:** $healthy_pods
- **Unhealthy Pods:** $unhealthy_pods
- **Health Percentage:** $health_percentage%

### Health Status
EOF
    
    if [[ $health_percentage -ge 90 ]]; then
        echo "üü¢ **EXCELLENT** - Cluster is in excellent health" >> "$health_report"
    elif [[ $health_percentage -ge 75 ]]; then
        echo "üü° **GOOD** - Cluster is in good health with minor issues" >> "$health_report"
    elif [[ $health_percentage -ge 50 ]]; then
        echo "üü† **WARNING** - Cluster has significant health issues" >> "$health_report"
    else
        echo "üî¥ **CRITICAL** - Cluster is in critical condition" >> "$health_report"
    fi
    
    log_success "Cluster health assessment completed. Report: $health_report"
}

# Generate comprehensive diagnostic report
generate_final_report() {
    log_info "Generating comprehensive diagnostic report..."
    
    local final_report="$OUTPUT_DIR/comprehensive_report.html"
    
    cat > "$final_report" <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Pod Diagnostics Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
        .header { background-color: #f4f4f4; padding: 20px; border-radius: 5px; margin-bottom: 30px; }
        .section { margin: 30px 0; }
        .pod-card { border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin: 10px 0; }
        .healthy { border-left: 5px solid #28a745; }
        .unhealthy { border-left: 5px solid #dc3545; }
        .warning { border-left: 5px solid #ffc107; }
        .metric { display: inline-block; margin: 10px 15px 10px 0; padding: 8px 12px; background-color: #e9ecef; border-radius: 3px; }
        .issue { background-color: #fff3cd; padding: 10px; border-radius: 3px; margin: 10px 0; }
        pre { background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }
        .tabs { border-bottom: 1px solid #ddd; margin-bottom: 20px; }
        .tab { display: inline-block; padding: 10px 20px; cursor: pointer; border-bottom: 2px solid transparent; }
        .tab.active { border-bottom-color: #007bff; color: #007bff; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }
    </style>
    <script>
        function showTab(tabName) {
            // Hide all tab contents
            var contents = document.getElementsByClassName('tab-content');
            for (var i = 0; i < contents.length; i++) {
                contents[i].classList.remove('active');
            }
            
            // Remove active class from all tabs
            var tabs = document.getElementsByClassName('tab');
            for (var i = 0; i < tabs.length; i++) {
                tabs[i].classList.remove('active');
            }
            
            // Show selected tab content and mark tab as active
            document.getElementById(tabName).classList.add('active');
            event.target.classList.add('active');
        }
    </script>
</head>
<body>
    <div class="header">
        <h1>üîç Pod Diagnostics Report</h1>
        <div class="metric">
            <strong>Generated:</strong> $(date)
        </div>
        <div class="metric">
            <strong>Cluster:</strong> $(kubectl config current-context)
        </div>
        <div class="metric">
            <strong>Diagnostics Version:</strong> 2.0
        </div>
    </div>
    
    <div class="tabs">
        <div class="tab active" onclick="showTab('overview')">Overview</div>
        <div class="tab" onclick="showTab('pods')">Pod Analysis</div>
        <div class="tab" onclick="showTab('issues')">Detected Issues</div>
        <div class="tab" onclick="showTab('recommendations')">Recommendations</div>
    </div>
    
    <div id="overview" class="tab-content active">
        <h2>üìä Cluster Overview</h2>
        <div class="section">
EOF
    
    # Add cluster metrics
    local total_nodes=$(kubectl get nodes --no-headers | wc -l)
    local ready_nodes=$(kubectl get nodes --no-headers | grep " Ready " | wc -l)
    local total_namespaces=$(kubectl get namespaces --no-headers | wc -l)
    
    cat >> "$final_report" <<EOF
            <div class="pod-card healthy">
                <h3>Cluster Metrics</h3>
                <div class="metric"><strong>Nodes:</strong> $ready_nodes/$total_nodes Ready</div>
                <div class="metric"><strong>Namespaces:</strong> $total_namespaces</div>
                <div class="metric"><strong>Kubernetes Version:</strong> $(kubectl version --short --client | cut -d' ' -f3)</div>
            </div>
        </div>
    </div>
    
    <div id="pods" class="tab-content">
        <h2>üöÄ Pod Analysis</h2>
EOF
    
    # Add pod analysis for each analyzed pod
    for pod_dir in "$OUTPUT_DIR"/pods/*/; do
        if [[ -d "$pod_dir" ]]; then
            local pod_name=$(basename "$pod_dir")
            local issues_count=0
            
            if [[ -f "$pod_dir/detected_issues.md" ]]; then
                issues_count=$(grep -c "## Issue" "$pod_dir/detected_issues.md" 2>/dev/null || echo "0")
            fi
            
            local card_class="healthy"
            if [[ $issues_count -gt 0 ]]; then
                card_class="unhealthy"
            fi
            
            cat >> "$final_report" <<EOF
        <div class="pod-card $card_class">
            <h3>üì¶ $pod_name</h3>
            <div class="metric"><strong>Issues Detected:</strong> $issues_count</div>
            <div class="metric"><strong>Analysis Files:</strong> $(ls "$pod_dir" | wc -l)</div>
            <div class="metric"><strong>Report Location:</strong> pods/$pod_name/</div>
        </div>
EOF
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="issues" class="tab-content">
        <h2>‚ö†Ô∏è Detected Issues</h2>
EOF
    
    # Aggregate all issues
    local total_issues=0
    for issues_file in "$OUTPUT_DIR"/pods/*/detected_issues.md; do
        if [[ -f "$issues_file" ]]; then
            local pod_issues=$(grep -c "## Issue" "$issues_file" 2>/dev/null || echo "0")
            ((total_issues += pod_issues))
            
            if [[ $pod_issues -gt 0 ]]; then
                local pod_name=$(basename "$(dirname "$issues_file")")
                echo "<h3>Issues for $pod_name</h3>" >> "$final_report"
                
                # Convert markdown issues to HTML
                grep "## Issue" "$issues_file" | while read -r line; do
                    echo "<div class=\"issue\">$line</div>" >> "$final_report"
                done
            fi
        fi
    done
    
    if [[ $total_issues -eq 0 ]]; then
        echo "<div class=\"pod-card healthy\"><h3>‚úÖ No Issues Detected</h3><p>All analyzed pods appear to be healthy!</p></div>" >> "$final_report"
    fi
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="recommendations" class="tab-content">
        <h2>üí° Recommendations</h2>
        <div class="section">
            <div class="pod-card warning">
                <h3>General Recommendations</h3>
                <ul>
                    <li>‚úÖ Implement comprehensive health checks for all pods</li>
                    <li>‚úÖ Set appropriate resource requests and limits</li>
                    <li>‚úÖ Use security contexts to harden pod security</li>
                    <li>‚úÖ Monitor resource usage and optimize accordingly</li>
                    <li>‚úÖ Implement graceful shutdown handling</li>
                    <li>‚úÖ Use multi-stage Docker builds for smaller images</li>
                    <li>‚úÖ Implement proper logging and observability</li>
                </ul>
            </div>
        </div>
EOF
    
    # Add pod-specific recommendations
    for rec_file in "$OUTPUT_DIR"/pods/*/recommendations.md; do
        if [[ -f "$rec_file" ]]; then
            local pod_name=$(basename "$(dirname "$rec_file")")
            echo "<div class=\"pod-card\"><h3>Recommendations for $pod_name</h3>" >> "$final_report"
            echo "<p>See detailed recommendations in: pods/$pod_name/recommendations.md</p></div>" >> "$final_report"
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div class="section">
        <hr>
        <p><em>Report generated by Pod Diagnostics Toolkit v2.0</em></p>
        <p><em>For detailed analysis, check individual files in the diagnostics output directory.</em></p>
    </div>
    
</body>
</html>
EOF
    
    log_success "Comprehensive report generated: $final_report"
    echo ""
    echo -e "${BOLD}üìã Diagnostic Summary:${NC}"
    echo "- Output Directory: $OUTPUT_DIR"
    echo "- HTML Report: $final_report"
    echo "- Total Issues Found: $total_issues"
    echo ""
    echo -e "${CYAN}üí° Next Steps:${NC}"
    echo "1. Open $final_report in your browser"
    echo "2. Review individual pod analysis in $OUTPUT_DIR/pods/"
    echo "3. Implement recommended fixes"
    echo "4. Re-run diagnostics to verify improvements"
}

# Main execution function
main() {
    local command=${1:-help}
    local pod_name=${2:-}
    local namespace=${3:-$NAMESPACE}
    
    case "$command" in
        "analyze")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for analysis"
                echo "Usage: $0 analyze <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            gather_pod_info "$pod_name" "$namespace"
            detect_common_issues "$pod_name" "$namespace"
            generate_recommendations "$pod_name" "$namespace"
            generate_final_report
            ;;
            
        "interactive")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for interactive mode"
                echo "Usage: $0 interactive <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            interactive_diagnostics "$pod_name" "$namespace"
            ;;
            
        "cluster-health")
            init_diagnostics
            cluster_health_assessment
            generate_final_report
            ;;
            
        "help"|*)
            cat <<EOF
üîç Advanced Pod Diagnostics Toolkit

Usage: $0 <command> [options]

Commands:
  analyze <pod-name> [namespace]     - Run comprehensive pod analysis
  interactive <pod-name> [namespace] - Start interactive diagnostic session
  cluster-health                     - Assess health of all pods in cluster
  help                              - Show this help message

Environment Variables:
  NAMESPACE - Default namespace (default: default)
  VERBOSE   - Enable verbose output (default: false)

Examples:
  $0 analyze nginx-pod production
  $0 interactive web-app-123
  $0 cluster-health
  VERBOSE=true $0 analyze problematic-pod

Output:
  All diagnostic data is saved to ./diagnostics-TIMESTAMP/
  HTML report provides comprehensive overview
  Individual pod analysis available in pods/ subdirectory

EOF
            ;;
    esac
}

# Execute main function
main "$@"
```

---

## Summary and Production-Ready Examples

### üèÜ Complete Production Workflow

Let's create a final comprehensive example that brings everything together:

```yaml
# complete-production-workflow.yaml
# This represents a complete production-ready pod deployment workflow

apiVersion: v1
kind: Namespace
metadata:
  name: production-workload
  labels:
    environment: production
    team: platform
---
# ConfigMap for application configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production-workload
data:
  app.properties: |
    server.port=8080
    management.port=8081
    logging.level=INFO
    metrics.enabled=true
  nginx.conf: |
    server {
        listen 80;
        location /health { return 200 'healthy\n'; }
        location /ready { return 200 'ready\n'; }
        location / {
            proxy_pass http://127.0.0.1:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
---
# Secret for sensitive configuration
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: production-workload
type: Opaque
data:
  database-password: c3VwZXJzZWNyZXQ=  # supersecret (base64)
  api-key: YWJjZGVmZ2hpams=  # abcdefghijk (base64)
---
# Production-ready pod with all best practices
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production-workload
  labels:
    app: production-app
    version: "2.1.0"
    environment: production
    team: platform
    component: backend
  annotations:
    description: "Production application with full observability"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/production-app"
    prometheus.io/scrape: "true"
    prometheus.io/port: "8081"
    prometheus.io/path: "/metrics"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Resource constraints and node placement
  nodeSelector:
    node-type: "application"
    performance-tier: "high"
    
  tolerations:
  - key: "dedicated-app"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
    
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: production-app
        topologyKey: kubernetes.io/hostname
        
  # DNS and network configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  # Init container for setup tasks
  initContainers:
  - name: setup
    image: busybox:1.35
    command:
    - /bin/sh
    - -c
    - |
      echo "Initializing application..."
      
      # Database migration simulation
      echo "Running database migrations..."
      sleep 5
      
      # Cache warming
      echo "Warming up caches..."
      sleep 3
      
      # Configuration validation
      echo "Validating configuration..."
      if [ -f /config/app.properties ]; then
        echo "‚úÖ Configuration file found"
      else
        echo "‚ùå Configuration file missing"
        exit 1
      fi
      
      echo "Initialization completed successfully"
      
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-init
      mountPath: /tmp
      
  # Main application containers
  containers:
  # Application container
  - name: app
    image: openjdk:11-jre-slim
    command:
    - /bin/bash
    - -c
    - |
      echo "Starting application..."
      
      # Simulated application startup
      java -Xmx200m -Xms100m -jar /app/application.jar \
        --spring.config.location=file:/config/app.properties \
        --server.port=8080 \
        --management.server.port=8081
        
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP
    - name: management
      containerPort: 8081
      protocol: TCP
      
    # Environment configuration
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # Sensitive configuration from secrets
    - name: DATABASE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: database-password
    - name: API_KEY
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: api-key
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security hardening
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    # Comprehensive health checks
    livenessProbe:
      httpGet:
        path: /actuator/health/liveness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /actuator/health/readiness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /actuator/health
        port: 8081
      initialDelaySeconds: 20
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle management
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Application started at $(date)" >> /tmp/startup.log
            # Custom post-start logic here
            
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Graceful shutdown initiated at $(date)" >> /tmp/shutdown.log
            # Send SIGTERM to application
            kill -TERM 1
            # Wait for graceful shutdown
            sleep 30
            
    # Volume mounts
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-volume
      mountPath: /tmp
    - name: app-logs
      mountPath: /app/logs
    - name: app-data
      mountPath: /app/data
      
  # Nginx reverse proxy sidecar
  - name: nginx-proxy
    image: nginx:1.21-alpine
    ports:
    - name: http-proxy
      containerPort: 80
      protocol: TCP
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        add: ["NET_BIND_SERVICE"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: nginx-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
      
  # Logging and monitoring sidecar
  - name: log-shipper
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: fluent-tmp
      mountPath: /tmp
      
  # Volumes
  volumes:
  - name: config-volume
    configMap:
      name: app-config
      items:
      - key: app.properties
        path: app.properties
  - name: nginx-config
    configMap:
      name: app-config
      items:
      - key: nginx.conf
        path: default.conf
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config  # Would be created separately
  # Temporary and cache volumes
  - name: tmp-volume
    emptyDir:
      sizeLimit: 256Mi
  - name: tmp-init
    emptyDir:
      sizeLimit: 64Mi
  - name: nginx-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: fluent-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: nginx-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: nginx-run
    emptyDir:
      sizeLimit: 32Mi
  # Application data volumes
  - name: app-logs
    emptyDir:
      sizeLimit: 1Gi
  - name: app-data
    emptyDir:
      sizeLimit: 2Gi
```

This comprehensive example demonstrates:

- **Complete security hardening** with proper contexts and capabilities
- **Multi-container architecture** with main app, proxy, and logging sidecars
- **Comprehensive health checks** for all containers
- **Resource optimization** with appropriate requests and limits
- **Configuration management** using ConfigMaps and Secrets
- **Observability** with structured logging and metrics endpoints
- **Production-ready networking** with reverse proxy
- **Graceful lifecycle management** with init containers and shutdown hooks

## üéì Key Learning Outcomes

By working through these enhanced examples, demos, and mini-projects, you've gained:

1. **Foundation Skills**: Basic pod creation, inspection, and management
2. **Intermediate Capabilities**: Multi-container patterns, health monitoring, and debugging
3. **Advanced Techniques**: Performance optimization, security hardening, and automation
4. **Expert-Level Mastery**: Custom controllers, comprehensive diagnostics, and production workflows

### üöÄ Next Steps for Continued Learning

1. **Practice the Examples**: Work through each example in your own cluster
2. **Customize for Your Use Cases**: Adapt the patterns to your specific applications
3. **Build Your Toolkit**: Create your own diagnostic and management scripts
4. **Share and Learn**: Contribute back to the community with your own improvements
5. **Scale Up**: Apply these pod management skills to higher-level controllers

The journey from basic pod creation to# 5. Working with Pods - From Fundamentals to Mastery (Enhanced Edition)

Understanding how to work with pods effectively forms the foundation of all Kubernetes operations. While you'll typically use higher-level controllers like Deployments in production environments, direct pod management skills are essential for debugging, troubleshooting, and truly understanding how Kubernetes applications function at their core. Think of this knowledge as learning to drive a manual transmission car‚Äîeven if you usually drive automatic, understanding the underlying mechanics makes you a better driver overall.

This enhanced guide provides progressive examples, hands-on demos, and real-world mini-projects to solidify your understanding through practical application.

## üéØ Learning Path Overview

- **Foundation Level**: Basic pod creation and inspection
- **Intermediate Level**: Multi-container patterns and health checks
- **Advanced Level**: Complex debugging and optimization
- **Expert Level**: Custom tooling and automation

---

## Understanding Pod Creation Strategies

Creating pods effectively requires understanding when to use imperative commands versus declarative configurations, and how different creation approaches serve different purposes.

### üìö Foundation Examples

Let's start with the absolute basics and progressively build complexity.

#### Example 1: Your First Pod
```bash
# Create the simplest possible pod
kubectl run hello-world --image=nginx --restart=Never

# Verify it's running
kubectl get pods

# Expected output:
# NAME          READY   STATUS    RESTARTS   AGE
# hello-world   1/1     Running   0          30s
```

#### Example 2: Pod with Custom Commands
```bash
# Create a pod that runs a custom command
kubectl run date-pod --image=busybox --restart=Never -- date

# This pod will run the date command and then exit
# Check the output
kubectl logs date-pod

# Clean up
kubectl delete pod date-pod
```

#### Example 3: Interactive Pod Session
```bash
# Create an interactive debugging pod
kubectl run -it debug-pod --image=busybox --restart=Never -- sh

# Inside the pod, try these commands:
# ls -la
# ps aux
# ping google.com
# nslookup kubernetes.default.svc.cluster.local

# Exit and clean up
# exit
kubectl delete pod debug-pod
```

### üõ†Ô∏è Demo: Pod Lifecycle Observation

Let's create a demo that shows the complete pod lifecycle in action:

```bash
#!/bin/bash
# pod-lifecycle-demo.sh

echo "=== Pod Lifecycle Demonstration ==="

# Terminal 1: Start watching pods
echo "In a separate terminal, run: kubectl get pods -w"
echo "Press Enter when ready..."
read

# Create a pod with a slow-starting application
echo "Creating pod with slow startup..."
kubectl run lifecycle-demo --image=nginx --restart=Never \
  --dry-run=client -o yaml > lifecycle-pod.yaml

# Add some customizations to make it more interesting
cat <<EOF >> lifecycle-pod.yaml
  containers:
  - name: nginx
    image: nginx:1.21
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod starting up...' && sleep 10"
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod shutting down...' && sleep 5"
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 5
EOF

echo "Applying pod configuration..."
kubectl apply -f lifecycle-pod.yaml

echo "Watch the pod states change from Pending -> ContainerCreating -> Running"
echo "Press Enter to continue when pod is Running..."
read

# Show detailed pod information
echo "=== Pod Details ==="
kubectl describe pod lifecycle-demo

echo "Press Enter to delete the pod and observe termination..."
read

# Delete and watch termination
kubectl delete pod lifecycle-demo

echo "Demo complete! Clean up the YAML file:"
echo "rm lifecycle-pod.yaml"
```

### üéØ Mini-Project 1: Pod Resource Monitor

Create a simple monitoring system using pods:

```yaml
# resource-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-monitor
  labels:
    app: monitor
    type: demo
spec:
  containers:
  - name: monitor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Starting Resource Monitor..."
      while true; do
        echo "=== $(date) ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "Load average:"
        uptime
        echo "Sleeping for 30 seconds..."
        sleep 30
      done
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
  restartPolicy: Always
```

```bash
# Deploy and monitor
kubectl apply -f resource-monitor-pod.yaml

# Watch the logs
kubectl logs -f resource-monitor

# In another terminal, check resource usage
kubectl top pod resource-monitor

# Clean up
kubectl delete -f resource-monitor-pod.yaml
```

---

## Deep Pod Inspection and Monitoring

### üîç Intermediate Examples

#### Example 4: Multi-Container Pod Investigation

```yaml
# multi-container-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-demo
  labels:
    demo: multi-container
spec:
  containers:
  - name: web-server
    image: nginx:1.21
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
    
  - name: log-processor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Log processor starting..."
      while true; do
        if [ -f /var/log/nginx/access.log ]; then
          echo "=== Access Log Summary $(date) ==="
          tail -10 /var/log/nginx/access.log | wc -l
          echo "Recent requests:"
          tail -5 /var/log/nginx/access.log
        else
          echo "Waiting for access.log..."
        fi
        sleep 30
      done
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
      
  - name: metrics-collector
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Metrics collector starting..."
      while true; do
        echo "=== Metrics $(date) ==="
        echo "Container count: 3"
        echo "Uptime: $(uptime)"
        echo "Memory: $(free -h | grep Mem)"
        sleep 60
      done
      
  volumes:
  - name: shared-logs
    emptyDir: {}
```

**Inspection Commands:**
```bash
# Apply the multi-container pod
kubectl apply -f multi-container-demo.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/multi-container-demo

# Inspect different aspects
echo "=== Basic Information ==="
kubectl get pod multi-container-demo -o wide

echo "=== Container Status ==="
kubectl get pod multi-container-demo -o jsonpath='{.status.containerStatuses[*].name}' | tr ' ' '\n'

echo "=== Logs from each container ==="
kubectl logs multi-container-demo -c web-server --tail=5
kubectl logs multi-container-demo -c log-processor --tail=5
kubectl logs multi-container-demo -c metrics-collector --tail=5

# Generate some traffic to see shared volume in action
kubectl port-forward multi-container-demo 8080:80 &
PF_PID=$!

# Generate requests
for i in {1..10}; do
  curl -s http://localhost:8080 > /dev/null
  echo "Request $i sent"
  sleep 1
done

kill $PF_PID

# Check log processor output
kubectl logs multi-container-demo -c log-processor --tail=10

# Clean up
kubectl delete -f multi-container-demo.yaml
```

### üõ†Ô∏è Demo: Advanced Pod Debugging Techniques

```bash
#!/bin/bash
# advanced-debugging-demo.sh

echo "=== Advanced Pod Debugging Demo ==="

# Create a problematic pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: problematic-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "2000m"  # This might cause scheduling issues
      limits:
        memory: "512Mi"  # Less than request - invalid!
        cpu: "500m"
    livenessProbe:
      httpGet:
        path: /nonexistent
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
EOF

echo "Created a pod with multiple issues. Let's debug it..."

# Wait a moment for issues to manifest
sleep 10

echo "=== Debugging Steps ==="

echo "1. Check pod status:"
kubectl get pod problematic-pod -o wide

echo "2. Look at events:"
kubectl describe pod problematic-pod | grep -A 10 Events:

echo "3. Check for resource issues:"
kubectl describe pod problematic-pod | grep -A 5 -B 5 "resource"

echo "4. Examine container status:"
kubectl get pod problematic-pod -o jsonpath='{.status.containerStatuses[0]}' | jq '.'

# Fix the pod
echo "5. Let's fix the issues..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: fixed-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
EOF

echo "6. Compare the fixed pod:"
kubectl wait --for=condition=Ready pod/fixed-pod --timeout=60s
kubectl get pods -l debug=demo

# Clean up
echo "Cleaning up..."
kubectl delete pod problematic-pod fixed-pod
```

### üéØ Mini-Project 2: Pod Health Monitoring Dashboard

Create a comprehensive health monitoring system:

```yaml
# health-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: health-dashboard
  labels:
    app: health-monitor
spec:
  containers:
  - name: health-checker
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Health Dashboard Starting..."
      
      # Create a simple HTML dashboard
      mkdir -p /tmp/dashboard
      
      while true; do
        cat > /tmp/dashboard/health.html <<EOF
      <!DOCTYPE html>
      <html>
      <head>
          <title>Pod Health Dashboard</title>
          <meta http-equiv="refresh" content="30">
          <style>
              body { font-family: Arial, sans-serif; margin: 40px; }
              .healthy { color: green; }
              .warning { color: orange; }
              .critical { color: red; }
              .metric { margin: 10px 0; padding: 10px; border: 1px solid #ccc; }
          </style>
      </head>
      <body>
          <h1>Pod Health Dashboard</h1>
          <p>Last Update: $(date)</p>
          
          <div class="metric">
              <h3>System Load</h3>
              <p>$(uptime)</p>
          </div>
          
          <div class="metric">
              <h3>Memory Usage</h3>
              <pre>$(free -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Disk Usage</h3>
              <pre>$(df -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Process Count</h3>
              <p>Running processes: $(ps aux | wc -l)</p>
          </div>
          
      </body>
      </html>
      EOF
        
        echo "Dashboard updated at $(date)"
        sleep 30
      done
    volumeMounts:
    - name: dashboard-storage
      mountPath: /tmp/dashboard
      
  - name: web-server
    image: nginx:alpine
    ports:
    - containerPort: 80
    command:
    - /bin/sh
    - -c
    - |
      # Configure nginx to serve our dashboard
      cat > /etc/nginx/conf.d/default.conf <<EOF
      server {
          listen 80;
          location / {
              root /usr/share/nginx/html;
              index health.html;
          }
      }
      EOF
      
      # Start nginx
      nginx -g "daemon off;"
    volumeMounts:
    - name: dashboard-storage
      mountPath: /usr/share/nginx/html
      
  volumes:
  - name: dashboard-storage
    emptyDir: {}
    
  restartPolicy: Always
```

**Usage:**
```bash
# Deploy the health dashboard
kubectl apply -f health-monitor-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/health-dashboard

# Access the dashboard
kubectl port-forward health-dashboard 8080:80

# Open browser to http://localhost:8080
echo "Open http://localhost:8080 in your browser"

# Monitor the pod's own health
kubectl top pod health-dashboard

# Check logs from both containers
kubectl logs health-dashboard -c health-checker --tail=10
kubectl logs health-dashboard -c web-server --tail=10

# Clean up
kubectl delete -f health-monitor-pod.yaml
```

---

## Interactive Pod Management and Debugging

### üîß Advanced Examples

#### Example 5: Network Debugging Pod

```yaml
# network-debug-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: network-debugger
  labels:
    purpose: network-debug
spec:
  containers:
  - name: nettools
    image: nicolaka/netshoot
    command: ["/bin/bash"]
    args:
    - -c
    - |
      echo "Network debugging tools ready!"
      echo "Available tools: dig, nslookup, ping, curl, wget, tcpdump, netstat"
      echo "Example commands:"
      echo "  dig kubernetes.default.svc.cluster.local"
      echo "  ping 8.8.8.8"
      echo "  curl -I http://httpbin.org/headers"
      echo "  netstat -tulpn"
      
      # Keep container running
      sleep 3600
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
  restartPolicy: Never
```

**Debugging Session:**
```bash
# Deploy the network debugger
kubectl apply -f network-debug-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/network-debugger

# Start interactive session
kubectl exec -it network-debugger -- bash

# Inside the pod, run network diagnostics:
# Test DNS resolution
# dig kubernetes.default.svc.cluster.local

# Test external connectivity
# ping -c 3 8.8.8.8

# Test HTTP services
# curl -I https://httpbin.org/headers

# Check network interfaces
# ip addr show

# Check routing table
# ip route show

# Test service discovery
# nslookup kubernetes.default

# Exit and clean up
# exit
kubectl delete -f network-debug-pod.yaml
```

### üõ†Ô∏è Demo: File Transfer and Volume Management

```bash
#!/bin/bash
# file-transfer-demo.sh

echo "=== File Transfer and Volume Demo ==="

# Create a pod with persistent data
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: file-demo
spec:
  containers:
  - name: app
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Creating sample files..."
      mkdir -p /data/logs /data/config
      
      # Generate some sample data
      for i in {1..5}; do
        echo "Log entry \$i at \$(date)" >> /data/logs/app.log
        sleep 1
      done
      
      echo "app_name=demo-app" > /data/config/settings.conf
      echo "version=1.0.0" >> /data/config/settings.conf
      echo "debug=true" >> /data/config/settings.conf
      
      echo "Files created. Keeping container running..."
      sleep 3600
    volumeMounts:
    - name: data-storage
      mountPath: /data
  volumes:
  - name: data-storage
    emptyDir: {}
EOF

echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/file-demo

# Demonstrate file operations
echo "=== File Operations Demo ==="

echo "1. List files in the pod:"
kubectl exec file-demo -- find /data -type f

echo "2. Copy file from pod to local:"
kubectl cp file-demo:/data/logs/app.log ./app.log.backup
echo "File copied to: app.log.backup"
cat app.log.backup

echo "3. Create local config file:"
cat > new-config.conf <<EOF
app_name=updated-demo-app
version=2.0.0
debug=false
environment=production
EOF

echo "4. Copy local file to pod:"
kubectl cp new-config.conf file-demo:/data/config/

echo "5. Verify file in pod:"
kubectl exec file-demo -- cat /data/config/new-config.conf

echo "6. Create a backup of all data:"
kubectl exec file-demo -- tar -czf /tmp/backup.tar.gz -C /data .
kubectl cp file-demo:/tmp/backup.tar.gz ./pod-data-backup.tar.gz
echo "Backup created: pod-data-backup.tar.gz"

# Clean up
echo "Cleaning up..."
kubectl delete pod file-demo
rm -f app.log.backup new-config.conf pod-data-backup.tar.gz

echo "Demo complete!"
```

### üéØ Mini-Project 3: Pod Security Scanner

Create a security scanning tool using pods:

```yaml
# security-scanner-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-scanner
  labels:
    app: security
    type: scanner
spec:
  serviceAccountName: default
  containers:
  - name: scanner
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "=== Pod Security Scanner Starting ==="
      
      # Function to check security configurations
      check_security() {
        echo "Checking security configurations..."
        
        # Check if running as root
        if [ "$(id -u)" -eq 0 ]; then
          echo "‚ö†Ô∏è  WARNING: Running as root user"
        else
          echo "‚úÖ GOOD: Running as non-root user ($(id -u))"
        fi
        
        # Check filesystem permissions
        if [ -w "/" ]; then
          echo "‚ö†Ô∏è  WARNING: Root filesystem is writable"
        else
          echo "‚úÖ GOOD: Root filesystem is read-only"
        fi
        
        # Check for sensitive mounts
        if mount | grep -q "/var/run/secrets"; then
          echo "‚ÑπÔ∏è  INFO: Service account token mounted"
        fi
        
        # Check available capabilities
        echo "Current capabilities:"
        if [ -f "/proc/self/status" ]; then
          grep Cap /proc/self/status
        fi
        
        # Check network access
        echo "Testing network access..."
        if ping -c 1 8.8.8.8 >/dev/null 2>&1; then
          echo "‚ÑπÔ∏è  INFO: External network access available"
        else
          echo "‚ÑπÔ∏è  INFO: No external network access"
        fi
        
        # Generate security report
        cat > /tmp/security-report.txt <<EOF
      === Security Scan Report ===
      Timestamp: $(date)
      User ID: $(id -u)
      Group ID: $(id -g)
      Working Directory: $(pwd)
      
      Filesystem Check:
      - Root writable: $([ -w "/" ] && echo "YES" || echo "NO")
      - /tmp writable: $([ -w "/tmp" ] && echo "YES" || echo "NO")
      
      Network Check:
      - External access: $(ping -c 1 8.8.8.8 >/dev/null 2>&1 && echo "YES" || echo "NO")
      
      Process Information:
      $(ps aux)
      EOF
        
        echo "Report generated at /tmp/security-report.txt"
      }
      
      # Run security check
      check_security
      
      # Keep running for inspection
      echo "Scanner complete. Container will stay running for inspection."
      sleep 3600
      
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 1000
      runAsGroup: 3000
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir: {}
    
  restartPolicy: Never
```

**Usage:**
```bash
# Deploy the security scanner
kubectl apply -f security-scanner-pod.yaml

# Monitor the scan
kubectl logs -f security-scanner

# Get the security report
kubectl cp security-scanner:/tmp/security-report.txt ./security-report.txt
cat security-report.txt

# Create a comparison with an insecure pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: insecure-pod
spec:
  containers:
  - name: insecure
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      runAsUser: 0  # Running as root
      privileged: true
EOF

# Compare security postures
echo "=== Security Comparison ==="
echo "Secure pod user:"
kubectl exec security-scanner -- id

echo "Insecure pod user:"
kubectl exec insecure-pod -- id

echo "Secure pod capabilities:"
kubectl exec security-scanner -- grep Cap /proc/self/status

echo "Insecure pod capabilities:"
kubectl exec insecure-pod -- grep Cap /proc/self/status

# Clean up
kubectl delete pod security-scanner insecure-pod
rm -f security-report.txt
```

---

## Declarative Pod Configuration and Management

### üèóÔ∏è Expert Examples

#### Example 6: Production-Ready Pod Template

```yaml
# production-pod-template.yaml
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production
  labels:
    app: web-server
    version: "2.1.0"
    environment: production
    team: platform
  annotations:
    description: "Production web server with full monitoring and security"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/web-server"
    version: "2.1.0"
    build-date: "2024-01-15T10:30:00Z"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Node selection
  nodeSelector:
    node-type: "application"
    zone: "us-west-2a"
    
  # Tolerations for dedicated nodes
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "application"
    effect: "NoSchedule"
    
  # Pod placement preferences
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: "node-type"
            operator: In
            values: ["application"]
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: web-server
          topologyKey: kubernetes.io/hostname
          
  # DNS configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  containers:
  - name: web-server
    image: nginx:1.21-alpine
    imagePullPolicy: IfNotPresent
    
    ports:
    - name: http
      containerPort: 80
      protocol: TCP
    - name: metrics
      containerPort: 9113
      protocol: TCP
      
    # Environment variables
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "info"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security context
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE
        
    # Health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 80
        scheme: HTTP
        httpHeaders:
        - name: Custom-Header
          value: liveness-check
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
        scheme: HTTP
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle hooks
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container started at $(date)" >> /tmp/startup.log
            # Custom initialization logic here
            
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container stopping at $(date)" >> /tmp/shutdown.log
            # Graceful shutdown logic here
            nginx -s quit
            sleep 15
            
    # Volume mounts
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  # Sidecar container for log processing
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  # Monitoring sidecar
  - name: nginx-exporter
    image: nginx/nginx-prometheus-exporter:0.10.0
    args:
    - -nginx.scrape-uri=http://localhost:80/nginx_status
    ports:
    - name: metrics
      containerPort: 9113
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
  # Shared volumes
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
      defaultMode: 0644
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
      defaultMode: 0644
  - name: html-content
    configMap:
      name: html-content
      defaultMode: 0644
  - name: tmp-dir
    emptyDir:
      sizeLimit: 256Mi
  - name: var-cache-nginx
    emptyDir:
      sizeLimit: 512Mi
  - name: var-run
    emptyDir:
      sizeLimit: 64Mi
  - name: logs
    emptyDir:
      sizeLimit: 1Gi
```

### üõ†Ô∏è Demo: Complex Pod Deployment Pipeline

```bash
#!/bin/bash
# production-pod-deployment.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

# Configuration
NAMESPACE="production-demo"
APP_NAME="web-server"
CONFIG_DIR="./config"

# Create namespace if it doesn't exist
create_namespace() {
    log "Creating namespace: $NAMESPACE"
    kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    success "Namespace $NAMESPACE ready"
}

# Create ConfigMaps for the application
create_configmaps() {
    log "Creating ConfigMaps..."
    
    mkdir -p $CONFIG_DIR
    
    # Nginx configuration
    cat > $CONFIG_DIR/nginx.conf <<EOF
server {
    listen 80;
    server_name localhost;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
    
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    location /ready {
        access_log off;
        return 200 "ready\n";
        add_header Content-Type text/plain;
    }
    
    location /nginx_status {
        stub_status on;
        access_log off;
        allow all;
    }
}
EOF

    # HTML content
    cat > $CONFIG_DIR/index.html <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Production Pod Demo</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .container { max-width: 800px; margin: 0 auto; }
        .status { padding: 20px; margin: 20px 0; border-radius: 5px; }
        .healthy { background-color: #d4edda; color: #155724; }
        .info { background-color: #d1ecf1; color: #0c5460; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Production Pod Demo</h1>
        <div class="status healthy">
            <h3>‚úÖ Application Status: Healthy</h3>
            <p>Pod is running successfully with full production configuration</p>
        </div>
        
        <div class="status info">
            <h3>üìä Features Enabled:</h3>
            <ul>
                <li>Multi-container architecture</li>
                <li>Comprehensive health checks</li>
                <li>Security hardening</li>
                <li>Log processing sidecar</li>
                <li>Prometheus metrics export</li>
                <li>Resource management</li>
            </ul>
        </div>
        
        <div class="status info">
            <h3>üîó Endpoints:</h3>
            <ul>
                <li><a href="/health">Health Check</a></li>
                <li><a href="/ready">Readiness Check</a></li>
                <li><a href="/nginx_status">Nginx Status</a></li>
            </ul>
        </div>
    </div>
</body>
</html>
EOF

    # Fluent Bit configuration
    cat > $CONFIG_DIR/fluent-bit.conf <<EOF
[SERVICE]
    Flush         1
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf

[INPUT]
    Name              tail
    Path              /var/log/nginx/access.log
    Parser            nginx
    Tag               nginx.access
    Refresh_Interval  5

[INPUT]
    Name              tail
    Path              /var/log/nginx/error.log
    Tag               nginx.error
    Refresh_Interval  5

[OUTPUT]
    Name  stdout
    Match nginx.*
EOF

    cat > $CONFIG_DIR/parsers.conf <<EOF
[PARSER]
    Name   nginx
    Format regex
    Regex  ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
    Time_Key time
    Time_Format %d/%b/%Y:%H:%M:%S %z
EOF

    # Create ConfigMaps
    kubectl create configmap nginx-config --from-file=$CONFIG_DIR/nginx.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap html-content --from-file=$CONFIG_DIR/index.html -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap fluent-bit-config --from-file=$CONFIG_DIR/fluent-bit.conf --from-file=$CONFIG_DIR/parsers.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    
    success "ConfigMaps created successfully"
}

# Deploy the production pod
deploy_pod() {
    log "Deploying production pod..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: $APP_NAME
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
    version: "1.0.0"
    environment: production
  annotations:
    deployment.kubernetes.io/revision: "1"
    deployed-by: "production-deployment-script"
    deployment-time: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    
  containers:
  - name: nginx
    image: nginx:1.21-alpine
    ports:
    - name: http
      containerPort: 80
    - name: metrics
      containerPort: 9113
      
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
  - name: html-content
    configMap:
      name: html-content
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
  - name: tmp-dir
    emptyDir: {}
  - name: var-cache-nginx
    emptyDir: {}
  - name: var-run
    emptyDir: {}
  - name: logs
    emptyDir: {}
EOF

    success "Pod deployed successfully"
}

# Wait for pod to be ready and perform health checks
verify_deployment() {
    log "Waiting for pod to be ready..."
    
    if kubectl wait --for=condition=Ready pod/$APP_NAME -n $NAMESPACE --timeout=120s; then
        success "Pod is ready!"
    else
        error "Pod failed to become ready within timeout"
    fi
    
    # Perform comprehensive health checks
    log "Performing health checks..."
    
    # Check pod status
    kubectl get pod $APP_NAME -n $NAMESPACE -o wide
    
    # Test health endpoints
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    if curl -s http://localhost:8080/health | grep -q "healthy"; then
        success "Health check passed"
    else
        warning "Health check failed"
    fi
    
    if curl -s http://localhost:8080/ready | grep -q "ready"; then
        success "Readiness check passed"
    else
        warning "Readiness check failed"
    fi
    
    # Test the main application
    if curl -s http://localhost:8080 | grep -q "Production Pod Demo"; then
        success "Application is serving content correctly"
    else
        warning "Application content check failed"
    fi
    
    kill $PF_PID 2>/dev/null
    
    # Check resource usage
    log "Checking resource usage..."
    if kubectl top pod $APP_NAME -n $NAMESPACE &>/dev/null; then
        kubectl top pod $APP_NAME -n $NAMESPACE
    else
        warning "Resource metrics not available"
    fi
    
    # Check logs from all containers
    log "Checking container logs..."
    echo "=== Nginx logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c nginx --tail=5
    echo "=== Log processor logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=5
}

# Generate load and monitor performance
performance_test() {
    log "Running performance test..."
    
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    # Generate some load
    for i in {1..50}; do
        curl -s http://localhost:8080 > /dev/null &
    done
    
    wait
    kill $PF_PID 2>/dev/null
    
    # Check logs after load test
    log "Logs after load test:"
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=10
    
    success "Performance test completed"
}

# Cleanup function
cleanup() {
    log "Cleaning up resources..."
    kubectl delete pod $APP_NAME -n $NAMESPACE --ignore-not-found
    kubectl delete configmap nginx-config html-content fluent-bit-config -n $NAMESPACE --ignore-not-found
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -rf $CONFIG_DIR
    success "Cleanup completed"
}

# Main execution
main() {
    echo "=== Production Pod Deployment Demo ==="
    
    case "${1:-deploy}" in
        "deploy")
            create_namespace
            create_configmaps
            deploy_pod
            verify_deployment
            performance_test
            
            echo ""
            success "Deployment completed successfully!"
            echo "Access the application:"
            echo "  kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80"
            echo "  Then open: http://localhost:8080"
            echo ""
            echo "Monitor the pod:"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c nginx"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c log-processor"
            echo ""
            echo "Run 'bash $0 cleanup' to remove all resources"
            ;;
        "cleanup")
            cleanup
            ;;
        "test")
            verify_deployment
            performance_test
            ;;
        *)
            echo "Usage: $0 [deploy|cleanup|test]"
            echo "  deploy  - Deploy the production pod (default)"
            echo "  cleanup - Remove all created resources"
            echo "  test    - Run verification and performance tests"
            ;;
    esac
}

main "$@"
```

### üéØ Mini-Project 4: Pod Chaos Engineering

Test pod resilience with chaos engineering principles:

```yaml
# chaos-test-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: chaos-resilient-app
  labels:
    app: chaos-test
    resilience: enabled
spec:
  containers:
  - name: main-app
    image: nginx:1.21-alpine
    ports:
    - containerPort: 80
    
    # Aggressive resource limits to test resilience
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    # Tight health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 2
      
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
      timeoutSeconds: 1
      failureThreshold: 2
      
    # Graceful shutdown
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 10"]
          
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  # Chaos monkey sidecar
  - name: chaos-monkey
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Chaos monkey starting..."
      
      # Function to create CPU load
      cpu_chaos() {
        echo "Creating CPU chaos..."
        for i in {1..4}; do
          yes > /dev/null &
        done
        sleep 30
        killall yes
      }
      
      # Function to create memory pressure
      memory_chaos() {
        echo "Creating memory chaos..."
        cat <(yes | tr \\n x | head -c 50000000) <(yes | tr \\n x | head -c 50000000) > /tmp/memory_eater &
        sleep 20
        rm -f /tmp/memory_eater
        killall cat
      }
      
      # Function to simulate network issues
      network_chaos() {
        echo "Creating network chaos..."
        # Simulate slow responses
        sleep $((RANDOM % 10 + 5))
      }
      
      # Function to create disk I/O pressure
      disk_chaos() {
        echo "Creating disk I/O chaos..."
        dd if=/dev/zero of=/tmp/disk_eater bs=1M count=10 2>/dev/null
        rm -f /tmp/disk_eater
      }
      
      # Main chaos loop
      while true; do
        chaos_type=$((RANDOM % 4))
        case $chaos_type in
          0) cpu_chaos ;;
          1) memory_chaos ;;
          2) network_chaos ;;
          3) disk_chaos ;;
        esac
        
        # Wait between chaos events
        sleep $((RANDOM % 60 + 30))
      done
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir:
      sizeLimit: 100Mi
      
  restartPolicy: Always
```

**Chaos Testing Script:**
```bash
#!/bin/bash
# chaos-engineering-test.sh

echo "=== Chaos Engineering Test ==="

# Deploy the chaos test pod
kubectl apply -f chaos-test-pod.yaml

# Wait for it to be ready
echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/chaos-resilient-app --timeout=60s

# Monitor pod resilience
echo "Starting resilience monitoring (Ctrl+C to stop)..."

monitor_resilience() {
    while true; do
        timestamp=$(date '+%H:%M:%S')
        
        # Check pod status
        status=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.phase}')
        ready=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
        restarts=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.containerStatuses[0].restartCount}')
        
        # Test application responsiveness
        kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
        PF_PID=$!
        sleep 2
        
        response_time=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8080 2>/dev/null || echo "FAIL")
        kill $PF_PID 2>/dev/null
        
        # Get resource usage if available
        resources=""
        if kubectl top pod chaos-resilient-app &>/dev/null; then
            resources=$(kubectl top pod chaos-resilient-app --no-headers 2>/dev/null | awk '{print $2" "$3}')
        fi
        
        printf "[$timestamp] Status: $status | Ready: $ready | Restarts: $restarts | Response: ${response_time}s | Resources: $resources\n"
        
        sleep 5
    done
}

# Start monitoring in background
monitor_resilience &
MONITOR_PID=$!

# Generate additional load to test resilience
echo "Generating load to test resilience..."
for i in {1..100}; do
    kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
    PF_PID=$!
    sleep 1
    
    curl -s http://localhost:8080 > /dev/null &
    
    kill $PF_PID 2>/dev/null
    sleep 2
done

# Stop monitoring
kill $MONITOR_PID 2>/dev/null

echo "Chaos test completed. Check pod logs:"
echo "kubectl logs chaos-resilient-app -c main-app --tail=20"
echo "kubectl logs chaos-resilient-app -c chaos-monkey --tail=20"

# Cleanup
read -p "Delete the chaos test pod? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    kubectl delete -f chaos-test-pod.yaml
fi
```

---

## Advanced Pod Management Techniques

### üî¨ Expert-Level Examples

#### Example 7: Custom Pod Controller

Create a custom controller for specialized pod management:

```python
#!/usr/bin/env python3
# custom-pod-controller.py

import time
import yaml
import subprocess
import json
from datetime import datetime, timedelta

class PodController:
    def __init__(self):
        self.managed_pods = {}
        self.check_interval = 30  # seconds
        
    def log(self, message):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"[{timestamp}] {message}")
        
    def run_kubectl(self, command):
        """Execute kubectl command and return JSON output"""
        try:
            result = subprocess.run(
                f"kubectl {command} -o json",
                shell=True,
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                self.log(f"kubectl error: {result.stderr}")
                return None
        except Exception as e:
            self.log(f"Command execution error: {e}")
            return None
            
    def get_pods_by_label(self, label_selector):
        """Get pods matching label selector"""
        command = f"get pods -l {label_selector}"
        result = self.run_kubectl(command)
        return result.get('items', []) if result else []
        
    def create_pod(self, name, spec):
        """Create a pod with given specification"""
        pod_manifest = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'name': name,
                'labels': {
                    'managed-by': 'custom-controller',
                    'created': datetime.now().strftime('%Y%m%d-%H%M%S')
                }
            },
            'spec': spec
        }
        
        # Write manifest to temporary file
        with open(f'/tmp/{name}.yaml', 'w') as f:
            yaml.dump(pod_manifest, f)
            
        # Apply the manifest
        result = subprocess.run(
            f"kubectl apply -f /tmp/{name}.yaml",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Created pod: {name}")
            return True
        else:
            self.log(f"Failed to create pod {name}: {result.stderr}")
            return False
            
    def delete_pod(self, name):
        """Delete a pod"""
        result = subprocess.run(
            f"kubectl delete pod {name} --grace-period=30",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Deleted pod: {name}")
            return True
        else:
            self.log(f"Failed to delete pod {name}: {result.stderr}")
            return False
            
    def check_pod_health(self, pod):
        """Check if a pod is healthy based on custom criteria"""
        name = pod['metadata']['name']
        status = pod['status']
        
        # Check if pod is running
        if status.get('phase') != 'Running':
            return False, f"Pod {name} is not running (phase: {status.get('phase')})"
            
        # Check container statuses
        container_statuses = status.get('containerStatuses', [])
        for container in container_statuses:
            if not container.get('ready'):
                return False, f"Container {container['name']} not ready in pod {name}"
                
            # Check restart count
            restart_count = container.get('restartCount', 0)
            if restart_count > 5:
                return False, f"Container {container['name']} restarted {restart_count} times"
                
        # Check resource usage (if metrics available)
        metrics = self.get_pod_metrics(name)
        if metrics:
            cpu_usage = self.parse_cpu_usage(metrics.get('cpu', '0m'))
            memory_usage = self.parse_memory_usage(metrics.get('memory', '0Mi'))
            
            if cpu_usage > 800:  # 800 millicores
                return False, f"Pod {name} CPU usage too high: {cpu_usage}m"
                
            if memory_usage > 512:  # 512 Mi
                return False, f"Pod {name} memory usage too high: {memory_usage}Mi"
                
        return True, f"Pod {name} is healthy"
        
    def get_pod_metrics(self, pod_name):
        """Get pod resource metrics if available"""
        result = subprocess.run(
            f"kubectl top pod {pod_name} --no-headers",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            parts = result.stdout.strip().split()
            if len(parts) >= 3:
                return {
                    'cpu': parts[1],
                    'memory': parts[2]
                }
        return None
        
    def parse_cpu_usage(self, cpu_str):
        """Parse CPU usage from string like '100m' to millicores"""
        if cpu_str.endswith('m'):
            return int(cpu_str[:-1])
        return int(cpu_str) * 1000
        
    def parse_memory_usage(self, memory_str):
        """Parse memory usage from string like '128Mi' to Mi"""
        if memory_str.endswith('Mi'):
            return int(memory_str[:-2])
        elif memory_str.endswith('Gi'):
            return int(memory_str[:-2]) * 1024
        return int(memory_str) // (1024 * 1024)
        
    def auto_heal_pod(self, pod_name, reason):
        """Attempt to heal an unhealthy pod"""
        self.log(f"Attempting to heal pod {pod_name}: {reason}")
        
        # Strategy 1: Restart the pod
        if "restart" in reason.lower():
            return self.delete_pod(pod_name)  # Pod will be recreated if managed by controller
            
        # Strategy 2: Scale resources if high usage
        if "usage too high" in reason.lower():
            self.log(f"High resource usage detected for {pod_name}, marking for recreation")
            return self.delete_pod(pod_name)
            
        # Strategy 3: Generic restart
        return self.delete_pod(pod_name)
        
    def manage_workload(self, workload_config):
        """Manage a workload with desired replica count"""
        app_name = workload_config['name']
        desired_replicas = workload_config['replicas']
        pod_spec = workload_config['pod_spec']
        
        # Get current pods for this workload
        current_pods = self.get_pods_by_label(f"app={app_name},managed-by=custom-controller")
        current_count = len(current_pods)
        
        self.log(f"Managing workload {app_name}: current={current_count}, desired={desired_replicas}")
        
        # Scale up if needed
        if current_count < desired_replicas:
            for i in range(current_count, desired_replicas):
                pod_name = f"{app_name}-{i}"
                pod_spec_copy = pod_spec.copy()
                pod_spec_copy.setdefault('containers', [{}])[0]['env'] = [
                    {'name': 'REPLICA_ID', 'value': str(i)},
                    {'name': 'APP_NAME', 'value': app_name}
                ]
                self.create_pod(pod_name, pod_spec_copy)
                
        # Scale down if needed
        elif current_count > desired_replicas:
            pods_to_delete = current_pods[desired_replicas:]
            for pod in pods_to_delete:
                self.delete_pod(pod['metadata']['name'])
                
        # Health check existing pods
        for pod in current_pods[:desired_replicas]:
            healthy, reason = self.check_pod_health(pod)
            if not healthy:
                self.log(f"Pod unhealthy: {reason}")
                self.auto_heal_pod(pod['metadata']['name'], reason)
                
    def run_control_loop(self):
        """Main control loop"""
        self.log("Starting custom pod controller...")
        
        # Sample workload configuration
        workloads = [
            {
                'name': 'web-app',
                'replicas': 2,
                'pod_spec': {
                    'containers': [{
                        'name': 'nginx',
                        'image': 'nginx:1.21-alpine',
                        'ports': [{'containerPort': 80}],
                        'resources': {
                            'requests': {'memory': '64Mi', 'cpu': '50m'},
                            'limits': {'memory': '128Mi', 'cpu': '100m'}
                        },
                        'livenessProbe': {
                            'httpGet': {'path': '/', 'port': 80},
                            'initialDelaySeconds': 10,
                            'periodSeconds': 30
                        }
                    }],
                    'restartPolicy': 'Always'
                }
            }
        ]
        
        try:
            while True:
                self.log("Running control loop...")
                
                for workload in workloads:
                    try:
                        self.manage_workload(workload)
                    except Exception as e:
                        self.log(f"Error managing workload {workload['name']}: {e}")
                        
                self.log(f"Sleeping for {self.check_interval} seconds...")
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            self.log("Shutting down controller...")
            
        except Exception as e:
            self.log(f"Controller error: {e}")
            
    def cleanup(self):
        """Clean up managed resources"""
        self.log("Cleaning up managed pods...")
        pods = self.get_pods_by_label("managed-by=custom-controller")
        for pod in pods:
            self.delete_pod(pod['metadata']['name'])

if __name__ == "__main__":
    import sys
    
    controller = PodController()
    
    if len(sys.argv) > 1 and sys.argv[1] == "cleanup":
        controller.cleanup()
    else:
        controller.run_control_loop()
```

**Usage:**
```bash
# Make the script executable
chmod +x custom-pod-controller.py

# Install dependencies
pip3 install pyyaml

# Run the controller
python3 custom-pod-controller.py

# In another terminal, watch the managed pods
watch kubectl get pods -l managed-by=custom-controller

# Simulate pod failures
kubectl delete pod web-app-0  # Controller will recreate it

# Clean up when done
python3 custom-pod-controller.py cleanup
```

### üéØ Mini-Project 5: Pod Performance Optimization Lab

Create a comprehensive performance optimization laboratory:

```yaml
# performance-lab-setup.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: performance-lab
---
# Baseline pod - unoptimized
apiVersion: v1
kind: Pod
metadata:
  name: baseline-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: baseline
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "1000m"
      limits:
        memory: "2Gi"
        cpu: "2000m"
---
# Optimized pod - resource-efficient
apiVersion: v1
kind: Pod
metadata:
  name: optimized-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: optimized
spec:
  containers:
  - name: app
    image: nginx:1.21-alpine  # Smaller image
    resources:
      requests:
        memory: "64Mi"        # Right-sized requests
        cpu: "100m"
      limits:
        memory: "128Mi"       # Conservative limits
        cpu: "200m"
    # Optimized health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5   # Faster startup
      periodSeconds: 30        # Less frequent checks
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
    # Security optimizations
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
    # Volume optimizations
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp-dir
    emptyDir:
      medium: Memory  # Use memory for temp files
      sizeLimit: 64Mi
  - name: var-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: var-run
    emptyDir:
      sizeLimit: 32Mi
---
# High-performance pod with advanced optimizations
apiVersion: v1
kind: Pod
metadata:
  name: high-performance-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: high-performance
spec:
  # Pod-level optimizations
  priorityClassName: high-priority
  nodeSelector:
    node-type: performance
  tolerations:
  - key: performance-node
    operator: Equal
    value: "true"
    effect: NoSchedule
  # Network optimizations
  dnsPolicy: ClusterFirstWithHostNet
  dnsConfig:
    options:
    - name: ndots
      value: "1"
    - name: edns0
  containers:
  - name: app
    image: nginx:1.21-alpine
    # Optimized resource allocation
    resources:
      requests:
        memory: "128Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "256Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
    # Performance-tuned environment
    env:
    - name: NGINX_WORKER_PROCESSES
      value: "auto"
    - name: NGINX_WORKER_CONNECTIONS
      value: "1024"
    # Aggressive health checks for faster recovery
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 15
      timeoutSeconds: 2
      failureThreshold: 2
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 3
      timeoutSeconds: 1
      failureThreshold: 1
    # Startup optimization
    startupProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 1
      timeoutSeconds: 1
      failureThreshold: 10
    # Performance-optimized volumes
    volumeMounts:
    - name: high-speed-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
  volumes:
  - name: high-speed-tmp
    emptyDir:
      medium: Memory
      sizeLimit: 128Mi
  - name: nginx-cache
    emptyDir:
      medium: Memory
      sizeLimit: 256Mi
  - name: nginx-run
    emptyDir:
      medium: Memory
      sizeLimit: 64Mi
```

**Performance Benchmarking Script:**
```bash
#!/bin/bash
# performance-benchmark.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

NAMESPACE="performance-lab"

# Deploy the performance lab
setup_lab() {
    log "Setting up performance lab..."
    kubectl apply -f performance-lab-setup.yaml
    
    log "Waiting for pods to be ready..."
    kubectl wait --for=condition=Ready pod/baseline-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/optimized-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/high-performance-app -n $NAMESPACE --timeout=120s
    
    success "Performance lab setup complete"
}

# Measure startup time
measure_startup_time() {
    local pod_name=$1
    log "Measuring startup time for $pod_name..."
    
    # Delete and recreate pod to measure startup
    kubectl delete pod $pod_name -n $NAMESPACE
    local start_time=$(date +%s.%N)
    
    # Recreate the pod (extract from original manifest)
    kubectl get pod $pod_name -n $NAMESPACE -o yaml --export 2>/dev/null | kubectl apply -f - 2>/dev/null || {
        warning "Couldn't recreate pod automatically, recreating from manifest"
        kubectl apply -f performance-lab-setup.yaml
    }
    
    # Wait for ready and measure time
    kubectl wait --for=condition=Ready pod/$pod_name -n $NAMESPACE --timeout=120s
    local end_time=$(date +%s.%N)
    
    local startup_time=$(echo "$end_time - $start_time" | bc -l)
    echo "$startup_time"
}

# Run load test on a pod
load_test_pod() {
    local pod_name=$1
    local duration=${2:-30}
    local concurrency=${3:-10}
    
    log "Running load test on $pod_name (${duration}s, ${concurrency} concurrent)"
    
    # Start port forwarding
    kubectl port-forward pod/$pod_name -n $NAMESPACE 8080:80 >/dev/null 2>&1 &
    local pf_pid=$!
    sleep 3
    
    # Use Apache Bench for load testing
    local results_file="/tmp/ab_results_${pod_name}.txt"
    
    if command -v ab >/dev/null; then
        ab -n $((duration * concurrency)) -c $concurrency -g /tmp/gnuplot_${pod_name}.dat \
           http://localhost:8080/ > $results_file 2>&1
        
        # Extract key metrics
        local rps=$(grep "Requests per second" $results_file | awk '{print $4}')
        local response_time=$(grep "Time per request.*mean" $results_file | head -1 | awk '{print $4}')
        local failed_requests=$(grep "Failed requests" $results_file | awk '{print $3}')
        
        echo "RPS:$rps,ResponseTime:$response_time,Failed:$failed_requests"
    else
        # Fallback to curl-based test
        local start_time=$(date +%s)
        local requests=0
        local total_time=0
        
        for i in $(seq 1 $((duration * concurrency))); do
            local req_start=$(date +%s.%N)
            if curl -s http://localhost:8080 >/dev/null 2>&1; then
                ((requests++))
            fi
            local req_end=$(date +%s.%N)
            local req_time=$(echo "$req_end - $req_start" | bc -l)
            total_time=$(echo "$total_time + $req_time" | bc -l)
            
            # Basic rate limiting
            sleep 0.1
        done
        
        local avg_response_time=$(echo "scale=3; $total_time / $requests" | bc -l)
        local rps=$(echo "scale=2; $requests / $duration" | bc -l)
        
        echo "RPS:$rps,ResponseTime:$avg_response_time,Failed:0"
    fi
    
    kill $pf_pid 2>/dev/null
}

# Get resource usage metrics
get_resource_usage() {
    local pod_name=$1
    log "Getting resource usage for $pod_name..."
    
    if kubectl top pod $pod_name -n $NAMESPACE >/dev/null 2>&1; then
        kubectl top pod $pod_name -n $NAMESPACE --no-headers | awk '{print "CPU:"$2",Memory:"$3}'
    else
        echo "CPU:N/A,Memory:N/A"
    fi
}

# Comprehensive benchmark
run_comprehensive_benchmark() {
    log "Running comprehensive performance benchmark..."
    
    declare -A results
    local pods=("baseline-app" "optimized-app" "high-performance-app")
    
    echo "=== Performance Benchmark Results ===" > benchmark_results.txt
    echo "Timestamp: $(date)" >> benchmark_results.txt
    echo "" >> benchmark_results.txt
    
    for pod in "${pods[@]}"; do
        log "Benchmarking $pod..."
        
        # Startup time measurement
        log "Measuring startup time for $pod..."
        # Skip startup measurement in this demo to avoid pod recreation issues
        startup_time="N/A"
        
        # Resource usage
        resource_usage=$(get_resource_usage $pod)
        
        # Load test
        load_results=$(load_test_pod $pod 30 10)
        
        # Pod status information
        pod_info=$(kubectl get pod $pod -n $NAMESPACE -o custom-columns=STATUS:.status.phase,READY:.status.conditions[?\(@.type==\"Ready\"\)].status,RESTARTS:.status.containerStatuses[0].restartCount --no-headers)
        
        # Store results
        results[$pod]="Startup:$startup_time,Resources:$resource_usage,Load:$load_results,Status:$pod_info"
        
        # Write to file
        cat >> benchmark_results.txt <<EOF

=== $pod ===
Startup Time: $startup_time seconds
Resource Usage: $resource_usage
Load Test Results: $load_results
Pod Status: $pod_info

EOF
    done
    
    # Generate comparison summary
    cat >> benchmark_results.txt <<EOF

=== Performance Summary ===
This benchmark compares three pod configurations:

1. Baseline App: Standard configuration with generous resource allocation
2. Optimized App: Resource-efficient with security hardening
3. High-Performance App: Maximum performance optimizations

Key Findings:
- Resource efficiency varies significantly between configurations
- Startup time impacts overall application availability
- Load handling capacity differs based on resource allocation
- Security optimizations may have performance trade-offs

Recommendations:
- Use optimized configuration for production workloads
- Consider high-performance setup for critical applications
- Monitor resource usage to fine-tune allocations
- Balance security and performance based on requirements

EOF
    
    success "Benchmark completed. Results saved to benchmark_results.txt"
    cat benchmark_results.txt
}

# Resource monitoring script
monitor_resources() {
    local duration=${1:-300}  # 5 minutes default
    log "Starting resource monitoring for ${duration} seconds..."
    
    local monitor_file="resource_monitor_$(date +%Y%m%d_%H%M%S).log"
    
    {
        echo "Timestamp,Pod,CPU,Memory,Status"
        local end_time=$(($(date +%s) + duration))
        
        while [ $(date +%s) -lt $end_time ]; do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            
            for pod in baseline-app optimized-app high-performance-app; do
                if kubectl get pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                    local status=$(kubectl get pod $pod -n $NAMESPACE -o jsonpath='{.status.phase}')
                    local usage="N/A,N/A"
                    
                    if kubectl top pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                        usage=$(kubectl top pod $pod -n $NAMESPACE --no-headers | awk '{print $2","$3}')
                    fi
                    
                    echo "$timestamp,$pod,$usage,$status"
                fi
            done
            
            sleep 10
        done
    } > $monitor_file
    
    success "Resource monitoring completed. Data saved to $monitor_file"
    
    # Generate simple analysis
    log "Generating resource usage analysis..."
    
    {
        echo "=== Resource Usage Analysis ==="
        echo ""
        
        for pod in baseline-app optimized-app high-performance-app; do
            echo "=== $pod ==="
            grep "$pod" $monitor_file | tail -10 | while IFS=',' read timestamp pod_name cpu memory status; do
                echo "[$timestamp] CPU: $cpu, Memory: $memory, Status: $status"
            done
            echo ""
        done
    } > resource_analysis.txt
    
    success "Analysis saved to resource_analysis.txt"
}

# Cleanup function
cleanup_lab() {
    log "Cleaning up performance lab..."
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -f benchmark_results.txt resource_*.log resource_analysis.txt
    rm -f /tmp/ab_results_*.txt /tmp/gnuplot_*.dat
    success "Cleanup completed"
}

# Main execution
main() {
    case "${1:-benchmark}" in
        "setup")
            setup_lab
            ;;
        "benchmark")
            setup_lab
            run_comprehensive_benchmark
            ;;
        "monitor")
            monitor_resources "${2:-300}"
            ;;
        "cleanup")
            cleanup_lab
            ;;
        "all")
            setup_lab
            run_comprehensive_benchmark
            monitor_resources 300
            echo ""
            success "Complete performance analysis finished!"
            echo "Files created:"
            echo "  - benchmark_results.txt"
            echo "  - resource_monitor_*.log"
            echo "  - resource_analysis.txt"
            ;;
        *)
            echo "Performance Lab - Pod Optimization Benchmark"
            echo ""
            echo "Usage: $0 <command> [options]"
            echo ""
            echo "Commands:"
            echo "  setup      - Set up the performance lab environment"
            echo "  benchmark  - Run comprehensive performance benchmark"
            echo "  monitor    - Monitor resource usage for specified duration"
            echo "  cleanup    - Remove all lab resources"
            echo "  all        - Run complete analysis (setup + benchmark + monitor)"
            echo ""
            echo "Examples:"
            echo "  $0 setup"
            echo "  $0 benchmark"
            echo "  $0 monitor 600  # Monitor for 10 minutes"
            echo "  $0 all          # Complete analysis"
            ;;
    esac
}

main "$@"
```

---

## Pod Troubleshooting Methodologies

### üîß Advanced Troubleshooting Toolkit

#### Example 8: Automated Diagnostic System

```bash
#!/bin/bash
# advanced-pod-diagnostics.sh

set -euo pipefail

# Enhanced diagnostic toolkit with automated problem detection
class PodDiagnostics {
    
# Configuration
NAMESPACE=${NAMESPACE:-default}
OUTPUT_DIR="./diagnostics-$(date +%Y%m%d-%H%M%S)"
VERBOSE=${VERBOSE:-false}

# Colors and formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'
BOLD='\033[1m'

# Logging functions with levels
log_debug() { [[ $VERBOSE == "true" ]] && echo -e "${CYAN}[DEBUG]${NC} $1"; }
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }

# Initialize diagnostics
init_diagnostics() {
    log_info "Initializing pod diagnostics system..."
    mkdir -p "$OUTPUT_DIR"/{logs,reports,metrics,manifests}
    
    # Create diagnostic report header
    cat > "$OUTPUT_DIR/diagnostic_report.md" <<EOF
# Pod Diagnostics Report

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)  
**Namespace:** $NAMESPACE  
**Output Directory:** $OUTPUT_DIR

---

EOF
    
    log_success "Diagnostics initialized in $OUTPUT_DIR"
}

# Comprehensive pod information gathering
gather_pod_info() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Gathering comprehensive information for pod: $pod_name"
    
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    mkdir -p "$pod_dir"
    
    # Basic pod information
    kubectl get pod "$pod_name" -n "$namespace" -o wide > "$pod_dir/basic_info.txt" 2>&1
    kubectl get pod "$pod_name" -n "$namespace" -o yaml > "$pod_dir/manifest.yaml" 2>&1
    
    # Detailed description
    kubectl describe pod "$pod_name" -n "$namespace" > "$pod_dir/description.txt" 2>&1
    
    # Events related to the pod
    kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
        --sort-by='.lastTimestamp' > "$pod_dir/events.txt" 2>&1
    
    # Container logs
    local containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}' 2>/dev/null)
    for container in $containers; do
        log_debug "Collecting logs for container: $container"
        kubectl logs "$pod_name" -n "$namespace" -c "$container" > "$pod_dir/logs_${container}.txt" 2>&1
        
        # Previous logs if container restarted
        kubectl logs "$pod_name" -n "$namespace" -c "$container" --previous > "$pod_dir/logs_${container}_previous.txt" 2>&1 || true
    done
    
    # Resource usage
    kubectl top pod "$pod_name" -n "$namespace" > "$pod_dir/resource_usage.txt" 2>&1 || echo "Metrics not available" > "$pod_dir/resource_usage.txt"
    
    log_success "Pod information gathered for $pod_name"
}

# Automated problem detection
detect_common_issues() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Running automated issue detection for $pod_name..."
    
    local issues_file="$pod_dir/detected_issues.md"
    echo "# Automated Issue Detection Report" > "$issues_file"
    echo "**Pod:** $pod_name" >> "$issues_file"
    echo "**Analysis Time:** $(date)" >> "$issues_file"
    echo "" >> "$issues_file"
    
    local issue_count=0
    
    # Check 1: Pod phase issues
    local phase=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.phase}' 2>/dev/null)
    if [[ "$phase" != "Running" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Pod Not Running
- **Severity:** High
- **Status:** Pod is in '$phase' phase instead of 'Running'
- **Impact:** Application unavailable
- **Investigation:** Check pod events and container status

EOF
    fi
    
    # Check 2: Container readiness issues
    local ready_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[?(@.ready==true)]}' | jq '. | length' 2>/dev/null || echo "0")
    local total_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers}' | jq '. | length' 2>/dev/null || echo "1")
    
    if [[ "$ready_containers" -lt "$total_containers" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Container Readiness Problems
- **Severity:** High
- **Status:** Only $ready_containers of $total_containers containers are ready
- **Impact:** Traffic routing may be affected
- **Investigation:** Check readiness probes and container logs

EOF
    fi
    
    # Check 3: Excessive restarts
    local restarts=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
    if [[ "$restarts" -gt 5 ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Excessive Container Restarts
- **Severity:** Medium
- **Status:** Container has restarted $restarts times
- **Impact:** Service instability and potential data loss
- **Investigation:** Check liveness probes, resource limits, and application logs

EOF
    fi
    
    # Check 4: Resource usage issues
    if kubectl top pod "$pod_name" -n "$namespace" >/dev/null 2>&1; then
        local cpu_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $2}' | sed 's/m$//')
        local memory_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $3}' | sed 's/Mi$//')
        
        if [[ "$cpu_usage" -gt 800 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High CPU Usage
- **Severity:** Medium
- **Status:** CPU usage is ${cpu_usage}m (> 800m threshold)
- **Impact:** Performance degradation and potential throttling
- **Investigation:** Check for CPU-intensive processes and consider scaling

EOF
        fi
        
        if [[ "$memory_usage" -gt 512 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High Memory Usage
- **Severity:** Medium  
- **Status:** Memory usage is ${memory_usage}Mi (> 512Mi threshold)
- **Impact:** Risk of OOM kills and service disruption
- **Investigation:** Check for memory leaks and optimize memory usage

EOF
        fi
    fi
    
    # Check 5: Image pull issues
    if grep -q "ImagePullBackOff\|ErrImagePull" "$pod_dir/description.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Image Pull Problems
- **Severity:** High
- **Status:** Unable to pull container image
- **Impact:** Pod cannot start
- **Investigation:** Check image name, registry access, and credentials

EOF
    fi
    
    # Check 6: Resource constraints
    if grep -q "Insufficient.*resources" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Resource Constraints
- **Severity:** High
- **Status:** Insufficient cluster resources for pod scheduling
- **Impact:** Pod cannot be scheduled
- **Investigation:** Check cluster capacity and node resources

EOF
    fi
    
    # Check 7: Network issues
    if grep -q "NetworkNotReady\|CNI.*error" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Network Configuration Problems
- **Severity:** High
- **Status:** Network setup issues detected
- **Impact:** Pod networking may not function correctly
- **Investigation:** Check CNI configuration and network policies

EOF
    fi
    
    # Summary
    if [[ $issue_count -eq 0 ]]; then
        echo "## Summary: No Critical Issues Detected ‚úÖ" >> "$issues_file"
        echo "The automated analysis found no obvious problems with this pod." >> "$issues_file"
        log_success "No critical issues detected for $pod_name"
    else
        echo "## Summary: $issue_count Issue(s) Detected ‚ö†Ô∏è" >> "$issues_file"
        echo "Review the issues above and follow the investigation recommendations." >> "$issues_file"
        log_warn "$issue_count issue(s) detected for $pod_name"
    fi
    
    return $issue_count
}

# Generate recommendations
generate_recommendations() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Generating recommendations for $pod_name..."
    
    local rec_file="$pod_dir/recommendations.md"
    echo "# Optimization Recommendations" > "$rec_file"
    echo "**Pod:** $pod_name" >> "$rec_file"
    echo "" >> "$rec_file"
    
    # Resource optimization recommendations
    echo "## Resource Optimization" >> "$rec_file"
    
    # Check current resource configuration
    local requests_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.memory}' 2>/dev/null || echo "not set")
    local requests_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.cpu}' 2>/dev/null || echo "not set")
    local limits_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.memory}' 2>/dev/null || echo "not set")
    local limits_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.cpu}' 2>/dev/null || echo "not set")
    
    cat >> "$rec_file" <<EOF
### Current Resource Configuration
- **Memory Request:** $requests_mem
- **CPU Request:** $requests_cpu  
- **Memory Limit:** $limits_mem
- **CPU Limit:** $limits_cpu

EOF
    
    # Security recommendations
    echo "## Security Hardening" >> "$rec_file"
    
    local security_context=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.securityContext}' 2>/dev/null)
    if [[ -z "$security_context" || "$security_context" == "null" ]]; then
        cat >> "$rec_file" <<EOF
### Security Context Improvements
- ‚úÖ **Add security context:** Configure runAsNonRoot, runAsUser, and fsGroup
- ‚úÖ **Drop capabilities:** Remove unnecessary Linux capabilities  
- ‚úÖ **Read-only root filesystem:** Set readOnlyRootFilesystem: true
- ‚úÖ **Prevent privilege escalation:** Set allowPrivilegeEscalation: false

EOF
    fi
    
    # Health check recommendations
    echo "## Health Check Optimization" >> "$rec_file"
    
    local has_liveness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].livenessProbe}' 2>/dev/null)
    local has_readiness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].readinessProbe}' 2>/dev/null)
    
    if [[ -z "$has_liveness" || "$has_liveness" == "null" ]]; then
        echo "- ‚úÖ **Add liveness probe:** Implement health checking for automatic restart" >> "$rec_file"
    fi
    
    if [[ -z "$has_readiness" || "$has_readiness" == "null" ]]; then
        echo "- ‚úÖ **Add readiness probe:** Control traffic routing based on application readiness" >> "$rec_file"
    fi
    
    # Performance recommendations
    echo "" >> "$rec_file"
    echo "## Performance Optimization" >> "$rec_file"
    cat >> "$rec_file" <<EOF
- ‚úÖ **Use Alpine images:** Reduce image size and startup time
- ‚úÖ **Implement resource requests:** Help scheduler make better placement decisions
- ‚úÖ **Optimize health check frequency:** Balance responsiveness with overhead
- ‚úÖ **Use memory-backed volumes:** For temporary files and caches
- ‚úÖ **Configure DNS caching:** Reduce DNS lookup overhead

EOF
    
    log_success "Recommendations generated for $pod_name"
}

# Interactive diagnostic session
interactive_diagnostics() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Starting interactive diagnostics for $pod_name..."
    
    echo -e "${BOLD}Interactive Pod Diagnostics${NC}"
    echo "Pod: $pod_name"
    echo "Namespace: $namespace"
    echo ""
    
    while true; do
        echo -e "${CYAN}Available actions:${NC}"
        echo "1) Show pod status"
        echo "2) View recent events"
        echo "3) Check container logs"
        echo "4) Execute command in pod"
        echo "5) Port forward to pod"
        echo "6) Resource usage"
        echo "7) Run full diagnostic"
        echo "8) Generate recommendations"
        echo "q) Quit"
        echo ""
        
        read -p "Select action [1-8,q]: " choice
        
        case $choice in
            1)
                echo "=== Pod Status ==="
                kubectl get pod "$pod_name" -n "$namespace" -o wide
```" \
        5
    
    check_item "Environment label present" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.metadata.labels.environment}' | grep -v '^
                kubectl describe pod "$pod_name" -n "$namespace" | grep -A 10 "Status\|Conditions"
                ;;
            2)
                echo "=== Recent Events ==="
                kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
                    --sort-by='.lastTimestamp' | tail -10
                ;;
            3)
                echo "=== Container Selection ==="
                local containers=($(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}'))
                if [[ ${#containers[@]} -eq 1 ]]; then
                    echo "Showing logs for container: ${containers[0]}"
                    kubectl logs "$pod_name" -n "$namespace" --tail=50
                else
                    echo "Available containers:"
                    for i in "${!containers[@]}"; do
                        echo "$((i+1))) ${containers[i]}"
                    done
                    read -p "Select container [1-${#containers[@]}]: " container_choice
                    if [[ $container_choice -ge 1 && $container_choice -le ${#containers[@]} ]]; then
                        local selected_container=${containers[$((container_choice-1))]}
                        echo "Showing logs for container: $selected_container"
                        kubectl logs "$pod_name" -n "$namespace" -c "$selected_container" --tail=50
                    fi
                fi
                ;;
            4)
                read -p "Enter command to execute: " exec_command
                kubectl exec -it "$pod_name" -n "$namespace" -- $exec_command
                ;;
            5)
                read -p "Enter local port: " local_port
                read -p "Enter pod port: " pod_port
                echo "Port forwarding $local_port:$pod_port - Press Ctrl+C to stop"
                kubectl port-forward "$pod_name" -n "$namespace" "$local_port:$pod_port"
                ;;
            6)
                echo "=== Resource Usage ==="
                kubectl top pod "$pod_name" -n "$namespace" 2>/dev/null || echo "Metrics not available"
                ;;
            7)
                gather_pod_info "$pod_name" "$namespace"
                detect_common_issues "$pod_name" "$namespace"
                generate_recommendations "$pod_name" "$namespace"
                echo "Full diagnostic completed. Check $OUTPUT_DIR/pods/$pod_name/"
                ;;
            8)
                generate_recommendations "$pod_name" "$namespace"
                echo "Recommendations generated. Check $OUTPUT_DIR/pods/$pod_name/recommendations.md"
                ;;
            q|Q)
                log_info "Exiting interactive diagnostics"
                break
                ;;
            *)
                echo "Invalid choice. Please try again."
                ;;
        esac
        
        echo ""
        read -p "Press Enter to continue..."
        echo ""
    done
}

# Cluster-wide pod health assessment
cluster_health_assessment() {
    log_info "Running cluster-wide pod health assessment..."
    
    local health_report="$OUTPUT_DIR/cluster_health_report.md"
    
    cat > "$health_report" <<EOF
# Cluster Pod Health Assessment

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)

---

EOF
    
    # Get all namespaces
    local namespaces=($(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'))
    
    local total_pods=0
    local healthy_pods=0
    local unhealthy_pods=0
    
    for ns in "${namespaces[@]}"; do
        log_info "Assessing namespace: $ns"
        
        local pods=($(kubectl get pods -n "$ns" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null))
        
        if [[ ${#pods[@]} -eq 0 ]]; then
            continue
        fi
        
        echo "## Namespace: $ns" >> "$health_report"
        echo "" >> "$health_report"
        
        local ns_healthy=0
        local ns_unhealthy=0
        
        for pod in "${pods[@]}"; do
            ((total_pods++))
            
            local phase=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.phase}')
            local ready_condition=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
            local restarts=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
            
            if [[ "$phase" == "Running" && "$ready_condition" == "True" && $restarts -lt 5 ]]; then
                ((healthy_pods++))
                ((ns_healthy++))
                echo "‚úÖ **$pod** - Healthy" >> "$health_report"
            else
                ((unhealthy_pods++))
                ((ns_unhealthy++))
                echo "‚ùå **$pod** - Issues detected (Phase: $phase, Ready: $ready_condition, Restarts: $restarts)" >> "$health_report"
                
                # Run quick diagnostics for unhealthy pods
                gather_pod_info "$pod" "$ns"
                detect_common_issues "$pod" "$ns"
            fi
        done
        
        echo "" >> "$health_report"
        echo "**Namespace Summary:** $ns_healthy healthy, $ns_unhealthy unhealthy" >> "$health_report"
        echo "" >> "$health_report"
    done
    
    # Overall summary
    local health_percentage=$((healthy_pods * 100 / total_pods))
    
    cat >> "$health_report" <<EOF

---

## Overall Cluster Health

- **Total Pods:** $total_pods
- **Healthy Pods:** $healthy_pods
- **Unhealthy Pods:** $unhealthy_pods
- **Health Percentage:** $health_percentage%

### Health Status
EOF
    
    if [[ $health_percentage -ge 90 ]]; then
        echo "üü¢ **EXCELLENT** - Cluster is in excellent health" >> "$health_report"
    elif [[ $health_percentage -ge 75 ]]; then
        echo "üü° **GOOD** - Cluster is in good health with minor issues" >> "$health_report"
    elif [[ $health_percentage -ge 50 ]]; then
        echo "üü† **WARNING** - Cluster has significant health issues" >> "$health_report"
    else
        echo "üî¥ **CRITICAL** - Cluster is in critical condition" >> "$health_report"
    fi
    
    log_success "Cluster health assessment completed. Report: $health_report"
}

# Generate comprehensive diagnostic report
generate_final_report() {
    log_info "Generating comprehensive diagnostic report..."
    
    local final_report="$OUTPUT_DIR/comprehensive_report.html"
    
    cat > "$final_report" <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Pod Diagnostics Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
        .header { background-color: #f4f4f4; padding: 20px; border-radius: 5px; margin-bottom: 30px; }
        .section { margin: 30px 0; }
        .pod-card { border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin: 10px 0; }
        .healthy { border-left: 5px solid #28a745; }
        .unhealthy { border-left: 5px solid #dc3545; }
        .warning { border-left: 5px solid #ffc107; }
        .metric { display: inline-block; margin: 10px 15px 10px 0; padding: 8px 12px; background-color: #e9ecef; border-radius: 3px; }
        .issue { background-color: #fff3cd; padding: 10px; border-radius: 3px; margin: 10px 0; }
        pre { background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }
        .tabs { border-bottom: 1px solid #ddd; margin-bottom: 20px; }
        .tab { display: inline-block; padding: 10px 20px; cursor: pointer; border-bottom: 2px solid transparent; }
        .tab.active { border-bottom-color: #007bff; color: #007bff; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }
    </style>
    <script>
        function showTab(tabName) {
            // Hide all tab contents
            var contents = document.getElementsByClassName('tab-content');
            for (var i = 0; i < contents.length; i++) {
                contents[i].classList.remove('active');
            }
            
            // Remove active class from all tabs
            var tabs = document.getElementsByClassName('tab');
            for (var i = 0; i < tabs.length; i++) {
                tabs[i].classList.remove('active');
            }
            
            // Show selected tab content and mark tab as active
            document.getElementById(tabName).classList.add('active');
            event.target.classList.add('active');
        }
    </script>
</head>
<body>
    <div class="header">
        <h1>üîç Pod Diagnostics Report</h1>
        <div class="metric">
            <strong>Generated:</strong> $(date)
        </div>
        <div class="metric">
            <strong>Cluster:</strong> $(kubectl config current-context)
        </div>
        <div class="metric">
            <strong>Diagnostics Version:</strong> 2.0
        </div>
    </div>
    
    <div class="tabs">
        <div class="tab active" onclick="showTab('overview')">Overview</div>
        <div class="tab" onclick="showTab('pods')">Pod Analysis</div>
        <div class="tab" onclick="showTab('issues')">Detected Issues</div>
        <div class="tab" onclick="showTab('recommendations')">Recommendations</div>
    </div>
    
    <div id="overview" class="tab-content active">
        <h2>üìä Cluster Overview</h2>
        <div class="section">
EOF
    
    # Add cluster metrics
    local total_nodes=$(kubectl get nodes --no-headers | wc -l)
    local ready_nodes=$(kubectl get nodes --no-headers | grep " Ready " | wc -l)
    local total_namespaces=$(kubectl get namespaces --no-headers | wc -l)
    
    cat >> "$final_report" <<EOF
            <div class="pod-card healthy">
                <h3>Cluster Metrics</h3>
                <div class="metric"><strong>Nodes:</strong> $ready_nodes/$total_nodes Ready</div>
                <div class="metric"><strong>Namespaces:</strong> $total_namespaces</div>
                <div class="metric"><strong>Kubernetes Version:</strong> $(kubectl version --short --client | cut -d' ' -f3)</div>
            </div>
        </div>
    </div>
    
    <div id="pods" class="tab-content">
        <h2>üöÄ Pod Analysis</h2>
EOF
    
    # Add pod analysis for each analyzed pod
    for pod_dir in "$OUTPUT_DIR"/pods/*/; do
        if [[ -d "$pod_dir" ]]; then
            local pod_name=$(basename "$pod_dir")
            local issues_count=0
            
            if [[ -f "$pod_dir/detected_issues.md" ]]; then
                issues_count=$(grep -c "## Issue" "$pod_dir/detected_issues.md" 2>/dev/null || echo "0")
            fi
            
            local card_class="healthy"
            if [[ $issues_count -gt 0 ]]; then
                card_class="unhealthy"
            fi
            
            cat >> "$final_report" <<EOF
        <div class="pod-card $card_class">
            <h3>üì¶ $pod_name</h3>
            <div class="metric"><strong>Issues Detected:</strong> $issues_count</div>
            <div class="metric"><strong>Analysis Files:</strong> $(ls "$pod_dir" | wc -l)</div>
            <div class="metric"><strong>Report Location:</strong> pods/$pod_name/</div>
        </div>
EOF
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="issues" class="tab-content">
        <h2>‚ö†Ô∏è Detected Issues</h2>
EOF
    
    # Aggregate all issues
    local total_issues=0
    for issues_file in "$OUTPUT_DIR"/pods/*/detected_issues.md; do
        if [[ -f "$issues_file" ]]; then
            local pod_issues=$(grep -c "## Issue" "$issues_file" 2>/dev/null || echo "0")
            ((total_issues += pod_issues))
            
            if [[ $pod_issues -gt 0 ]]; then
                local pod_name=$(basename "$(dirname "$issues_file")")
                echo "<h3>Issues for $pod_name</h3>" >> "$final_report"
                
                # Convert markdown issues to HTML
                grep "## Issue" "$issues_file" | while read -r line; do
                    echo "<div class=\"issue\">$line</div>" >> "$final_report"
                done
            fi
        fi
    done
    
    if [[ $total_issues -eq 0 ]]; then
        echo "<div class=\"pod-card healthy\"><h3>‚úÖ No Issues Detected</h3><p>All analyzed pods appear to be healthy!</p></div>" >> "$final_report"
    fi
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="recommendations" class="tab-content">
        <h2>üí° Recommendations</h2>
        <div class="section">
            <div class="pod-card warning">
                <h3>General Recommendations</h3>
                <ul>
                    <li>‚úÖ Implement comprehensive health checks for all pods</li>
                    <li>‚úÖ Set appropriate resource requests and limits</li>
                    <li>‚úÖ Use security contexts to harden pod security</li>
                    <li>‚úÖ Monitor resource usage and optimize accordingly</li>
                    <li>‚úÖ Implement graceful shutdown handling</li>
                    <li>‚úÖ Use multi-stage Docker builds for smaller images</li>
                    <li>‚úÖ Implement proper logging and observability</li>
                </ul>
            </div>
        </div>
EOF
    
    # Add pod-specific recommendations
    for rec_file in "$OUTPUT_DIR"/pods/*/recommendations.md; do
        if [[ -f "$rec_file" ]]; then
            local pod_name=$(basename "$(dirname "$rec_file")")
            echo "<div class=\"pod-card\"><h3>Recommendations for $pod_name</h3>" >> "$final_report"
            echo "<p>See detailed recommendations in: pods/$pod_name/recommendations.md</p></div>" >> "$final_report"
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div class="section">
        <hr>
        <p><em>Report generated by Pod Diagnostics Toolkit v2.0</em></p>
        <p><em>For detailed analysis, check individual files in the diagnostics output directory.</em></p>
    </div>
    
</body>
</html>
EOF
    
    log_success "Comprehensive report generated: $final_report"
    echo ""
    echo -e "${BOLD}üìã Diagnostic Summary:${NC}"
    echo "- Output Directory: $OUTPUT_DIR"
    echo "- HTML Report: $final_report"
    echo "- Total Issues Found: $total_issues"
    echo ""
    echo -e "${CYAN}üí° Next Steps:${NC}"
    echo "1. Open $final_report in your browser"
    echo "2. Review individual pod analysis in $OUTPUT_DIR/pods/"
    echo "3. Implement recommended fixes"
    echo "4. Re-run diagnostics to verify improvements"
}

# Main execution function
main() {
    local command=${1:-help}
    local pod_name=${2:-}
    local namespace=${3:-$NAMESPACE}
    
    case "$command" in
        "analyze")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for analysis"
                echo "Usage: $0 analyze <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            gather_pod_info "$pod_name" "$namespace"
            detect_common_issues "$pod_name" "$namespace"
            generate_recommendations "$pod_name" "$namespace"
            generate_final_report
            ;;
            
        "interactive")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for interactive mode"
                echo "Usage: $0 interactive <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            interactive_diagnostics "$pod_name" "$namespace"
            ;;
            
        "cluster-health")
            init_diagnostics
            cluster_health_assessment
            generate_final_report
            ;;
            
        "help"|*)
            cat <<EOF
üîç Advanced Pod Diagnostics Toolkit

Usage: $0 <command> [options]

Commands:
  analyze <pod-name> [namespace]     - Run comprehensive pod analysis
  interactive <pod-name> [namespace] - Start interactive diagnostic session
  cluster-health                     - Assess health of all pods in cluster
  help                              - Show this help message

Environment Variables:
  NAMESPACE - Default namespace (default: default)
  VERBOSE   - Enable verbose output (default: false)

Examples:
  $0 analyze nginx-pod production
  $0 interactive web-app-123
  $0 cluster-health
  VERBOSE=true $0 analyze problematic-pod

Output:
  All diagnostic data is saved to ./diagnostics-TIMESTAMP/
  HTML report provides comprehensive overview
  Individual pod analysis available in pods/ subdirectory

EOF
            ;;
    esac
}

# Execute main function
main "$@"
```

---

## Summary and Production-Ready Examples

### üèÜ Complete Production Workflow

Let's create a final comprehensive example that brings everything together:

```yaml
# complete-production-workflow.yaml
# This represents a complete production-ready pod deployment workflow

apiVersion: v1
kind: Namespace
metadata:
  name: production-workload
  labels:
    environment: production
    team: platform
---
# ConfigMap for application configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production-workload
data:
  app.properties: |
    server.port=8080
    management.port=8081
    logging.level=INFO
    metrics.enabled=true
  nginx.conf: |
    server {
        listen 80;
        location /health { return 200 'healthy\n'; }
        location /ready { return 200 'ready\n'; }
        location / {
            proxy_pass http://127.0.0.1:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
---
# Secret for sensitive configuration
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: production-workload
type: Opaque
data:
  database-password: c3VwZXJzZWNyZXQ=  # supersecret (base64)
  api-key: YWJjZGVmZ2hpams=  # abcdefghijk (base64)
---
# Production-ready pod with all best practices
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production-workload
  labels:
    app: production-app
    version: "2.1.0"
    environment: production
    team: platform
    component: backend
  annotations:
    description: "Production application with full observability"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/production-app"
    prometheus.io/scrape: "true"
    prometheus.io/port: "8081"
    prometheus.io/path: "/metrics"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Resource constraints and node placement
  nodeSelector:
    node-type: "application"
    performance-tier: "high"
    
  tolerations:
  - key: "dedicated-app"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
    
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: production-app
        topologyKey: kubernetes.io/hostname
        
  # DNS and network configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  # Init container for setup tasks
  initContainers:
  - name: setup
    image: busybox:1.35
    command:
    - /bin/sh
    - -c
    - |
      echo "Initializing application..."
      
      # Database migration simulation
      echo "Running database migrations..."
      sleep 5
      
      # Cache warming
      echo "Warming up caches..."
      sleep 3
      
      # Configuration validation
      echo "Validating configuration..."
      if [ -f /config/app.properties ]; then
        echo "‚úÖ Configuration file found"
      else
        echo "‚ùå Configuration file missing"
        exit 1
      fi
      
      echo "Initialization completed successfully"
      
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-init
      mountPath: /tmp
      
  # Main application containers
  containers:
  # Application container
  - name: app
    image: openjdk:11-jre-slim
    command:
    - /bin/bash
    - -c
    - |
      echo "Starting application..."
      
      # Simulated application startup
      java -Xmx200m -Xms100m -jar /app/application.jar \
        --spring.config.location=file:/config/app.properties \
        --server.port=8080 \
        --management.server.port=8081
        
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP
    - name: management
      containerPort: 8081
      protocol: TCP
      
    # Environment configuration
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # Sensitive configuration from secrets
    - name: DATABASE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: database-password
    - name: API_KEY
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: api-key
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security hardening
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    # Comprehensive health checks
    livenessProbe:
      httpGet:
        path: /actuator/health/liveness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /actuator/health/readiness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /actuator/health
        port: 8081
      initialDelaySeconds: 20
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle management
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Application started at $(date)" >> /tmp/startup.log
            # Custom post-start logic here
            
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Graceful shutdown initiated at $(date)" >> /tmp/shutdown.log
            # Send SIGTERM to application
            kill -TERM 1
            # Wait for graceful shutdown
            sleep 30
            
    # Volume mounts
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-volume
      mountPath: /tmp
    - name: app-logs
      mountPath: /app/logs
    - name: app-data
      mountPath: /app/data
      
  # Nginx reverse proxy sidecar
  - name: nginx-proxy
    image: nginx:1.21-alpine
    ports:
    - name: http-proxy
      containerPort: 80
      protocol: TCP
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        add: ["NET_BIND_SERVICE"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: nginx-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
      
  # Logging and monitoring sidecar
  - name: log-shipper
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: fluent-tmp
      mountPath: /tmp
      
  # Volumes
  volumes:
  - name: config-volume
    configMap:
      name: app-config
      items:
      - key: app.properties
        path: app.properties
  - name: nginx-config
    configMap:
      name: app-config
      items:
      - key: nginx.conf
        path: default.conf
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config  # Would be created separately
  # Temporary and cache volumes
  - name: tmp-volume
    emptyDir:
      sizeLimit: 256Mi
  - name: tmp-init
    emptyDir:
      sizeLimit: 64Mi
  - name: nginx-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: fluent-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: nginx-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: nginx-run
    emptyDir:
      sizeLimit: 32Mi
  # Application data volumes
  - name: app-logs
    emptyDir:
      sizeLimit: 1Gi
  - name: app-data
    emptyDir:
      sizeLimit: 2Gi
```

This comprehensive example demonstrates:

- **Complete security hardening** with proper contexts and capabilities
- **Multi-container architecture** with main app, proxy, and logging sidecars
- **Comprehensive health checks** for all containers
- **Resource optimization** with appropriate requests and limits
- **Configuration management** using ConfigMaps and Secrets
- **Observability** with structured logging and metrics endpoints
- **Production-ready networking** with reverse proxy
- **Graceful lifecycle management** with init containers and shutdown hooks

## üéì Key Learning Outcomes

By working through these enhanced examples, demos, and mini-projects, you've gained:

1. **Foundation Skills**: Basic pod creation, inspection, and management
2. **Intermediate Capabilities**: Multi-container patterns, health monitoring, and debugging
3. **Advanced Techniques**: Performance optimization, security hardening, and automation
4. **Expert-Level Mastery**: Custom controllers, comprehensive diagnostics, and production workflows

### üöÄ Next Steps for Continued Learning

1. **Practice the Examples**: Work through each example in your own cluster
2. **Customize for Your Use Cases**: Adapt the patterns to your specific applications
3. **Build Your Toolkit**: Create your own diagnostic and management scripts
4. **Share and Learn**: Contribute back to the community with your own improvements
5. **Scale Up**: Apply these pod management skills to higher-level controllers

The journey from basic pod creation to# 5. Working with Pods - From Fundamentals to Mastery (Enhanced Edition)

Understanding how to work with pods effectively forms the foundation of all Kubernetes operations. While you'll typically use higher-level controllers like Deployments in production environments, direct pod management skills are essential for debugging, troubleshooting, and truly understanding how Kubernetes applications function at their core. Think of this knowledge as learning to drive a manual transmission car‚Äîeven if you usually drive automatic, understanding the underlying mechanics makes you a better driver overall.

This enhanced guide provides progressive examples, hands-on demos, and real-world mini-projects to solidify your understanding through practical application.

## üéØ Learning Path Overview

- **Foundation Level**: Basic pod creation and inspection
- **Intermediate Level**: Multi-container patterns and health checks
- **Advanced Level**: Complex debugging and optimization
- **Expert Level**: Custom tooling and automation

---

## Understanding Pod Creation Strategies

Creating pods effectively requires understanding when to use imperative commands versus declarative configurations, and how different creation approaches serve different purposes.

### üìö Foundation Examples

Let's start with the absolute basics and progressively build complexity.

#### Example 1: Your First Pod
```bash
# Create the simplest possible pod
kubectl run hello-world --image=nginx --restart=Never

# Verify it's running
kubectl get pods

# Expected output:
# NAME          READY   STATUS    RESTARTS   AGE
# hello-world   1/1     Running   0          30s
```

#### Example 2: Pod with Custom Commands
```bash
# Create a pod that runs a custom command
kubectl run date-pod --image=busybox --restart=Never -- date

# This pod will run the date command and then exit
# Check the output
kubectl logs date-pod

# Clean up
kubectl delete pod date-pod
```

#### Example 3: Interactive Pod Session
```bash
# Create an interactive debugging pod
kubectl run -it debug-pod --image=busybox --restart=Never -- sh

# Inside the pod, try these commands:
# ls -la
# ps aux
# ping google.com
# nslookup kubernetes.default.svc.cluster.local

# Exit and clean up
# exit
kubectl delete pod debug-pod
```

### üõ†Ô∏è Demo: Pod Lifecycle Observation

Let's create a demo that shows the complete pod lifecycle in action:

```bash
#!/bin/bash
# pod-lifecycle-demo.sh

echo "=== Pod Lifecycle Demonstration ==="

# Terminal 1: Start watching pods
echo "In a separate terminal, run: kubectl get pods -w"
echo "Press Enter when ready..."
read

# Create a pod with a slow-starting application
echo "Creating pod with slow startup..."
kubectl run lifecycle-demo --image=nginx --restart=Never \
  --dry-run=client -o yaml > lifecycle-pod.yaml

# Add some customizations to make it more interesting
cat <<EOF >> lifecycle-pod.yaml
  containers:
  - name: nginx
    image: nginx:1.21
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod starting up...' && sleep 10"
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod shutting down...' && sleep 5"
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 5
EOF

echo "Applying pod configuration..."
kubectl apply -f lifecycle-pod.yaml

echo "Watch the pod states change from Pending -> ContainerCreating -> Running"
echo "Press Enter to continue when pod is Running..."
read

# Show detailed pod information
echo "=== Pod Details ==="
kubectl describe pod lifecycle-demo

echo "Press Enter to delete the pod and observe termination..."
read

# Delete and watch termination
kubectl delete pod lifecycle-demo

echo "Demo complete! Clean up the YAML file:"
echo "rm lifecycle-pod.yaml"
```

### üéØ Mini-Project 1: Pod Resource Monitor

Create a simple monitoring system using pods:

```yaml
# resource-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-monitor
  labels:
    app: monitor
    type: demo
spec:
  containers:
  - name: monitor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Starting Resource Monitor..."
      while true; do
        echo "=== $(date) ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "Load average:"
        uptime
        echo "Sleeping for 30 seconds..."
        sleep 30
      done
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
  restartPolicy: Always
```

```bash
# Deploy and monitor
kubectl apply -f resource-monitor-pod.yaml

# Watch the logs
kubectl logs -f resource-monitor

# In another terminal, check resource usage
kubectl top pod resource-monitor

# Clean up
kubectl delete -f resource-monitor-pod.yaml
```

---

## Deep Pod Inspection and Monitoring

### üîç Intermediate Examples

#### Example 4: Multi-Container Pod Investigation

```yaml
# multi-container-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-demo
  labels:
    demo: multi-container
spec:
  containers:
  - name: web-server
    image: nginx:1.21
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
    
  - name: log-processor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Log processor starting..."
      while true; do
        if [ -f /var/log/nginx/access.log ]; then
          echo "=== Access Log Summary $(date) ==="
          tail -10 /var/log/nginx/access.log | wc -l
          echo "Recent requests:"
          tail -5 /var/log/nginx/access.log
        else
          echo "Waiting for access.log..."
        fi
        sleep 30
      done
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
      
  - name: metrics-collector
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Metrics collector starting..."
      while true; do
        echo "=== Metrics $(date) ==="
        echo "Container count: 3"
        echo "Uptime: $(uptime)"
        echo "Memory: $(free -h | grep Mem)"
        sleep 60
      done
      
  volumes:
  - name: shared-logs
    emptyDir: {}
```

**Inspection Commands:**
```bash
# Apply the multi-container pod
kubectl apply -f multi-container-demo.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/multi-container-demo

# Inspect different aspects
echo "=== Basic Information ==="
kubectl get pod multi-container-demo -o wide

echo "=== Container Status ==="
kubectl get pod multi-container-demo -o jsonpath='{.status.containerStatuses[*].name}' | tr ' ' '\n'

echo "=== Logs from each container ==="
kubectl logs multi-container-demo -c web-server --tail=5
kubectl logs multi-container-demo -c log-processor --tail=5
kubectl logs multi-container-demo -c metrics-collector --tail=5

# Generate some traffic to see shared volume in action
kubectl port-forward multi-container-demo 8080:80 &
PF_PID=$!

# Generate requests
for i in {1..10}; do
  curl -s http://localhost:8080 > /dev/null
  echo "Request $i sent"
  sleep 1
done

kill $PF_PID

# Check log processor output
kubectl logs multi-container-demo -c log-processor --tail=10

# Clean up
kubectl delete -f multi-container-demo.yaml
```

### üõ†Ô∏è Demo: Advanced Pod Debugging Techniques

```bash
#!/bin/bash
# advanced-debugging-demo.sh

echo "=== Advanced Pod Debugging Demo ==="

# Create a problematic pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: problematic-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "2000m"  # This might cause scheduling issues
      limits:
        memory: "512Mi"  # Less than request - invalid!
        cpu: "500m"
    livenessProbe:
      httpGet:
        path: /nonexistent
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
EOF

echo "Created a pod with multiple issues. Let's debug it..."

# Wait a moment for issues to manifest
sleep 10

echo "=== Debugging Steps ==="

echo "1. Check pod status:"
kubectl get pod problematic-pod -o wide

echo "2. Look at events:"
kubectl describe pod problematic-pod | grep -A 10 Events:

echo "3. Check for resource issues:"
kubectl describe pod problematic-pod | grep -A 5 -B 5 "resource"

echo "4. Examine container status:"
kubectl get pod problematic-pod -o jsonpath='{.status.containerStatuses[0]}' | jq '.'

# Fix the pod
echo "5. Let's fix the issues..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: fixed-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
EOF

echo "6. Compare the fixed pod:"
kubectl wait --for=condition=Ready pod/fixed-pod --timeout=60s
kubectl get pods -l debug=demo

# Clean up
echo "Cleaning up..."
kubectl delete pod problematic-pod fixed-pod
```

### üéØ Mini-Project 2: Pod Health Monitoring Dashboard

Create a comprehensive health monitoring system:

```yaml
# health-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: health-dashboard
  labels:
    app: health-monitor
spec:
  containers:
  - name: health-checker
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Health Dashboard Starting..."
      
      # Create a simple HTML dashboard
      mkdir -p /tmp/dashboard
      
      while true; do
        cat > /tmp/dashboard/health.html <<EOF
      <!DOCTYPE html>
      <html>
      <head>
          <title>Pod Health Dashboard</title>
          <meta http-equiv="refresh" content="30">
          <style>
              body { font-family: Arial, sans-serif; margin: 40px; }
              .healthy { color: green; }
              .warning { color: orange; }
              .critical { color: red; }
              .metric { margin: 10px 0; padding: 10px; border: 1px solid #ccc; }
          </style>
      </head>
      <body>
          <h1>Pod Health Dashboard</h1>
          <p>Last Update: $(date)</p>
          
          <div class="metric">
              <h3>System Load</h3>
              <p>$(uptime)</p>
          </div>
          
          <div class="metric">
              <h3>Memory Usage</h3>
              <pre>$(free -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Disk Usage</h3>
              <pre>$(df -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Process Count</h3>
              <p>Running processes: $(ps aux | wc -l)</p>
          </div>
          
      </body>
      </html>
      EOF
        
        echo "Dashboard updated at $(date)"
        sleep 30
      done
    volumeMounts:
    - name: dashboard-storage
      mountPath: /tmp/dashboard
      
  - name: web-server
    image: nginx:alpine
    ports:
    - containerPort: 80
    command:
    - /bin/sh
    - -c
    - |
      # Configure nginx to serve our dashboard
      cat > /etc/nginx/conf.d/default.conf <<EOF
      server {
          listen 80;
          location / {
              root /usr/share/nginx/html;
              index health.html;
          }
      }
      EOF
      
      # Start nginx
      nginx -g "daemon off;"
    volumeMounts:
    - name: dashboard-storage
      mountPath: /usr/share/nginx/html
      
  volumes:
  - name: dashboard-storage
    emptyDir: {}
    
  restartPolicy: Always
```

**Usage:**
```bash
# Deploy the health dashboard
kubectl apply -f health-monitor-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/health-dashboard

# Access the dashboard
kubectl port-forward health-dashboard 8080:80

# Open browser to http://localhost:8080
echo "Open http://localhost:8080 in your browser"

# Monitor the pod's own health
kubectl top pod health-dashboard

# Check logs from both containers
kubectl logs health-dashboard -c health-checker --tail=10
kubectl logs health-dashboard -c web-server --tail=10

# Clean up
kubectl delete -f health-monitor-pod.yaml
```

---

## Interactive Pod Management and Debugging

### üîß Advanced Examples

#### Example 5: Network Debugging Pod

```yaml
# network-debug-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: network-debugger
  labels:
    purpose: network-debug
spec:
  containers:
  - name: nettools
    image: nicolaka/netshoot
    command: ["/bin/bash"]
    args:
    - -c
    - |
      echo "Network debugging tools ready!"
      echo "Available tools: dig, nslookup, ping, curl, wget, tcpdump, netstat"
      echo "Example commands:"
      echo "  dig kubernetes.default.svc.cluster.local"
      echo "  ping 8.8.8.8"
      echo "  curl -I http://httpbin.org/headers"
      echo "  netstat -tulpn"
      
      # Keep container running
      sleep 3600
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
  restartPolicy: Never
```

**Debugging Session:**
```bash
# Deploy the network debugger
kubectl apply -f network-debug-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/network-debugger

# Start interactive session
kubectl exec -it network-debugger -- bash

# Inside the pod, run network diagnostics:
# Test DNS resolution
# dig kubernetes.default.svc.cluster.local

# Test external connectivity
# ping -c 3 8.8.8.8

# Test HTTP services
# curl -I https://httpbin.org/headers

# Check network interfaces
# ip addr show

# Check routing table
# ip route show

# Test service discovery
# nslookup kubernetes.default

# Exit and clean up
# exit
kubectl delete -f network-debug-pod.yaml
```

### üõ†Ô∏è Demo: File Transfer and Volume Management

```bash
#!/bin/bash
# file-transfer-demo.sh

echo "=== File Transfer and Volume Demo ==="

# Create a pod with persistent data
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: file-demo
spec:
  containers:
  - name: app
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Creating sample files..."
      mkdir -p /data/logs /data/config
      
      # Generate some sample data
      for i in {1..5}; do
        echo "Log entry \$i at \$(date)" >> /data/logs/app.log
        sleep 1
      done
      
      echo "app_name=demo-app" > /data/config/settings.conf
      echo "version=1.0.0" >> /data/config/settings.conf
      echo "debug=true" >> /data/config/settings.conf
      
      echo "Files created. Keeping container running..."
      sleep 3600
    volumeMounts:
    - name: data-storage
      mountPath: /data
  volumes:
  - name: data-storage
    emptyDir: {}
EOF

echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/file-demo

# Demonstrate file operations
echo "=== File Operations Demo ==="

echo "1. List files in the pod:"
kubectl exec file-demo -- find /data -type f

echo "2. Copy file from pod to local:"
kubectl cp file-demo:/data/logs/app.log ./app.log.backup
echo "File copied to: app.log.backup"
cat app.log.backup

echo "3. Create local config file:"
cat > new-config.conf <<EOF
app_name=updated-demo-app
version=2.0.0
debug=false
environment=production
EOF

echo "4. Copy local file to pod:"
kubectl cp new-config.conf file-demo:/data/config/

echo "5. Verify file in pod:"
kubectl exec file-demo -- cat /data/config/new-config.conf

echo "6. Create a backup of all data:"
kubectl exec file-demo -- tar -czf /tmp/backup.tar.gz -C /data .
kubectl cp file-demo:/tmp/backup.tar.gz ./pod-data-backup.tar.gz
echo "Backup created: pod-data-backup.tar.gz"

# Clean up
echo "Cleaning up..."
kubectl delete pod file-demo
rm -f app.log.backup new-config.conf pod-data-backup.tar.gz

echo "Demo complete!"
```

### üéØ Mini-Project 3: Pod Security Scanner

Create a security scanning tool using pods:

```yaml
# security-scanner-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-scanner
  labels:
    app: security
    type: scanner
spec:
  serviceAccountName: default
  containers:
  - name: scanner
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "=== Pod Security Scanner Starting ==="
      
      # Function to check security configurations
      check_security() {
        echo "Checking security configurations..."
        
        # Check if running as root
        if [ "$(id -u)" -eq 0 ]; then
          echo "‚ö†Ô∏è  WARNING: Running as root user"
        else
          echo "‚úÖ GOOD: Running as non-root user ($(id -u))"
        fi
        
        # Check filesystem permissions
        if [ -w "/" ]; then
          echo "‚ö†Ô∏è  WARNING: Root filesystem is writable"
        else
          echo "‚úÖ GOOD: Root filesystem is read-only"
        fi
        
        # Check for sensitive mounts
        if mount | grep -q "/var/run/secrets"; then
          echo "‚ÑπÔ∏è  INFO: Service account token mounted"
        fi
        
        # Check available capabilities
        echo "Current capabilities:"
        if [ -f "/proc/self/status" ]; then
          grep Cap /proc/self/status
        fi
        
        # Check network access
        echo "Testing network access..."
        if ping -c 1 8.8.8.8 >/dev/null 2>&1; then
          echo "‚ÑπÔ∏è  INFO: External network access available"
        else
          echo "‚ÑπÔ∏è  INFO: No external network access"
        fi
        
        # Generate security report
        cat > /tmp/security-report.txt <<EOF
      === Security Scan Report ===
      Timestamp: $(date)
      User ID: $(id -u)
      Group ID: $(id -g)
      Working Directory: $(pwd)
      
      Filesystem Check:
      - Root writable: $([ -w "/" ] && echo "YES" || echo "NO")
      - /tmp writable: $([ -w "/tmp" ] && echo "YES" || echo "NO")
      
      Network Check:
      - External access: $(ping -c 1 8.8.8.8 >/dev/null 2>&1 && echo "YES" || echo "NO")
      
      Process Information:
      $(ps aux)
      EOF
        
        echo "Report generated at /tmp/security-report.txt"
      }
      
      # Run security check
      check_security
      
      # Keep running for inspection
      echo "Scanner complete. Container will stay running for inspection."
      sleep 3600
      
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 1000
      runAsGroup: 3000
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir: {}
    
  restartPolicy: Never
```

**Usage:**
```bash
# Deploy the security scanner
kubectl apply -f security-scanner-pod.yaml

# Monitor the scan
kubectl logs -f security-scanner

# Get the security report
kubectl cp security-scanner:/tmp/security-report.txt ./security-report.txt
cat security-report.txt

# Create a comparison with an insecure pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: insecure-pod
spec:
  containers:
  - name: insecure
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      runAsUser: 0  # Running as root
      privileged: true
EOF

# Compare security postures
echo "=== Security Comparison ==="
echo "Secure pod user:"
kubectl exec security-scanner -- id

echo "Insecure pod user:"
kubectl exec insecure-pod -- id

echo "Secure pod capabilities:"
kubectl exec security-scanner -- grep Cap /proc/self/status

echo "Insecure pod capabilities:"
kubectl exec insecure-pod -- grep Cap /proc/self/status

# Clean up
kubectl delete pod security-scanner insecure-pod
rm -f security-report.txt
```

---

## Declarative Pod Configuration and Management

### üèóÔ∏è Expert Examples

#### Example 6: Production-Ready Pod Template

```yaml
# production-pod-template.yaml
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production
  labels:
    app: web-server
    version: "2.1.0"
    environment: production
    team: platform
  annotations:
    description: "Production web server with full monitoring and security"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/web-server"
    version: "2.1.0"
    build-date: "2024-01-15T10:30:00Z"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Node selection
  nodeSelector:
    node-type: "application"
    zone: "us-west-2a"
    
  # Tolerations for dedicated nodes
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "application"
    effect: "NoSchedule"
    
  # Pod placement preferences
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: "node-type"
            operator: In
            values: ["application"]
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: web-server
          topologyKey: kubernetes.io/hostname
          
  # DNS configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  containers:
  - name: web-server
    image: nginx:1.21-alpine
    imagePullPolicy: IfNotPresent
    
    ports:
    - name: http
      containerPort: 80
      protocol: TCP
    - name: metrics
      containerPort: 9113
      protocol: TCP
      
    # Environment variables
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "info"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security context
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE
        
    # Health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 80
        scheme: HTTP
        httpHeaders:
        - name: Custom-Header
          value: liveness-check
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
        scheme: HTTP
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle hooks
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container started at $(date)" >> /tmp/startup.log
            # Custom initialization logic here
            
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container stopping at $(date)" >> /tmp/shutdown.log
            # Graceful shutdown logic here
            nginx -s quit
            sleep 15
            
    # Volume mounts
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  # Sidecar container for log processing
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  # Monitoring sidecar
  - name: nginx-exporter
    image: nginx/nginx-prometheus-exporter:0.10.0
    args:
    - -nginx.scrape-uri=http://localhost:80/nginx_status
    ports:
    - name: metrics
      containerPort: 9113
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
  # Shared volumes
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
      defaultMode: 0644
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
      defaultMode: 0644
  - name: html-content
    configMap:
      name: html-content
      defaultMode: 0644
  - name: tmp-dir
    emptyDir:
      sizeLimit: 256Mi
  - name: var-cache-nginx
    emptyDir:
      sizeLimit: 512Mi
  - name: var-run
    emptyDir:
      sizeLimit: 64Mi
  - name: logs
    emptyDir:
      sizeLimit: 1Gi
```

### üõ†Ô∏è Demo: Complex Pod Deployment Pipeline

```bash
#!/bin/bash
# production-pod-deployment.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

# Configuration
NAMESPACE="production-demo"
APP_NAME="web-server"
CONFIG_DIR="./config"

# Create namespace if it doesn't exist
create_namespace() {
    log "Creating namespace: $NAMESPACE"
    kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    success "Namespace $NAMESPACE ready"
}

# Create ConfigMaps for the application
create_configmaps() {
    log "Creating ConfigMaps..."
    
    mkdir -p $CONFIG_DIR
    
    # Nginx configuration
    cat > $CONFIG_DIR/nginx.conf <<EOF
server {
    listen 80;
    server_name localhost;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
    
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    location /ready {
        access_log off;
        return 200 "ready\n";
        add_header Content-Type text/plain;
    }
    
    location /nginx_status {
        stub_status on;
        access_log off;
        allow all;
    }
}
EOF

    # HTML content
    cat > $CONFIG_DIR/index.html <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Production Pod Demo</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .container { max-width: 800px; margin: 0 auto; }
        .status { padding: 20px; margin: 20px 0; border-radius: 5px; }
        .healthy { background-color: #d4edda; color: #155724; }
        .info { background-color: #d1ecf1; color: #0c5460; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Production Pod Demo</h1>
        <div class="status healthy">
            <h3>‚úÖ Application Status: Healthy</h3>
            <p>Pod is running successfully with full production configuration</p>
        </div>
        
        <div class="status info">
            <h3>üìä Features Enabled:</h3>
            <ul>
                <li>Multi-container architecture</li>
                <li>Comprehensive health checks</li>
                <li>Security hardening</li>
                <li>Log processing sidecar</li>
                <li>Prometheus metrics export</li>
                <li>Resource management</li>
            </ul>
        </div>
        
        <div class="status info">
            <h3>üîó Endpoints:</h3>
            <ul>
                <li><a href="/health">Health Check</a></li>
                <li><a href="/ready">Readiness Check</a></li>
                <li><a href="/nginx_status">Nginx Status</a></li>
            </ul>
        </div>
    </div>
</body>
</html>
EOF

    # Fluent Bit configuration
    cat > $CONFIG_DIR/fluent-bit.conf <<EOF
[SERVICE]
    Flush         1
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf

[INPUT]
    Name              tail
    Path              /var/log/nginx/access.log
    Parser            nginx
    Tag               nginx.access
    Refresh_Interval  5

[INPUT]
    Name              tail
    Path              /var/log/nginx/error.log
    Tag               nginx.error
    Refresh_Interval  5

[OUTPUT]
    Name  stdout
    Match nginx.*
EOF

    cat > $CONFIG_DIR/parsers.conf <<EOF
[PARSER]
    Name   nginx
    Format regex
    Regex  ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
    Time_Key time
    Time_Format %d/%b/%Y:%H:%M:%S %z
EOF

    # Create ConfigMaps
    kubectl create configmap nginx-config --from-file=$CONFIG_DIR/nginx.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap html-content --from-file=$CONFIG_DIR/index.html -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap fluent-bit-config --from-file=$CONFIG_DIR/fluent-bit.conf --from-file=$CONFIG_DIR/parsers.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    
    success "ConfigMaps created successfully"
}

# Deploy the production pod
deploy_pod() {
    log "Deploying production pod..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: $APP_NAME
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
    version: "1.0.0"
    environment: production
  annotations:
    deployment.kubernetes.io/revision: "1"
    deployed-by: "production-deployment-script"
    deployment-time: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    
  containers:
  - name: nginx
    image: nginx:1.21-alpine
    ports:
    - name: http
      containerPort: 80
    - name: metrics
      containerPort: 9113
      
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
  - name: html-content
    configMap:
      name: html-content
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
  - name: tmp-dir
    emptyDir: {}
  - name: var-cache-nginx
    emptyDir: {}
  - name: var-run
    emptyDir: {}
  - name: logs
    emptyDir: {}
EOF

    success "Pod deployed successfully"
}

# Wait for pod to be ready and perform health checks
verify_deployment() {
    log "Waiting for pod to be ready..."
    
    if kubectl wait --for=condition=Ready pod/$APP_NAME -n $NAMESPACE --timeout=120s; then
        success "Pod is ready!"
    else
        error "Pod failed to become ready within timeout"
    fi
    
    # Perform comprehensive health checks
    log "Performing health checks..."
    
    # Check pod status
    kubectl get pod $APP_NAME -n $NAMESPACE -o wide
    
    # Test health endpoints
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    if curl -s http://localhost:8080/health | grep -q "healthy"; then
        success "Health check passed"
    else
        warning "Health check failed"
    fi
    
    if curl -s http://localhost:8080/ready | grep -q "ready"; then
        success "Readiness check passed"
    else
        warning "Readiness check failed"
    fi
    
    # Test the main application
    if curl -s http://localhost:8080 | grep -q "Production Pod Demo"; then
        success "Application is serving content correctly"
    else
        warning "Application content check failed"
    fi
    
    kill $PF_PID 2>/dev/null
    
    # Check resource usage
    log "Checking resource usage..."
    if kubectl top pod $APP_NAME -n $NAMESPACE &>/dev/null; then
        kubectl top pod $APP_NAME -n $NAMESPACE
    else
        warning "Resource metrics not available"
    fi
    
    # Check logs from all containers
    log "Checking container logs..."
    echo "=== Nginx logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c nginx --tail=5
    echo "=== Log processor logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=5
}

# Generate load and monitor performance
performance_test() {
    log "Running performance test..."
    
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    # Generate some load
    for i in {1..50}; do
        curl -s http://localhost:8080 > /dev/null &
    done
    
    wait
    kill $PF_PID 2>/dev/null
    
    # Check logs after load test
    log "Logs after load test:"
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=10
    
    success "Performance test completed"
}

# Cleanup function
cleanup() {
    log "Cleaning up resources..."
    kubectl delete pod $APP_NAME -n $NAMESPACE --ignore-not-found
    kubectl delete configmap nginx-config html-content fluent-bit-config -n $NAMESPACE --ignore-not-found
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -rf $CONFIG_DIR
    success "Cleanup completed"
}

# Main execution
main() {
    echo "=== Production Pod Deployment Demo ==="
    
    case "${1:-deploy}" in
        "deploy")
            create_namespace
            create_configmaps
            deploy_pod
            verify_deployment
            performance_test
            
            echo ""
            success "Deployment completed successfully!"
            echo "Access the application:"
            echo "  kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80"
            echo "  Then open: http://localhost:8080"
            echo ""
            echo "Monitor the pod:"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c nginx"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c log-processor"
            echo ""
            echo "Run 'bash $0 cleanup' to remove all resources"
            ;;
        "cleanup")
            cleanup
            ;;
        "test")
            verify_deployment
            performance_test
            ;;
        *)
            echo "Usage: $0 [deploy|cleanup|test]"
            echo "  deploy  - Deploy the production pod (default)"
            echo "  cleanup - Remove all created resources"
            echo "  test    - Run verification and performance tests"
            ;;
    esac
}

main "$@"
```

### üéØ Mini-Project 4: Pod Chaos Engineering

Test pod resilience with chaos engineering principles:

```yaml
# chaos-test-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: chaos-resilient-app
  labels:
    app: chaos-test
    resilience: enabled
spec:
  containers:
  - name: main-app
    image: nginx:1.21-alpine
    ports:
    - containerPort: 80
    
    # Aggressive resource limits to test resilience
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    # Tight health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 2
      
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
      timeoutSeconds: 1
      failureThreshold: 2
      
    # Graceful shutdown
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 10"]
          
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  # Chaos monkey sidecar
  - name: chaos-monkey
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Chaos monkey starting..."
      
      # Function to create CPU load
      cpu_chaos() {
        echo "Creating CPU chaos..."
        for i in {1..4}; do
          yes > /dev/null &
        done
        sleep 30
        killall yes
      }
      
      # Function to create memory pressure
      memory_chaos() {
        echo "Creating memory chaos..."
        cat <(yes | tr \\n x | head -c 50000000) <(yes | tr \\n x | head -c 50000000) > /tmp/memory_eater &
        sleep 20
        rm -f /tmp/memory_eater
        killall cat
      }
      
      # Function to simulate network issues
      network_chaos() {
        echo "Creating network chaos..."
        # Simulate slow responses
        sleep $((RANDOM % 10 + 5))
      }
      
      # Function to create disk I/O pressure
      disk_chaos() {
        echo "Creating disk I/O chaos..."
        dd if=/dev/zero of=/tmp/disk_eater bs=1M count=10 2>/dev/null
        rm -f /tmp/disk_eater
      }
      
      # Main chaos loop
      while true; do
        chaos_type=$((RANDOM % 4))
        case $chaos_type in
          0) cpu_chaos ;;
          1) memory_chaos ;;
          2) network_chaos ;;
          3) disk_chaos ;;
        esac
        
        # Wait between chaos events
        sleep $((RANDOM % 60 + 30))
      done
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir:
      sizeLimit: 100Mi
      
  restartPolicy: Always
```

**Chaos Testing Script:**
```bash
#!/bin/bash
# chaos-engineering-test.sh

echo "=== Chaos Engineering Test ==="

# Deploy the chaos test pod
kubectl apply -f chaos-test-pod.yaml

# Wait for it to be ready
echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/chaos-resilient-app --timeout=60s

# Monitor pod resilience
echo "Starting resilience monitoring (Ctrl+C to stop)..."

monitor_resilience() {
    while true; do
        timestamp=$(date '+%H:%M:%S')
        
        # Check pod status
        status=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.phase}')
        ready=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
        restarts=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.containerStatuses[0].restartCount}')
        
        # Test application responsiveness
        kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
        PF_PID=$!
        sleep 2
        
        response_time=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8080 2>/dev/null || echo "FAIL")
        kill $PF_PID 2>/dev/null
        
        # Get resource usage if available
        resources=""
        if kubectl top pod chaos-resilient-app &>/dev/null; then
            resources=$(kubectl top pod chaos-resilient-app --no-headers 2>/dev/null | awk '{print $2" "$3}')
        fi
        
        printf "[$timestamp] Status: $status | Ready: $ready | Restarts: $restarts | Response: ${response_time}s | Resources: $resources\n"
        
        sleep 5
    done
}

# Start monitoring in background
monitor_resilience &
MONITOR_PID=$!

# Generate additional load to test resilience
echo "Generating load to test resilience..."
for i in {1..100}; do
    kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
    PF_PID=$!
    sleep 1
    
    curl -s http://localhost:8080 > /dev/null &
    
    kill $PF_PID 2>/dev/null
    sleep 2
done

# Stop monitoring
kill $MONITOR_PID 2>/dev/null

echo "Chaos test completed. Check pod logs:"
echo "kubectl logs chaos-resilient-app -c main-app --tail=20"
echo "kubectl logs chaos-resilient-app -c chaos-monkey --tail=20"

# Cleanup
read -p "Delete the chaos test pod? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    kubectl delete -f chaos-test-pod.yaml
fi
```

---

## Advanced Pod Management Techniques

### üî¨ Expert-Level Examples

#### Example 7: Custom Pod Controller

Create a custom controller for specialized pod management:

```python
#!/usr/bin/env python3
# custom-pod-controller.py

import time
import yaml
import subprocess
import json
from datetime import datetime, timedelta

class PodController:
    def __init__(self):
        self.managed_pods = {}
        self.check_interval = 30  # seconds
        
    def log(self, message):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"[{timestamp}] {message}")
        
    def run_kubectl(self, command):
        """Execute kubectl command and return JSON output"""
        try:
            result = subprocess.run(
                f"kubectl {command} -o json",
                shell=True,
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                self.log(f"kubectl error: {result.stderr}")
                return None
        except Exception as e:
            self.log(f"Command execution error: {e}")
            return None
            
    def get_pods_by_label(self, label_selector):
        """Get pods matching label selector"""
        command = f"get pods -l {label_selector}"
        result = self.run_kubectl(command)
        return result.get('items', []) if result else []
        
    def create_pod(self, name, spec):
        """Create a pod with given specification"""
        pod_manifest = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'name': name,
                'labels': {
                    'managed-by': 'custom-controller',
                    'created': datetime.now().strftime('%Y%m%d-%H%M%S')
                }
            },
            'spec': spec
        }
        
        # Write manifest to temporary file
        with open(f'/tmp/{name}.yaml', 'w') as f:
            yaml.dump(pod_manifest, f)
            
        # Apply the manifest
        result = subprocess.run(
            f"kubectl apply -f /tmp/{name}.yaml",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Created pod: {name}")
            return True
        else:
            self.log(f"Failed to create pod {name}: {result.stderr}")
            return False
            
    def delete_pod(self, name):
        """Delete a pod"""
        result = subprocess.run(
            f"kubectl delete pod {name} --grace-period=30",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Deleted pod: {name}")
            return True
        else:
            self.log(f"Failed to delete pod {name}: {result.stderr}")
            return False
            
    def check_pod_health(self, pod):
        """Check if a pod is healthy based on custom criteria"""
        name = pod['metadata']['name']
        status = pod['status']
        
        # Check if pod is running
        if status.get('phase') != 'Running':
            return False, f"Pod {name} is not running (phase: {status.get('phase')})"
            
        # Check container statuses
        container_statuses = status.get('containerStatuses', [])
        for container in container_statuses:
            if not container.get('ready'):
                return False, f"Container {container['name']} not ready in pod {name}"
                
            # Check restart count
            restart_count = container.get('restartCount', 0)
            if restart_count > 5:
                return False, f"Container {container['name']} restarted {restart_count} times"
                
        # Check resource usage (if metrics available)
        metrics = self.get_pod_metrics(name)
        if metrics:
            cpu_usage = self.parse_cpu_usage(metrics.get('cpu', '0m'))
            memory_usage = self.parse_memory_usage(metrics.get('memory', '0Mi'))
            
            if cpu_usage > 800:  # 800 millicores
                return False, f"Pod {name} CPU usage too high: {cpu_usage}m"
                
            if memory_usage > 512:  # 512 Mi
                return False, f"Pod {name} memory usage too high: {memory_usage}Mi"
                
        return True, f"Pod {name} is healthy"
        
    def get_pod_metrics(self, pod_name):
        """Get pod resource metrics if available"""
        result = subprocess.run(
            f"kubectl top pod {pod_name} --no-headers",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            parts = result.stdout.strip().split()
            if len(parts) >= 3:
                return {
                    'cpu': parts[1],
                    'memory': parts[2]
                }
        return None
        
    def parse_cpu_usage(self, cpu_str):
        """Parse CPU usage from string like '100m' to millicores"""
        if cpu_str.endswith('m'):
            return int(cpu_str[:-1])
        return int(cpu_str) * 1000
        
    def parse_memory_usage(self, memory_str):
        """Parse memory usage from string like '128Mi' to Mi"""
        if memory_str.endswith('Mi'):
            return int(memory_str[:-2])
        elif memory_str.endswith('Gi'):
            return int(memory_str[:-2]) * 1024
        return int(memory_str) // (1024 * 1024)
        
    def auto_heal_pod(self, pod_name, reason):
        """Attempt to heal an unhealthy pod"""
        self.log(f"Attempting to heal pod {pod_name}: {reason}")
        
        # Strategy 1: Restart the pod
        if "restart" in reason.lower():
            return self.delete_pod(pod_name)  # Pod will be recreated if managed by controller
            
        # Strategy 2: Scale resources if high usage
        if "usage too high" in reason.lower():
            self.log(f"High resource usage detected for {pod_name}, marking for recreation")
            return self.delete_pod(pod_name)
            
        # Strategy 3: Generic restart
        return self.delete_pod(pod_name)
        
    def manage_workload(self, workload_config):
        """Manage a workload with desired replica count"""
        app_name = workload_config['name']
        desired_replicas = workload_config['replicas']
        pod_spec = workload_config['pod_spec']
        
        # Get current pods for this workload
        current_pods = self.get_pods_by_label(f"app={app_name},managed-by=custom-controller")
        current_count = len(current_pods)
        
        self.log(f"Managing workload {app_name}: current={current_count}, desired={desired_replicas}")
        
        # Scale up if needed
        if current_count < desired_replicas:
            for i in range(current_count, desired_replicas):
                pod_name = f"{app_name}-{i}"
                pod_spec_copy = pod_spec.copy()
                pod_spec_copy.setdefault('containers', [{}])[0]['env'] = [
                    {'name': 'REPLICA_ID', 'value': str(i)},
                    {'name': 'APP_NAME', 'value': app_name}
                ]
                self.create_pod(pod_name, pod_spec_copy)
                
        # Scale down if needed
        elif current_count > desired_replicas:
            pods_to_delete = current_pods[desired_replicas:]
            for pod in pods_to_delete:
                self.delete_pod(pod['metadata']['name'])
                
        # Health check existing pods
        for pod in current_pods[:desired_replicas]:
            healthy, reason = self.check_pod_health(pod)
            if not healthy:
                self.log(f"Pod unhealthy: {reason}")
                self.auto_heal_pod(pod['metadata']['name'], reason)
                
    def run_control_loop(self):
        """Main control loop"""
        self.log("Starting custom pod controller...")
        
        # Sample workload configuration
        workloads = [
            {
                'name': 'web-app',
                'replicas': 2,
                'pod_spec': {
                    'containers': [{
                        'name': 'nginx',
                        'image': 'nginx:1.21-alpine',
                        'ports': [{'containerPort': 80}],
                        'resources': {
                            'requests': {'memory': '64Mi', 'cpu': '50m'},
                            'limits': {'memory': '128Mi', 'cpu': '100m'}
                        },
                        'livenessProbe': {
                            'httpGet': {'path': '/', 'port': 80},
                            'initialDelaySeconds': 10,
                            'periodSeconds': 30
                        }
                    }],
                    'restartPolicy': 'Always'
                }
            }
        ]
        
        try:
            while True:
                self.log("Running control loop...")
                
                for workload in workloads:
                    try:
                        self.manage_workload(workload)
                    except Exception as e:
                        self.log(f"Error managing workload {workload['name']}: {e}")
                        
                self.log(f"Sleeping for {self.check_interval} seconds...")
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            self.log("Shutting down controller...")
            
        except Exception as e:
            self.log(f"Controller error: {e}")
            
    def cleanup(self):
        """Clean up managed resources"""
        self.log("Cleaning up managed pods...")
        pods = self.get_pods_by_label("managed-by=custom-controller")
        for pod in pods:
            self.delete_pod(pod['metadata']['name'])

if __name__ == "__main__":
    import sys
    
    controller = PodController()
    
    if len(sys.argv) > 1 and sys.argv[1] == "cleanup":
        controller.cleanup()
    else:
        controller.run_control_loop()
```

**Usage:**
```bash
# Make the script executable
chmod +x custom-pod-controller.py

# Install dependencies
pip3 install pyyaml

# Run the controller
python3 custom-pod-controller.py

# In another terminal, watch the managed pods
watch kubectl get pods -l managed-by=custom-controller

# Simulate pod failures
kubectl delete pod web-app-0  # Controller will recreate it

# Clean up when done
python3 custom-pod-controller.py cleanup
```

### üéØ Mini-Project 5: Pod Performance Optimization Lab

Create a comprehensive performance optimization laboratory:

```yaml
# performance-lab-setup.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: performance-lab
---
# Baseline pod - unoptimized
apiVersion: v1
kind: Pod
metadata:
  name: baseline-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: baseline
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "1000m"
      limits:
        memory: "2Gi"
        cpu: "2000m"
---
# Optimized pod - resource-efficient
apiVersion: v1
kind: Pod
metadata:
  name: optimized-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: optimized
spec:
  containers:
  - name: app
    image: nginx:1.21-alpine  # Smaller image
    resources:
      requests:
        memory: "64Mi"        # Right-sized requests
        cpu: "100m"
      limits:
        memory: "128Mi"       # Conservative limits
        cpu: "200m"
    # Optimized health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5   # Faster startup
      periodSeconds: 30        # Less frequent checks
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
    # Security optimizations
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
    # Volume optimizations
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp-dir
    emptyDir:
      medium: Memory  # Use memory for temp files
      sizeLimit: 64Mi
  - name: var-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: var-run
    emptyDir:
      sizeLimit: 32Mi
---
# High-performance pod with advanced optimizations
apiVersion: v1
kind: Pod
metadata:
  name: high-performance-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: high-performance
spec:
  # Pod-level optimizations
  priorityClassName: high-priority
  nodeSelector:
    node-type: performance
  tolerations:
  - key: performance-node
    operator: Equal
    value: "true"
    effect: NoSchedule
  # Network optimizations
  dnsPolicy: ClusterFirstWithHostNet
  dnsConfig:
    options:
    - name: ndots
      value: "1"
    - name: edns0
  containers:
  - name: app
    image: nginx:1.21-alpine
    # Optimized resource allocation
    resources:
      requests:
        memory: "128Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "256Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
    # Performance-tuned environment
    env:
    - name: NGINX_WORKER_PROCESSES
      value: "auto"
    - name: NGINX_WORKER_CONNECTIONS
      value: "1024"
    # Aggressive health checks for faster recovery
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 15
      timeoutSeconds: 2
      failureThreshold: 2
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 3
      timeoutSeconds: 1
      failureThreshold: 1
    # Startup optimization
    startupProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 1
      timeoutSeconds: 1
      failureThreshold: 10
    # Performance-optimized volumes
    volumeMounts:
    - name: high-speed-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
  volumes:
  - name: high-speed-tmp
    emptyDir:
      medium: Memory
      sizeLimit: 128Mi
  - name: nginx-cache
    emptyDir:
      medium: Memory
      sizeLimit: 256Mi
  - name: nginx-run
    emptyDir:
      medium: Memory
      sizeLimit: 64Mi
```

**Performance Benchmarking Script:**
```bash
#!/bin/bash
# performance-benchmark.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

NAMESPACE="performance-lab"

# Deploy the performance lab
setup_lab() {
    log "Setting up performance lab..."
    kubectl apply -f performance-lab-setup.yaml
    
    log "Waiting for pods to be ready..."
    kubectl wait --for=condition=Ready pod/baseline-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/optimized-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/high-performance-app -n $NAMESPACE --timeout=120s
    
    success "Performance lab setup complete"
}

# Measure startup time
measure_startup_time() {
    local pod_name=$1
    log "Measuring startup time for $pod_name..."
    
    # Delete and recreate pod to measure startup
    kubectl delete pod $pod_name -n $NAMESPACE
    local start_time=$(date +%s.%N)
    
    # Recreate the pod (extract from original manifest)
    kubectl get pod $pod_name -n $NAMESPACE -o yaml --export 2>/dev/null | kubectl apply -f - 2>/dev/null || {
        warning "Couldn't recreate pod automatically, recreating from manifest"
        kubectl apply -f performance-lab-setup.yaml
    }
    
    # Wait for ready and measure time
    kubectl wait --for=condition=Ready pod/$pod_name -n $NAMESPACE --timeout=120s
    local end_time=$(date +%s.%N)
    
    local startup_time=$(echo "$end_time - $start_time" | bc -l)
    echo "$startup_time"
}

# Run load test on a pod
load_test_pod() {
    local pod_name=$1
    local duration=${2:-30}
    local concurrency=${3:-10}
    
    log "Running load test on $pod_name (${duration}s, ${concurrency} concurrent)"
    
    # Start port forwarding
    kubectl port-forward pod/$pod_name -n $NAMESPACE 8080:80 >/dev/null 2>&1 &
    local pf_pid=$!
    sleep 3
    
    # Use Apache Bench for load testing
    local results_file="/tmp/ab_results_${pod_name}.txt"
    
    if command -v ab >/dev/null; then
        ab -n $((duration * concurrency)) -c $concurrency -g /tmp/gnuplot_${pod_name}.dat \
           http://localhost:8080/ > $results_file 2>&1
        
        # Extract key metrics
        local rps=$(grep "Requests per second" $results_file | awk '{print $4}')
        local response_time=$(grep "Time per request.*mean" $results_file | head -1 | awk '{print $4}')
        local failed_requests=$(grep "Failed requests" $results_file | awk '{print $3}')
        
        echo "RPS:$rps,ResponseTime:$response_time,Failed:$failed_requests"
    else
        # Fallback to curl-based test
        local start_time=$(date +%s)
        local requests=0
        local total_time=0
        
        for i in $(seq 1 $((duration * concurrency))); do
            local req_start=$(date +%s.%N)
            if curl -s http://localhost:8080 >/dev/null 2>&1; then
                ((requests++))
            fi
            local req_end=$(date +%s.%N)
            local req_time=$(echo "$req_end - $req_start" | bc -l)
            total_time=$(echo "$total_time + $req_time" | bc -l)
            
            # Basic rate limiting
            sleep 0.1
        done
        
        local avg_response_time=$(echo "scale=3; $total_time / $requests" | bc -l)
        local rps=$(echo "scale=2; $requests / $duration" | bc -l)
        
        echo "RPS:$rps,ResponseTime:$avg_response_time,Failed:0"
    fi
    
    kill $pf_pid 2>/dev/null
}

# Get resource usage metrics
get_resource_usage() {
    local pod_name=$1
    log "Getting resource usage for $pod_name..."
    
    if kubectl top pod $pod_name -n $NAMESPACE >/dev/null 2>&1; then
        kubectl top pod $pod_name -n $NAMESPACE --no-headers | awk '{print "CPU:"$2",Memory:"$3}'
    else
        echo "CPU:N/A,Memory:N/A"
    fi
}

# Comprehensive benchmark
run_comprehensive_benchmark() {
    log "Running comprehensive performance benchmark..."
    
    declare -A results
    local pods=("baseline-app" "optimized-app" "high-performance-app")
    
    echo "=== Performance Benchmark Results ===" > benchmark_results.txt
    echo "Timestamp: $(date)" >> benchmark_results.txt
    echo "" >> benchmark_results.txt
    
    for pod in "${pods[@]}"; do
        log "Benchmarking $pod..."
        
        # Startup time measurement
        log "Measuring startup time for $pod..."
        # Skip startup measurement in this demo to avoid pod recreation issues
        startup_time="N/A"
        
        # Resource usage
        resource_usage=$(get_resource_usage $pod)
        
        # Load test
        load_results=$(load_test_pod $pod 30 10)
        
        # Pod status information
        pod_info=$(kubectl get pod $pod -n $NAMESPACE -o custom-columns=STATUS:.status.phase,READY:.status.conditions[?\(@.type==\"Ready\"\)].status,RESTARTS:.status.containerStatuses[0].restartCount --no-headers)
        
        # Store results
        results[$pod]="Startup:$startup_time,Resources:$resource_usage,Load:$load_results,Status:$pod_info"
        
        # Write to file
        cat >> benchmark_results.txt <<EOF

=== $pod ===
Startup Time: $startup_time seconds
Resource Usage: $resource_usage
Load Test Results: $load_results
Pod Status: $pod_info

EOF
    done
    
    # Generate comparison summary
    cat >> benchmark_results.txt <<EOF

=== Performance Summary ===
This benchmark compares three pod configurations:

1. Baseline App: Standard configuration with generous resource allocation
2. Optimized App: Resource-efficient with security hardening
3. High-Performance App: Maximum performance optimizations

Key Findings:
- Resource efficiency varies significantly between configurations
- Startup time impacts overall application availability
- Load handling capacity differs based on resource allocation
- Security optimizations may have performance trade-offs

Recommendations:
- Use optimized configuration for production workloads
- Consider high-performance setup for critical applications
- Monitor resource usage to fine-tune allocations
- Balance security and performance based on requirements

EOF
    
    success "Benchmark completed. Results saved to benchmark_results.txt"
    cat benchmark_results.txt
}

# Resource monitoring script
monitor_resources() {
    local duration=${1:-300}  # 5 minutes default
    log "Starting resource monitoring for ${duration} seconds..."
    
    local monitor_file="resource_monitor_$(date +%Y%m%d_%H%M%S).log"
    
    {
        echo "Timestamp,Pod,CPU,Memory,Status"
        local end_time=$(($(date +%s) + duration))
        
        while [ $(date +%s) -lt $end_time ]; do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            
            for pod in baseline-app optimized-app high-performance-app; do
                if kubectl get pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                    local status=$(kubectl get pod $pod -n $NAMESPACE -o jsonpath='{.status.phase}')
                    local usage="N/A,N/A"
                    
                    if kubectl top pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                        usage=$(kubectl top pod $pod -n $NAMESPACE --no-headers | awk '{print $2","$3}')
                    fi
                    
                    echo "$timestamp,$pod,$usage,$status"
                fi
            done
            
            sleep 10
        done
    } > $monitor_file
    
    success "Resource monitoring completed. Data saved to $monitor_file"
    
    # Generate simple analysis
    log "Generating resource usage analysis..."
    
    {
        echo "=== Resource Usage Analysis ==="
        echo ""
        
        for pod in baseline-app optimized-app high-performance-app; do
            echo "=== $pod ==="
            grep "$pod" $monitor_file | tail -10 | while IFS=',' read timestamp pod_name cpu memory status; do
                echo "[$timestamp] CPU: $cpu, Memory: $memory, Status: $status"
            done
            echo ""
        done
    } > resource_analysis.txt
    
    success "Analysis saved to resource_analysis.txt"
}

# Cleanup function
cleanup_lab() {
    log "Cleaning up performance lab..."
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -f benchmark_results.txt resource_*.log resource_analysis.txt
    rm -f /tmp/ab_results_*.txt /tmp/gnuplot_*.dat
    success "Cleanup completed"
}

# Main execution
main() {
    case "${1:-benchmark}" in
        "setup")
            setup_lab
            ;;
        "benchmark")
            setup_lab
            run_comprehensive_benchmark
            ;;
        "monitor")
            monitor_resources "${2:-300}"
            ;;
        "cleanup")
            cleanup_lab
            ;;
        "all")
            setup_lab
            run_comprehensive_benchmark
            monitor_resources 300
            echo ""
            success "Complete performance analysis finished!"
            echo "Files created:"
            echo "  - benchmark_results.txt"
            echo "  - resource_monitor_*.log"
            echo "  - resource_analysis.txt"
            ;;
        *)
            echo "Performance Lab - Pod Optimization Benchmark"
            echo ""
            echo "Usage: $0 <command> [options]"
            echo ""
            echo "Commands:"
            echo "  setup      - Set up the performance lab environment"
            echo "  benchmark  - Run comprehensive performance benchmark"
            echo "  monitor    - Monitor resource usage for specified duration"
            echo "  cleanup    - Remove all lab resources"
            echo "  all        - Run complete analysis (setup + benchmark + monitor)"
            echo ""
            echo "Examples:"
            echo "  $0 setup"
            echo "  $0 benchmark"
            echo "  $0 monitor 600  # Monitor for 10 minutes"
            echo "  $0 all          # Complete analysis"
            ;;
    esac
}

main "$@"
```

---

## Pod Troubleshooting Methodologies

### üîß Advanced Troubleshooting Toolkit

#### Example 8: Automated Diagnostic System

```bash
#!/bin/bash
# advanced-pod-diagnostics.sh

set -euo pipefail

# Enhanced diagnostic toolkit with automated problem detection
class PodDiagnostics {
    
# Configuration
NAMESPACE=${NAMESPACE:-default}
OUTPUT_DIR="./diagnostics-$(date +%Y%m%d-%H%M%S)"
VERBOSE=${VERBOSE:-false}

# Colors and formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'
BOLD='\033[1m'

# Logging functions with levels
log_debug() { [[ $VERBOSE == "true" ]] && echo -e "${CYAN}[DEBUG]${NC} $1"; }
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }

# Initialize diagnostics
init_diagnostics() {
    log_info "Initializing pod diagnostics system..."
    mkdir -p "$OUTPUT_DIR"/{logs,reports,metrics,manifests}
    
    # Create diagnostic report header
    cat > "$OUTPUT_DIR/diagnostic_report.md" <<EOF
# Pod Diagnostics Report

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)  
**Namespace:** $NAMESPACE  
**Output Directory:** $OUTPUT_DIR

---

EOF
    
    log_success "Diagnostics initialized in $OUTPUT_DIR"
}

# Comprehensive pod information gathering
gather_pod_info() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Gathering comprehensive information for pod: $pod_name"
    
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    mkdir -p "$pod_dir"
    
    # Basic pod information
    kubectl get pod "$pod_name" -n "$namespace" -o wide > "$pod_dir/basic_info.txt" 2>&1
    kubectl get pod "$pod_name" -n "$namespace" -o yaml > "$pod_dir/manifest.yaml" 2>&1
    
    # Detailed description
    kubectl describe pod "$pod_name" -n "$namespace" > "$pod_dir/description.txt" 2>&1
    
    # Events related to the pod
    kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
        --sort-by='.lastTimestamp' > "$pod_dir/events.txt" 2>&1
    
    # Container logs
    local containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}' 2>/dev/null)
    for container in $containers; do
        log_debug "Collecting logs for container: $container"
        kubectl logs "$pod_name" -n "$namespace" -c "$container" > "$pod_dir/logs_${container}.txt" 2>&1
        
        # Previous logs if container restarted
        kubectl logs "$pod_name" -n "$namespace" -c "$container" --previous > "$pod_dir/logs_${container}_previous.txt" 2>&1 || true
    done
    
    # Resource usage
    kubectl top pod "$pod_name" -n "$namespace" > "$pod_dir/resource_usage.txt" 2>&1 || echo "Metrics not available" > "$pod_dir/resource_usage.txt"
    
    log_success "Pod information gathered for $pod_name"
}

# Automated problem detection
detect_common_issues() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Running automated issue detection for $pod_name..."
    
    local issues_file="$pod_dir/detected_issues.md"
    echo "# Automated Issue Detection Report" > "$issues_file"
    echo "**Pod:** $pod_name" >> "$issues_file"
    echo "**Analysis Time:** $(date)" >> "$issues_file"
    echo "" >> "$issues_file"
    
    local issue_count=0
    
    # Check 1: Pod phase issues
    local phase=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.phase}' 2>/dev/null)
    if [[ "$phase" != "Running" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Pod Not Running
- **Severity:** High
- **Status:** Pod is in '$phase' phase instead of 'Running'
- **Impact:** Application unavailable
- **Investigation:** Check pod events and container status

EOF
    fi
    
    # Check 2: Container readiness issues
    local ready_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[?(@.ready==true)]}' | jq '. | length' 2>/dev/null || echo "0")
    local total_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers}' | jq '. | length' 2>/dev/null || echo "1")
    
    if [[ "$ready_containers" -lt "$total_containers" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Container Readiness Problems
- **Severity:** High
- **Status:** Only $ready_containers of $total_containers containers are ready
- **Impact:** Traffic routing may be affected
- **Investigation:** Check readiness probes and container logs

EOF
    fi
    
    # Check 3: Excessive restarts
    local restarts=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
    if [[ "$restarts" -gt 5 ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Excessive Container Restarts
- **Severity:** Medium
- **Status:** Container has restarted $restarts times
- **Impact:** Service instability and potential data loss
- **Investigation:** Check liveness probes, resource limits, and application logs

EOF
    fi
    
    # Check 4: Resource usage issues
    if kubectl top pod "$pod_name" -n "$namespace" >/dev/null 2>&1; then
        local cpu_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $2}' | sed 's/m$//')
        local memory_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $3}' | sed 's/Mi$//')
        
        if [[ "$cpu_usage" -gt 800 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High CPU Usage
- **Severity:** Medium
- **Status:** CPU usage is ${cpu_usage}m (> 800m threshold)
- **Impact:** Performance degradation and potential throttling
- **Investigation:** Check for CPU-intensive processes and consider scaling

EOF
        fi
        
        if [[ "$memory_usage" -gt 512 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High Memory Usage
- **Severity:** Medium  
- **Status:** Memory usage is ${memory_usage}Mi (> 512Mi threshold)
- **Impact:** Risk of OOM kills and service disruption
- **Investigation:** Check for memory leaks and optimize memory usage

EOF
        fi
    fi
    
    # Check 5: Image pull issues
    if grep -q "ImagePullBackOff\|ErrImagePull" "$pod_dir/description.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Image Pull Problems
- **Severity:** High
- **Status:** Unable to pull container image
- **Impact:** Pod cannot start
- **Investigation:** Check image name, registry access, and credentials

EOF
    fi
    
    # Check 6: Resource constraints
    if grep -q "Insufficient.*resources" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Resource Constraints
- **Severity:** High
- **Status:** Insufficient cluster resources for pod scheduling
- **Impact:** Pod cannot be scheduled
- **Investigation:** Check cluster capacity and node resources

EOF
    fi
    
    # Check 7: Network issues
    if grep -q "NetworkNotReady\|CNI.*error" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Network Configuration Problems
- **Severity:** High
- **Status:** Network setup issues detected
- **Impact:** Pod networking may not function correctly
- **Investigation:** Check CNI configuration and network policies

EOF
    fi
    
    # Summary
    if [[ $issue_count -eq 0 ]]; then
        echo "## Summary: No Critical Issues Detected ‚úÖ" >> "$issues_file"
        echo "The automated analysis found no obvious problems with this pod." >> "$issues_file"
        log_success "No critical issues detected for $pod_name"
    else
        echo "## Summary: $issue_count Issue(s) Detected ‚ö†Ô∏è" >> "$issues_file"
        echo "Review the issues above and follow the investigation recommendations." >> "$issues_file"
        log_warn "$issue_count issue(s) detected for $pod_name"
    fi
    
    return $issue_count
}

# Generate recommendations
generate_recommendations() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Generating recommendations for $pod_name..."
    
    local rec_file="$pod_dir/recommendations.md"
    echo "# Optimization Recommendations" > "$rec_file"
    echo "**Pod:** $pod_name" >> "$rec_file"
    echo "" >> "$rec_file"
    
    # Resource optimization recommendations
    echo "## Resource Optimization" >> "$rec_file"
    
    # Check current resource configuration
    local requests_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.memory}' 2>/dev/null || echo "not set")
    local requests_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.cpu}' 2>/dev/null || echo "not set")
    local limits_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.memory}' 2>/dev/null || echo "not set")
    local limits_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.cpu}' 2>/dev/null || echo "not set")
    
    cat >> "$rec_file" <<EOF
### Current Resource Configuration
- **Memory Request:** $requests_mem
- **CPU Request:** $requests_cpu  
- **Memory Limit:** $limits_mem
- **CPU Limit:** $limits_cpu

EOF
    
    # Security recommendations
    echo "## Security Hardening" >> "$rec_file"
    
    local security_context=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.securityContext}' 2>/dev/null)
    if [[ -z "$security_context" || "$security_context" == "null" ]]; then
        cat >> "$rec_file" <<EOF
### Security Context Improvements
- ‚úÖ **Add security context:** Configure runAsNonRoot, runAsUser, and fsGroup
- ‚úÖ **Drop capabilities:** Remove unnecessary Linux capabilities  
- ‚úÖ **Read-only root filesystem:** Set readOnlyRootFilesystem: true
- ‚úÖ **Prevent privilege escalation:** Set allowPrivilegeEscalation: false

EOF
    fi
    
    # Health check recommendations
    echo "## Health Check Optimization" >> "$rec_file"
    
    local has_liveness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].livenessProbe}' 2>/dev/null)
    local has_readiness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].readinessProbe}' 2>/dev/null)
    
    if [[ -z "$has_liveness" || "$has_liveness" == "null" ]]; then
        echo "- ‚úÖ **Add liveness probe:** Implement health checking for automatic restart" >> "$rec_file"
    fi
    
    if [[ -z "$has_readiness" || "$has_readiness" == "null" ]]; then
        echo "- ‚úÖ **Add readiness probe:** Control traffic routing based on application readiness" >> "$rec_file"
    fi
    
    # Performance recommendations
    echo "" >> "$rec_file"
    echo "## Performance Optimization" >> "$rec_file"
    cat >> "$rec_file" <<EOF
- ‚úÖ **Use Alpine images:** Reduce image size and startup time
- ‚úÖ **Implement resource requests:** Help scheduler make better placement decisions
- ‚úÖ **Optimize health check frequency:** Balance responsiveness with overhead
- ‚úÖ **Use memory-backed volumes:** For temporary files and caches
- ‚úÖ **Configure DNS caching:** Reduce DNS lookup overhead

EOF
    
    log_success "Recommendations generated for $pod_name"
}

# Interactive diagnostic session
interactive_diagnostics() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Starting interactive diagnostics for $pod_name..."
    
    echo -e "${BOLD}Interactive Pod Diagnostics${NC}"
    echo "Pod: $pod_name"
    echo "Namespace: $namespace"
    echo ""
    
    while true; do
        echo -e "${CYAN}Available actions:${NC}"
        echo "1) Show pod status"
        echo "2) View recent events"
        echo "3) Check container logs"
        echo "4) Execute command in pod"
        echo "5) Port forward to pod"
        echo "6) Resource usage"
        echo "7) Run full diagnostic"
        echo "8) Generate recommendations"
        echo "q) Quit"
        echo ""
        
        read -p "Select action [1-8,q]: " choice
        
        case $choice in
            1)
                echo "=== Pod Status ==="
                kubectl get pod "$pod_name" -n "$namespace" -o wide
```" \
        5
    
    echo ""
    echo "üìä Observability"
    echo "---------------"
    
    check_item "Structured logging (JSON format)" \
        "kubectl logs $pod_name -n $namespace --tail=5 | head -1 | grep -q '^{'" \
        10
    
    check_item "Metrics endpoint available" \
        "kubectl get pod $pod_name -n $namespace -o jsonpath='{.metadata.annotations}' | grep -q prometheus" \
        10
    
    echo ""
    echo "üéØ Final Score"
    echo "============="
    
    local percentage=$((score * 100 / max_score))
    echo "Score: $score/$max_score ($percentage%)"
    
    if [[ $percentage -ge 90 ]]; then
        echo "üü¢ EXCELLENT - Production ready!"
    elif [[ $percentage -ge 75 ]]; then
        echo "üü° GOOD - Minor improvements needed"
    elif [[ $percentage -ge 50 ]]; then
        echo "üü† FAIR - Significant improvements required"
    else
        echo "üî¥ POOR - Major changes needed before production"
    fi
    
    echo ""
    echo "üí° Recommendations:"
    if [[ $percentage -lt 90 ]]; then
        echo "- Implement missing security controls"
        echo "- Add comprehensive health checks"
        echo "- Define proper resource requests and limits"
        echo "- Improve metadata and labeling"
        echo "- Enhance observability features"
    else
        echo "- Maintain current excellent standards"
        echo "- Consider advanced features like startup probes"
        echo "- Implement comprehensive monitoring"
    fi
}

# Export function
export -f check_production_readiness
```

## üéâ Conclusion

This enhanced guide has taken you on a comprehensive journey through pod management in Kubernetes, from basic concepts to expert-level practices. The examples, demos, and mini-projects provided here represent real-world scenarios and battle-tested patterns that you can immediately apply in your own environments.

### Key Achievements

By working through this guide, you've gained:

- **Foundational Knowledge**: Understanding of pod lifecycle, creation patterns, and basic management
- **Practical Skills**: Hands-on experience with debugging, monitoring, and optimization
- **Advanced Techniques**: Custom tooling, automation, and production-ready configurations
- **Expert Insights**: Comprehensive diagnostics, performance tuning, and security hardening

### The Path Forward

Pod management is the gateway to mastering Kubernetes. The skills you've developed here will serve as the foundation for:

- **Higher-Level Controllers**: Deployments, StatefulSets, DaemonSets, and Jobs
- **Service Mesh Integration**: Istio, Linkerd, and other mesh technologies
- **Advanced Networking**: Network policies, ingress controllers, and service discovery
- **Security Frameworks**: Pod Security Standards, admission controllers, and compliance
- **Observability Platforms**: Prometheus, Grafana, Jaeger, and comprehensive monitoring
- **GitOps Workflows**: ArgoCD, Flux, and automated deployment pipelines

Remember that Kubernetes is constantly evolving, and the best practices in this guide will continue to develop. Stay engaged with the community, experiment with new features, and always prioritize security, reliability, and maintainability in your pod configurations.

The time you've invested in mastering pod management will pay dividends throughout your entire Kubernetes journey. Whether you're troubleshooting a midnight outage, optimizing performance for a high-traffic application, or designing the architecture for a new microservice, the deep understanding you've built here will guide your decisions and help you create robust, efficient solutions.

Keep practicing, keep learning, and most importantly, keep sharing your knowledge with others in the Kubernetes community! üöÄ
                kubectl describe pod "$pod_name" -n "$namespace" | grep -A 10 "Status\|Conditions"
                ;;
            2)
                echo "=== Recent Events ==="
                kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
                    --sort-by='.lastTimestamp' | tail -10
                ;;
            3)
                echo "=== Container Selection ==="
                local containers=($(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}'))
                if [[ ${#containers[@]} -eq 1 ]]; then
                    echo "Showing logs for container: ${containers[0]}"
                    kubectl logs "$pod_name" -n "$namespace" --tail=50
                else
                    echo "Available containers:"
                    for i in "${!containers[@]}"; do
                        echo "$((i+1))) ${containers[i]}"
                    done
                    read -p "Select container [1-${#containers[@]}]: " container_choice
                    if [[ $container_choice -ge 1 && $container_choice -le ${#containers[@]} ]]; then
                        local selected_container=${containers[$((container_choice-1))]}
                        echo "Showing logs for container: $selected_container"
                        kubectl logs "$pod_name" -n "$namespace" -c "$selected_container" --tail=50
                    fi
                fi
                ;;
            4)
                read -p "Enter command to execute: " exec_command
                kubectl exec -it "$pod_name" -n "$namespace" -- $exec_command
                ;;
            5)
                read -p "Enter local port: " local_port
                read -p "Enter pod port: " pod_port
                echo "Port forwarding $local_port:$pod_port - Press Ctrl+C to stop"
                kubectl port-forward "$pod_name" -n "$namespace" "$local_port:$pod_port"
                ;;
            6)
                echo "=== Resource Usage ==="
                kubectl top pod "$pod_name" -n "$namespace" 2>/dev/null || echo "Metrics not available"
                ;;
            7)
                gather_pod_info "$pod_name" "$namespace"
                detect_common_issues "$pod_name" "$namespace"
                generate_recommendations "$pod_name" "$namespace"
                echo "Full diagnostic completed. Check $OUTPUT_DIR/pods/$pod_name/"
                ;;
            8)
                generate_recommendations "$pod_name" "$namespace"
                echo "Recommendations generated. Check $OUTPUT_DIR/pods/$pod_name/recommendations.md"
                ;;
            q|Q)
                log_info "Exiting interactive diagnostics"
                break
                ;;
            *)
                echo "Invalid choice. Please try again."
                ;;
        esac
        
        echo ""
        read -p "Press Enter to continue..."
        echo ""
    done
}

# Cluster-wide pod health assessment
cluster_health_assessment() {
    log_info "Running cluster-wide pod health assessment..."
    
    local health_report="$OUTPUT_DIR/cluster_health_report.md"
    
    cat > "$health_report" <<EOF
# Cluster Pod Health Assessment

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)

---

EOF
    
    # Get all namespaces
    local namespaces=($(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'))
    
    local total_pods=0
    local healthy_pods=0
    local unhealthy_pods=0
    
    for ns in "${namespaces[@]}"; do
        log_info "Assessing namespace: $ns"
        
        local pods=($(kubectl get pods -n "$ns" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null))
        
        if [[ ${#pods[@]} -eq 0 ]]; then
            continue
        fi
        
        echo "## Namespace: $ns" >> "$health_report"
        echo "" >> "$health_report"
        
        local ns_healthy=0
        local ns_unhealthy=0
        
        for pod in "${pods[@]}"; do
            ((total_pods++))
            
            local phase=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.phase}')
            local ready_condition=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
            local restarts=$(kubectl get pod "$pod" -n "$ns" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
            
            if [[ "$phase" == "Running" && "$ready_condition" == "True" && $restarts -lt 5 ]]; then
                ((healthy_pods++))
                ((ns_healthy++))
                echo "‚úÖ **$pod** - Healthy" >> "$health_report"
            else
                ((unhealthy_pods++))
                ((ns_unhealthy++))
                echo "‚ùå **$pod** - Issues detected (Phase: $phase, Ready: $ready_condition, Restarts: $restarts)" >> "$health_report"
                
                # Run quick diagnostics for unhealthy pods
                gather_pod_info "$pod" "$ns"
                detect_common_issues "$pod" "$ns"
            fi
        done
        
        echo "" >> "$health_report"
        echo "**Namespace Summary:** $ns_healthy healthy, $ns_unhealthy unhealthy" >> "$health_report"
        echo "" >> "$health_report"
    done
    
    # Overall summary
    local health_percentage=$((healthy_pods * 100 / total_pods))
    
    cat >> "$health_report" <<EOF

---

## Overall Cluster Health

- **Total Pods:** $total_pods
- **Healthy Pods:** $healthy_pods
- **Unhealthy Pods:** $unhealthy_pods
- **Health Percentage:** $health_percentage%

### Health Status
EOF
    
    if [[ $health_percentage -ge 90 ]]; then
        echo "üü¢ **EXCELLENT** - Cluster is in excellent health" >> "$health_report"
    elif [[ $health_percentage -ge 75 ]]; then
        echo "üü° **GOOD** - Cluster is in good health with minor issues" >> "$health_report"
    elif [[ $health_percentage -ge 50 ]]; then
        echo "üü† **WARNING** - Cluster has significant health issues" >> "$health_report"
    else
        echo "üî¥ **CRITICAL** - Cluster is in critical condition" >> "$health_report"
    fi
    
    log_success "Cluster health assessment completed. Report: $health_report"
}

# Generate comprehensive diagnostic report
generate_final_report() {
    log_info "Generating comprehensive diagnostic report..."
    
    local final_report="$OUTPUT_DIR/comprehensive_report.html"
    
    cat > "$final_report" <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Pod Diagnostics Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
        .header { background-color: #f4f4f4; padding: 20px; border-radius: 5px; margin-bottom: 30px; }
        .section { margin: 30px 0; }
        .pod-card { border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin: 10px 0; }
        .healthy { border-left: 5px solid #28a745; }
        .unhealthy { border-left: 5px solid #dc3545; }
        .warning { border-left: 5px solid #ffc107; }
        .metric { display: inline-block; margin: 10px 15px 10px 0; padding: 8px 12px; background-color: #e9ecef; border-radius: 3px; }
        .issue { background-color: #fff3cd; padding: 10px; border-radius: 3px; margin: 10px 0; }
        pre { background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }
        .tabs { border-bottom: 1px solid #ddd; margin-bottom: 20px; }
        .tab { display: inline-block; padding: 10px 20px; cursor: pointer; border-bottom: 2px solid transparent; }
        .tab.active { border-bottom-color: #007bff; color: #007bff; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }
    </style>
    <script>
        function showTab(tabName) {
            // Hide all tab contents
            var contents = document.getElementsByClassName('tab-content');
            for (var i = 0; i < contents.length; i++) {
                contents[i].classList.remove('active');
            }
            
            // Remove active class from all tabs
            var tabs = document.getElementsByClassName('tab');
            for (var i = 0; i < tabs.length; i++) {
                tabs[i].classList.remove('active');
            }
            
            // Show selected tab content and mark tab as active
            document.getElementById(tabName).classList.add('active');
            event.target.classList.add('active');
        }
    </script>
</head>
<body>
    <div class="header">
        <h1>üîç Pod Diagnostics Report</h1>
        <div class="metric">
            <strong>Generated:</strong> $(date)
        </div>
        <div class="metric">
            <strong>Cluster:</strong> $(kubectl config current-context)
        </div>
        <div class="metric">
            <strong>Diagnostics Version:</strong> 2.0
        </div>
    </div>
    
    <div class="tabs">
        <div class="tab active" onclick="showTab('overview')">Overview</div>
        <div class="tab" onclick="showTab('pods')">Pod Analysis</div>
        <div class="tab" onclick="showTab('issues')">Detected Issues</div>
        <div class="tab" onclick="showTab('recommendations')">Recommendations</div>
    </div>
    
    <div id="overview" class="tab-content active">
        <h2>üìä Cluster Overview</h2>
        <div class="section">
EOF
    
    # Add cluster metrics
    local total_nodes=$(kubectl get nodes --no-headers | wc -l)
    local ready_nodes=$(kubectl get nodes --no-headers | grep " Ready " | wc -l)
    local total_namespaces=$(kubectl get namespaces --no-headers | wc -l)
    
    cat >> "$final_report" <<EOF
            <div class="pod-card healthy">
                <h3>Cluster Metrics</h3>
                <div class="metric"><strong>Nodes:</strong> $ready_nodes/$total_nodes Ready</div>
                <div class="metric"><strong>Namespaces:</strong> $total_namespaces</div>
                <div class="metric"><strong>Kubernetes Version:</strong> $(kubectl version --short --client | cut -d' ' -f3)</div>
            </div>
        </div>
    </div>
    
    <div id="pods" class="tab-content">
        <h2>üöÄ Pod Analysis</h2>
EOF
    
    # Add pod analysis for each analyzed pod
    for pod_dir in "$OUTPUT_DIR"/pods/*/; do
        if [[ -d "$pod_dir" ]]; then
            local pod_name=$(basename "$pod_dir")
            local issues_count=0
            
            if [[ -f "$pod_dir/detected_issues.md" ]]; then
                issues_count=$(grep -c "## Issue" "$pod_dir/detected_issues.md" 2>/dev/null || echo "0")
            fi
            
            local card_class="healthy"
            if [[ $issues_count -gt 0 ]]; then
                card_class="unhealthy"
            fi
            
            cat >> "$final_report" <<EOF
        <div class="pod-card $card_class">
            <h3>üì¶ $pod_name</h3>
            <div class="metric"><strong>Issues Detected:</strong> $issues_count</div>
            <div class="metric"><strong>Analysis Files:</strong> $(ls "$pod_dir" | wc -l)</div>
            <div class="metric"><strong>Report Location:</strong> pods/$pod_name/</div>
        </div>
EOF
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="issues" class="tab-content">
        <h2>‚ö†Ô∏è Detected Issues</h2>
EOF
    
    # Aggregate all issues
    local total_issues=0
    for issues_file in "$OUTPUT_DIR"/pods/*/detected_issues.md; do
        if [[ -f "$issues_file" ]]; then
            local pod_issues=$(grep -c "## Issue" "$issues_file" 2>/dev/null || echo "0")
            ((total_issues += pod_issues))
            
            if [[ $pod_issues -gt 0 ]]; then
                local pod_name=$(basename "$(dirname "$issues_file")")
                echo "<h3>Issues for $pod_name</h3>" >> "$final_report"
                
                # Convert markdown issues to HTML
                grep "## Issue" "$issues_file" | while read -r line; do
                    echo "<div class=\"issue\">$line</div>" >> "$final_report"
                done
            fi
        fi
    done
    
    if [[ $total_issues -eq 0 ]]; then
        echo "<div class=\"pod-card healthy\"><h3>‚úÖ No Issues Detected</h3><p>All analyzed pods appear to be healthy!</p></div>" >> "$final_report"
    fi
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div id="recommendations" class="tab-content">
        <h2>üí° Recommendations</h2>
        <div class="section">
            <div class="pod-card warning">
                <h3>General Recommendations</h3>
                <ul>
                    <li>‚úÖ Implement comprehensive health checks for all pods</li>
                    <li>‚úÖ Set appropriate resource requests and limits</li>
                    <li>‚úÖ Use security contexts to harden pod security</li>
                    <li>‚úÖ Monitor resource usage and optimize accordingly</li>
                    <li>‚úÖ Implement graceful shutdown handling</li>
                    <li>‚úÖ Use multi-stage Docker builds for smaller images</li>
                    <li>‚úÖ Implement proper logging and observability</li>
                </ul>
            </div>
        </div>
EOF
    
    # Add pod-specific recommendations
    for rec_file in "$OUTPUT_DIR"/pods/*/recommendations.md; do
        if [[ -f "$rec_file" ]]; then
            local pod_name=$(basename "$(dirname "$rec_file")")
            echo "<div class=\"pod-card\"><h3>Recommendations for $pod_name</h3>" >> "$final_report"
            echo "<p>See detailed recommendations in: pods/$pod_name/recommendations.md</p></div>" >> "$final_report"
        fi
    done
    
    cat >> "$final_report" <<EOF
    </div>
    
    <div class="section">
        <hr>
        <p><em>Report generated by Pod Diagnostics Toolkit v2.0</em></p>
        <p><em>For detailed analysis, check individual files in the diagnostics output directory.</em></p>
    </div>
    
</body>
</html>
EOF
    
    log_success "Comprehensive report generated: $final_report"
    echo ""
    echo -e "${BOLD}üìã Diagnostic Summary:${NC}"
    echo "- Output Directory: $OUTPUT_DIR"
    echo "- HTML Report: $final_report"
    echo "- Total Issues Found: $total_issues"
    echo ""
    echo -e "${CYAN}üí° Next Steps:${NC}"
    echo "1. Open $final_report in your browser"
    echo "2. Review individual pod analysis in $OUTPUT_DIR/pods/"
    echo "3. Implement recommended fixes"
    echo "4. Re-run diagnostics to verify improvements"
}

# Main execution function
main() {
    local command=${1:-help}
    local pod_name=${2:-}
    local namespace=${3:-$NAMESPACE}
    
    case "$command" in
        "analyze")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for analysis"
                echo "Usage: $0 analyze <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            gather_pod_info "$pod_name" "$namespace"
            detect_common_issues "$pod_name" "$namespace"
            generate_recommendations "$pod_name" "$namespace"
            generate_final_report
            ;;
            
        "interactive")
            if [[ -z "$pod_name" ]]; then
                log_error "Pod name required for interactive mode"
                echo "Usage: $0 interactive <pod-name> [namespace]"
                exit 1
            fi
            
            init_diagnostics
            interactive_diagnostics "$pod_name" "$namespace"
            ;;
            
        "cluster-health")
            init_diagnostics
            cluster_health_assessment
            generate_final_report
            ;;
            
        "help"|*)
            cat <<EOF
üîç Advanced Pod Diagnostics Toolkit

Usage: $0 <command> [options]

Commands:
  analyze <pod-name> [namespace]     - Run comprehensive pod analysis
  interactive <pod-name> [namespace] - Start interactive diagnostic session
  cluster-health                     - Assess health of all pods in cluster
  help                              - Show this help message

Environment Variables:
  NAMESPACE - Default namespace (default: default)
  VERBOSE   - Enable verbose output (default: false)

Examples:
  $0 analyze nginx-pod production
  $0 interactive web-app-123
  $0 cluster-health
  VERBOSE=true $0 analyze problematic-pod

Output:
  All diagnostic data is saved to ./diagnostics-TIMESTAMP/
  HTML report provides comprehensive overview
  Individual pod analysis available in pods/ subdirectory

EOF
            ;;
    esac
}

# Execute main function
main "$@"
```

---

## Summary and Production-Ready Examples

### üèÜ Complete Production Workflow

Let's create a final comprehensive example that brings everything together:

```yaml
# complete-production-workflow.yaml
# This represents a complete production-ready pod deployment workflow

apiVersion: v1
kind: Namespace
metadata:
  name: production-workload
  labels:
    environment: production
    team: platform
---
# ConfigMap for application configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production-workload
data:
  app.properties: |
    server.port=8080
    management.port=8081
    logging.level=INFO
    metrics.enabled=true
  nginx.conf: |
    server {
        listen 80;
        location /health { return 200 'healthy\n'; }
        location /ready { return 200 'ready\n'; }
        location / {
            proxy_pass http://127.0.0.1:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
---
# Secret for sensitive configuration
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: production-workload
type: Opaque
data:
  database-password: c3VwZXJzZWNyZXQ=  # supersecret (base64)
  api-key: YWJjZGVmZ2hpams=  # abcdefghijk (base64)
---
# Production-ready pod with all best practices
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production-workload
  labels:
    app: production-app
    version: "2.1.0"
    environment: production
    team: platform
    component: backend
  annotations:
    description: "Production application with full observability"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/production-app"
    prometheus.io/scrape: "true"
    prometheus.io/port: "8081"
    prometheus.io/path: "/metrics"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Resource constraints and node placement
  nodeSelector:
    node-type: "application"
    performance-tier: "high"
    
  tolerations:
  - key: "dedicated-app"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
    
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: production-app
        topologyKey: kubernetes.io/hostname
        
  # DNS and network configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  # Init container for setup tasks
  initContainers:
  - name: setup
    image: busybox:1.35
    command:
    - /bin/sh
    - -c
    - |
      echo "Initializing application..."
      
      # Database migration simulation
      echo "Running database migrations..."
      sleep 5
      
      # Cache warming
      echo "Warming up caches..."
      sleep 3
      
      # Configuration validation
      echo "Validating configuration..."
      if [ -f /config/app.properties ]; then
        echo "‚úÖ Configuration file found"
      else
        echo "‚ùå Configuration file missing"
        exit 1
      fi
      
      echo "Initialization completed successfully"
      
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-init
      mountPath: /tmp
      
  # Main application containers
  containers:
  # Application container
  - name: app
    image: openjdk:11-jre-slim
    command:
    - /bin/bash
    - -c
    - |
      echo "Starting application..."
      
      # Simulated application startup
      java -Xmx200m -Xms100m -jar /app/application.jar \
        --spring.config.location=file:/config/app.properties \
        --server.port=8080 \
        --management.server.port=8081
        
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP
    - name: management
      containerPort: 8081
      protocol: TCP
      
    # Environment configuration
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # Sensitive configuration from secrets
    - name: DATABASE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: database-password
    - name: API_KEY
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: api-key
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security hardening
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    # Comprehensive health checks
    livenessProbe:
      httpGet:
        path: /actuator/health/liveness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /actuator/health/readiness
        port: 8081
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /actuator/health
        port: 8081
      initialDelaySeconds: 20
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle management
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Application started at $(date)" >> /tmp/startup.log
            # Custom post-start logic here
            
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "Graceful shutdown initiated at $(date)" >> /tmp/shutdown.log
            # Send SIGTERM to application
            kill -TERM 1
            # Wait for graceful shutdown
            sleep 30
            
    # Volume mounts
    volumeMounts:
    - name: config-volume
      mountPath: /config
      readOnly: true
    - name: tmp-volume
      mountPath: /tmp
    - name: app-logs
      mountPath: /app/logs
    - name: app-data
      mountPath: /app/data
      
  # Nginx reverse proxy sidecar
  - name: nginx-proxy
    image: nginx:1.21-alpine
    ports:
    - name: http-proxy
      containerPort: 80
      protocol: TCP
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        add: ["NET_BIND_SERVICE"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: nginx-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
      
  # Logging and monitoring sidecar
  - name: log-shipper
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: fluent-tmp
      mountPath: /tmp
      
  # Volumes
  volumes:
  - name: config-volume
    configMap:
      name: app-config
      items:
      - key: app.properties
        path: app.properties
  - name: nginx-config
    configMap:
      name: app-config
      items:
      - key: nginx.conf
        path: default.conf
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config  # Would be created separately
  # Temporary and cache volumes
  - name: tmp-volume
    emptyDir:
      sizeLimit: 256Mi
  - name: tmp-init
    emptyDir:
      sizeLimit: 64Mi
  - name: nginx-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: fluent-tmp
    emptyDir:
      sizeLimit: 32Mi
  - name: nginx-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: nginx-run
    emptyDir:
      sizeLimit: 32Mi
  # Application data volumes
  - name: app-logs
    emptyDir:
      sizeLimit: 1Gi
  - name: app-data
    emptyDir:
      sizeLimit: 2Gi
```

This comprehensive example demonstrates:

- **Complete security hardening** with proper contexts and capabilities
- **Multi-container architecture** with main app, proxy, and logging sidecars
- **Comprehensive health checks** for all containers
- **Resource optimization** with appropriate requests and limits
- **Configuration management** using ConfigMaps and Secrets
- **Observability** with structured logging and metrics endpoints
- **Production-ready networking** with reverse proxy
- **Graceful lifecycle management** with init containers and shutdown hooks

## üéì Key Learning Outcomes

By working through these enhanced examples, demos, and mini-projects, you've gained:

1. **Foundation Skills**: Basic pod creation, inspection, and management
2. **Intermediate Capabilities**: Multi-container patterns, health monitoring, and debugging
3. **Advanced Techniques**: Performance optimization, security hardening, and automation
4. **Expert-Level Mastery**: Custom controllers, comprehensive diagnostics, and production workflows

### üöÄ Next Steps for Continued Learning

1. **Practice the Examples**: Work through each example in your own cluster
2. **Customize for Your Use Cases**: Adapt the patterns to your specific applications
3. **Build Your Toolkit**: Create your own diagnostic and management scripts
4. **Share and Learn**: Contribute back to the community with your own improvements
5. **Scale Up**: Apply these pod management skills to higher-level controllers

The journey from basic pod creation to# 5. Working with Pods - From Fundamentals to Mastery (Enhanced Edition)

Understanding how to work with pods effectively forms the foundation of all Kubernetes operations. While you'll typically use higher-level controllers like Deployments in production environments, direct pod management skills are essential for debugging, troubleshooting, and truly understanding how Kubernetes applications function at their core. Think of this knowledge as learning to drive a manual transmission car‚Äîeven if you usually drive automatic, understanding the underlying mechanics makes you a better driver overall.

This enhanced guide provides progressive examples, hands-on demos, and real-world mini-projects to solidify your understanding through practical application.

## üéØ Learning Path Overview

- **Foundation Level**: Basic pod creation and inspection
- **Intermediate Level**: Multi-container patterns and health checks
- **Advanced Level**: Complex debugging and optimization
- **Expert Level**: Custom tooling and automation

---

## Understanding Pod Creation Strategies

Creating pods effectively requires understanding when to use imperative commands versus declarative configurations, and how different creation approaches serve different purposes.

### üìö Foundation Examples

Let's start with the absolute basics and progressively build complexity.

#### Example 1: Your First Pod
```bash
# Create the simplest possible pod
kubectl run hello-world --image=nginx --restart=Never

# Verify it's running
kubectl get pods

# Expected output:
# NAME          READY   STATUS    RESTARTS   AGE
# hello-world   1/1     Running   0          30s
```

#### Example 2: Pod with Custom Commands
```bash
# Create a pod that runs a custom command
kubectl run date-pod --image=busybox --restart=Never -- date

# This pod will run the date command and then exit
# Check the output
kubectl logs date-pod

# Clean up
kubectl delete pod date-pod
```

#### Example 3: Interactive Pod Session
```bash
# Create an interactive debugging pod
kubectl run -it debug-pod --image=busybox --restart=Never -- sh

# Inside the pod, try these commands:
# ls -la
# ps aux
# ping google.com
# nslookup kubernetes.default.svc.cluster.local

# Exit and clean up
# exit
kubectl delete pod debug-pod
```

### üõ†Ô∏è Demo: Pod Lifecycle Observation

Let's create a demo that shows the complete pod lifecycle in action:

```bash
#!/bin/bash
# pod-lifecycle-demo.sh

echo "=== Pod Lifecycle Demonstration ==="

# Terminal 1: Start watching pods
echo "In a separate terminal, run: kubectl get pods -w"
echo "Press Enter when ready..."
read

# Create a pod with a slow-starting application
echo "Creating pod with slow startup..."
kubectl run lifecycle-demo --image=nginx --restart=Never \
  --dry-run=client -o yaml > lifecycle-pod.yaml

# Add some customizations to make it more interesting
cat <<EOF >> lifecycle-pod.yaml
  containers:
  - name: nginx
    image: nginx:1.21
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod starting up...' && sleep 10"
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - "echo 'Pod shutting down...' && sleep 5"
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 5
EOF

echo "Applying pod configuration..."
kubectl apply -f lifecycle-pod.yaml

echo "Watch the pod states change from Pending -> ContainerCreating -> Running"
echo "Press Enter to continue when pod is Running..."
read

# Show detailed pod information
echo "=== Pod Details ==="
kubectl describe pod lifecycle-demo

echo "Press Enter to delete the pod and observe termination..."
read

# Delete and watch termination
kubectl delete pod lifecycle-demo

echo "Demo complete! Clean up the YAML file:"
echo "rm lifecycle-pod.yaml"
```

### üéØ Mini-Project 1: Pod Resource Monitor

Create a simple monitoring system using pods:

```yaml
# resource-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-monitor
  labels:
    app: monitor
    type: demo
spec:
  containers:
  - name: monitor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Starting Resource Monitor..."
      while true; do
        echo "=== $(date) ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "Load average:"
        uptime
        echo "Sleeping for 30 seconds..."
        sleep 30
      done
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
  restartPolicy: Always
```

```bash
# Deploy and monitor
kubectl apply -f resource-monitor-pod.yaml

# Watch the logs
kubectl logs -f resource-monitor

# In another terminal, check resource usage
kubectl top pod resource-monitor

# Clean up
kubectl delete -f resource-monitor-pod.yaml
```

---

## Deep Pod Inspection and Monitoring

### üîç Intermediate Examples

#### Example 4: Multi-Container Pod Investigation

```yaml
# multi-container-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-demo
  labels:
    demo: multi-container
spec:
  containers:
  - name: web-server
    image: nginx:1.21
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
    
  - name: log-processor
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Log processor starting..."
      while true; do
        if [ -f /var/log/nginx/access.log ]; then
          echo "=== Access Log Summary $(date) ==="
          tail -10 /var/log/nginx/access.log | wc -l
          echo "Recent requests:"
          tail -5 /var/log/nginx/access.log
        else
          echo "Waiting for access.log..."
        fi
        sleep 30
      done
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
      
  - name: metrics-collector
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Metrics collector starting..."
      while true; do
        echo "=== Metrics $(date) ==="
        echo "Container count: 3"
        echo "Uptime: $(uptime)"
        echo "Memory: $(free -h | grep Mem)"
        sleep 60
      done
      
  volumes:
  - name: shared-logs
    emptyDir: {}
```

**Inspection Commands:**
```bash
# Apply the multi-container pod
kubectl apply -f multi-container-demo.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/multi-container-demo

# Inspect different aspects
echo "=== Basic Information ==="
kubectl get pod multi-container-demo -o wide

echo "=== Container Status ==="
kubectl get pod multi-container-demo -o jsonpath='{.status.containerStatuses[*].name}' | tr ' ' '\n'

echo "=== Logs from each container ==="
kubectl logs multi-container-demo -c web-server --tail=5
kubectl logs multi-container-demo -c log-processor --tail=5
kubectl logs multi-container-demo -c metrics-collector --tail=5

# Generate some traffic to see shared volume in action
kubectl port-forward multi-container-demo 8080:80 &
PF_PID=$!

# Generate requests
for i in {1..10}; do
  curl -s http://localhost:8080 > /dev/null
  echo "Request $i sent"
  sleep 1
done

kill $PF_PID

# Check log processor output
kubectl logs multi-container-demo -c log-processor --tail=10

# Clean up
kubectl delete -f multi-container-demo.yaml
```

### üõ†Ô∏è Demo: Advanced Pod Debugging Techniques

```bash
#!/bin/bash
# advanced-debugging-demo.sh

echo "=== Advanced Pod Debugging Demo ==="

# Create a problematic pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: problematic-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "2000m"  # This might cause scheduling issues
      limits:
        memory: "512Mi"  # Less than request - invalid!
        cpu: "500m"
    livenessProbe:
      httpGet:
        path: /nonexistent
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
EOF

echo "Created a pod with multiple issues. Let's debug it..."

# Wait a moment for issues to manifest
sleep 10

echo "=== Debugging Steps ==="

echo "1. Check pod status:"
kubectl get pod problematic-pod -o wide

echo "2. Look at events:"
kubectl describe pod problematic-pod | grep -A 10 Events:

echo "3. Check for resource issues:"
kubectl describe pod problematic-pod | grep -A 5 -B 5 "resource"

echo "4. Examine container status:"
kubectl get pod problematic-pod -o jsonpath='{.status.containerStatuses[0]}' | jq '.'

# Fix the pod
echo "5. Let's fix the issues..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: fixed-pod
  labels:
    debug: demo
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 30
EOF

echo "6. Compare the fixed pod:"
kubectl wait --for=condition=Ready pod/fixed-pod --timeout=60s
kubectl get pods -l debug=demo

# Clean up
echo "Cleaning up..."
kubectl delete pod problematic-pod fixed-pod
```

### üéØ Mini-Project 2: Pod Health Monitoring Dashboard

Create a comprehensive health monitoring system:

```yaml
# health-monitor-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: health-dashboard
  labels:
    app: health-monitor
spec:
  containers:
  - name: health-checker
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Health Dashboard Starting..."
      
      # Create a simple HTML dashboard
      mkdir -p /tmp/dashboard
      
      while true; do
        cat > /tmp/dashboard/health.html <<EOF
      <!DOCTYPE html>
      <html>
      <head>
          <title>Pod Health Dashboard</title>
          <meta http-equiv="refresh" content="30">
          <style>
              body { font-family: Arial, sans-serif; margin: 40px; }
              .healthy { color: green; }
              .warning { color: orange; }
              .critical { color: red; }
              .metric { margin: 10px 0; padding: 10px; border: 1px solid #ccc; }
          </style>
      </head>
      <body>
          <h1>Pod Health Dashboard</h1>
          <p>Last Update: $(date)</p>
          
          <div class="metric">
              <h3>System Load</h3>
              <p>$(uptime)</p>
          </div>
          
          <div class="metric">
              <h3>Memory Usage</h3>
              <pre>$(free -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Disk Usage</h3>
              <pre>$(df -h)</pre>
          </div>
          
          <div class="metric">
              <h3>Process Count</h3>
              <p>Running processes: $(ps aux | wc -l)</p>
          </div>
          
      </body>
      </html>
      EOF
        
        echo "Dashboard updated at $(date)"
        sleep 30
      done
    volumeMounts:
    - name: dashboard-storage
      mountPath: /tmp/dashboard
      
  - name: web-server
    image: nginx:alpine
    ports:
    - containerPort: 80
    command:
    - /bin/sh
    - -c
    - |
      # Configure nginx to serve our dashboard
      cat > /etc/nginx/conf.d/default.conf <<EOF
      server {
          listen 80;
          location / {
              root /usr/share/nginx/html;
              index health.html;
          }
      }
      EOF
      
      # Start nginx
      nginx -g "daemon off;"
    volumeMounts:
    - name: dashboard-storage
      mountPath: /usr/share/nginx/html
      
  volumes:
  - name: dashboard-storage
    emptyDir: {}
    
  restartPolicy: Always
```

**Usage:**
```bash
# Deploy the health dashboard
kubectl apply -f health-monitor-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/health-dashboard

# Access the dashboard
kubectl port-forward health-dashboard 8080:80

# Open browser to http://localhost:8080
echo "Open http://localhost:8080 in your browser"

# Monitor the pod's own health
kubectl top pod health-dashboard

# Check logs from both containers
kubectl logs health-dashboard -c health-checker --tail=10
kubectl logs health-dashboard -c web-server --tail=10

# Clean up
kubectl delete -f health-monitor-pod.yaml
```

---

## Interactive Pod Management and Debugging

### üîß Advanced Examples

#### Example 5: Network Debugging Pod

```yaml
# network-debug-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: network-debugger
  labels:
    purpose: network-debug
spec:
  containers:
  - name: nettools
    image: nicolaka/netshoot
    command: ["/bin/bash"]
    args:
    - -c
    - |
      echo "Network debugging tools ready!"
      echo "Available tools: dig, nslookup, ping, curl, wget, tcpdump, netstat"
      echo "Example commands:"
      echo "  dig kubernetes.default.svc.cluster.local"
      echo "  ping 8.8.8.8"
      echo "  curl -I http://httpbin.org/headers"
      echo "  netstat -tulpn"
      
      # Keep container running
      sleep 3600
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
  restartPolicy: Never
```

**Debugging Session:**
```bash
# Deploy the network debugger
kubectl apply -f network-debug-pod.yaml

# Wait for it to be ready
kubectl wait --for=condition=Ready pod/network-debugger

# Start interactive session
kubectl exec -it network-debugger -- bash

# Inside the pod, run network diagnostics:
# Test DNS resolution
# dig kubernetes.default.svc.cluster.local

# Test external connectivity
# ping -c 3 8.8.8.8

# Test HTTP services
# curl -I https://httpbin.org/headers

# Check network interfaces
# ip addr show

# Check routing table
# ip route show

# Test service discovery
# nslookup kubernetes.default

# Exit and clean up
# exit
kubectl delete -f network-debug-pod.yaml
```

### üõ†Ô∏è Demo: File Transfer and Volume Management

```bash
#!/bin/bash
# file-transfer-demo.sh

echo "=== File Transfer and Volume Demo ==="

# Create a pod with persistent data
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: file-demo
spec:
  containers:
  - name: app
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Creating sample files..."
      mkdir -p /data/logs /data/config
      
      # Generate some sample data
      for i in {1..5}; do
        echo "Log entry \$i at \$(date)" >> /data/logs/app.log
        sleep 1
      done
      
      echo "app_name=demo-app" > /data/config/settings.conf
      echo "version=1.0.0" >> /data/config/settings.conf
      echo "debug=true" >> /data/config/settings.conf
      
      echo "Files created. Keeping container running..."
      sleep 3600
    volumeMounts:
    - name: data-storage
      mountPath: /data
  volumes:
  - name: data-storage
    emptyDir: {}
EOF

echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/file-demo

# Demonstrate file operations
echo "=== File Operations Demo ==="

echo "1. List files in the pod:"
kubectl exec file-demo -- find /data -type f

echo "2. Copy file from pod to local:"
kubectl cp file-demo:/data/logs/app.log ./app.log.backup
echo "File copied to: app.log.backup"
cat app.log.backup

echo "3. Create local config file:"
cat > new-config.conf <<EOF
app_name=updated-demo-app
version=2.0.0
debug=false
environment=production
EOF

echo "4. Copy local file to pod:"
kubectl cp new-config.conf file-demo:/data/config/

echo "5. Verify file in pod:"
kubectl exec file-demo -- cat /data/config/new-config.conf

echo "6. Create a backup of all data:"
kubectl exec file-demo -- tar -czf /tmp/backup.tar.gz -C /data .
kubectl cp file-demo:/tmp/backup.tar.gz ./pod-data-backup.tar.gz
echo "Backup created: pod-data-backup.tar.gz"

# Clean up
echo "Cleaning up..."
kubectl delete pod file-demo
rm -f app.log.backup new-config.conf pod-data-backup.tar.gz

echo "Demo complete!"
```

### üéØ Mini-Project 3: Pod Security Scanner

Create a security scanning tool using pods:

```yaml
# security-scanner-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-scanner
  labels:
    app: security
    type: scanner
spec:
  serviceAccountName: default
  containers:
  - name: scanner
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "=== Pod Security Scanner Starting ==="
      
      # Function to check security configurations
      check_security() {
        echo "Checking security configurations..."
        
        # Check if running as root
        if [ "$(id -u)" -eq 0 ]; then
          echo "‚ö†Ô∏è  WARNING: Running as root user"
        else
          echo "‚úÖ GOOD: Running as non-root user ($(id -u))"
        fi
        
        # Check filesystem permissions
        if [ -w "/" ]; then
          echo "‚ö†Ô∏è  WARNING: Root filesystem is writable"
        else
          echo "‚úÖ GOOD: Root filesystem is read-only"
        fi
        
        # Check for sensitive mounts
        if mount | grep -q "/var/run/secrets"; then
          echo "‚ÑπÔ∏è  INFO: Service account token mounted"
        fi
        
        # Check available capabilities
        echo "Current capabilities:"
        if [ -f "/proc/self/status" ]; then
          grep Cap /proc/self/status
        fi
        
        # Check network access
        echo "Testing network access..."
        if ping -c 1 8.8.8.8 >/dev/null 2>&1; then
          echo "‚ÑπÔ∏è  INFO: External network access available"
        else
          echo "‚ÑπÔ∏è  INFO: No external network access"
        fi
        
        # Generate security report
        cat > /tmp/security-report.txt <<EOF
      === Security Scan Report ===
      Timestamp: $(date)
      User ID: $(id -u)
      Group ID: $(id -g)
      Working Directory: $(pwd)
      
      Filesystem Check:
      - Root writable: $([ -w "/" ] && echo "YES" || echo "NO")
      - /tmp writable: $([ -w "/tmp" ] && echo "YES" || echo "NO")
      
      Network Check:
      - External access: $(ping -c 1 8.8.8.8 >/dev/null 2>&1 && echo "YES" || echo "NO")
      
      Process Information:
      $(ps aux)
      EOF
        
        echo "Report generated at /tmp/security-report.txt"
      }
      
      # Run security check
      check_security
      
      # Keep running for inspection
      echo "Scanner complete. Container will stay running for inspection."
      sleep 3600
      
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 1000
      runAsGroup: 3000
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir: {}
    
  restartPolicy: Never
```

**Usage:**
```bash
# Deploy the security scanner
kubectl apply -f security-scanner-pod.yaml

# Monitor the scan
kubectl logs -f security-scanner

# Get the security report
kubectl cp security-scanner:/tmp/security-report.txt ./security-report.txt
cat security-report.txt

# Create a comparison with an insecure pod
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: insecure-pod
spec:
  containers:
  - name: insecure
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      runAsUser: 0  # Running as root
      privileged: true
EOF

# Compare security postures
echo "=== Security Comparison ==="
echo "Secure pod user:"
kubectl exec security-scanner -- id

echo "Insecure pod user:"
kubectl exec insecure-pod -- id

echo "Secure pod capabilities:"
kubectl exec security-scanner -- grep Cap /proc/self/status

echo "Insecure pod capabilities:"
kubectl exec insecure-pod -- grep Cap /proc/self/status

# Clean up
kubectl delete pod security-scanner insecure-pod
rm -f security-report.txt
```

---

## Declarative Pod Configuration and Management

### üèóÔ∏è Expert Examples

#### Example 6: Production-Ready Pod Template

```yaml
# production-pod-template.yaml
apiVersion: v1
kind: Pod
metadata:
  name: production-app
  namespace: production
  labels:
    app: web-server
    version: "2.1.0"
    environment: production
    team: platform
  annotations:
    description: "Production web server with full monitoring and security"
    contact: "platform-team@company.com"
    runbook: "https://wiki.company.com/runbooks/web-server"
    version: "2.1.0"
    build-date: "2024-01-15T10:30:00Z"
spec:
  # Security context for the entire pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
      
  # Node selection
  nodeSelector:
    node-type: "application"
    zone: "us-west-2a"
    
  # Tolerations for dedicated nodes
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "application"
    effect: "NoSchedule"
    
  # Pod placement preferences
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: "node-type"
            operator: In
            values: ["application"]
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: web-server
          topologyKey: kubernetes.io/hostname
          
  # DNS configuration
  dnsPolicy: ClusterFirst
  dnsConfig:
    options:
    - name: ndots
      value: "2"
    - name: edns0
      
  # Termination settings
  terminationGracePeriodSeconds: 60
  restartPolicy: Always
  
  containers:
  - name: web-server
    image: nginx:1.21-alpine
    imagePullPolicy: IfNotPresent
    
    ports:
    - name: http
      containerPort: 80
      protocol: TCP
    - name: metrics
      containerPort: 9113
      protocol: TCP
      
    # Environment variables
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "info"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    # Resource management
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
        
    # Security context
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE
        
    # Health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 80
        scheme: HTTP
        httpHeaders:
        - name: Custom-Header
          value: liveness-check
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
        scheme: HTTP
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 3
      successThreshold: 1
      
    startupProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 30
      successThreshold: 1
      
    # Lifecycle hooks
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container started at $(date)" >> /tmp/startup.log
            # Custom initialization logic here
            
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container stopping at $(date)" >> /tmp/shutdown.log
            # Graceful shutdown logic here
            nginx -s quit
            sleep 15
            
    # Volume mounts
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  # Sidecar container for log processing
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  # Monitoring sidecar
  - name: nginx-exporter
    image: nginx/nginx-prometheus-exporter:0.10.0
    args:
    - -nginx.scrape-uri=http://localhost:80/nginx_status
    ports:
    - name: metrics
      containerPort: 9113
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
        
  # Shared volumes
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
      defaultMode: 0644
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
      defaultMode: 0644
  - name: html-content
    configMap:
      name: html-content
      defaultMode: 0644
  - name: tmp-dir
    emptyDir:
      sizeLimit: 256Mi
  - name: var-cache-nginx
    emptyDir:
      sizeLimit: 512Mi
  - name: var-run
    emptyDir:
      sizeLimit: 64Mi
  - name: logs
    emptyDir:
      sizeLimit: 1Gi
```

### üõ†Ô∏è Demo: Complex Pod Deployment Pipeline

```bash
#!/bin/bash
# production-pod-deployment.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

# Configuration
NAMESPACE="production-demo"
APP_NAME="web-server"
CONFIG_DIR="./config"

# Create namespace if it doesn't exist
create_namespace() {
    log "Creating namespace: $NAMESPACE"
    kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    success "Namespace $NAMESPACE ready"
}

# Create ConfigMaps for the application
create_configmaps() {
    log "Creating ConfigMaps..."
    
    mkdir -p $CONFIG_DIR
    
    # Nginx configuration
    cat > $CONFIG_DIR/nginx.conf <<EOF
server {
    listen 80;
    server_name localhost;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
    
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    location /ready {
        access_log off;
        return 200 "ready\n";
        add_header Content-Type text/plain;
    }
    
    location /nginx_status {
        stub_status on;
        access_log off;
        allow all;
    }
}
EOF

    # HTML content
    cat > $CONFIG_DIR/index.html <<EOF
<!DOCTYPE html>
<html>
<head>
    <title>Production Pod Demo</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .container { max-width: 800px; margin: 0 auto; }
        .status { padding: 20px; margin: 20px 0; border-radius: 5px; }
        .healthy { background-color: #d4edda; color: #155724; }
        .info { background-color: #d1ecf1; color: #0c5460; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Production Pod Demo</h1>
        <div class="status healthy">
            <h3>‚úÖ Application Status: Healthy</h3>
            <p>Pod is running successfully with full production configuration</p>
        </div>
        
        <div class="status info">
            <h3>üìä Features Enabled:</h3>
            <ul>
                <li>Multi-container architecture</li>
                <li>Comprehensive health checks</li>
                <li>Security hardening</li>
                <li>Log processing sidecar</li>
                <li>Prometheus metrics export</li>
                <li>Resource management</li>
            </ul>
        </div>
        
        <div class="status info">
            <h3>üîó Endpoints:</h3>
            <ul>
                <li><a href="/health">Health Check</a></li>
                <li><a href="/ready">Readiness Check</a></li>
                <li><a href="/nginx_status">Nginx Status</a></li>
            </ul>
        </div>
    </div>
</body>
</html>
EOF

    # Fluent Bit configuration
    cat > $CONFIG_DIR/fluent-bit.conf <<EOF
[SERVICE]
    Flush         1
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf

[INPUT]
    Name              tail
    Path              /var/log/nginx/access.log
    Parser            nginx
    Tag               nginx.access
    Refresh_Interval  5

[INPUT]
    Name              tail
    Path              /var/log/nginx/error.log
    Tag               nginx.error
    Refresh_Interval  5

[OUTPUT]
    Name  stdout
    Match nginx.*
EOF

    cat > $CONFIG_DIR/parsers.conf <<EOF
[PARSER]
    Name   nginx
    Format regex
    Regex  ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
    Time_Key time
    Time_Format %d/%b/%Y:%H:%M:%S %z
EOF

    # Create ConfigMaps
    kubectl create configmap nginx-config --from-file=$CONFIG_DIR/nginx.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap html-content --from-file=$CONFIG_DIR/index.html -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create configmap fluent-bit-config --from-file=$CONFIG_DIR/fluent-bit.conf --from-file=$CONFIG_DIR/parsers.conf -n $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    
    success "ConfigMaps created successfully"
}

# Deploy the production pod
deploy_pod() {
    log "Deploying production pod..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: $APP_NAME
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
    version: "1.0.0"
    environment: production
  annotations:
    deployment.kubernetes.io/revision: "1"
    deployed-by: "production-deployment-script"
    deployment-time: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    runAsNonRoot: true
    
  containers:
  - name: nginx
    image: nginx:1.21-alpine
    ports:
    - name: http
      containerPort: 80
    - name: metrics
      containerPort: 9113
      
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
          
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    livenessProbe:
      httpGet:
        path: /health
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 30
      
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    - name: html-content
      mountPath: /usr/share/nginx/html
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
    - name: logs
      mountPath: /var/log/nginx
      
  - name: log-processor
    image: fluent/fluent-bit:2.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop: ["ALL"]
        
    volumeMounts:
    - name: logs
      mountPath: /var/log/nginx
      readOnly: true
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
      readOnly: true
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
  - name: html-content
    configMap:
      name: html-content
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
  - name: tmp-dir
    emptyDir: {}
  - name: var-cache-nginx
    emptyDir: {}
  - name: var-run
    emptyDir: {}
  - name: logs
    emptyDir: {}
EOF

    success "Pod deployed successfully"
}

# Wait for pod to be ready and perform health checks
verify_deployment() {
    log "Waiting for pod to be ready..."
    
    if kubectl wait --for=condition=Ready pod/$APP_NAME -n $NAMESPACE --timeout=120s; then
        success "Pod is ready!"
    else
        error "Pod failed to become ready within timeout"
    fi
    
    # Perform comprehensive health checks
    log "Performing health checks..."
    
    # Check pod status
    kubectl get pod $APP_NAME -n $NAMESPACE -o wide
    
    # Test health endpoints
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    if curl -s http://localhost:8080/health | grep -q "healthy"; then
        success "Health check passed"
    else
        warning "Health check failed"
    fi
    
    if curl -s http://localhost:8080/ready | grep -q "ready"; then
        success "Readiness check passed"
    else
        warning "Readiness check failed"
    fi
    
    # Test the main application
    if curl -s http://localhost:8080 | grep -q "Production Pod Demo"; then
        success "Application is serving content correctly"
    else
        warning "Application content check failed"
    fi
    
    kill $PF_PID 2>/dev/null
    
    # Check resource usage
    log "Checking resource usage..."
    if kubectl top pod $APP_NAME -n $NAMESPACE &>/dev/null; then
        kubectl top pod $APP_NAME -n $NAMESPACE
    else
        warning "Resource metrics not available"
    fi
    
    # Check logs from all containers
    log "Checking container logs..."
    echo "=== Nginx logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c nginx --tail=5
    echo "=== Log processor logs ==="
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=5
}

# Generate load and monitor performance
performance_test() {
    log "Running performance test..."
    
    kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80 &
    PF_PID=$!
    sleep 5
    
    # Generate some load
    for i in {1..50}; do
        curl -s http://localhost:8080 > /dev/null &
    done
    
    wait
    kill $PF_PID 2>/dev/null
    
    # Check logs after load test
    log "Logs after load test:"
    kubectl logs $APP_NAME -n $NAMESPACE -c log-processor --tail=10
    
    success "Performance test completed"
}

# Cleanup function
cleanup() {
    log "Cleaning up resources..."
    kubectl delete pod $APP_NAME -n $NAMESPACE --ignore-not-found
    kubectl delete configmap nginx-config html-content fluent-bit-config -n $NAMESPACE --ignore-not-found
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -rf $CONFIG_DIR
    success "Cleanup completed"
}

# Main execution
main() {
    echo "=== Production Pod Deployment Demo ==="
    
    case "${1:-deploy}" in
        "deploy")
            create_namespace
            create_configmaps
            deploy_pod
            verify_deployment
            performance_test
            
            echo ""
            success "Deployment completed successfully!"
            echo "Access the application:"
            echo "  kubectl port-forward pod/$APP_NAME -n $NAMESPACE 8080:80"
            echo "  Then open: http://localhost:8080"
            echo ""
            echo "Monitor the pod:"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c nginx"
            echo "  kubectl logs -f $APP_NAME -n $NAMESPACE -c log-processor"
            echo ""
            echo "Run 'bash $0 cleanup' to remove all resources"
            ;;
        "cleanup")
            cleanup
            ;;
        "test")
            verify_deployment
            performance_test
            ;;
        *)
            echo "Usage: $0 [deploy|cleanup|test]"
            echo "  deploy  - Deploy the production pod (default)"
            echo "  cleanup - Remove all created resources"
            echo "  test    - Run verification and performance tests"
            ;;
    esac
}

main "$@"
```

### üéØ Mini-Project 4: Pod Chaos Engineering

Test pod resilience with chaos engineering principles:

```yaml
# chaos-test-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: chaos-resilient-app
  labels:
    app: chaos-test
    resilience: enabled
spec:
  containers:
  - name: main-app
    image: nginx:1.21-alpine
    ports:
    - containerPort: 80
    
    # Aggressive resource limits to test resilience
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"
        
    # Tight health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 2
      
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
      timeoutSeconds: 1
      failureThreshold: 2
      
    # Graceful shutdown
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 10"]
          
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  # Chaos monkey sidecar
  - name: chaos-monkey
    image: busybox
    command:
    - /bin/sh
    - -c
    - |
      echo "Chaos monkey starting..."
      
      # Function to create CPU load
      cpu_chaos() {
        echo "Creating CPU chaos..."
        for i in {1..4}; do
          yes > /dev/null &
        done
        sleep 30
        killall yes
      }
      
      # Function to create memory pressure
      memory_chaos() {
        echo "Creating memory chaos..."
        cat <(yes | tr \\n x | head -c 50000000) <(yes | tr \\n x | head -c 50000000) > /tmp/memory_eater &
        sleep 20
        rm -f /tmp/memory_eater
        killall cat
      }
      
      # Function to simulate network issues
      network_chaos() {
        echo "Creating network chaos..."
        # Simulate slow responses
        sleep $((RANDOM % 10 + 5))
      }
      
      # Function to create disk I/O pressure
      disk_chaos() {
        echo "Creating disk I/O chaos..."
        dd if=/dev/zero of=/tmp/disk_eater bs=1M count=10 2>/dev/null
        rm -f /tmp/disk_eater
      }
      
      # Main chaos loop
      while true; do
        chaos_type=$((RANDOM % 4))
        case $chaos_type in
          0) cpu_chaos ;;
          1) memory_chaos ;;
          2) network_chaos ;;
          3) disk_chaos ;;
        esac
        
        # Wait between chaos events
        sleep $((RANDOM % 60 + 30))
      done
      
    resources:
      requests:
        memory: "32Mi"
        cpu: "25m"
      limits:
        memory: "64Mi"
        cpu: "50m"
        
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
      
  volumes:
  - name: tmp-dir
    emptyDir:
      sizeLimit: 100Mi
      
  restartPolicy: Always
```

**Chaos Testing Script:**
```bash
#!/bin/bash
# chaos-engineering-test.sh

echo "=== Chaos Engineering Test ==="

# Deploy the chaos test pod
kubectl apply -f chaos-test-pod.yaml

# Wait for it to be ready
echo "Waiting for pod to be ready..."
kubectl wait --for=condition=Ready pod/chaos-resilient-app --timeout=60s

# Monitor pod resilience
echo "Starting resilience monitoring (Ctrl+C to stop)..."

monitor_resilience() {
    while true; do
        timestamp=$(date '+%H:%M:%S')
        
        # Check pod status
        status=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.phase}')
        ready=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}')
        restarts=$(kubectl get pod chaos-resilient-app -o jsonpath='{.status.containerStatuses[0].restartCount}')
        
        # Test application responsiveness
        kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
        PF_PID=$!
        sleep 2
        
        response_time=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8080 2>/dev/null || echo "FAIL")
        kill $PF_PID 2>/dev/null
        
        # Get resource usage if available
        resources=""
        if kubectl top pod chaos-resilient-app &>/dev/null; then
            resources=$(kubectl top pod chaos-resilient-app --no-headers 2>/dev/null | awk '{print $2" "$3}')
        fi
        
        printf "[$timestamp] Status: $status | Ready: $ready | Restarts: $restarts | Response: ${response_time}s | Resources: $resources\n"
        
        sleep 5
    done
}

# Start monitoring in background
monitor_resilience &
MONITOR_PID=$!

# Generate additional load to test resilience
echo "Generating load to test resilience..."
for i in {1..100}; do
    kubectl port-forward pod/chaos-resilient-app 8080:80 >/dev/null 2>&1 &
    PF_PID=$!
    sleep 1
    
    curl -s http://localhost:8080 > /dev/null &
    
    kill $PF_PID 2>/dev/null
    sleep 2
done

# Stop monitoring
kill $MONITOR_PID 2>/dev/null

echo "Chaos test completed. Check pod logs:"
echo "kubectl logs chaos-resilient-app -c main-app --tail=20"
echo "kubectl logs chaos-resilient-app -c chaos-monkey --tail=20"

# Cleanup
read -p "Delete the chaos test pod? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    kubectl delete -f chaos-test-pod.yaml
fi
```

---

## Advanced Pod Management Techniques

### üî¨ Expert-Level Examples

#### Example 7: Custom Pod Controller

Create a custom controller for specialized pod management:

```python
#!/usr/bin/env python3
# custom-pod-controller.py

import time
import yaml
import subprocess
import json
from datetime import datetime, timedelta

class PodController:
    def __init__(self):
        self.managed_pods = {}
        self.check_interval = 30  # seconds
        
    def log(self, message):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"[{timestamp}] {message}")
        
    def run_kubectl(self, command):
        """Execute kubectl command and return JSON output"""
        try:
            result = subprocess.run(
                f"kubectl {command} -o json",
                shell=True,
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                self.log(f"kubectl error: {result.stderr}")
                return None
        except Exception as e:
            self.log(f"Command execution error: {e}")
            return None
            
    def get_pods_by_label(self, label_selector):
        """Get pods matching label selector"""
        command = f"get pods -l {label_selector}"
        result = self.run_kubectl(command)
        return result.get('items', []) if result else []
        
    def create_pod(self, name, spec):
        """Create a pod with given specification"""
        pod_manifest = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'name': name,
                'labels': {
                    'managed-by': 'custom-controller',
                    'created': datetime.now().strftime('%Y%m%d-%H%M%S')
                }
            },
            'spec': spec
        }
        
        # Write manifest to temporary file
        with open(f'/tmp/{name}.yaml', 'w') as f:
            yaml.dump(pod_manifest, f)
            
        # Apply the manifest
        result = subprocess.run(
            f"kubectl apply -f /tmp/{name}.yaml",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Created pod: {name}")
            return True
        else:
            self.log(f"Failed to create pod {name}: {result.stderr}")
            return False
            
    def delete_pod(self, name):
        """Delete a pod"""
        result = subprocess.run(
            f"kubectl delete pod {name} --grace-period=30",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            self.log(f"Deleted pod: {name}")
            return True
        else:
            self.log(f"Failed to delete pod {name}: {result.stderr}")
            return False
            
    def check_pod_health(self, pod):
        """Check if a pod is healthy based on custom criteria"""
        name = pod['metadata']['name']
        status = pod['status']
        
        # Check if pod is running
        if status.get('phase') != 'Running':
            return False, f"Pod {name} is not running (phase: {status.get('phase')})"
            
        # Check container statuses
        container_statuses = status.get('containerStatuses', [])
        for container in container_statuses:
            if not container.get('ready'):
                return False, f"Container {container['name']} not ready in pod {name}"
                
            # Check restart count
            restart_count = container.get('restartCount', 0)
            if restart_count > 5:
                return False, f"Container {container['name']} restarted {restart_count} times"
                
        # Check resource usage (if metrics available)
        metrics = self.get_pod_metrics(name)
        if metrics:
            cpu_usage = self.parse_cpu_usage(metrics.get('cpu', '0m'))
            memory_usage = self.parse_memory_usage(metrics.get('memory', '0Mi'))
            
            if cpu_usage > 800:  # 800 millicores
                return False, f"Pod {name} CPU usage too high: {cpu_usage}m"
                
            if memory_usage > 512:  # 512 Mi
                return False, f"Pod {name} memory usage too high: {memory_usage}Mi"
                
        return True, f"Pod {name} is healthy"
        
    def get_pod_metrics(self, pod_name):
        """Get pod resource metrics if available"""
        result = subprocess.run(
            f"kubectl top pod {pod_name} --no-headers",
            shell=True,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            parts = result.stdout.strip().split()
            if len(parts) >= 3:
                return {
                    'cpu': parts[1],
                    'memory': parts[2]
                }
        return None
        
    def parse_cpu_usage(self, cpu_str):
        """Parse CPU usage from string like '100m' to millicores"""
        if cpu_str.endswith('m'):
            return int(cpu_str[:-1])
        return int(cpu_str) * 1000
        
    def parse_memory_usage(self, memory_str):
        """Parse memory usage from string like '128Mi' to Mi"""
        if memory_str.endswith('Mi'):
            return int(memory_str[:-2])
        elif memory_str.endswith('Gi'):
            return int(memory_str[:-2]) * 1024
        return int(memory_str) // (1024 * 1024)
        
    def auto_heal_pod(self, pod_name, reason):
        """Attempt to heal an unhealthy pod"""
        self.log(f"Attempting to heal pod {pod_name}: {reason}")
        
        # Strategy 1: Restart the pod
        if "restart" in reason.lower():
            return self.delete_pod(pod_name)  # Pod will be recreated if managed by controller
            
        # Strategy 2: Scale resources if high usage
        if "usage too high" in reason.lower():
            self.log(f"High resource usage detected for {pod_name}, marking for recreation")
            return self.delete_pod(pod_name)
            
        # Strategy 3: Generic restart
        return self.delete_pod(pod_name)
        
    def manage_workload(self, workload_config):
        """Manage a workload with desired replica count"""
        app_name = workload_config['name']
        desired_replicas = workload_config['replicas']
        pod_spec = workload_config['pod_spec']
        
        # Get current pods for this workload
        current_pods = self.get_pods_by_label(f"app={app_name},managed-by=custom-controller")
        current_count = len(current_pods)
        
        self.log(f"Managing workload {app_name}: current={current_count}, desired={desired_replicas}")
        
        # Scale up if needed
        if current_count < desired_replicas:
            for i in range(current_count, desired_replicas):
                pod_name = f"{app_name}-{i}"
                pod_spec_copy = pod_spec.copy()
                pod_spec_copy.setdefault('containers', [{}])[0]['env'] = [
                    {'name': 'REPLICA_ID', 'value': str(i)},
                    {'name': 'APP_NAME', 'value': app_name}
                ]
                self.create_pod(pod_name, pod_spec_copy)
                
        # Scale down if needed
        elif current_count > desired_replicas:
            pods_to_delete = current_pods[desired_replicas:]
            for pod in pods_to_delete:
                self.delete_pod(pod['metadata']['name'])
                
        # Health check existing pods
        for pod in current_pods[:desired_replicas]:
            healthy, reason = self.check_pod_health(pod)
            if not healthy:
                self.log(f"Pod unhealthy: {reason}")
                self.auto_heal_pod(pod['metadata']['name'], reason)
                
    def run_control_loop(self):
        """Main control loop"""
        self.log("Starting custom pod controller...")
        
        # Sample workload configuration
        workloads = [
            {
                'name': 'web-app',
                'replicas': 2,
                'pod_spec': {
                    'containers': [{
                        'name': 'nginx',
                        'image': 'nginx:1.21-alpine',
                        'ports': [{'containerPort': 80}],
                        'resources': {
                            'requests': {'memory': '64Mi', 'cpu': '50m'},
                            'limits': {'memory': '128Mi', 'cpu': '100m'}
                        },
                        'livenessProbe': {
                            'httpGet': {'path': '/', 'port': 80},
                            'initialDelaySeconds': 10,
                            'periodSeconds': 30
                        }
                    }],
                    'restartPolicy': 'Always'
                }
            }
        ]
        
        try:
            while True:
                self.log("Running control loop...")
                
                for workload in workloads:
                    try:
                        self.manage_workload(workload)
                    except Exception as e:
                        self.log(f"Error managing workload {workload['name']}: {e}")
                        
                self.log(f"Sleeping for {self.check_interval} seconds...")
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            self.log("Shutting down controller...")
            
        except Exception as e:
            self.log(f"Controller error: {e}")
            
    def cleanup(self):
        """Clean up managed resources"""
        self.log("Cleaning up managed pods...")
        pods = self.get_pods_by_label("managed-by=custom-controller")
        for pod in pods:
            self.delete_pod(pod['metadata']['name'])

if __name__ == "__main__":
    import sys
    
    controller = PodController()
    
    if len(sys.argv) > 1 and sys.argv[1] == "cleanup":
        controller.cleanup()
    else:
        controller.run_control_loop()
```

**Usage:**
```bash
# Make the script executable
chmod +x custom-pod-controller.py

# Install dependencies
pip3 install pyyaml

# Run the controller
python3 custom-pod-controller.py

# In another terminal, watch the managed pods
watch kubectl get pods -l managed-by=custom-controller

# Simulate pod failures
kubectl delete pod web-app-0  # Controller will recreate it

# Clean up when done
python3 custom-pod-controller.py cleanup
```

### üéØ Mini-Project 5: Pod Performance Optimization Lab

Create a comprehensive performance optimization laboratory:

```yaml
# performance-lab-setup.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: performance-lab
---
# Baseline pod - unoptimized
apiVersion: v1
kind: Pod
metadata:
  name: baseline-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: baseline
spec:
  containers:
  - name: app
    image: nginx:1.21
    resources:
      requests:
        memory: "1Gi"
        cpu: "1000m"
      limits:
        memory: "2Gi"
        cpu: "2000m"
---
# Optimized pod - resource-efficient
apiVersion: v1
kind: Pod
metadata:
  name: optimized-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: optimized
spec:
  containers:
  - name: app
    image: nginx:1.21-alpine  # Smaller image
    resources:
      requests:
        memory: "64Mi"        # Right-sized requests
        cpu: "100m"
      limits:
        memory: "128Mi"       # Conservative limits
        cpu: "200m"
    # Optimized health checks
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5   # Faster startup
      periodSeconds: 30        # Less frequent checks
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 2
      periodSeconds: 5
    # Security optimizations
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop: ["ALL"]
    # Volume optimizations
    volumeMounts:
    - name: tmp-dir
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp-dir
    emptyDir:
      medium: Memory  # Use memory for temp files
      sizeLimit: 64Mi
  - name: var-cache
    emptyDir:
      sizeLimit: 128Mi
  - name: var-run
    emptyDir:
      sizeLimit: 32Mi
---
# High-performance pod with advanced optimizations
apiVersion: v1
kind: Pod
metadata:
  name: high-performance-app
  namespace: performance-lab
  labels:
    app: performance-test
    optimization: high-performance
spec:
  # Pod-level optimizations
  priorityClassName: high-priority
  nodeSelector:
    node-type: performance
  tolerations:
  - key: performance-node
    operator: Equal
    value: "true"
    effect: NoSchedule
  # Network optimizations
  dnsPolicy: ClusterFirstWithHostNet
  dnsConfig:
    options:
    - name: ndots
      value: "1"
    - name: edns0
  containers:
  - name: app
    image: nginx:1.21-alpine
    # Optimized resource allocation
    resources:
      requests:
        memory: "128Mi"
        cpu: "200m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "256Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
    # Performance-tuned environment
    env:
    - name: NGINX_WORKER_PROCESSES
      value: "auto"
    - name: NGINX_WORKER_CONNECTIONS
      value: "1024"
    # Aggressive health checks for faster recovery
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 15
      timeoutSeconds: 2
      failureThreshold: 2
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 3
      timeoutSeconds: 1
      failureThreshold: 1
    # Startup optimization
    startupProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 1
      periodSeconds: 1
      timeoutSeconds: 1
      failureThreshold: 10
    # Performance-optimized volumes
    volumeMounts:
    - name: high-speed-tmp
      mountPath: /tmp
    - name: nginx-cache
      mountPath: /var/cache/nginx
    - name: nginx-run
      mountPath: /var/run
  volumes:
  - name: high-speed-tmp
    emptyDir:
      medium: Memory
      sizeLimit: 128Mi
  - name: nginx-cache
    emptyDir:
      medium: Memory
      sizeLimit: 256Mi
  - name: nginx-run
    emptyDir:
      medium: Memory
      sizeLimit: 64Mi
```

**Performance Benchmarking Script:**
```bash
#!/bin/bash
# performance-benchmark.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

NAMESPACE="performance-lab"

# Deploy the performance lab
setup_lab() {
    log "Setting up performance lab..."
    kubectl apply -f performance-lab-setup.yaml
    
    log "Waiting for pods to be ready..."
    kubectl wait --for=condition=Ready pod/baseline-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/optimized-app -n $NAMESPACE --timeout=120s
    kubectl wait --for=condition=Ready pod/high-performance-app -n $NAMESPACE --timeout=120s
    
    success "Performance lab setup complete"
}

# Measure startup time
measure_startup_time() {
    local pod_name=$1
    log "Measuring startup time for $pod_name..."
    
    # Delete and recreate pod to measure startup
    kubectl delete pod $pod_name -n $NAMESPACE
    local start_time=$(date +%s.%N)
    
    # Recreate the pod (extract from original manifest)
    kubectl get pod $pod_name -n $NAMESPACE -o yaml --export 2>/dev/null | kubectl apply -f - 2>/dev/null || {
        warning "Couldn't recreate pod automatically, recreating from manifest"
        kubectl apply -f performance-lab-setup.yaml
    }
    
    # Wait for ready and measure time
    kubectl wait --for=condition=Ready pod/$pod_name -n $NAMESPACE --timeout=120s
    local end_time=$(date +%s.%N)
    
    local startup_time=$(echo "$end_time - $start_time" | bc -l)
    echo "$startup_time"
}

# Run load test on a pod
load_test_pod() {
    local pod_name=$1
    local duration=${2:-30}
    local concurrency=${3:-10}
    
    log "Running load test on $pod_name (${duration}s, ${concurrency} concurrent)"
    
    # Start port forwarding
    kubectl port-forward pod/$pod_name -n $NAMESPACE 8080:80 >/dev/null 2>&1 &
    local pf_pid=$!
    sleep 3
    
    # Use Apache Bench for load testing
    local results_file="/tmp/ab_results_${pod_name}.txt"
    
    if command -v ab >/dev/null; then
        ab -n $((duration * concurrency)) -c $concurrency -g /tmp/gnuplot_${pod_name}.dat \
           http://localhost:8080/ > $results_file 2>&1
        
        # Extract key metrics
        local rps=$(grep "Requests per second" $results_file | awk '{print $4}')
        local response_time=$(grep "Time per request.*mean" $results_file | head -1 | awk '{print $4}')
        local failed_requests=$(grep "Failed requests" $results_file | awk '{print $3}')
        
        echo "RPS:$rps,ResponseTime:$response_time,Failed:$failed_requests"
    else
        # Fallback to curl-based test
        local start_time=$(date +%s)
        local requests=0
        local total_time=0
        
        for i in $(seq 1 $((duration * concurrency))); do
            local req_start=$(date +%s.%N)
            if curl -s http://localhost:8080 >/dev/null 2>&1; then
                ((requests++))
            fi
            local req_end=$(date +%s.%N)
            local req_time=$(echo "$req_end - $req_start" | bc -l)
            total_time=$(echo "$total_time + $req_time" | bc -l)
            
            # Basic rate limiting
            sleep 0.1
        done
        
        local avg_response_time=$(echo "scale=3; $total_time / $requests" | bc -l)
        local rps=$(echo "scale=2; $requests / $duration" | bc -l)
        
        echo "RPS:$rps,ResponseTime:$avg_response_time,Failed:0"
    fi
    
    kill $pf_pid 2>/dev/null
}

# Get resource usage metrics
get_resource_usage() {
    local pod_name=$1
    log "Getting resource usage for $pod_name..."
    
    if kubectl top pod $pod_name -n $NAMESPACE >/dev/null 2>&1; then
        kubectl top pod $pod_name -n $NAMESPACE --no-headers | awk '{print "CPU:"$2",Memory:"$3}'
    else
        echo "CPU:N/A,Memory:N/A"
    fi
}

# Comprehensive benchmark
run_comprehensive_benchmark() {
    log "Running comprehensive performance benchmark..."
    
    declare -A results
    local pods=("baseline-app" "optimized-app" "high-performance-app")
    
    echo "=== Performance Benchmark Results ===" > benchmark_results.txt
    echo "Timestamp: $(date)" >> benchmark_results.txt
    echo "" >> benchmark_results.txt
    
    for pod in "${pods[@]}"; do
        log "Benchmarking $pod..."
        
        # Startup time measurement
        log "Measuring startup time for $pod..."
        # Skip startup measurement in this demo to avoid pod recreation issues
        startup_time="N/A"
        
        # Resource usage
        resource_usage=$(get_resource_usage $pod)
        
        # Load test
        load_results=$(load_test_pod $pod 30 10)
        
        # Pod status information
        pod_info=$(kubectl get pod $pod -n $NAMESPACE -o custom-columns=STATUS:.status.phase,READY:.status.conditions[?\(@.type==\"Ready\"\)].status,RESTARTS:.status.containerStatuses[0].restartCount --no-headers)
        
        # Store results
        results[$pod]="Startup:$startup_time,Resources:$resource_usage,Load:$load_results,Status:$pod_info"
        
        # Write to file
        cat >> benchmark_results.txt <<EOF

=== $pod ===
Startup Time: $startup_time seconds
Resource Usage: $resource_usage
Load Test Results: $load_results
Pod Status: $pod_info

EOF
    done
    
    # Generate comparison summary
    cat >> benchmark_results.txt <<EOF

=== Performance Summary ===
This benchmark compares three pod configurations:

1. Baseline App: Standard configuration with generous resource allocation
2. Optimized App: Resource-efficient with security hardening
3. High-Performance App: Maximum performance optimizations

Key Findings:
- Resource efficiency varies significantly between configurations
- Startup time impacts overall application availability
- Load handling capacity differs based on resource allocation
- Security optimizations may have performance trade-offs

Recommendations:
- Use optimized configuration for production workloads
- Consider high-performance setup for critical applications
- Monitor resource usage to fine-tune allocations
- Balance security and performance based on requirements

EOF
    
    success "Benchmark completed. Results saved to benchmark_results.txt"
    cat benchmark_results.txt
}

# Resource monitoring script
monitor_resources() {
    local duration=${1:-300}  # 5 minutes default
    log "Starting resource monitoring for ${duration} seconds..."
    
    local monitor_file="resource_monitor_$(date +%Y%m%d_%H%M%S).log"
    
    {
        echo "Timestamp,Pod,CPU,Memory,Status"
        local end_time=$(($(date +%s) + duration))
        
        while [ $(date +%s) -lt $end_time ]; do
            local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            
            for pod in baseline-app optimized-app high-performance-app; do
                if kubectl get pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                    local status=$(kubectl get pod $pod -n $NAMESPACE -o jsonpath='{.status.phase}')
                    local usage="N/A,N/A"
                    
                    if kubectl top pod $pod -n $NAMESPACE >/dev/null 2>&1; then
                        usage=$(kubectl top pod $pod -n $NAMESPACE --no-headers | awk '{print $2","$3}')
                    fi
                    
                    echo "$timestamp,$pod,$usage,$status"
                fi
            done
            
            sleep 10
        done
    } > $monitor_file
    
    success "Resource monitoring completed. Data saved to $monitor_file"
    
    # Generate simple analysis
    log "Generating resource usage analysis..."
    
    {
        echo "=== Resource Usage Analysis ==="
        echo ""
        
        for pod in baseline-app optimized-app high-performance-app; do
            echo "=== $pod ==="
            grep "$pod" $monitor_file | tail -10 | while IFS=',' read timestamp pod_name cpu memory status; do
                echo "[$timestamp] CPU: $cpu, Memory: $memory, Status: $status"
            done
            echo ""
        done
    } > resource_analysis.txt
    
    success "Analysis saved to resource_analysis.txt"
}

# Cleanup function
cleanup_lab() {
    log "Cleaning up performance lab..."
    kubectl delete namespace $NAMESPACE --ignore-not-found
    rm -f benchmark_results.txt resource_*.log resource_analysis.txt
    rm -f /tmp/ab_results_*.txt /tmp/gnuplot_*.dat
    success "Cleanup completed"
}

# Main execution
main() {
    case "${1:-benchmark}" in
        "setup")
            setup_lab
            ;;
        "benchmark")
            setup_lab
            run_comprehensive_benchmark
            ;;
        "monitor")
            monitor_resources "${2:-300}"
            ;;
        "cleanup")
            cleanup_lab
            ;;
        "all")
            setup_lab
            run_comprehensive_benchmark
            monitor_resources 300
            echo ""
            success "Complete performance analysis finished!"
            echo "Files created:"
            echo "  - benchmark_results.txt"
            echo "  - resource_monitor_*.log"
            echo "  - resource_analysis.txt"
            ;;
        *)
            echo "Performance Lab - Pod Optimization Benchmark"
            echo ""
            echo "Usage: $0 <command> [options]"
            echo ""
            echo "Commands:"
            echo "  setup      - Set up the performance lab environment"
            echo "  benchmark  - Run comprehensive performance benchmark"
            echo "  monitor    - Monitor resource usage for specified duration"
            echo "  cleanup    - Remove all lab resources"
            echo "  all        - Run complete analysis (setup + benchmark + monitor)"
            echo ""
            echo "Examples:"
            echo "  $0 setup"
            echo "  $0 benchmark"
            echo "  $0 monitor 600  # Monitor for 10 minutes"
            echo "  $0 all          # Complete analysis"
            ;;
    esac
}

main "$@"
```

---

## Pod Troubleshooting Methodologies

### üîß Advanced Troubleshooting Toolkit

#### Example 8: Automated Diagnostic System

```bash
#!/bin/bash
# advanced-pod-diagnostics.sh

set -euo pipefail

# Enhanced diagnostic toolkit with automated problem detection
class PodDiagnostics {
    
# Configuration
NAMESPACE=${NAMESPACE:-default}
OUTPUT_DIR="./diagnostics-$(date +%Y%m%d-%H%M%S)"
VERBOSE=${VERBOSE:-false}

# Colors and formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'
BOLD='\033[1m'

# Logging functions with levels
log_debug() { [[ $VERBOSE == "true" ]] && echo -e "${CYAN}[DEBUG]${NC} $1"; }
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }

# Initialize diagnostics
init_diagnostics() {
    log_info "Initializing pod diagnostics system..."
    mkdir -p "$OUTPUT_DIR"/{logs,reports,metrics,manifests}
    
    # Create diagnostic report header
    cat > "$OUTPUT_DIR/diagnostic_report.md" <<EOF
# Pod Diagnostics Report

**Generated:** $(date)  
**Cluster:** $(kubectl config current-context)  
**Namespace:** $NAMESPACE  
**Output Directory:** $OUTPUT_DIR

---

EOF
    
    log_success "Diagnostics initialized in $OUTPUT_DIR"
}

# Comprehensive pod information gathering
gather_pod_info() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Gathering comprehensive information for pod: $pod_name"
    
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    mkdir -p "$pod_dir"
    
    # Basic pod information
    kubectl get pod "$pod_name" -n "$namespace" -o wide > "$pod_dir/basic_info.txt" 2>&1
    kubectl get pod "$pod_name" -n "$namespace" -o yaml > "$pod_dir/manifest.yaml" 2>&1
    
    # Detailed description
    kubectl describe pod "$pod_name" -n "$namespace" > "$pod_dir/description.txt" 2>&1
    
    # Events related to the pod
    kubectl get events -n "$namespace" --field-selector involvedObject.name="$pod_name" \
        --sort-by='.lastTimestamp' > "$pod_dir/events.txt" 2>&1
    
    # Container logs
    local containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[*].name}' 2>/dev/null)
    for container in $containers; do
        log_debug "Collecting logs for container: $container"
        kubectl logs "$pod_name" -n "$namespace" -c "$container" > "$pod_dir/logs_${container}.txt" 2>&1
        
        # Previous logs if container restarted
        kubectl logs "$pod_name" -n "$namespace" -c "$container" --previous > "$pod_dir/logs_${container}_previous.txt" 2>&1 || true
    done
    
    # Resource usage
    kubectl top pod "$pod_name" -n "$namespace" > "$pod_dir/resource_usage.txt" 2>&1 || echo "Metrics not available" > "$pod_dir/resource_usage.txt"
    
    log_success "Pod information gathered for $pod_name"
}

# Automated problem detection
detect_common_issues() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Running automated issue detection for $pod_name..."
    
    local issues_file="$pod_dir/detected_issues.md"
    echo "# Automated Issue Detection Report" > "$issues_file"
    echo "**Pod:** $pod_name" >> "$issues_file"
    echo "**Analysis Time:** $(date)" >> "$issues_file"
    echo "" >> "$issues_file"
    
    local issue_count=0
    
    # Check 1: Pod phase issues
    local phase=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.phase}' 2>/dev/null)
    if [[ "$phase" != "Running" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Pod Not Running
- **Severity:** High
- **Status:** Pod is in '$phase' phase instead of 'Running'
- **Impact:** Application unavailable
- **Investigation:** Check pod events and container status

EOF
    fi
    
    # Check 2: Container readiness issues
    local ready_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[?(@.ready==true)]}' | jq '. | length' 2>/dev/null || echo "0")
    local total_containers=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers}' | jq '. | length' 2>/dev/null || echo "1")
    
    if [[ "$ready_containers" -lt "$total_containers" ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Container Readiness Problems
- **Severity:** High
- **Status:** Only $ready_containers of $total_containers containers are ready
- **Impact:** Traffic routing may be affected
- **Investigation:** Check readiness probes and container logs

EOF
    fi
    
    # Check 3: Excessive restarts
    local restarts=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
    if [[ "$restarts" -gt 5 ]]; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Excessive Container Restarts
- **Severity:** Medium
- **Status:** Container has restarted $restarts times
- **Impact:** Service instability and potential data loss
- **Investigation:** Check liveness probes, resource limits, and application logs

EOF
    fi
    
    # Check 4: Resource usage issues
    if kubectl top pod "$pod_name" -n "$namespace" >/dev/null 2>&1; then
        local cpu_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $2}' | sed 's/m$//')
        local memory_usage=$(kubectl top pod "$pod_name" -n "$namespace" --no-headers | awk '{print $3}' | sed 's/Mi$//')
        
        if [[ "$cpu_usage" -gt 800 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High CPU Usage
- **Severity:** Medium
- **Status:** CPU usage is ${cpu_usage}m (> 800m threshold)
- **Impact:** Performance degradation and potential throttling
- **Investigation:** Check for CPU-intensive processes and consider scaling

EOF
        fi
        
        if [[ "$memory_usage" -gt 512 ]]; then
            ((issue_count++))
            cat >> "$issues_file" <<EOF
## Issue $issue_count: High Memory Usage
- **Severity:** Medium  
- **Status:** Memory usage is ${memory_usage}Mi (> 512Mi threshold)
- **Impact:** Risk of OOM kills and service disruption
- **Investigation:** Check for memory leaks and optimize memory usage

EOF
        fi
    fi
    
    # Check 5: Image pull issues
    if grep -q "ImagePullBackOff\|ErrImagePull" "$pod_dir/description.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Image Pull Problems
- **Severity:** High
- **Status:** Unable to pull container image
- **Impact:** Pod cannot start
- **Investigation:** Check image name, registry access, and credentials

EOF
    fi
    
    # Check 6: Resource constraints
    if grep -q "Insufficient.*resources" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Resource Constraints
- **Severity:** High
- **Status:** Insufficient cluster resources for pod scheduling
- **Impact:** Pod cannot be scheduled
- **Investigation:** Check cluster capacity and node resources

EOF
    fi
    
    # Check 7: Network issues
    if grep -q "NetworkNotReady\|CNI.*error" "$pod_dir/events.txt" 2>/dev/null; then
        ((issue_count++))
        cat >> "$issues_file" <<EOF
## Issue $issue_count: Network Configuration Problems
- **Severity:** High
- **Status:** Network setup issues detected
- **Impact:** Pod networking may not function correctly
- **Investigation:** Check CNI configuration and network policies

EOF
    fi
    
    # Summary
    if [[ $issue_count -eq 0 ]]; then
        echo "## Summary: No Critical Issues Detected ‚úÖ" >> "$issues_file"
        echo "The automated analysis found no obvious problems with this pod." >> "$issues_file"
        log_success "No critical issues detected for $pod_name"
    else
        echo "## Summary: $issue_count Issue(s) Detected ‚ö†Ô∏è" >> "$issues_file"
        echo "Review the issues above and follow the investigation recommendations." >> "$issues_file"
        log_warn "$issue_count issue(s) detected for $pod_name"
    fi
    
    return $issue_count
}

# Generate recommendations
generate_recommendations() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    local pod_dir="$OUTPUT_DIR/pods/$pod_name"
    
    log_info "Generating recommendations for $pod_name..."
    
    local rec_file="$pod_dir/recommendations.md"
    echo "# Optimization Recommendations" > "$rec_file"
    echo "**Pod:** $pod_name" >> "$rec_file"
    echo "" >> "$rec_file"
    
    # Resource optimization recommendations
    echo "## Resource Optimization" >> "$rec_file"
    
    # Check current resource configuration
    local requests_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.memory}' 2>/dev/null || echo "not set")
    local requests_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.requests.cpu}' 2>/dev/null || echo "not set")
    local limits_mem=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.memory}' 2>/dev/null || echo "not set")
    local limits_cpu=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].resources.limits.cpu}' 2>/dev/null || echo "not set")
    
    cat >> "$rec_file" <<EOF
### Current Resource Configuration
- **Memory Request:** $requests_mem
- **CPU Request:** $requests_cpu  
- **Memory Limit:** $limits_mem
- **CPU Limit:** $limits_cpu

EOF
    
    # Security recommendations
    echo "## Security Hardening" >> "$rec_file"
    
    local security_context=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.securityContext}' 2>/dev/null)
    if [[ -z "$security_context" || "$security_context" == "null" ]]; then
        cat >> "$rec_file" <<EOF
### Security Context Improvements
- ‚úÖ **Add security context:** Configure runAsNonRoot, runAsUser, and fsGroup
- ‚úÖ **Drop capabilities:** Remove unnecessary Linux capabilities  
- ‚úÖ **Read-only root filesystem:** Set readOnlyRootFilesystem: true
- ‚úÖ **Prevent privilege escalation:** Set allowPrivilegeEscalation: false

EOF
    fi
    
    # Health check recommendations
    echo "## Health Check Optimization" >> "$rec_file"
    
    local has_liveness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].livenessProbe}' 2>/dev/null)
    local has_readiness=$(kubectl get pod "$pod_name" -n "$namespace" -o jsonpath='{.spec.containers[0].readinessProbe}' 2>/dev/null)
    
    if [[ -z "$has_liveness" || "$has_liveness" == "null" ]]; then
        echo "- ‚úÖ **Add liveness probe:** Implement health checking for automatic restart" >> "$rec_file"
    fi
    
    if [[ -z "$has_readiness" || "$has_readiness" == "null" ]]; then
        echo "- ‚úÖ **Add readiness probe:** Control traffic routing based on application readiness" >> "$rec_file"
    fi
    
    # Performance recommendations
    echo "" >> "$rec_file"
    echo "## Performance Optimization" >> "$rec_file"
    cat >> "$rec_file" <<EOF
- ‚úÖ **Use Alpine images:** Reduce image size and startup time
- ‚úÖ **Implement resource requests:** Help scheduler make better placement decisions
- ‚úÖ **Optimize health check frequency:** Balance responsiveness with overhead
- ‚úÖ **Use memory-backed volumes:** For temporary files and caches
- ‚úÖ **Configure DNS caching:** Reduce DNS lookup overhead

EOF
    
    log_success "Recommendations generated for $pod_name"
}

# Interactive diagnostic session
interactive_diagnostics() {
    local pod_name=$1
    local namespace=${2:-$NAMESPACE}
    
    log_info "Starting interactive diagnostics for $pod_name..."
    
    echo -e "${BOLD}Interactive Pod Diagnostics${NC}"
    echo "Pod: $pod_name"
    echo "Namespace: $namespace"
    echo ""
    
    while true; do
        echo -e "${CYAN}Available actions:${NC}"
        echo "1) Show pod status"
        echo "2) View recent events"
        echo "3) Check container logs"
        echo "4) Execute command in pod"
        echo "5) Port forward to pod"
        echo "6) Resource usage"
        echo "7) Run full diagnostic"
        echo "8) Generate recommendations"
        echo "q) Quit"
        echo ""
        
        read -p "Select action [1-8,q]: " choice
        
        case $choice in
            1)
                echo "=== Pod Status ==="
                kubectl get pod "$pod_name" -n "$namespace" -o wide
```